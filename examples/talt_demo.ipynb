{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8004983c",
   "metadata": {},
   "source": [
    "# Topology-Aware Learning Trajectory (TALT) Optimizer Demo\n",
    "\n",
    "This notebook demonstrates how to use the improved TALT optimizer for training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Ensure TALT is installed/available\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import talt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a71a359",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Let's set up our environment and parameters for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Experiment parameters\n",
    "dataset_name = 'cifar10'\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0f522",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "We'll use the CIFAR-10 dataset for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423973de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "with talt.Timer(\"Loading dataset\"):\n",
    "    train_loader, test_loader, num_channels, image_size, num_classes = talt.get_loaders(\n",
    "        dataset_name=dataset_name,\n",
    "        batch_size=batch_size,\n",
    "        data_dir='./data'\n",
    "    )\n",
    "\n",
    "# Show a few sample images\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    \n",
    "# Get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images using matplotlib instead of torchvision\n",
    "fig, axes = plt.subplots(1, 8, figsize=(16, 2))\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "for i in range(8):\n",
    "    img = images[i] / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    axes[i].imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    axes[i].set_title(classes[labels[i]])\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab6c311",
   "metadata": {},
   "source": [
    "## 3. Create Model\n",
    "\n",
    "We'll use a simple CNN model provided by the TALT package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = talt.SimpleCNN(\n",
    "    num_channels=num_channels,\n",
    "    image_size=image_size,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(\"Model architecture:\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21112b7f",
   "metadata": {},
   "source": [
    "## 4. Train with Standard SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265fb3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with standard SGD\n",
    "print(\"\\nTraining with standard SGD optimizer...\")\n",
    "sgd_results = talt.train_and_evaluate_improved(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    use_improved_talt=False,\n",
    "    device=device,\n",
    "    visualization_dir=\"./visualizations\",\n",
    "    experiment_name=\"SGD_Example\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b19893",
   "metadata": {},
   "source": [
    "## 5. Train with Improved TALT Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset model\n",
    "model = talt.SimpleCNN(\n",
    "    num_channels=num_channels,\n",
    "    image_size=image_size,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "\n",
    "# Train with improved TALT\n",
    "print(\"\\nTraining with improved TALT optimizer...\")\n",
    "talt_results = talt.train_and_evaluate_improved(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    use_improved_talt=True,\n",
    "    device=device,\n",
    "    projection_dim=32,\n",
    "    update_interval=20,\n",
    "    valley_strength=0.2,\n",
    "    smoothing_factor=0.3,\n",
    "    visualization_dir=\"./visualizations\",\n",
    "    experiment_name=\"TALT_Example\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e5296f",
   "metadata": {},
   "source": [
    "## 6. Compare Results\n",
    "\n",
    "Let's compare the performance of the standard SGD optimizer versus the improved TALT optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b87fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and test loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(sgd_results['train_loss'], label='SGD')\n",
    "plt.plot(talt_results['train_loss'], label='TALT')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot test accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(sgd_results['test_acc'], label='SGD')\n",
    "plt.plot(talt_results['test_acc'], label='TALT')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"SGD Test Accuracy: {sgd_results['final_test_acc']:.2f}% (Time: {sgd_results['total_time']:.2f}s)\")\n",
    "print(f\"TALT Test Accuracy: {talt_results['final_test_acc']:.2f}% (Time: {talt_results['total_time']:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b090d",
   "metadata": {},
   "source": [
    "## 7. View Visualizations\n",
    "\n",
    "The TALT package automatically generates visualizations. Let's take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visualizer and generate additional visualizations\n",
    "model_state_dict = model.state_dict()\n",
    "visualizer = talt.ImprovedTALTVisualizer(output_dir=\"./visualizations/custom\")\n",
    "\n",
    "# Generate some example visualizations\n",
    "os.makedirs(\"./visualizations/custom\", exist_ok=True)\n",
    "\n",
    "# You can add data from your optimizer here\n",
    "# visualizer.add_data(optimizer._visualization_data)\n",
    "\n",
    "# Display the loss visualization files\n",
    "sgd_viz_path = \"./visualizations/SGD_Example/loss_trajectory.png\"\n",
    "talt_viz_path = \"./visualizations/TALT_Example/loss_trajectory.png\"\n",
    "\n",
    "if os.path.exists(sgd_viz_path) and os.path.exists(talt_viz_path):\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    \n",
    "    # SGD\n",
    "    plt.subplot(1, 2, 1)\n",
    "    img = plt.imread(sgd_viz_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"SGD Loss Trajectory\")\n",
    "    \n",
    "    # TALT\n",
    "    plt.subplot(1, 2, 2)\n",
    "    img = plt.imread(talt_viz_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"TALT Loss Trajectory\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Visualization files not found. Please check if the training completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fd50bf",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to use the improved TALT optimizer and compared its performance with the standard SGD optimizer. The visualizations showed how TALT detects valleys in the loss landscape to accelerate convergence."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
