{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzIwSYTtERIrRXJK5udEbP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umairjavaid/Talt/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "glqtGzh7_Uh0",
        "outputId": "5b972d75-08ff-430c-f514-7644c6fcbfca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demonstrating enhanced adaptive landscape optimizer on MNIST...\n",
            "\n",
            "Epoch 1/3\n",
            "\n",
            "Training standard model:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard - Batch 0/469: Loss: 2.312919\n",
            "Standard - Batch 20/469: Loss: 2.283566\n",
            "Standard - Batch 40/469: Loss: 2.297691\n",
            "Standard - Batch 60/469: Loss: 2.270408\n",
            "Standard - Batch 80/469: Loss: 2.178622\n",
            "Standard - Batch 100/469: Loss: 2.124534\n",
            "Standard - Batch 120/469: Loss: 1.875776\n",
            "Standard - Batch 140/469: Loss: 1.861577\n",
            "Standard - Batch 160/469: Loss: 1.724311\n",
            "Standard - Batch 180/469: Loss: 1.524591\n",
            "Standard - Batch 200/469: Loss: 1.217411\n",
            "Standard - Batch 220/469: Loss: 1.152322\n",
            "Standard - Batch 240/469: Loss: 1.028770\n",
            "Standard - Batch 260/469: Loss: 1.042779\n",
            "Standard - Batch 280/469: Loss: 0.882860\n",
            "Standard - Batch 300/469: Loss: 0.904064\n",
            "Standard - Batch 320/469: Loss: 0.798910\n",
            "Standard - Batch 340/469: Loss: 0.686002\n",
            "Standard - Batch 360/469: Loss: 0.765180\n",
            "Standard - Batch 380/469: Loss: 0.829010\n",
            "Standard - Batch 400/469: Loss: 0.663580\n",
            "Standard - Batch 420/469: Loss: 0.803849\n",
            "Standard - Batch 440/469: Loss: 0.681837\n",
            "Standard - Batch 460/469: Loss: 0.667886\n",
            "\n",
            "Training enhanced adaptive landscape model:\n",
            "Enhanced - Batch 0/469: Loss: 2.313896\n",
            "Enhanced - Batch 20/469: Loss: 2.288986\n",
            "Enhanced - Batch 40/469: Loss: 2.255850\n",
            "Enhanced - Batch 60/469: Loss: 2.217534\n",
            "Enhanced - Batch 80/469: Loss: 2.161699\n",
            "Enhanced - Batch 100/469: Loss: 2.178129\n",
            "Enhanced - Batch 120/469: Loss: 2.054064\n",
            "Enhanced - Batch 140/469: Loss: 1.994039\n",
            "Enhanced - Batch 160/469: Loss: 2.004305\n",
            "Enhanced - Batch 180/469: Loss: 1.832861\n",
            "Enhanced - Batch 200/469: Loss: 1.707351\n",
            "Enhanced - Batch 220/469: Loss: 1.668503\n",
            "Enhanced - Batch 240/469: Loss: 1.376721\n",
            "Enhanced - Batch 260/469: Loss: 1.367697\n",
            "Enhanced - Batch 280/469: Loss: 1.192182\n",
            "Enhanced - Batch 300/469: Loss: 1.091067\n",
            "Enhanced - Batch 320/469: Loss: 1.215147\n",
            "Enhanced - Batch 340/469: Loss: 1.010765\n",
            "Enhanced - Batch 360/469: Loss: 1.002595\n",
            "Enhanced - Batch 380/469: Loss: 0.876616\n",
            "Enhanced - Batch 400/469: Loss: 0.945531\n",
            "Enhanced - Batch 420/469: Loss: 0.823991\n",
            "Enhanced - Batch 440/469: Loss: 1.016848\n",
            "Enhanced - Batch 460/469: Loss: 0.862250\n",
            "\n",
            "Testing standard model:\n",
            "Test set: Average loss: 0.3187, Accuracy: 9129/10000 (91.29%)\n",
            "\n",
            "Testing enhanced model:\n",
            "Test set: Average loss: 0.4176, Accuracy: 8924/10000 (89.24%)\n",
            "\n",
            "Epoch 2/3\n",
            "\n",
            "Training standard model:\n",
            "Standard - Batch 0/469: Loss: 0.626479\n",
            "Standard - Batch 20/469: Loss: 0.556441\n",
            "Standard - Batch 40/469: Loss: 0.839266\n",
            "Standard - Batch 60/469: Loss: 0.753186\n",
            "Standard - Batch 80/469: Loss: 0.562540\n",
            "Standard - Batch 100/469: Loss: 0.597734\n",
            "Standard - Batch 120/469: Loss: 0.709563\n",
            "Standard - Batch 140/469: Loss: 0.681270\n",
            "Standard - Batch 160/469: Loss: 0.473180\n",
            "Standard - Batch 180/469: Loss: 0.611491\n",
            "Standard - Batch 200/469: Loss: 0.543994\n",
            "Standard - Batch 220/469: Loss: 0.507529\n",
            "Standard - Batch 240/469: Loss: 0.352894\n",
            "Standard - Batch 260/469: Loss: 0.465028\n",
            "Standard - Batch 280/469: Loss: 0.549027\n",
            "Standard - Batch 300/469: Loss: 0.503831\n",
            "Standard - Batch 320/469: Loss: 0.513290\n",
            "Standard - Batch 340/469: Loss: 0.381234\n",
            "Standard - Batch 360/469: Loss: 0.635346\n",
            "Standard - Batch 380/469: Loss: 0.631272\n",
            "Standard - Batch 400/469: Loss: 0.486567\n",
            "Standard - Batch 420/469: Loss: 0.481751\n",
            "Standard - Batch 440/469: Loss: 0.475650\n",
            "Standard - Batch 460/469: Loss: 0.512994\n",
            "\n",
            "Training enhanced adaptive landscape model:\n",
            "Enhanced - Batch 0/469: Loss: 0.904278\n",
            "Enhanced - Batch 20/469: Loss: 0.734437\n",
            "Enhanced - Batch 40/469: Loss: 0.782682\n",
            "Enhanced - Batch 60/469: Loss: 0.746761\n",
            "Enhanced - Batch 80/469: Loss: 0.838582\n",
            "Enhanced - Batch 100/469: Loss: 0.583818\n",
            "Enhanced - Batch 120/469: Loss: 0.831041\n",
            "Enhanced - Batch 140/469: Loss: 0.750000\n",
            "Enhanced - Batch 160/469: Loss: 0.657843\n",
            "Enhanced - Batch 180/469: Loss: 0.491585\n",
            "Enhanced - Batch 200/469: Loss: 0.711968\n",
            "Enhanced - Batch 220/469: Loss: 0.594568\n",
            "Enhanced - Batch 240/469: Loss: 0.564006\n",
            "Enhanced - Batch 260/469: Loss: 0.480111\n",
            "Enhanced - Batch 280/469: Loss: 0.667078\n",
            "Enhanced - Batch 300/469: Loss: 0.597347\n",
            "Enhanced - Batch 320/469: Loss: 0.408483\n",
            "Enhanced - Batch 340/469: Loss: 0.641387\n",
            "Enhanced - Batch 360/469: Loss: 0.496085\n",
            "Enhanced - Batch 380/469: Loss: 0.481833\n",
            "Enhanced - Batch 400/469: Loss: 0.552280\n",
            "Enhanced - Batch 420/469: Loss: 0.377252\n",
            "Enhanced - Batch 440/469: Loss: 0.626026\n",
            "Enhanced - Batch 460/469: Loss: 0.314730\n",
            "\n",
            "Testing standard model:\n",
            "Test set: Average loss: 0.1904, Accuracy: 9431/10000 (94.31%)\n",
            "\n",
            "Testing enhanced model:\n",
            "Test set: Average loss: 0.2065, Accuracy: 9421/10000 (94.21%)\n",
            "\n",
            "Epoch 3/3\n",
            "\n",
            "Training standard model:\n",
            "Standard - Batch 0/469: Loss: 0.423250\n",
            "Standard - Batch 20/469: Loss: 0.428717\n",
            "Standard - Batch 40/469: Loss: 0.457001\n",
            "Standard - Batch 60/469: Loss: 0.360120\n",
            "Standard - Batch 80/469: Loss: 0.669381\n",
            "Standard - Batch 100/469: Loss: 0.376454\n",
            "Standard - Batch 120/469: Loss: 0.384953\n",
            "Standard - Batch 140/469: Loss: 0.483386\n",
            "Standard - Batch 160/469: Loss: 0.320539\n",
            "Standard - Batch 180/469: Loss: 0.475009\n",
            "Standard - Batch 200/469: Loss: 0.346677\n",
            "Standard - Batch 220/469: Loss: 0.328639\n",
            "Standard - Batch 240/469: Loss: 0.263377\n",
            "Standard - Batch 260/469: Loss: 0.443928\n",
            "Standard - Batch 280/469: Loss: 0.387139\n",
            "Standard - Batch 300/469: Loss: 0.414715\n",
            "Standard - Batch 320/469: Loss: 0.289766\n",
            "Standard - Batch 340/469: Loss: 0.419521\n",
            "Standard - Batch 360/469: Loss: 0.415577\n",
            "Standard - Batch 380/469: Loss: 0.435252\n",
            "Standard - Batch 400/469: Loss: 0.322876\n",
            "Standard - Batch 420/469: Loss: 0.352979\n",
            "Standard - Batch 440/469: Loss: 0.299701\n",
            "Standard - Batch 460/469: Loss: 0.472478\n",
            "\n",
            "Training enhanced adaptive landscape model:\n",
            "Enhanced - Batch 0/469: Loss: 0.625289\n",
            "Enhanced - Batch 20/469: Loss: 0.504474\n",
            "Enhanced - Batch 40/469: Loss: 0.437537\n",
            "Enhanced - Batch 60/469: Loss: 0.447607\n",
            "Enhanced - Batch 80/469: Loss: 0.476518\n",
            "Enhanced - Batch 100/469: Loss: 0.378138\n",
            "Enhanced - Batch 120/469: Loss: 0.425700\n",
            "Enhanced - Batch 140/469: Loss: 0.292563\n",
            "Enhanced - Batch 160/469: Loss: 0.478704\n",
            "Enhanced - Batch 180/469: Loss: 0.281567\n",
            "Enhanced - Batch 200/469: Loss: 0.447458\n",
            "Enhanced - Batch 220/469: Loss: 0.391174\n",
            "Enhanced - Batch 240/469: Loss: 0.474363\n",
            "Enhanced - Batch 260/469: Loss: 0.350462\n",
            "Enhanced - Batch 280/469: Loss: 0.360007\n",
            "Enhanced - Batch 300/469: Loss: 0.313799\n",
            "Enhanced - Batch 320/469: Loss: 0.443452\n",
            "Enhanced - Batch 340/469: Loss: 0.413465\n",
            "Enhanced - Batch 360/469: Loss: 0.356124\n",
            "Enhanced - Batch 380/469: Loss: 0.313989\n",
            "Enhanced - Batch 400/469: Loss: 0.444966\n",
            "Enhanced - Batch 420/469: Loss: 0.297853\n",
            "Enhanced - Batch 440/469: Loss: 0.517590\n",
            "Enhanced - Batch 460/469: Loss: 0.440702\n",
            "\n",
            "Testing standard model:\n",
            "Test set: Average loss: 0.1451, Accuracy: 9548/10000 (95.48%)\n",
            "\n",
            "Testing enhanced model:\n",
            "Test set: Average loss: 0.1553, Accuracy: 9539/10000 (95.39%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class EnhancedAdaptiveLandscapeOptimizer:\n",
        "    \"\"\"\n",
        "    An improved optimizer that modifies the loss landscape based on the optimization trajectory\n",
        "    with additional safeguards and more conservative modifications.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, base_optimizer, lr=0.01,\n",
        "                 path_enhancement_strength=0.1,  # Controls how much we enhance successful directions\n",
        "                 spectral_damping=0.05,          # More conservative dampening\n",
        "                 memory_size=20,                 # Larger memory\n",
        "                 adaptation_interval=5,\n",
        "                 warmup_steps=100):              # Gradually introduce modifications\n",
        "\n",
        "        self.model = model\n",
        "        self.optimizer = base_optimizer(model.parameters(), lr=lr)\n",
        "        self.path_enhancement_strength = path_enhancement_strength\n",
        "        self.spectral_damping = spectral_damping\n",
        "        self.memory_size = memory_size\n",
        "        self.adaptation_interval = adaptation_interval\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "        # Memory for trajectory history\n",
        "        self.gradient_memory = deque(maxlen=memory_size)\n",
        "        self.param_memory = deque(maxlen=memory_size)\n",
        "        self.loss_memory = deque(maxlen=memory_size)\n",
        "\n",
        "        # Landscape modification components\n",
        "        self.path_enhancement = None\n",
        "        self.spectral_reshape_matrices = {}\n",
        "\n",
        "        # Initialize hooks for gradient modifications\n",
        "        self.hooks = []\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                hook = param.register_hook(\n",
        "                    lambda grad, name=name: self._modify_gradient(grad, name)\n",
        "                )\n",
        "                self.hooks.append(hook)\n",
        "                self.spectral_reshape_matrices[name] = None\n",
        "\n",
        "        # Statistics\n",
        "        self.steps = 0\n",
        "        self.loss_history = []\n",
        "\n",
        "        # Debug tracking\n",
        "        self.gradient_norms_before = {}\n",
        "        self.gradient_norms_after = {}\n",
        "\n",
        "    def _modify_gradient(self, gradient, param_name):\n",
        "        \"\"\"\n",
        "        Modify gradients with safeguards to ensure stability.\n",
        "        \"\"\"\n",
        "        original_gradient = gradient.clone()\n",
        "\n",
        "        # Record original gradient norm for debugging\n",
        "        if param_name not in self.gradient_norms_before:\n",
        "            self.gradient_norms_before[param_name] = []\n",
        "        self.gradient_norms_before[param_name].append(torch.norm(original_gradient).item())\n",
        "\n",
        "        # Apply warmup - gradually introduce modifications\n",
        "        warmup_factor = min(1.0, self.steps / self.warmup_steps)\n",
        "\n",
        "        # Apply path enhancement (preferred directions based on history)\n",
        "        if self.path_enhancement is not None:\n",
        "            for direction, improvement in self.path_enhancement:\n",
        "                if param_name in direction:\n",
        "                    # Project gradient onto successful historical directions\n",
        "                    norm_dir = torch.norm(direction[param_name])\n",
        "                    if norm_dir > 1e-10:  # Avoid division by zero\n",
        "                        proj = torch.sum(gradient * direction[param_name]) / (norm_dir ** 2)\n",
        "                        # Apply with warmup and safety scaling\n",
        "                        enhancement = self.path_enhancement_strength * improvement * warmup_factor\n",
        "                        gradient = gradient + enhancement * proj * direction[param_name]\n",
        "\n",
        "        # Apply spectral reshaping with extreme caution\n",
        "        if self.spectral_reshape_matrices.get(param_name) is not None and self.steps > self.warmup_steps:\n",
        "            try:\n",
        "                # Use diagonal-only reshaping for stability\n",
        "                diag_values = torch.diag(self.spectral_reshape_matrices[param_name])\n",
        "                # Apply clipping to diagonal values\n",
        "                diag_values = torch.clamp(diag_values, min=0.5, max=2.0)\n",
        "                # Element-wise multiply by diagonal instead of matrix multiply\n",
        "                flat_grad = gradient.flatten()\n",
        "                reshaped_grad = flat_grad * diag_values\n",
        "                gradient = reshaped_grad.reshape(gradient.shape)\n",
        "            except Exception as e:\n",
        "                print(f\"Error in spectral reshaping: {e}\")\n",
        "                # Fall back to original gradient\n",
        "                gradient = original_gradient\n",
        "\n",
        "        # Safety: ensure gradient doesn't explode by comparing with original\n",
        "        grad_norm_ratio = torch.norm(gradient) / (torch.norm(original_gradient) + 1e-10)\n",
        "        if grad_norm_ratio > 3.0 or torch.isnan(gradient).any():\n",
        "            print(f\"Warning: Gradient scaling too large ({grad_norm_ratio:.2f}) or contains NaN. Using original gradient.\")\n",
        "            gradient = original_gradient\n",
        "\n",
        "        # Record modified gradient norm for debugging\n",
        "        if param_name not in self.gradient_norms_after:\n",
        "            self.gradient_norms_after[param_name] = []\n",
        "        self.gradient_norms_after[param_name].append(torch.norm(gradient).item())\n",
        "\n",
        "        return gradient\n",
        "\n",
        "    def step(self, loss_fn, inputs, targets):\n",
        "        \"\"\"\n",
        "        Perform an optimization step with landscape adaptation.\n",
        "        \"\"\"\n",
        "        # Regular optimization step\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        # Capture current state before optimizer step\n",
        "        current_params = {}\n",
        "        current_grads = {}\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                current_params[name] = param.data.clone()\n",
        "                current_grads[name] = param.grad.clone() if param.grad is not None else None\n",
        "\n",
        "        # Perform the optimization step\n",
        "        self.optimizer.step()\n",
        "        self.steps += 1\n",
        "        loss_value = loss.item()\n",
        "        self.loss_history.append(loss_value)\n",
        "\n",
        "        # Store the trajectory information\n",
        "        self.gradient_memory.append(current_grads)\n",
        "        self.param_memory.append(current_params)\n",
        "        self.loss_memory.append(loss_value)\n",
        "\n",
        "        # Adapt the landscape periodically after collecting enough history\n",
        "        if (self.steps % self.adaptation_interval == 0 and\n",
        "            len(self.loss_memory) > 1 and\n",
        "            self.steps >= 10):  # Make sure we have enough data\n",
        "            self._adapt_landscape()\n",
        "\n",
        "        return loss_value, outputs\n",
        "\n",
        "    def _adapt_landscape(self):\n",
        "        \"\"\"\n",
        "        Adapt the loss landscape with improved safeguards.\n",
        "        \"\"\"\n",
        "        # Only update path enhancement in the early stages\n",
        "        if len(self.gradient_memory) > 3:\n",
        "            self._update_path_enhancement()\n",
        "\n",
        "        # More cautiously update spectral reshaping after collecting enough history\n",
        "        if len(self.param_memory) > 10 and self.steps > self.warmup_steps / 2:\n",
        "            self._update_spectral_reshaping()\n",
        "\n",
        "    def _update_path_enhancement(self):\n",
        "        \"\"\"\n",
        "        Identify and enhance promising gradient directions with improved filtering.\n",
        "        \"\"\"\n",
        "        successful_directions = []\n",
        "\n",
        "        # Compare pairs of consecutive steps with improved criteria\n",
        "        window_size = min(5, len(self.loss_memory)-1)\n",
        "        for i in range(len(self.loss_memory) - window_size):\n",
        "            current_loss = self.loss_memory[i]\n",
        "            future_loss = self.loss_memory[i + window_size]\n",
        "\n",
        "            # Ensure substantial improvement to filter noise\n",
        "            if current_loss > future_loss and (current_loss - future_loss) / current_loss > 0.01:\n",
        "                direction = {}\n",
        "                for name, grad in self.gradient_memory[i].items():\n",
        "                    if grad is not None:\n",
        "                        # Store the negative gradient as a successful direction\n",
        "                        direction[name] = -grad / (torch.norm(grad) + 1e-10)\n",
        "\n",
        "                # Calculate how successful this direction was\n",
        "                improvement = (current_loss - future_loss) / current_loss\n",
        "                successful_directions.append((direction, improvement))\n",
        "\n",
        "        # Sort by improvement and keep the top directions\n",
        "        successful_directions.sort(key=lambda x: x[1], reverse=True)\n",
        "        successful_directions = successful_directions[:2]  # More conservative, keep fewer directions\n",
        "\n",
        "        if successful_directions:\n",
        "            self.path_enhancement = successful_directions\n",
        "\n",
        "    def _update_spectral_reshaping(self):\n",
        "        \"\"\"\n",
        "        Reshape the landscape with improved stability safeguards.\n",
        "        \"\"\"\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and param.grad is not None:\n",
        "                try:\n",
        "                    # Choose temporally separated gradients for better estimation\n",
        "                    idx1 = len(self.gradient_memory) - 1\n",
        "                    idx2 = max(0, len(self.gradient_memory) - 5)  # Look further back for stability\n",
        "\n",
        "                    current_grad = self.gradient_memory[idx1][name]\n",
        "                    prev_grad = self.gradient_memory[idx2][name]\n",
        "\n",
        "                    current_param = self.param_memory[idx1][name]\n",
        "                    prev_param = self.param_memory[idx2][name]\n",
        "\n",
        "                    if current_grad is not None and prev_grad is not None:\n",
        "                        grad_diff = current_grad - prev_grad\n",
        "                        param_diff = current_param - prev_param\n",
        "\n",
        "                        # Avoid division by zero with improved check\n",
        "                        param_norm = torch.norm(param_diff)\n",
        "                        if param_norm > 1e-6:  # Stricter threshold\n",
        "                            # Compute preconditioner with robust estimation\n",
        "                            # Instead of element-wise division, use a smoother approach\n",
        "                            hessian_approx = torch.abs(grad_diff) / (param_norm + 1e-6)\n",
        "\n",
        "                            # Conservative rescaling to form preconditioner\n",
        "                            # Values > 1 flatten the landscape, values < 1 steepen it\n",
        "                            diag = 1.0 / (torch.clamp(hessian_approx.flatten(), min=0.5, max=2.0) + 1e-6)\n",
        "\n",
        "                            # Stability: clamp diagonal values to reasonable range\n",
        "                            diag = torch.clamp(diag, min=0.5, max=2.0)\n",
        "\n",
        "                            # Create diagonal matrix for preconditioning\n",
        "                            reshape_matrix = torch.diag(diag)\n",
        "\n",
        "                            # Gradually update the reshape matrix\n",
        "                            if self.spectral_reshape_matrices[name] is None:\n",
        "                                self.spectral_reshape_matrices[name] = reshape_matrix\n",
        "                            else:\n",
        "                                # Very conservative update\n",
        "                                current = self.spectral_reshape_matrices[name]\n",
        "                                dampening = self.spectral_damping * min(1.0, self.steps / self.warmup_steps)\n",
        "                                self.spectral_reshape_matrices[name] = (\n",
        "                                    (1 - dampening) * current + dampening * reshape_matrix\n",
        "                                )\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in spectral reshaping for {name}: {e}\")\n",
        "                    # Don't update this parameter's reshaping matrix\n",
        "                    pass\n",
        "\n",
        "    def plot_loss_history(self):\n",
        "        \"\"\"Plot the loss history to visualize optimization progress.\"\"\"\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(self.loss_history)\n",
        "        plt.xlabel('Steps')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_gradient_modifications(self):\n",
        "        \"\"\"Plot how gradients are being modified.\"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        for i, name in enumerate(list(self.gradient_norms_before.keys())[:4]):  # Show first 4 params\n",
        "            if len(self.gradient_norms_before[name]) > 0:\n",
        "                plt.subplot(2, 2, i+1)\n",
        "                steps = range(len(self.gradient_norms_before[name]))\n",
        "                plt.plot(steps, self.gradient_norms_before[name], label='Before')\n",
        "                plt.plot(steps, self.gradient_norms_after[name], label='After')\n",
        "                plt.title(f'Param: {name[:10]}...')\n",
        "                plt.xlabel('Step')\n",
        "                plt.ylabel('Gradient Norm')\n",
        "                plt.legend()\n",
        "                plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Example with a more realistic neural network\n",
        "def train_mnist_with_enhanced_optimizer():\n",
        "    # Set up data loaders\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    # Load MNIST dataset (or use a small synthetic dataset if MNIST is not available)\n",
        "    try:\n",
        "        train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "        test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=1000)\n",
        "    except:\n",
        "        # Fallback to synthetic data if MNIST download fails\n",
        "        print(\"Using synthetic data instead of MNIST\")\n",
        "\n",
        "        # Create synthetic data\n",
        "        n_samples = 1000\n",
        "        input_dim = 784  # 28x28\n",
        "        n_classes = 10\n",
        "\n",
        "        # Random inputs\n",
        "        X = torch.randn(n_samples, 1, 28, 28)\n",
        "        # Random labels\n",
        "        y = torch.randint(0, n_classes, (n_samples,))\n",
        "\n",
        "        # Create simple DataLoader\n",
        "        train_dataset = TensorDataset(X, y)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "        test_loader = train_loader  # Use the same data for testing in this synthetic case\n",
        "\n",
        "    # Define a simple CNN\n",
        "    class SimpleCNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(SimpleCNN, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "            self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "            self.fc1 = nn.Linear(320, 50)\n",
        "            self.fc2 = nn.Linear(50, 10)\n",
        "            self.relu = nn.ReLU()\n",
        "            self.max_pool = nn.MaxPool2d(2)\n",
        "            self.dropout = nn.Dropout2d(0.5)\n",
        "            self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.relu(self.max_pool(self.conv1(x)))\n",
        "            x = self.relu(self.max_pool(self.dropout(self.conv2(x))))\n",
        "            x = x.view(-1, 320)\n",
        "            x = self.relu(self.fc1(x))\n",
        "            x = self.dropout(x)\n",
        "            x = self.fc2(x)\n",
        "            return self.log_softmax(x)\n",
        "\n",
        "    # Create models for comparison\n",
        "    standard_model = SimpleCNN()\n",
        "    enhanced_model = SimpleCNN()\n",
        "\n",
        "    # Loss function\n",
        "    loss_fn = nn.NLLLoss()\n",
        "\n",
        "    # Standard optimizer\n",
        "    standard_optimizer = optim.SGD(standard_model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "    # Enhanced optimizer with more conservative settings\n",
        "    enhanced_optimizer = EnhancedAdaptiveLandscapeOptimizer(\n",
        "        enhanced_model,\n",
        "        base_optimizer=optim.SGD,\n",
        "        lr=0.01,\n",
        "        path_enhancement_strength=0.05,  # Very conservative\n",
        "        spectral_damping=0.01,           # Very slow adaptation\n",
        "        memory_size=30,                  # Larger memory\n",
        "        adaptation_interval=10,          # Less frequent adaptation\n",
        "        warmup_steps=200                 # Longer warmup period\n",
        "    )\n",
        "\n",
        "    # Training function\n",
        "    def train_epoch(model, optimizer, data_loader, is_adaptive=False):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(data_loader):\n",
        "            if not is_adaptive:\n",
        "                # Standard approach\n",
        "                optimizer.zero_grad()\n",
        "                output = model(data)\n",
        "                loss = loss_fn(output, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            else:\n",
        "                # Enhanced approach\n",
        "                loss, output = enhanced_optimizer.step(loss_fn, data, target)\n",
        "\n",
        "            # Use the appropriate output for accuracy\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            # Add the scalar loss value\n",
        "            if isinstance(loss, torch.Tensor):\n",
        "                total_loss += loss.item()\n",
        "            else:\n",
        "                total_loss += loss\n",
        "\n",
        "            if batch_idx % 20 == 0:\n",
        "                print(f\"{'Enhanced' if is_adaptive else 'Standard'} - \"\n",
        "                      f\"Batch {batch_idx}/{len(data_loader)}: Loss: {loss:.6f}\")\n",
        "\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        accuracy = 100. * correct / len(data_loader.dataset)\n",
        "        return avg_loss, accuracy\n",
        "\n",
        "    # Test function\n",
        "    def test(model, data_loader):\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in data_loader:\n",
        "                output = model(data)\n",
        "                test_loss += loss_fn(output, target).item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(data_loader)\n",
        "        accuracy = 100. * correct / len(data_loader.dataset)\n",
        "\n",
        "        print(f\"Test set: Average loss: {test_loss:.4f}, \"\n",
        "              f\"Accuracy: {correct}/{len(data_loader.dataset)} ({accuracy:.2f}%)\")\n",
        "\n",
        "        return test_loss, accuracy\n",
        "\n",
        "    # Train for a few epochs\n",
        "    n_epochs = 3\n",
        "    results = {\n",
        "        'standard': {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []},\n",
        "        'enhanced': {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
        "    }\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
        "\n",
        "        # Train standard model\n",
        "        print(\"\\nTraining standard model:\")\n",
        "        loss, acc = train_epoch(standard_model, standard_optimizer, train_loader)\n",
        "        results['standard']['train_loss'].append(loss)\n",
        "        results['standard']['train_acc'].append(acc)\n",
        "\n",
        "        # Train enhanced model\n",
        "        print(\"\\nTraining enhanced adaptive landscape model:\")\n",
        "        loss, acc = train_epoch(enhanced_model, None, train_loader, is_adaptive=True)\n",
        "        results['enhanced']['train_loss'].append(loss)\n",
        "        results['enhanced']['train_acc'].append(acc)\n",
        "\n",
        "        # Test both models\n",
        "        print(\"\\nTesting standard model:\")\n",
        "        loss, acc = test(standard_model, test_loader)\n",
        "        results['standard']['test_loss'].append(loss)\n",
        "        results['standard']['test_acc'].append(acc)\n",
        "\n",
        "        print(\"\\nTesting enhanced model:\")\n",
        "        loss, acc = test(enhanced_model, test_loader)\n",
        "        results['enhanced']['test_loss'].append(loss)\n",
        "        results['enhanced']['test_acc'].append(acc)\n",
        "\n",
        "    # Plot results\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(results['standard']['train_loss'], label='Standard')\n",
        "    plt.plot(results['enhanced']['train_loss'], label='Enhanced')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Training Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(results['standard']['test_loss'], label='Standard')\n",
        "    plt.plot(results['enhanced']['test_loss'], label='Enhanced')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Test Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(results['standard']['train_acc'], label='Standard')\n",
        "    plt.plot(results['enhanced']['train_acc'], label='Enhanced')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Training Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(results['standard']['test_acc'], label='Standard')\n",
        "    plt.plot(results['enhanced']['test_acc'], label='Enhanced')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Test Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot gradient modifications\n",
        "    enhanced_optimizer.plot_gradient_modifications()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run the enhanced example\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Demonstrating enhanced adaptive landscape optimizer on MNIST...\")\n",
        "    results = train_mnist_with_enhanced_optimizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class FastTopologyTransformer:\n",
        "    \"\"\"\n",
        "    GPU-optimized version of Topology-Aware Landscape Transformer\n",
        "    \"\"\"\n",
        "    def __init__(self, model, base_optimizer, lr=0.01,\n",
        "                 topology_update_interval=50,  # Only update topology occasionally\n",
        "                 eigenspace_memory_size=10,    # Smaller memory for efficiency\n",
        "                 valley_strength=0.1,\n",
        "                 smoothing_factor=0.3):\n",
        "\n",
        "        self.model = model\n",
        "        self.optimizer = base_optimizer(model.parameters(), lr=lr)\n",
        "        self.update_interval = topology_update_interval\n",
        "        self.memory_size = eigenspace_memory_size\n",
        "        self.valley_strength = valley_strength\n",
        "        self.smoothing_factor = smoothing_factor\n",
        "\n",
        "        # Gradient memory (store fewer samples for better performance)\n",
        "        self.grad_memory = {}\n",
        "        self.principal_dirs = {}\n",
        "        self.eigenvalues = {}\n",
        "\n",
        "        # Statistics\n",
        "        self.steps = 0\n",
        "        self.loss_history = []\n",
        "        self.eig_history = {}\n",
        "        self.bifurcations = []\n",
        "\n",
        "        # Register hooks for all parameters and initialize data structures\n",
        "        self.hooks = []\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad and param.grad is not None and param.numel() > 10:\n",
        "                hook = param.register_hook(\n",
        "                    lambda grad, name=name: self._transform_gradient(grad, name)\n",
        "                )\n",
        "                self.hooks.append(hook)\n",
        "                self.grad_memory[name] = deque(maxlen=self.memory_size)\n",
        "                self.principal_dirs[name] = None\n",
        "                self.eigenvalues[name] = None\n",
        "                self.eig_history[name] = []\n",
        "\n",
        "    def _transform_gradient(self, gradient, param_name):\n",
        "        \"\"\"\n",
        "        Transform gradients based on topology awareness - optimized for GPU\n",
        "        \"\"\"\n",
        "        # Skip small parameters or those without history\n",
        "        if param_name not in self.grad_memory or gradient.numel() < 10:\n",
        "            return gradient\n",
        "\n",
        "        # Get original gradient\n",
        "        original_grad = gradient.clone()\n",
        "\n",
        "        # Only apply transformation if we have topology information\n",
        "        if self.principal_dirs[param_name] is not None and self.eigenvalues[param_name] is not None:\n",
        "            try:\n",
        "                # Keep operations on GPU\n",
        "                device = gradient.device\n",
        "                flat_grad = gradient.view(-1)\n",
        "\n",
        "                eigenvectors = self.principal_dirs[param_name].to(device)\n",
        "                eigenvalues = self.eigenvalues[param_name].to(device)\n",
        "\n",
        "                # Project onto eigenspace\n",
        "                proj_coeffs = torch.matmul(flat_grad, eigenvectors)\n",
        "\n",
        "                # Apply topological transformations\n",
        "                # 1. Valley creation in saddle directions\n",
        "                near_zero_eigs = torch.abs(eigenvalues) < 0.05\n",
        "                if near_zero_eigs.any():\n",
        "                    # Record bifurcation\n",
        "                    self.bifurcations.append(self.steps)\n",
        "\n",
        "                    # Create valleys by enhancing gradients in saddle directions\n",
        "                    for i in range(len(eigenvalues)):\n",
        "                        if near_zero_eigs[i]:\n",
        "                            # Amplify gradient in this direction to create valley\n",
        "                            proj_coeffs[i] *= (1.0 + self.valley_strength)\n",
        "\n",
        "                # 2. Curvature-aware smoothing\n",
        "                for i in range(len(eigenvalues)):\n",
        "                    # For high-curvature directions (steep regions)\n",
        "                    if torch.abs(eigenvalues[i]) > 1.0:\n",
        "                        # Apply smoother scaling based on curvature\n",
        "                        scaling = 1.0 / torch.sqrt(torch.abs(eigenvalues[i]))\n",
        "                        proj_coeffs[i] *= scaling * self.smoothing_factor\n",
        "                    # For low-curvature directions (flat regions)\n",
        "                    elif torch.abs(eigenvalues[i]) < 0.5:\n",
        "                        # Enhance gradients to escape plateaus\n",
        "                        proj_coeffs[i] *= (1.0 + (1.0 - torch.abs(eigenvalues[i])))\n",
        "\n",
        "                # Reconstruct gradient in original space\n",
        "                flat_transformed = torch.matmul(proj_coeffs, eigenvectors.t())\n",
        "                gradient = flat_transformed.view(gradient.shape)\n",
        "\n",
        "                # Safety: blend with original if direction changed too much\n",
        "                cos_sim = torch.nn.functional.cosine_similarity(\n",
        "                    gradient.view(-1), original_grad.view(-1), dim=0)\n",
        "                if cos_sim < 0.7:  # More aggressive blending\n",
        "                    blend = 0.7 - cos_sim\n",
        "                    gradient = (1 - blend) * gradient + blend * original_grad\n",
        "\n",
        "            except Exception as e:\n",
        "                # Fall back to original gradient on any error\n",
        "                return original_grad\n",
        "\n",
        "        # Final safety check\n",
        "        if torch.isnan(gradient).any() or torch.isinf(gradient).any():\n",
        "            return original_grad\n",
        "\n",
        "        return gradient\n",
        "\n",
        "    def step(self, loss_fn, inputs, targets):\n",
        "        \"\"\"\n",
        "        Perform optimization step with topology awareness\n",
        "        \"\"\"\n",
        "        # Standard forward and backward pass\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        # Store gradient before optimization step\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad and param.grad is not None and name in self.grad_memory:\n",
        "                self.grad_memory[name].append(param.grad.data.clone().view(-1))\n",
        "\n",
        "        # Apply optimizer step (with transformed gradients via hooks)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Update step count and loss history\n",
        "        self.steps += 1\n",
        "        loss_value = loss.item()\n",
        "        self.loss_history.append(loss_value)\n",
        "\n",
        "        # Periodically update topology information (not every step)\n",
        "        if self.steps % self.update_interval == 0:\n",
        "            self._update_topology()\n",
        "\n",
        "        return loss_value, outputs\n",
        "\n",
        "    def _update_topology(self):\n",
        "        \"\"\"\n",
        "        Update topology information - done periodically for efficiency\n",
        "        \"\"\"\n",
        "        for name, grads in self.grad_memory.items():\n",
        "            # Skip if we don't have enough gradient history\n",
        "            if len(grads) < 5:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Stack recent gradients (keeping on GPU if possible)\n",
        "                device = grads[0].device\n",
        "                stacked_grads = torch.stack(list(grads)).to(device)\n",
        "\n",
        "                # Center gradients\n",
        "                grad_mean = torch.mean(stacked_grads, dim=0)\n",
        "                centered = stacked_grads - grad_mean\n",
        "\n",
        "                # Efficient batch matrix multiplication for covariance\n",
        "                # Using batched operations for better GPU utilization\n",
        "                cov = torch.matmul(centered.t(), centered)\n",
        "\n",
        "                # Ensure symmetry\n",
        "                cov = 0.5 * (cov + cov.t())\n",
        "\n",
        "                # Add small regularization for stability\n",
        "                cov += torch.eye(cov.shape[0], device=device) * 1e-6\n",
        "\n",
        "                # Compute eigendecomposition directly on GPU if possible\n",
        "                try:\n",
        "                    # Try GPU eigendecomposition\n",
        "                    eigenvalues, eigenvectors = torch.linalg.eigh(cov)\n",
        "\n",
        "                    # Sort eigenvalues (descending by absolute value)\n",
        "                    idx = torch.argsort(-torch.abs(eigenvalues))\n",
        "                    eigenvalues = eigenvalues[idx]\n",
        "                    eigenvectors = eigenvectors[:, idx]\n",
        "\n",
        "                except RuntimeError:\n",
        "                    # Fall back to CPU computation if GPU fails\n",
        "                    cpu_cov = cov.cpu()\n",
        "                    eigenvalues, eigenvectors = torch.linalg.eigh(cpu_cov)\n",
        "\n",
        "                    # Sort eigenvalues\n",
        "                    idx = torch.argsort(-torch.abs(eigenvalues))\n",
        "                    eigenvalues = eigenvalues[idx]\n",
        "                    eigenvectors = eigenvectors[:, idx]\n",
        "\n",
        "                # Keep only top eigenvalues/vectors for efficiency\n",
        "                max_dims = min(10, eigenvalues.shape[0])\n",
        "                eigenvalues = eigenvalues[:max_dims]\n",
        "                eigenvectors = eigenvectors[:, :max_dims]\n",
        "\n",
        "                # Update topology information\n",
        "                self.principal_dirs[name] = eigenvectors\n",
        "                self.eigenvalues[name] = eigenvalues\n",
        "\n",
        "                # Store for visualization\n",
        "                if len(eigenvalues) > 0:\n",
        "                    top_n = min(3, len(eigenvalues))\n",
        "                    self.eig_history[name].append(eigenvalues[:top_n].cpu().numpy())\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error updating topology for {name}: {e}\")\n",
        "                continue\n",
        "\n",
        "    def plot_results(self, standard_results, talt_results):\n",
        "        \"\"\"\n",
        "        Plot comparative results\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        # Training loss\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.plot(standard_results['train_loss'], label='Standard')\n",
        "        plt.plot(talt_results['train_loss'], label='Topology-Aware')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Training Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Test loss\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.plot(standard_results['test_loss'], label='Standard')\n",
        "        plt.plot(talt_results['test_loss'], label='Topology-Aware')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Test Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Training accuracy\n",
        "        plt.subplot(2, 2, 3)\n",
        "        plt.plot(standard_results['train_acc'], label='Standard')\n",
        "        plt.plot(talt_results['train_acc'], label='Topology-Aware')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Training Accuracy (%)')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Test accuracy\n",
        "        plt.subplot(2, 2, 4)\n",
        "        plt.plot(standard_results['test_acc'], label='Standard')\n",
        "        plt.plot(talt_results['test_acc'], label='Topology-Aware')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Test Accuracy (%)')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Plot eigenvalue history for one parameter\n",
        "        if self.eig_history:\n",
        "            param_name = next(iter(self.eig_history.keys()))\n",
        "            if self.eig_history[param_name]:\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                eig_vals = np.array(self.eig_history[param_name])\n",
        "                for i in range(eig_vals.shape[1]):\n",
        "                    plt.plot(range(len(eig_vals)), eig_vals[:, i], label=f'Eigenvalue {i+1}')\n",
        "                plt.xlabel('Updates')\n",
        "                plt.ylabel('Eigenvalue Magnitude')\n",
        "                plt.title(f'Landscape Curvature Evolution')\n",
        "                plt.legend()\n",
        "                plt.grid(True)\n",
        "\n",
        "                # Mark bifurcation events\n",
        "                for step in self.bifurcations:\n",
        "                    update_idx = step // self.update_interval\n",
        "                    if update_idx < len(eig_vals):\n",
        "                        plt.axvline(x=update_idx, color='r', linestyle='--', alpha=0.3)\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "# Example with MNIST\n",
        "def train_mnist_with_fast_transformer():\n",
        "    # Set up data loaders\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    # Load MNIST dataset\n",
        "    try:\n",
        "        train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "        test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=1000)\n",
        "    except:\n",
        "        # Fallback to synthetic data\n",
        "        print(\"Using synthetic data instead of MNIST\")\n",
        "        n_samples = 1000\n",
        "        X = torch.randn(n_samples, 1, 28, 28)\n",
        "        y = torch.randint(0, 10, (n_samples,))\n",
        "        train_dataset = TensorDataset(X, y)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "        test_loader = train_loader\n",
        "\n",
        "    # Define CNN model\n",
        "    class SimpleCNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(SimpleCNN, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "            self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "            self.fc1 = nn.Linear(320, 50)\n",
        "            self.fc2 = nn.Linear(50, 10)\n",
        "            self.relu = nn.ReLU()\n",
        "            self.max_pool = nn.MaxPool2d(2)\n",
        "            self.dropout = nn.Dropout2d(0.5)\n",
        "            self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.relu(self.max_pool(self.conv1(x)))\n",
        "            x = self.relu(self.max_pool(self.dropout(self.conv2(x))))\n",
        "            x = x.view(-1, 320)\n",
        "            x = self.relu(self.fc1(x))\n",
        "            x = self.dropout(x)\n",
        "            x = self.fc2(x)\n",
        "            return self.log_softmax(x)\n",
        "\n",
        "    # Check if GPU is available and move models to it\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create models\n",
        "    standard_model = SimpleCNN().to(device)\n",
        "    talt_model = SimpleCNN().to(device)\n",
        "\n",
        "    # Loss function\n",
        "    loss_fn = nn.NLLLoss()\n",
        "\n",
        "    # Standard optimizer\n",
        "    standard_optimizer = optim.SGD(standard_model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "    # Fast TALT optimizer\n",
        "    fast_transformer = FastTopologyTransformer(\n",
        "        talt_model,\n",
        "        base_optimizer=optim.SGD,\n",
        "        lr=0.01,\n",
        "        topology_update_interval=20,  # Update topology less frequently\n",
        "        eigenspace_memory_size=10,    # Store fewer gradient samples\n",
        "        valley_strength=0.1,\n",
        "        smoothing_factor=0.3\n",
        "    )\n",
        "\n",
        "    # Training function\n",
        "    def train_epoch(model, optimizer, data_loader, is_transformer=False):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(data_loader):\n",
        "            # Move data to device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            if not is_transformer:\n",
        "                # Standard approach\n",
        "                optimizer.zero_grad()\n",
        "                output = model(data)\n",
        "                loss = loss_fn(output, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            else:\n",
        "                # Use our fast transformer\n",
        "                loss, output = fast_transformer.step(loss_fn, data, target)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            # Add loss\n",
        "            total_loss += loss if isinstance(loss, float) else loss.item()\n",
        "\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"{'TALT' if is_transformer else 'Standard'} - \"\n",
        "                      f\"Batch {batch_idx}/{len(data_loader)}: Loss: {loss:.6f}\")\n",
        "\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        accuracy = 100. * correct / len(data_loader.dataset)\n",
        "        return avg_loss, accuracy\n",
        "\n",
        "    # Test function\n",
        "    def test(model, data_loader):\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in data_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss += loss_fn(output, target).item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(data_loader)\n",
        "        accuracy = 100. * correct / len(data_loader.dataset)\n",
        "\n",
        "        print(f\"Test set: Average loss: {test_loss:.4f}, \"\n",
        "              f\"Accuracy: {correct}/{len(data_loader.dataset)} ({accuracy:.2f}%)\")\n",
        "\n",
        "        return test_loss, accuracy\n",
        "\n",
        "    # Train for a few epochs\n",
        "    n_epochs = 3\n",
        "    results = {\n",
        "        'standard': {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []},\n",
        "        'talt': {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
        "    }\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
        "\n",
        "        # Train standard model\n",
        "        print(\"\\nTraining standard model:\")\n",
        "        loss, acc = train_epoch(standard_model, standard_optimizer, train_loader)\n",
        "        results['standard']['train_loss'].append(loss)\n",
        "        results['standard']['train_acc'].append(acc)\n",
        "\n",
        "        # Train TALT model\n",
        "        print(\"\\nTraining topology-aware model:\")\n",
        "        loss, acc = train_epoch(talt_model, None, train_loader, is_transformer=True)\n",
        "        results['talt']['train_loss'].append(loss)\n",
        "        results['talt']['train_acc'].append(acc)\n",
        "\n",
        "        # Test both models\n",
        "        print(\"\\nTesting standard model:\")\n",
        "        loss, acc = test(standard_model, test_loader)\n",
        "        results['standard']['test_loss'].append(loss)\n",
        "        results['standard']['test_acc'].append(acc)\n",
        "\n",
        "        print(\"\\nTesting topology-aware model:\")\n",
        "        loss, acc = test(talt_model, test_loader)\n",
        "        results['talt']['test_loss'].append(loss)\n",
        "        results['talt']['test_acc'].append(acc)\n",
        "\n",
        "    # Plot results\n",
        "    fast_transformer.plot_results(results['standard'], results['talt'])\n",
        "\n",
        "    return results, fast_transformer\n",
        "\n",
        "# Run the training\n",
        "if __name__ == \"__main__\":\n",
        "    results, transformer = train_mnist_with_fast_transformer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k2wYfzoQFwy9",
        "outputId": "ae9645f4-8a03-4d20-aa4e-4082b3da23e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Epoch 1/3\n",
            "\n",
            "Training standard model:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard - Batch 0/469: Loss: 2.322268\n",
            "Standard - Batch 50/469: Loss: 2.172442\n",
            "Standard - Batch 100/469: Loss: 1.712940\n",
            "Standard - Batch 150/469: Loss: 1.311851\n",
            "Standard - Batch 200/469: Loss: 0.806221\n",
            "Standard - Batch 250/469: Loss: 1.028502\n",
            "Standard - Batch 300/469: Loss: 0.658337\n",
            "Standard - Batch 350/469: Loss: 0.614062\n",
            "Standard - Batch 400/469: Loss: 0.459579\n",
            "Standard - Batch 450/469: Loss: 0.703316\n",
            "\n",
            "Training topology-aware model:\n",
            "TALT - Batch 0/469: Loss: 2.275140\n",
            "TALT - Batch 50/469: Loss: 2.290392\n",
            "TALT - Batch 100/469: Loss: 2.256799\n",
            "TALT - Batch 150/469: Loss: 2.189874\n",
            "TALT - Batch 200/469: Loss: 2.058684\n",
            "TALT - Batch 250/469: Loss: 1.718782\n",
            "TALT - Batch 300/469: Loss: 1.535674\n",
            "TALT - Batch 350/469: Loss: 1.175947\n",
            "TALT - Batch 400/469: Loss: 0.927030\n",
            "TALT - Batch 450/469: Loss: 0.961166\n",
            "\n",
            "Testing standard model:\n",
            "Test set: Average loss: 0.2706, Accuracy: 9247/10000 (92.47%)\n",
            "\n",
            "Testing topology-aware model:\n",
            "Test set: Average loss: 0.5842, Accuracy: 8734/10000 (87.34%)\n",
            "\n",
            "Epoch 2/3\n",
            "\n",
            "Training standard model:\n",
            "Standard - Batch 0/469: Loss: 0.587520\n",
            "Standard - Batch 50/469: Loss: 0.537725\n",
            "Standard - Batch 100/469: Loss: 0.371604\n",
            "Standard - Batch 150/469: Loss: 0.431401\n",
            "Standard - Batch 200/469: Loss: 0.398583\n",
            "Standard - Batch 250/469: Loss: 0.429970\n",
            "Standard - Batch 300/469: Loss: 0.314713\n",
            "Standard - Batch 350/469: Loss: 0.371346\n",
            "Standard - Batch 400/469: Loss: 0.440643\n",
            "Standard - Batch 450/469: Loss: 0.397515\n",
            "\n",
            "Training topology-aware model:\n",
            "TALT - Batch 0/469: Loss: 1.129859\n",
            "TALT - Batch 50/469: Loss: 0.906542\n",
            "TALT - Batch 100/469: Loss: 0.936326\n",
            "TALT - Batch 150/469: Loss: 0.735693\n",
            "TALT - Batch 200/469: Loss: 0.909029\n",
            "TALT - Batch 250/469: Loss: 0.679599\n",
            "TALT - Batch 300/469: Loss: 0.727254\n",
            "TALT - Batch 350/469: Loss: 0.607561\n",
            "TALT - Batch 400/469: Loss: 0.555637\n",
            "TALT - Batch 450/469: Loss: 0.617299\n",
            "\n",
            "Testing standard model:\n",
            "Test set: Average loss: 0.1663, Accuracy: 9498/10000 (94.98%)\n",
            "\n",
            "Testing topology-aware model:\n",
            "Test set: Average loss: 0.2872, Accuracy: 9271/10000 (92.71%)\n",
            "\n",
            "Epoch 3/3\n",
            "\n",
            "Training standard model:\n",
            "Standard - Batch 0/469: Loss: 0.471556\n",
            "Standard - Batch 50/469: Loss: 0.407204\n",
            "Standard - Batch 100/469: Loss: 0.360461\n",
            "Standard - Batch 150/469: Loss: 0.319780\n",
            "Standard - Batch 200/469: Loss: 0.393904\n",
            "Standard - Batch 250/469: Loss: 0.278345\n",
            "Standard - Batch 300/469: Loss: 0.407709\n",
            "Standard - Batch 350/469: Loss: 0.351169\n",
            "Standard - Batch 400/469: Loss: 0.435508\n",
            "Standard - Batch 450/469: Loss: 0.318059\n",
            "\n",
            "Training topology-aware model:\n",
            "TALT - Batch 0/469: Loss: 0.669988\n",
            "TALT - Batch 50/469: Loss: 0.522573\n",
            "TALT - Batch 100/469: Loss: 0.612820\n",
            "TALT - Batch 150/469: Loss: 0.437875\n",
            "TALT - Batch 200/469: Loss: 0.307224\n",
            "TALT - Batch 250/469: Loss: 0.619589\n",
            "TALT - Batch 300/469: Loss: 0.473292\n",
            "TALT - Batch 350/469: Loss: 0.445036\n",
            "TALT - Batch 400/469: Loss: 0.510342\n",
            "TALT - Batch 450/469: Loss: 0.378411\n",
            "\n",
            "Testing standard model:\n",
            "Test set: Average loss: 0.1269, Accuracy: 9607/10000 (96.07%)\n",
            "\n",
            "Testing topology-aware model:\n",
            "Test set: Average loss: 0.2038, Accuracy: 9448/10000 (94.48%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "class FastTopologyTransformer:\n",
        "    \"\"\"\n",
        "    GPU‑optimized version of Topology‑Aware Landscape Transformer\n",
        "    \"\"\"\n",
        "    def __init__(self, model, base_optimizer, lr=0.01,\n",
        "                 topology_update_interval=50,\n",
        "                 eigenspace_memory_size=10,\n",
        "                 valley_strength=0.1,\n",
        "                 smoothing_factor=0.3):\n",
        "        self.model = model\n",
        "        self.optimizer = base_optimizer(model.parameters(), lr=lr)\n",
        "        self.update_interval = topology_update_interval\n",
        "        self.memory_size = eigenspace_memory_size\n",
        "        self.valley_strength = valley_strength\n",
        "        self.smoothing_factor = smoothing_factor\n",
        "\n",
        "        # Memory & stats\n",
        "        self.grad_memory   = {}\n",
        "        self.principal_dirs = {}\n",
        "        self.eigenvalues    = {}\n",
        "        self.steps         = 0\n",
        "        self.loss_history  = []\n",
        "        self.loss_memory   = []\n",
        "        self.eig_history   = {}\n",
        "        self.bifurcations  = []\n",
        "\n",
        "        # Register hooks\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad and param.numel() > 10:\n",
        "                param.register_hook(\n",
        "                    lambda grad, name=name: self._transform_gradient(grad, name)\n",
        "                )\n",
        "                self.grad_memory[name]   = deque(maxlen=self.memory_size)\n",
        "                self.principal_dirs[name] = None\n",
        "                self.eigenvalues[name]    = None\n",
        "                self.eig_history[name]    = []\n",
        "\n",
        "    def _transform_gradient(self, gradient, param_name):\n",
        "        if param_name not in self.grad_memory or gradient.numel() < 10:\n",
        "            return gradient\n",
        "        original = gradient.clone()\n",
        "        if self.principal_dirs[param_name] is not None:\n",
        "            try:\n",
        "                device   = gradient.device\n",
        "                flat     = gradient.view(-1)\n",
        "                eigvecs  = self.principal_dirs[param_name].to(device)\n",
        "                eigvals  = self.eigenvalues[param_name].to(device)\n",
        "                coeffs   = flat @ eigvecs\n",
        "\n",
        "                # Valley creation in saddle dirs\n",
        "                near_zero = torch.abs(eigvals) < 0.05\n",
        "                if near_zero.any():\n",
        "                    self.bifurcations.append(self.steps)\n",
        "                    coeffs[near_zero] *= (1.0 + self.valley_strength)\n",
        "\n",
        "                # Curvature smoothing & plateau escape\n",
        "                for i, v in enumerate(eigvals):\n",
        "                    av = torch.abs(v)\n",
        "                    if av > 1.0:\n",
        "                        coeffs[i] *= (1.0/torch.sqrt(av)) * self.smoothing_factor\n",
        "                    elif av < 0.5:\n",
        "                        coeffs[i] *= (1.0 + (1.0 - av))\n",
        "\n",
        "                new_flat = coeffs @ eigvecs.t()\n",
        "                gradient = new_flat.view_as(gradient)\n",
        "\n",
        "                # Blend if too dissimilar\n",
        "                cos = torch.nn.functional.cosine_similarity(\n",
        "                    gradient.view(-1), original.view(-1), dim=0\n",
        "                )\n",
        "                if cos < 0.7:\n",
        "                    blend = 0.7 - cos\n",
        "                    gradient = (1 - blend) * gradient + blend * original\n",
        "            except:\n",
        "                return original\n",
        "        if torch.isnan(gradient).any() or torch.isinf(gradient).any():\n",
        "            return original\n",
        "        return gradient\n",
        "\n",
        "    def step(self, loss_fn, inputs, targets):\n",
        "        # Standard forward/backward\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(inputs)\n",
        "        loss    = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        # Record grads & loss\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.grad is not None and name in self.grad_memory:\n",
        "                self.grad_memory[name].append(param.grad.detach().view(-1))\n",
        "        self.loss_memory.append(loss.item())\n",
        "\n",
        "        # Apply update\n",
        "        self.optimizer.step()\n",
        "        self.steps += 1\n",
        "        self.loss_history.append(loss.item())\n",
        "\n",
        "        if self.steps % self.update_interval == 0:\n",
        "            self._update_topology()\n",
        "\n",
        "        return loss.item(), outputs\n",
        "\n",
        "    def _update_topology(self):\n",
        "        for name, mem in self.grad_memory.items():\n",
        "            if len(mem) < 5:\n",
        "                continue\n",
        "            try:\n",
        "                stacked  = torch.stack(list(mem))\n",
        "                centered = stacked - stacked.mean(0)\n",
        "                cov      = centered.t() @ centered\n",
        "                cov      = 0.5*(cov + cov.t()) + torch.eye(cov.size(0), device=cov.device)*1e-6\n",
        "                try:\n",
        "                    vals, vecs = torch.linalg.eigh(cov)\n",
        "                except RuntimeError:\n",
        "                    vals, vecs = torch.linalg.eigh(cov.cpu())\n",
        "                idx       = torch.argsort(-torch.abs(vals))\n",
        "                vecs, vals= vecs[:, idx], vals[idx]\n",
        "                d         = min(len(vals), self.memory_size)\n",
        "                self.principal_dirs[name] = vecs[:, :d]\n",
        "                self.eigenvalues[name]    = vals[:d]\n",
        "                self.eig_history[name].append(vals[:min(3, len(vals))].cpu().numpy())\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    # --- Visualization Methods ---\n",
        "\n",
        "    def visualize_gradient_transformations_by_type(self):\n",
        "        weight_params = [n for n in self.grad_memory if '.weight' in n]\n",
        "        bias_params   = [n for n in self.grad_memory if '.bias' in n]\n",
        "        fig, axes = plt.subplots(2,1,figsize=(14,10))\n",
        "        for ax, params, lbl in zip(axes, (weight_params, bias_params), ('Weight','Bias')):\n",
        "            if not params:\n",
        "                ax.axis('off'); continue\n",
        "            before = np.vstack([np.array(self.grad_memory[n]) for n in params])\n",
        "            after  = before.copy()  # replace if tracking true 'after'\n",
        "            m0, s0 = before.mean(0), before.std(0)\n",
        "            m1, s1 = after.mean(0),  after.std(0)\n",
        "            x = np.arange(len(m0))\n",
        "            ax.plot(x, m0, label='Before'); ax.fill_between(x, m0-s0, m0+s0, alpha=0.2)\n",
        "            ax.plot(x, m1, label='After');  ax.fill_between(x, m1-s1, m1+s1, alpha=0.2)\n",
        "            for u in self.bifurcations:\n",
        "                if u < len(x): ax.axvline(u, color='g', linestyle='--', alpha=0.3)\n",
        "            ax.plot(x, m1/(m0+1e-10), 'r--', label='Ratio')\n",
        "            ax.set_title(f'{lbl} Gradient Norm Transformation')\n",
        "            ax.set_xlabel('Step'); ax.set_ylabel('Norm'); ax.legend(); ax.grid(True)\n",
        "        plt.tight_layout(); plt.show()\n",
        "\n",
        "    def analyze_gradient_signal_to_noise(self):\n",
        "        window=10\n",
        "        snr = {'weight':[], 'bias':[]}\n",
        "        for name, mem in self.grad_memory.items():\n",
        "            arr = np.vstack(mem)\n",
        "            if arr.shape[0] <= window: continue\n",
        "            seq = [(arr[i-window:i].mean()/(arr[i-window:i].std()+1e-10))\n",
        "                   for i in range(window, arr.shape[0])]\n",
        "            key = 'weight' if '.weight' in name else 'bias'\n",
        "            snr[key].append(seq)\n",
        "        fig, axes = plt.subplots(2,1,figsize=(14,10))\n",
        "        for ax, key in zip(axes, ('weight','bias')):\n",
        "            if not snr[key]:\n",
        "                ax.axis('off'); continue\n",
        "            m = np.vstack(snr[key]).mean(0)\n",
        "            ax.plot(m, label='SNR (mean/std)')\n",
        "            ax.set_title(f'{key.title()} Signal-to-Noise Ratio')\n",
        "            ax.set_xlabel('Step'); ax.set_ylabel('SNR'); ax.grid(True)\n",
        "        plt.tight_layout(); plt.show()\n",
        "\n",
        "    def visualize_gradient_variance_reduction(self):\n",
        "        window=10\n",
        "        data = {'weight':[], 'bias':[]}\n",
        "        for name, mem in self.grad_memory.items():\n",
        "            arr = np.vstack(mem)\n",
        "            if arr.shape[0] <= window: continue\n",
        "            rolls = [arr[i-window:i] for i in range(window, arr.shape[0])]\n",
        "            vars_b = [r.var(axis=1).mean() for r in rolls]\n",
        "            vars_a = vars_b.copy()  # replace with actual after if available\n",
        "            key = 'weight' if '.weight' in name else 'bias'\n",
        "            data[key].append((vars_b, vars_a))\n",
        "        fig, axes = plt.subplots(2,2,figsize=(15,12))\n",
        "        labels = ['Weight Variance','Weight Reduction %','Bias Variance','Bias Reduction %']\n",
        "        for ax, lbl, key in zip(axes.flatten(), labels, ('weight','weight','bias','bias')):\n",
        "            if not data[key]:\n",
        "                ax.axis('off'); continue\n",
        "            bs, as_ = zip(*data[key])\n",
        "            mb, ma = np.vstack(bs).mean(0), np.vstack(as_).mean(0)\n",
        "            x = np.arange(len(mb))\n",
        "            if 'Reduction' in lbl:\n",
        "                red = (1 - ma/(mb+1e-10))*100\n",
        "                ax.plot(x, red)\n",
        "                ax.set_ylabel('Reduction %')\n",
        "            else:\n",
        "                ax.plot(x, mb, label='Before'); ax.plot(x, ma, label='After'); ax.legend()\n",
        "                ax.set_ylabel('Variance')\n",
        "            ax.set_title(lbl); ax.set_xlabel('Step'); ax.grid(True)\n",
        "        plt.tight_layout(); plt.show()\n",
        "\n",
        "    def analyze_effective_learning_rates(self):\n",
        "        fig, axes = plt.subplots(2,1,figsize=(14,10))\n",
        "        for ax, key in zip(axes, ('.weight','.bias')):\n",
        "            scales = []\n",
        "            for name, mem in self.grad_memory.items():\n",
        "                if key not in name: continue\n",
        "                arr = np.vstack(mem)\n",
        "                sc = arr/(arr+1e-10)\n",
        "                scales.append(sc.mean(0))\n",
        "            if not scales:\n",
        "                ax.axis('off'); continue\n",
        "            m = np.vstack(scales).mean(0)\n",
        "            s = np.vstack(scales).std(0)\n",
        "            x = np.arange(len(m))\n",
        "            ax.plot(x, m, label='Effective LR Scaling')\n",
        "            ax.fill_between(x, m-s, m+s, alpha=0.2)\n",
        "            ax.axhline(1.0, color='r', linestyle='--', label='No Change')\n",
        "            for bif in self.bifurcations:\n",
        "                if bif < len(x): ax.axvline(bif, color='purple', linestyle=':', alpha=0.5)\n",
        "            ax.set_title(f'{\"Weight\" if key==\".weight\" else \"Bias\"} Effective LR Scaling')\n",
        "            ax.set_xlabel('Step'); ax.set_ylabel('Scaling'); ax.set_ylim(0,2); ax.legend(); ax.grid(True)\n",
        "        plt.tight_layout(); plt.show()\n",
        "\n",
        "    def visualize_saddle_point_escapes(self):\n",
        "        window=5\n",
        "        if not self.bifurcations or len(self.loss_history) < 2*window:\n",
        "            print(\"Not enough data for saddle escape analysis\")\n",
        "            return\n",
        "        effects = []\n",
        "        for bif in self.bifurcations:\n",
        "            if bif < window or bif > len(self.loss_history)-window: continue\n",
        "            before = self.loss_history[bif-window:bif]\n",
        "            after  = self.loss_history[bif:bif+window]\n",
        "            slope_b = (before[-1]-before[0])/window\n",
        "            slope_a = (after[-1]-after[0])/window\n",
        "            acc = slope_a/(slope_b+1e-10)\n",
        "            effects.append((bif, before+after, acc))\n",
        "        if not effects:\n",
        "            return\n",
        "        fig, axes = plt.subplots(1,2,figsize=(15,6))\n",
        "        for step, vals, _ in effects[:5]:\n",
        "            x = np.arange(-window, window)\n",
        "            axes[0].plot(x, vals, marker='o', label=f'bif {step}')\n",
        "        axes[0].axvline(0, color='r', linestyle='--', alpha=0.3)\n",
        "        axes[0].set_title('Loss Around Bifurcations')\n",
        "        axes[0].set_xlabel('Relative Step'); axes[0].set_ylabel('Loss'); axes[0].grid(True); axes[0].legend()\n",
        "\n",
        "        accs = [e[2] for e in effects]\n",
        "        clipped = np.clip(accs, -5, 5)\n",
        "        axes[1].hist(clipped, bins=20, alpha=0.7)\n",
        "        axes[1].axvline(1.0, color='r', linestyle='--')\n",
        "        median, mean = np.median(accs), np.mean(accs)\n",
        "        improved = 100 * np.sum(np.array(accs)<1.0) / len(accs)\n",
        "        axes[1].text(0.05,0.95, f\"Median:{median:.2f}\\nMean:{mean:.2f}\\nImproved:{improved:.1f}%\",\n",
        "                     transform=axes[1].transAxes, verticalalignment='top',\n",
        "                     bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
        "        axes[1].set_title('Acceleration Histogram')\n",
        "        axes[1].set_xlabel('Factor'); axes[1].set_ylabel('Freq'); axes[1].grid(True)\n",
        "        plt.tight_layout(); plt.show()\n",
        "\n",
        "    def plot_results(self, standard_results, talt_results):\n",
        "        plt.figure(figsize=(15,10))\n",
        "        metrics = [\n",
        "            ('Training Loss', standard_results['train_loss'], talt_results['train_loss']),\n",
        "            ('Test Loss',     standard_results['test_loss'],  talt_results['test_loss']),\n",
        "            ('Training Acc',  standard_results['train_acc'],  talt_results['train_acc']),\n",
        "            ('Test Acc',      standard_results['test_acc'],   talt_results['test_acc']),\n",
        "        ]\n",
        "        for idx, (title, std, tal) in enumerate(metrics, 1):\n",
        "            plt.subplot(2,2,idx)\n",
        "            plt.plot(std, label='Standard')\n",
        "            plt.plot(tal, label='Topology‑Aware')\n",
        "            plt.title(title)\n",
        "            plt.xlabel('Epoch'); plt.ylabel(title); plt.legend(); plt.grid(True)\n",
        "        plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "# Example MNIST training function with FastTopologyTransformer\n",
        "def train_mnist_with_fast_transformer():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "    try:\n",
        "        train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "        test_dataset  = datasets.MNIST('./data', train=False, transform=transform)\n",
        "        train_loader  = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "        test_loader   = DataLoader(test_dataset, batch_size=1000)\n",
        "    except:\n",
        "        print(\"Using synthetic data\")\n",
        "        X = torch.randn(1000,1,28,28)\n",
        "        y = torch.randint(0,10,(1000,))\n",
        "        train_dataset = TensorDataset(X,y)\n",
        "        train_loader  = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "        test_loader   = train_loader\n",
        "\n",
        "    class SimpleCNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv2d(1,10,5)\n",
        "            self.conv2 = nn.Conv2d(10,20,5)\n",
        "            self.fc1   = nn.Linear(320,50)\n",
        "            self.fc2   = nn.Linear(50,10)\n",
        "            self.relu  = nn.ReLU()\n",
        "            self.pool  = nn.MaxPool2d(2)\n",
        "            self.drop  = nn.Dropout2d(0.5)\n",
        "            self.logsoft= nn.LogSoftmax(dim=1)\n",
        "        def forward(self,x):\n",
        "            x = self.relu(self.pool(self.conv1(x)))\n",
        "            x = self.relu(self.pool(self.drop(self.conv2(x))))\n",
        "            x = x.view(-1,320)\n",
        "            x = self.relu(self.fc1(x))\n",
        "            x = self.drop(x)\n",
        "            x = self.fc2(x)\n",
        "            return self.logsoft(x)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    standard_model = SimpleCNN().to(device)\n",
        "    talt_model     = SimpleCNN().to(device)\n",
        "    loss_fn        = nn.NLLLoss()\n",
        "    standard_opt   = optim.SGD(standard_model.parameters(), lr=0.01, momentum=0.5)\n",
        "    fast_transformer = FastTopologyTransformer(\n",
        "        talt_model, optim.SGD, lr=0.01, topology_update_interval=20,\n",
        "        eigenspace_memory_size=10, valley_strength=0.1, smoothing_factor=0.3\n",
        "    )\n",
        "\n",
        "    def train_epoch(model, optimizer, loader, is_talt=False):\n",
        "        model.train()\n",
        "        total_loss, correct = 0, 0\n",
        "        for batch_idx, (data, target) in enumerate(loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            if not is_talt:\n",
        "                optimizer.zero_grad()\n",
        "                out = model(data)\n",
        "                loss = loss_fn(out, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            else:\n",
        "                loss, out = fast_transformer.step(loss_fn, data, target)\n",
        "            pred = out.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total_loss += loss if isinstance(loss, float) else loss.item()\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"{'TALT' if is_talt else 'Std'} Batch {batch_idx}/{len(loader)} Loss {loss:.4f}\")\n",
        "        return total_loss/len(loader), 100.*correct/len(loader.dataset)\n",
        "\n",
        "    def test(model, loader):\n",
        "        model.eval()\n",
        "        test_loss, correct = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                out = model(data)\n",
        "                test_loss += loss_fn(out, target).item()\n",
        "                pred = out.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        return test_loss/len(loader), 100.*correct/len(loader.dataset)\n",
        "\n",
        "    results = {\n",
        "        'standard': {'train_loss':[], 'train_acc':[], 'test_loss':[], 'test_acc':[]},\n",
        "        'talt':     {'train_loss':[], 'train_acc':[], 'test_loss':[], 'test_acc':[]}\n",
        "    }\n",
        "\n",
        "    n_epochs = 3\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        print(f\"\\nEpoch {epoch}/{n_epochs}\")\n",
        "        tr_loss, tr_acc = train_epoch(standard_model, standard_opt, train_loader)\n",
        "        results['standard']['train_loss'].append(tr_loss)\n",
        "        results['standard']['train_acc'].append(tr_acc)\n",
        "\n",
        "        tr_loss, tr_acc = train_epoch(talt_model, None, train_loader, is_talt=True)\n",
        "        results['talt']['train_loss'].append(tr_loss)\n",
        "        results['talt']['train_acc'].append(tr_acc)\n",
        "\n",
        "        te_loss, te_acc = test(standard_model, test_loader)\n",
        "        results['standard']['test_loss'].append(te_loss)\n",
        "        results['standard']['test_acc'].append(te_acc)\n",
        "        print(f\"Standard Test: Loss {te_loss:.4f}, Acc {te_acc:.2f}%\")\n",
        "\n",
        "        te_loss, te_acc = test(talt_model, test_loader)\n",
        "        results['talt']['test_loss'].append(te_loss)\n",
        "        results['talt']['test_acc'].append(te_acc)\n",
        "        print(f\"TALT Test:     Loss {te_loss:.4f}, Acc {te_acc:.2f}%\")\n",
        "\n",
        "    return results, fast_transformer\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results, transformer = train_mnist_with_fast_transformer()\n",
        "\n",
        "    # Original comparison plot\n",
        "    transformer.plot_results(results['standard'], results['talt'])\n",
        "\n",
        "    # Added visualizations\n",
        "    transformer.visualize_gradient_transformations_by_type()\n",
        "    transformer.analyze_gradient_signal_to_noise()\n",
        "    transformer.visualize_gradient_variance_reduction()\n",
        "    transformer.analyze_effective_learning_rates()\n",
        "    transformer.visualize_saddle_point_escapes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jOVmD99DNgMk",
        "outputId": "0de6feea-4bf4-444d-b77f-12535dad86cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Std Batch 0/469 Loss 2.2949\n",
            "Std Batch 50/469 Loss 2.2164\n",
            "Std Batch 100/469 Loss 1.9664\n",
            "Std Batch 150/469 Loss 1.4374\n",
            "Std Batch 200/469 Loss 1.1163\n",
            "Std Batch 250/469 Loss 0.9561\n",
            "Std Batch 300/469 Loss 0.7399\n",
            "Std Batch 350/469 Loss 0.8560\n",
            "Std Batch 400/469 Loss 0.9310\n",
            "Std Batch 450/469 Loss 0.7558\n",
            "TALT Batch 0/469 Loss 2.3055\n",
            "TALT Batch 50/469 Loss 2.2881\n",
            "TALT Batch 100/469 Loss 2.2377\n",
            "TALT Batch 150/469 Loss 2.2234\n",
            "TALT Batch 200/469 Loss 2.1806\n",
            "TALT Batch 250/469 Loss 2.0419\n",
            "TALT Batch 300/469 Loss 2.0219\n",
            "TALT Batch 350/469 Loss 1.8010\n",
            "TALT Batch 400/469 Loss 1.8384\n",
            "TALT Batch 450/469 Loss 1.6058\n",
            "Standard Test: Loss 0.3472, Acc 89.80%\n",
            "TALT Test:     Loss 1.3349, Acc 69.52%\n",
            "\n",
            "Epoch 2/3\n",
            "Std Batch 0/469 Loss 0.7903\n",
            "Std Batch 50/469 Loss 0.6516\n",
            "Std Batch 100/469 Loss 0.6646\n",
            "Std Batch 150/469 Loss 0.5347\n",
            "Std Batch 200/469 Loss 0.5279\n",
            "Std Batch 250/469 Loss 0.6985\n",
            "Std Batch 300/469 Loss 0.4785\n",
            "Std Batch 350/469 Loss 0.3888\n",
            "Std Batch 400/469 Loss 0.4172\n",
            "Std Batch 450/469 Loss 0.5829\n",
            "TALT Batch 0/469 Loss 1.6705\n",
            "TALT Batch 50/469 Loss 1.5924\n",
            "TALT Batch 100/469 Loss 1.4555\n",
            "TALT Batch 150/469 Loss 1.3059\n",
            "TALT Batch 200/469 Loss 1.2690\n",
            "TALT Batch 250/469 Loss 1.3263\n",
            "TALT Batch 300/469 Loss 0.8976\n",
            "TALT Batch 350/469 Loss 1.1106\n",
            "TALT Batch 400/469 Loss 0.9483\n",
            "TALT Batch 450/469 Loss 0.9761\n",
            "Standard Test: Loss 0.1972, Acc 94.09%\n",
            "TALT Test:     Loss 0.6008, Acc 84.04%\n",
            "\n",
            "Epoch 3/3\n",
            "Std Batch 0/469 Loss 0.4611\n",
            "Std Batch 50/469 Loss 0.6140\n",
            "Std Batch 100/469 Loss 0.4872\n",
            "Std Batch 150/469 Loss 0.4700\n",
            "Std Batch 200/469 Loss 0.3136\n",
            "Std Batch 250/469 Loss 0.3107\n",
            "Std Batch 300/469 Loss 0.4480\n",
            "Std Batch 350/469 Loss 0.2942\n",
            "Std Batch 400/469 Loss 0.4023\n",
            "Std Batch 450/469 Loss 0.3595\n",
            "TALT Batch 0/469 Loss 0.9385\n",
            "TALT Batch 50/469 Loss 0.9257\n",
            "TALT Batch 100/469 Loss 0.8185\n",
            "TALT Batch 150/469 Loss 0.9495\n",
            "TALT Batch 200/469 Loss 0.9785\n",
            "TALT Batch 250/469 Loss 0.7698\n",
            "TALT Batch 300/469 Loss 0.8505\n",
            "TALT Batch 350/469 Loss 0.9478\n",
            "TALT Batch 400/469 Loss 0.8753\n",
            "TALT Batch 450/469 Loss 0.8952\n",
            "Standard Test: Loss 0.1479, Acc 95.57%\n",
            "TALT Test:     Loss 0.4249, Acc 88.40%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-623e5aae9509>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;31m# Added visualizations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_gradient_transformations_by_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_gradient_signal_to_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_gradient_variance_reduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-623e5aae9509>\u001b[0m in \u001b[0;36mvisualize_gradient_transformations_by_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mbefore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_memory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mafter\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# replace if tracking true 'after'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mm0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-623e5aae9509>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mbefore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_memory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mafter\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# replace if tracking true 'after'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mm0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================\n",
        "# PERFORMANCE MONITORING\n",
        "# ===================================\n",
        "\n",
        "class Timer:\n",
        "    \"\"\"Simple timer for measuring execution time of code blocks.\"\"\"\n",
        "\n",
        "    def __init__(self, name: str = \"Operation\"):\n",
        "        \"\"\"\n",
        "        Initialize timer.\n",
        "\n",
        "        Args:\n",
        "            name: Name of the operation being timed\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.start_time = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        \"\"\"Start timer when entering context.\"\"\"\n",
        "        self.start_time = time.time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        \"\"\"Print elapsed time when exiting context.\"\"\"\n",
        "        elapsed = time.time() - self.start_time\n",
        "        print(f\"⏱️ {self.name} took {elapsed:.4f} seconds\")\n",
        "\n",
        "def print_memory_usage(prefix: str = \"\"):\n",
        "    \"\"\"\n",
        "    Print current memory usage statistics.\n",
        "\n",
        "    Args:\n",
        "        prefix: Optional prefix for the output message\n",
        "    \"\"\"\n",
        "    # System memory (RAM)\n",
        "    process = psutil.Process(os.getpid())\n",
        "    ram_usage = process.memory_info().rss / (1024 * 1024)  # MB\n",
        "\n",
        "    # GPU memory if available\n",
        "    gpu_memory = \"\"\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_allocated = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
        "        gpu_reserved = torch.cuda.memory_reserved() / (1024 * 1024)  # MB\n",
        "        gpu_memory = f\", GPU: {gpu_allocated:.1f}MB allocated, {gpu_reserved:.1f}MB reserved\"\n",
        "\n",
        "    print(f\"🔄 {prefix}Memory - RAM: {ram_usage:.1f}MB{gpu_memory}\")\n",
        "\n",
        "class PerformanceTracker:\n",
        "    \"\"\"Tracks performance metrics during training.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize performance tracker.\"\"\"\n",
        "        self.timings = {\n",
        "            \"forward_pass\": [],\n",
        "            \"backward_pass\": [],\n",
        "            \"optimizer_step\": [],\n",
        "            \"topology_update\": [],\n",
        "            \"batch_total\": []\n",
        "        }\n",
        "        self.memory_usage = []\n",
        "\n",
        "    def record_timing(self, operation: str, elapsed: float):\n",
        "        \"\"\"\n",
        "        Record timing for an operation.\n",
        "\n",
        "        Args:\n",
        "            operation: Name of the operation\n",
        "            elapsed: Time taken in seconds\n",
        "        \"\"\"\n",
        "        if operation in self.timings:\n",
        "            self.timings[operation].append(elapsed)\n",
        "\n",
        "    def record_memory(self):\n",
        "        \"\"\"Record current memory usage.\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            gpu_allocated = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
        "            self.memory_usage.append(gpu_allocated)\n",
        "        else:\n",
        "            process = psutil.Process(os.getpid())\n",
        "            ram_usage = process.memory_info().rss / (1024 * 1024)  # MB\n",
        "            self.memory_usage.append(ram_usage)\n",
        "\n",
        "    def print_summary(self):\n",
        "        \"\"\"Print summary of performance statistics.\"\"\"\n",
        "        print(\"\\n===== PERFORMANCE SUMMARY =====\")\n",
        "\n",
        "        print(\"⏱️ Timing Statistics (in seconds):\")\n",
        "        for operation, times in self.timings.items():\n",
        "            if times:\n",
        "                avg_time = sum(times) / len(times)\n",
        "                max_time = max(times)\n",
        "                print(f\"  - {operation:15s}: avg={avg_time:.4f}, max={max_time:.4f}\")\n",
        "\n",
        "        if self.memory_usage:\n",
        "            avg_memory = sum(self.memory_usage) / len(self.memory_usage)\n",
        "            peak_memory = max(self.memory_usage)\n",
        "            print(f\"🔄 Memory Usage (MB): avg={avg_memory:.1f}, peak={peak_memory:.1f}\")\n",
        "\n",
        "        print(\"===============================\\n\")\n",
        "\n",
        "\"\"\"\n",
        "Improved Topology-Aware Learning Trajectory (TALT) Optimizer\n",
        "\n",
        "This module implements an enhanced version of the TALT optimizer that uses\n",
        "dimensionality reduction, robust eigendecomposition, and non-parametric\n",
        "valley detection to improve optimization performance while reducing memory usage.\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import psutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from torch.amp import autocast, GradScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import Dict, List, Tuple, Optional, Union, Callable, Any\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import gc\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ===================================\n",
        "# MODEL DEFINITION\n",
        "# ===================================\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple convolutional neural network for image classification.\n",
        "\n",
        "    Features a convolutional feature extractor followed by a fully-connected\n",
        "    classifier with dropout for regularization.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_channels: int, image_size: int, num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        # Convolutional layers with BatchNorm\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(num_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Calculate flattened dimension after convolutions\n",
        "        flat_dim = (image_size // 4) ** 2 * 64\n",
        "\n",
        "        # Classifier layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(flat_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass through the network.\"\"\"\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# DIMENSIONALITY REDUCTION\n",
        "# ===================================\n",
        "\n",
        "class RandomProjection:\n",
        "    \"\"\"\n",
        "    Implements sparse random projection for dimension reduction.\n",
        "\n",
        "    Uses a memory-efficient sparse random projection matrix to reduce\n",
        "    the dimensionality of input data while approximately preserving\n",
        "    distances between points.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, original_dim: int, target_dim: int, seed: int = 42):\n",
        "        \"\"\"\n",
        "        Initialize random projection matrix.\n",
        "\n",
        "        Args:\n",
        "            original_dim: Original dimension\n",
        "            target_dim: Target dimension after projection\n",
        "            seed: Random seed for reproducibility\n",
        "        \"\"\"\n",
        "        self.original_dim = original_dim\n",
        "        self.target_dim = min(target_dim, original_dim)\n",
        "\n",
        "        # Set random seed for reproducibility\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        # Create sparse random projection matrix\n",
        "        sparsity = 1.0 / math.sqrt(self.original_dim)\n",
        "        self.projection = self._create_sparse_projection(sparsity)\n",
        "\n",
        "    def _create_sparse_projection(self, sparsity: float) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Create a sparse random projection matrix.\n",
        "\n",
        "        Uses the 'very sparse' random projection method where most values\n",
        "        are 0, and non-zero values are +/- sqrt(3) with equal probability.\n",
        "\n",
        "        Args:\n",
        "            sparsity: Sparsity level (fraction of non-zero elements)\n",
        "\n",
        "        Returns:\n",
        "            Sparse projection matrix\n",
        "        \"\"\"\n",
        "        # Create a mask for non-zero elements\n",
        "        mask = torch.rand(self.target_dim, self.original_dim) < sparsity\n",
        "\n",
        "        # Create random signs: 1 or -1\n",
        "        signs = torch.randint(0, 2, (self.target_dim, self.original_dim)) * 2 - 1\n",
        "\n",
        "        # Scale factor for unit variance\n",
        "        scale = math.sqrt(1.0 / sparsity)\n",
        "\n",
        "        # Create projection matrix\n",
        "        projection = (mask.float() * signs.float() * scale) / math.sqrt(self.target_dim)\n",
        "        return projection\n",
        "\n",
        "    def project(self, data: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Project data from original dimension to target dimension.\n",
        "\n",
        "        Args:\n",
        "            data: Data tensor of shape (batch_size, original_dim) or (original_dim,)\n",
        "\n",
        "        Returns:\n",
        "            Projected data of shape (batch_size, target_dim) or (target_dim,)\n",
        "        \"\"\"\n",
        "        # Check if data is 1D or 2D\n",
        "        is_1d = data.dim() == 1\n",
        "\n",
        "        # Ensure data is 2D for matrix multiplication\n",
        "        if is_1d:\n",
        "            data = data.unsqueeze(0)\n",
        "\n",
        "        # Move projection matrix to same device as data\n",
        "        projection = self.projection.to(data.device)\n",
        "\n",
        "        # Project data\n",
        "        projected = torch.matmul(data, projection.t())\n",
        "\n",
        "        # Return in original shape\n",
        "        return projected.squeeze(0) if is_1d else projected\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# COVARIANCE ESTIMATION\n",
        "# ===================================\n",
        "\n",
        "class IncrementalCovariance:\n",
        "    \"\"\"\n",
        "    Computes covariance matrix incrementally to save memory.\n",
        "\n",
        "    Allows for updating the covariance estimate one sample at a time,\n",
        "    with exponential forgetting to give more weight to recent samples.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim: int, decay: float = 0.95):\n",
        "        \"\"\"\n",
        "        Initialize incremental covariance estimator.\n",
        "\n",
        "        Args:\n",
        "            dim: Dimension of data\n",
        "            decay: Decay factor for old observations (0-1)\n",
        "        \"\"\"\n",
        "        self.dim = dim\n",
        "        self.decay = decay\n",
        "        self.n_samples = 0\n",
        "        self.mean = torch.zeros(dim)\n",
        "        self.cov = torch.zeros(dim, dim)\n",
        "\n",
        "    def update(self, x: torch.Tensor) -> None:\n",
        "        \"\"\"\n",
        "        Update covariance estimate with new data.\n",
        "\n",
        "        Args:\n",
        "            x: New data point(s) of shape (batch_size, dim) or (dim,)\n",
        "        \"\"\"\n",
        "        # Ensure input is on CPU and 2D\n",
        "        x = x.cpu()\n",
        "        if x.dim() == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            x_i = x[i]\n",
        "\n",
        "            # Apply decay to previous statistics\n",
        "            if self.n_samples > 0:\n",
        "                self.mean *= self.decay\n",
        "                self.cov *= self.decay**2\n",
        "\n",
        "            # Update sample count with decay\n",
        "            self.n_samples = self.decay * self.n_samples + 1\n",
        "\n",
        "            # Update mean\n",
        "            delta = x_i - self.mean\n",
        "            self.mean += delta / self.n_samples\n",
        "\n",
        "            # Update covariance\n",
        "            delta2 = x_i - self.mean\n",
        "            self.cov += torch.outer(delta, delta2) / max(1, self.n_samples - 1)\n",
        "\n",
        "    def get_covariance(self, reg: float = 1e-6) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Get current covariance estimate with regularization.\n",
        "\n",
        "        Args:\n",
        "            reg: Regularization parameter\n",
        "\n",
        "        Returns:\n",
        "            Covariance matrix with regularization\n",
        "        \"\"\"\n",
        "        if self.n_samples < 2:\n",
        "            # Not enough samples, return identity matrix\n",
        "            return torch.eye(self.dim) * reg\n",
        "\n",
        "        # Add regularization\n",
        "        cov = self.cov + torch.eye(self.dim) * reg\n",
        "\n",
        "        # Ensure symmetry\n",
        "        cov = 0.5 * (cov + cov.t())\n",
        "\n",
        "        return cov\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# EIGENDECOMPOSITION\n",
        "# ===================================\n",
        "\n",
        "class PowerIteration:\n",
        "    \"\"\"\n",
        "    Computes top eigenvectors using power iteration method.\n",
        "\n",
        "    A more stable alternative to direct eigendecomposition that\n",
        "    iteratively finds principal eigenvectors and eigenvalues.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_iter: int = 20, tol: float = 1e-6):\n",
        "        \"\"\"\n",
        "        Initialize power iteration.\n",
        "\n",
        "        Args:\n",
        "            max_iter: Maximum number of iterations\n",
        "            tol: Convergence tolerance\n",
        "        \"\"\"\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "\n",
        "    def compute_eigenpairs(self, matrix: torch.Tensor, k: int = 5) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Compute top k eigenvectors and eigenvalues.\n",
        "\n",
        "        Args:\n",
        "            matrix: Square matrix\n",
        "            k: Number of eigenpairs to compute\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (eigenvalues, eigenvectors)\n",
        "        \"\"\"\n",
        "        n = matrix.shape[0]\n",
        "        k = min(k, n)\n",
        "\n",
        "        # Initialize storage for eigenvectors and eigenvalues\n",
        "        eigenvectors = torch.zeros((n, k), device=matrix.device)\n",
        "        eigenvalues = torch.zeros(k, device=matrix.device)\n",
        "\n",
        "        # Initial random vectors, orthogonalized\n",
        "        vecs = torch.randn(n, k, device=matrix.device)\n",
        "        vecs, _ = torch.linalg.qr(vecs)\n",
        "\n",
        "        # Deflation approach: find eigenvectors one by one\n",
        "        for i in range(k):\n",
        "            # Current vector\n",
        "            v = vecs[:, i].clone()\n",
        "\n",
        "            # Power iteration\n",
        "            for _ in range(self.max_iter):\n",
        "                prev_v = v.clone()\n",
        "\n",
        "                # Apply matrix\n",
        "                v = torch.mv(matrix, v)\n",
        "\n",
        "                # Orthogonalize against previous eigenvectors\n",
        "                for j in range(i):\n",
        "                    v = v - torch.dot(v, eigenvectors[:, j]) * eigenvectors[:, j]\n",
        "\n",
        "                # Normalize\n",
        "                norm = torch.norm(v)\n",
        "                if norm > 1e-10:\n",
        "                    v = v / norm\n",
        "                else:\n",
        "                    # If vector is close to zero, reset with random\n",
        "                    v = torch.randn_like(v)\n",
        "                    v = v / torch.norm(v)\n",
        "\n",
        "                # Check convergence\n",
        "                cosine = torch.abs(torch.dot(v, prev_v))\n",
        "                if cosine > 1 - self.tol:\n",
        "                    break\n",
        "\n",
        "            # Compute Rayleigh quotient for eigenvalue\n",
        "            eigenvalues[i] = torch.dot(v, torch.mv(matrix, v))\n",
        "            eigenvectors[:, i] = v\n",
        "\n",
        "            # Deflate matrix to find next eigenvector\n",
        "            matrix = matrix - eigenvalues[i] * torch.outer(v, v)\n",
        "\n",
        "        return eigenvalues, eigenvectors\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# VALLEY DETECTION\n",
        "# ===================================\n",
        "\n",
        "class ValleyDetector:\n",
        "    \"\"\"\n",
        "    Non-parametric valley detection using gradient consistency.\n",
        "\n",
        "    Analyzes gradient direction changes to identify valleys in the\n",
        "    loss landscape without relying on eigendecomposition.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size: int = 5, threshold: float = 0.2):\n",
        "        \"\"\"\n",
        "        Initialize valley detector.\n",
        "\n",
        "        Args:\n",
        "            window_size: Size of window for gradient analysis\n",
        "            threshold: Threshold for valley detection\n",
        "        \"\"\"\n",
        "        self.window_size = window_size\n",
        "        self.threshold = threshold\n",
        "        self.grad_history = deque(maxlen=window_size)\n",
        "\n",
        "    def update(self, grad: torch.Tensor) -> None:\n",
        "        \"\"\"\n",
        "        Update gradient history.\n",
        "\n",
        "        Args:\n",
        "            grad: Current gradient\n",
        "        \"\"\"\n",
        "        # Store normalized gradient\n",
        "        grad_norm = grad / (torch.norm(grad) + 1e-10)\n",
        "        self.grad_history.append(grad_norm.cpu())\n",
        "\n",
        "    def detect_valley(self) -> Tuple[bool, Optional[torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        Detect if current point is in a valley.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_valley, valley_direction)\n",
        "        \"\"\"\n",
        "        if len(self.grad_history) < self.window_size:\n",
        "            return False, None\n",
        "\n",
        "        # Convert history to tensor\n",
        "        grads = torch.stack(list(self.grad_history))\n",
        "\n",
        "        # Compute gradient consistency (average cosine similarity)\n",
        "        n = len(self.grad_history)\n",
        "        cosine_sum = 0.0\n",
        "        count = 0\n",
        "\n",
        "        for i in range(n):\n",
        "            for j in range(i+1, n):\n",
        "                cos = torch.dot(grads[i], grads[j])\n",
        "                cosine_sum += cos.item()\n",
        "                count += 1\n",
        "\n",
        "        avg_cosine = cosine_sum / max(1, count)\n",
        "\n",
        "        # If gradients are inconsistent (pointing in different directions)\n",
        "        # then we might be in a valley\n",
        "        is_valley = avg_cosine < self.threshold\n",
        "\n",
        "        # If in valley, compute valley direction using PCA\n",
        "        if is_valley:\n",
        "            try:\n",
        "                # Center gradients\n",
        "                centered = grads - grads.mean(dim=0, keepdim=True)\n",
        "\n",
        "                # Compute covariance\n",
        "                cov = torch.matmul(centered.t(), centered) / (n - 1)\n",
        "\n",
        "                # Get eigenvector with smallest eigenvalue (valley direction)\n",
        "                eigenvalues, eigenvectors = torch.linalg.eigh(cov)\n",
        "                valley_dir = eigenvectors[:, 0]  # Direction of smallest eigenvalue\n",
        "                return True, valley_dir\n",
        "            except Exception:\n",
        "                return is_valley, None\n",
        "\n",
        "        return is_valley, None\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# IMPROVED TALT OPTIMIZER\n",
        "# ===================================\n",
        "\n",
        "class ImprovedTALTOptimizer:\n",
        "    \"\"\"\n",
        "    Improved Topology-Aware Learning Trajectory Optimizer\n",
        "\n",
        "    This optimizer implements an enhanced version of TALT with:\n",
        "    1. Dimension reduction via random projections\n",
        "    2. Incremental covariance estimation\n",
        "    3. Robust eigendecomposition via power iteration\n",
        "    4. Non-parametric valley detection\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        base_optimizer: Callable,\n",
        "        *,\n",
        "        lr: float = 1e-2,\n",
        "        projection_dim: int = 32,\n",
        "        memory_size: int = 10,\n",
        "        update_interval: int = 20,\n",
        "        valley_strength: float = 0.2,\n",
        "        smoothing_factor: float = 0.3,\n",
        "        grad_store_interval: int = 5,\n",
        "        min_param_size: int = 100,\n",
        "        cov_decay: float = 0.95,\n",
        "        adaptive_reg: bool = True,\n",
        "        device: Union[str, torch.device] = \"cuda\",\n",
        "        max_stored_steps: int = 1000,\n",
        "        max_visualization_points: int = 100\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the improved TALT optimizer.\n",
        "\n",
        "        Args:\n",
        "            model: Neural network model\n",
        "            base_optimizer: Base optimizer class (e.g., optim.SGD)\n",
        "            lr: Learning rate\n",
        "            projection_dim: Dimension after random projection\n",
        "            memory_size: Number of past gradients to store\n",
        "            update_interval: Steps between topology updates\n",
        "            valley_strength: Strength of valley acceleration\n",
        "            smoothing_factor: Factor for smoothing high-curvature directions\n",
        "            grad_store_interval: Steps between gradient storage\n",
        "            min_param_size: Minimum parameter size to track\n",
        "            cov_decay: Decay factor for incremental covariance\n",
        "            adaptive_reg: Whether to use adaptive regularization\n",
        "            device: Device to perform computations on\n",
        "            max_stored_steps: Maximum steps to store in history\n",
        "            max_visualization_points: Maximum visualization datapoints\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.optimizer = base_optimizer(model.parameters(), lr=lr)\n",
        "        self.projection_dim = projection_dim\n",
        "        self.memory_size = memory_size\n",
        "        self.update_interval = update_interval\n",
        "        self.valley_strength = valley_strength\n",
        "        self.smoothing_factor = smoothing_factor\n",
        "        self.store_interval = grad_store_interval\n",
        "        self.min_param_size = min_param_size\n",
        "        self.cov_decay = cov_decay\n",
        "        self.adaptive_reg = adaptive_reg\n",
        "        self.device = device if isinstance(device, torch.device) else torch.device(device)\n",
        "        self.max_stored_steps = max_stored_steps\n",
        "        self.max_visualization_points = max_visualization_points\n",
        "\n",
        "        # Initialize GradScaler for mixed precision\n",
        "        self.scaler = GradScaler('cuda')\n",
        "\n",
        "        # Tracking variables\n",
        "        self.steps = 0\n",
        "        self.loss_history = deque(maxlen=max_stored_steps)\n",
        "        self.bifurcations = deque(maxlen=100)  # Track bifurcation points\n",
        "\n",
        "        # Thread pool for asynchronous operations\n",
        "        self.executor = ThreadPoolExecutor(max_workers=1)\n",
        "        self._topology_update_future = None\n",
        "\n",
        "        # Visualization data with limited history\n",
        "        self._visualization_data = {\n",
        "            'loss_values': deque(maxlen=max_visualization_points),\n",
        "            'valley_detections': deque(maxlen=max_visualization_points),\n",
        "            'gradient_stats': {}\n",
        "        }\n",
        "\n",
        "        # Parameter-specific structures\n",
        "        self.param_data = {}\n",
        "\n",
        "        # Register hooks for parameters of sufficient size\n",
        "        for name, p in model.named_parameters():\n",
        "            if p.requires_grad and p.numel() > self.min_param_size:\n",
        "                # Create dimension-reduced representation\n",
        "                dim = p.numel()\n",
        "                target_dim = min(self.projection_dim, dim // 4)  # No more than 1/4 of original\n",
        "\n",
        "                self.param_data[name] = {\n",
        "                    'projector': RandomProjection(dim, target_dim),\n",
        "                    'covariance': IncrementalCovariance(target_dim, decay=cov_decay),\n",
        "                    'valley_detector': ValleyDetector(window_size=5, threshold=0.2),\n",
        "                    'valley_dirs': None,\n",
        "                    'transformation': None,\n",
        "                    'gradient_norm_history': deque(maxlen=50),\n",
        "                    'consistency_history': deque(maxlen=50)\n",
        "                }\n",
        "\n",
        "                self._visualization_data['gradient_stats'][name] = deque(maxlen=max_visualization_points)\n",
        "\n",
        "                # Register gradient hook\n",
        "                p.register_hook(lambda grad, name=name: self._transform_gradient(grad, name))\n",
        "\n",
        "    def _transform_gradient(self, grad: torch.Tensor, name: str) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Transform gradient using learned topology information.\n",
        "\n",
        "        Args:\n",
        "            grad: Original gradient\n",
        "            name: Parameter name\n",
        "\n",
        "        Returns:\n",
        "            Transformed gradient\n",
        "        \"\"\"\n",
        "        if name not in self.param_data:\n",
        "            return grad\n",
        "\n",
        "        # Make a copy of original gradient\n",
        "        orig_grad = grad.clone()\n",
        "        flat_grad = grad.view(-1)\n",
        "\n",
        "        # Get parameter data\n",
        "        param_info = self.param_data[name]\n",
        "        transformation = param_info['transformation']\n",
        "\n",
        "        # If no transformation available, just return original\n",
        "        if transformation is None:\n",
        "            return grad\n",
        "\n",
        "        try:\n",
        "            # Update valley detector with current gradient\n",
        "            param_info['valley_detector'].update(flat_grad.detach().cpu())\n",
        "\n",
        "            # Store gradient norm\n",
        "            grad_norm = torch.norm(flat_grad).item()\n",
        "            param_info['gradient_norm_history'].append(grad_norm)\n",
        "\n",
        "            # Apply learned transformation\n",
        "            is_valley, valley_dir = param_info['valley_detector'].detect_valley()\n",
        "\n",
        "            if is_valley and valley_dir is not None:\n",
        "                # Record bifurcation point\n",
        "                if len(self.bifurcations) < self.max_stored_steps:\n",
        "                    self.bifurcations.append(self.steps)\n",
        "\n",
        "                # Store detection for visualization\n",
        "                self._visualization_data['valley_detections'].append(\n",
        "                    (self.steps, name, 'valley')\n",
        "                )\n",
        "\n",
        "                # Project valley direction to original space if needed\n",
        "                if valley_dir.shape[0] != flat_grad.shape[0]:\n",
        "                    # This would happen if we're using dimension reduction\n",
        "                    # We need an approximate mapping back to original space\n",
        "                    # For now, we just rely on the transformation matrix\n",
        "                    pass\n",
        "\n",
        "                # Transform the gradient\n",
        "                # First, compute the component in valley direction\n",
        "                valley_dir = valley_dir.to(self.device)\n",
        "                valley_component = torch.dot(flat_grad, valley_dir) * valley_dir\n",
        "\n",
        "                # Amplify the valley component\n",
        "                flat_grad = flat_grad + self.valley_strength * valley_component\n",
        "\n",
        "            # Apply curvature-based transformation\n",
        "            transformed_grad = torch.matmul(transformation, flat_grad.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "            # Check if transformation is reasonable\n",
        "            cos_sim = nn.functional.cosine_similarity(\n",
        "                transformed_grad.view(-1), orig_grad.view(-1), dim=0\n",
        "            )\n",
        "\n",
        "            # If very different from original, blend back\n",
        "            if cos_sim < 0.6:\n",
        "                blend_factor = 0.6 - cos_sim\n",
        "                transformed_grad = (1.0 - blend_factor) * transformed_grad.view_as(orig_grad) + blend_factor * orig_grad\n",
        "            else:\n",
        "                transformed_grad = transformed_grad.view_as(orig_grad)\n",
        "\n",
        "            # Safety check for NaN or Inf\n",
        "            if torch.isnan(transformed_grad).any() or torch.isinf(transformed_grad).any():\n",
        "                logger.warning(f\"NaN or Inf in transformed gradient for {name}\")\n",
        "                return orig_grad\n",
        "\n",
        "            return transformed_grad\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error transforming gradient for {name}: {e}\")\n",
        "            return orig_grad\n",
        "\n",
        "    def _update_topology(self) -> None:\n",
        "        \"\"\"Update topology information for all tracked parameters.\"\"\"\n",
        "        for name, param_info in self.param_data.items():\n",
        "            # Skip if not enough data\n",
        "            if len(param_info['gradient_norm_history']) < 3:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Get the covariance matrix\n",
        "                cov = param_info['covariance'].get_covariance()\n",
        "\n",
        "                # Adaptive regularization based on condition number\n",
        "                if self.adaptive_reg:\n",
        "                    try:\n",
        "                        eigs = torch.linalg.eigvalsh(cov)\n",
        "                        if eigs[0] > 0:  # Avoid division by zero\n",
        "                            condition_number = eigs[-1] / eigs[0]\n",
        "                            reg = max(1e-6, min(1e-2, 1e-5 * condition_number))\n",
        "                            cov = cov + reg * torch.eye(cov.shape[0], device=cov.device)\n",
        "                    except Exception:\n",
        "                        # Fallback: add standard regularization\n",
        "                        cov = cov + 1e-6 * torch.eye(cov.shape[0], device=cov.device)\n",
        "\n",
        "                # Use power iteration for more stable eigendecomposition\n",
        "                power_iter = PowerIteration(max_iter=20, tol=1e-5)\n",
        "                eigenvalues, eigenvectors = power_iter.compute_eigenpairs(cov, k=min(5, cov.shape[0]))\n",
        "\n",
        "                # Create transformation matrix for gradient adjustment\n",
        "                # This is like a preconditioner based on the eigenstructure\n",
        "                transform = torch.eye(cov.shape[0], device=cov.device)\n",
        "\n",
        "                for i, val in enumerate(eigenvalues):\n",
        "                    vec = eigenvectors[:, i].unsqueeze(1)\n",
        "                    abs_val = abs(val.item())\n",
        "\n",
        "                    if abs_val > 1.0:\n",
        "                        # Reduce step size in high-curvature directions\n",
        "                        scale = 1.0 / np.sqrt(abs_val) * self.smoothing_factor\n",
        "                    elif abs_val < 0.2:\n",
        "                        # Boost step size in flat regions\n",
        "                        scale = 1.5\n",
        "                    else:\n",
        "                        scale = 1.0\n",
        "\n",
        "                    transform += (scale - 1.0) * torch.matmul(vec, vec.t())\n",
        "\n",
        "                # Store transformation matrix\n",
        "                param_info['transformation'] = transform.to(self.device)\n",
        "\n",
        "                # Store top eigenvalues for visualization if needed\n",
        "                top_vals = eigenvalues[:min(3, len(eigenvalues))].detach().cpu().numpy()\n",
        "                self._visualization_data['gradient_stats'][name].append({\n",
        "                    'step': self.steps,\n",
        "                    'eigenvalues': top_vals,\n",
        "                    'grad_norm': np.mean([n for n in param_info['gradient_norm_history']])\n",
        "                })\n",
        "\n",
        "                # Clean up to avoid memory leaks\n",
        "                del cov, eigenvalues, eigenvectors, transform\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error updating topology for {name}: {e}\")\n",
        "\n",
        "    def _update_topology_async(self) -> None:\n",
        "        \"\"\"Update topology asynchronously.\"\"\"\n",
        "        if self._topology_update_future and not self._topology_update_future.done():\n",
        "            return\n",
        "\n",
        "        self._topology_update_future = self.executor.submit(self._update_topology)\n",
        "\n",
        "    def step(self, loss_fn: Callable, x: torch.Tensor, y: torch.Tensor) -> Tuple[float, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Perform an optimization step.\n",
        "\n",
        "        Args:\n",
        "            loss_fn: Loss function\n",
        "            x: Input data\n",
        "            y: Target data\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (loss value, model output)\n",
        "        \"\"\"\n",
        "        # Initialize timers\n",
        "        timings = {}\n",
        "        batch_start = time.time()\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        self.model.train()\n",
        "\n",
        "        # Forward pass\n",
        "        forward_start = time.time()\n",
        "        with autocast('cuda'):\n",
        "            out = self.model(x)\n",
        "            loss = loss_fn(out, y)\n",
        "        forward_time = time.time() - forward_start\n",
        "        timings['forward_pass'] = forward_time\n",
        "\n",
        "        # Backward pass\n",
        "        backward_start = time.time()\n",
        "        self.scaler.scale(loss).backward()\n",
        "        backward_time = time.time() - backward_start\n",
        "        timings['backward_pass'] = backward_time\n",
        "\n",
        "        # Store and analyze gradients periodically\n",
        "        grad_start = time.time()\n",
        "        if self.steps % self.store_interval == 0:\n",
        "            for name, p in self.model.named_parameters():\n",
        "                if p.grad is not None and name in self.param_data:\n",
        "                    flat_grad = p.grad.detach().view(-1)\n",
        "\n",
        "                    # Update covariance with projected gradient\n",
        "                    projected_grad = self.param_data[name]['projector'].project(flat_grad)\n",
        "                    self.param_data[name]['covariance'].update(projected_grad)\n",
        "        grad_time = time.time() - grad_start\n",
        "        timings['gradient_processing'] = grad_time\n",
        "\n",
        "        # Update parameters\n",
        "        optim_start = time.time()\n",
        "        self.scaler.step(self.optimizer)\n",
        "        self.scaler.update()\n",
        "        optim_time = time.time() - optim_start\n",
        "        timings['optimizer_step'] = optim_time\n",
        "\n",
        "        # Track progress\n",
        "        self.steps += 1\n",
        "        loss_value = loss.item()\n",
        "        self.loss_history.append(loss_value)\n",
        "        self._visualization_data['loss_values'].append(loss_value)\n",
        "\n",
        "        # Print progress\n",
        "        if self.steps % 10 == 0 or self.steps == 1:\n",
        "            # Current memory usage\n",
        "            if torch.cuda.is_available():\n",
        "                mem_allocated = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
        "                mem_reserved = torch.cuda.memory_reserved() / (1024 * 1024)  # MB\n",
        "                mem_str = f\"GPU: {mem_allocated:.1f}MB / {mem_reserved:.1f}MB\"\n",
        "            else:\n",
        "                process = psutil.Process(os.getpid())\n",
        "                mem_usage = process.memory_info().rss / (1024 * 1024)  # MB\n",
        "                mem_str = f\"RAM: {mem_usage:.1f}MB\"\n",
        "\n",
        "            print(f\"Step {self.steps:4d} | Loss: {loss_value:.6f} | {mem_str} | \"\n",
        "                  f\"F: {forward_time:.4f}s, B: {backward_time:.4f}s, O: {optim_time:.4f}s\")\n",
        "\n",
        "        # Update topology information periodically\n",
        "        topo_time = 0\n",
        "        if self.steps % self.update_interval == 0:\n",
        "            topo_start = time.time()\n",
        "            self._update_topology_async()\n",
        "            topo_time = time.time() - topo_start\n",
        "            timings['topology_update'] = topo_time\n",
        "\n",
        "            # Log topology update\n",
        "            print(f\"🔄 Topology update at step {self.steps} took {topo_time:.4f}s\")\n",
        "\n",
        "        # Periodic cleanup\n",
        "        if self.steps % 100 == 0:\n",
        "            cleanup_start = time.time()\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            cleanup_time = time.time() - cleanup_start\n",
        "\n",
        "            print(f\"🧹 Memory cleanup at step {self.steps} took {cleanup_time:.4f}s\")\n",
        "\n",
        "        # Total batch time\n",
        "        batch_time = time.time() - batch_start\n",
        "        timings['batch_total'] = batch_time\n",
        "\n",
        "        return loss_value, out\n",
        "\n",
        "    def shutdown(self) -> None:\n",
        "        \"\"\"Clean up resources.\"\"\"\n",
        "        # Cancel any pending tasks\n",
        "        if self._topology_update_future and not self._topology_update_future.done():\n",
        "            self._topology_update_future.cancel()\n",
        "\n",
        "        # Shut down executor\n",
        "        self.executor.shutdown(wait=False)\n",
        "\n",
        "        # Clear memory\n",
        "        self.param_data.clear()\n",
        "        self._visualization_data.clear()\n",
        "\n",
        "        # Force garbage collection\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# VISUALIZATION\n",
        "# ===================================\n",
        "\n",
        "class ImprovedTALTVisualizer:\n",
        "    \"\"\"Visualization utilities for the Improved TALT optimizer.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_results(\n",
        "        std_res: Dict[str, List[float]],\n",
        "        talt_res: Dict[str, List[float]],\n",
        "        save_path: Optional[str] = None,\n",
        "        show: bool = False\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Plot comparative results between standard and TALT optimizers.\n",
        "\n",
        "        Args:\n",
        "            std_res: Results from standard optimizer\n",
        "            talt_res: Results from TALT optimizer\n",
        "            save_path: Path to save the figure\n",
        "            show: Whether to display the figure\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        titles = [\"Train Loss\", \"Test Loss\", \"Train Acc\", \"Test Acc\"]\n",
        "\n",
        "        for i, (k1, k2) in enumerate([(\"train_loss\", \"train_acc\"), (\"test_loss\", \"test_acc\")], 1):\n",
        "            plt.subplot(2, 2, i * 1 - 1)\n",
        "            plt.plot(std_res[k1], label=\"Standard\")\n",
        "            plt.plot(talt_res[k1], label=\"Improved TALT\")\n",
        "            plt.title(titles[(i - 1) * 2])\n",
        "            plt.xlabel(\"Epoch\")\n",
        "            plt.ylabel(\"Loss\" if \"loss\" in k1 else \"Accuracy (%)\")\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            plt.subplot(2, 2, i * 1)\n",
        "            plt.plot(std_res[k2], label=\"Standard\")\n",
        "            plt.plot(talt_res[k2], label=\"Improved TALT\")\n",
        "            plt.title(titles[(i - 1) * 2 + 1])\n",
        "            plt.xlabel(\"Epoch\")\n",
        "            plt.ylabel(\"Accuracy (%)\" if \"acc\" in k2 else \"Loss\")\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path)\n",
        "\n",
        "        if show:\n",
        "            plt.show()\n",
        "\n",
        "        # Close the figure to free memory\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def visualize_valley_detections(\n",
        "        talt_opt: ImprovedTALTOptimizer,\n",
        "        save_path: Optional[str] = None,\n",
        "        show: bool = False\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Visualize valley detections.\n",
        "\n",
        "        Args:\n",
        "            talt_opt: Improved TALT optimizer instance\n",
        "            save_path: Path to save the figure\n",
        "            show: Whether to display the figure\n",
        "        \"\"\"\n",
        "        if not talt_opt._visualization_data['valley_detections']:\n",
        "            logger.warning(\"No valley detection data available\")\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Plot loss history\n",
        "        loss_history = list(talt_opt.loss_history)\n",
        "        steps = range(len(loss_history))\n",
        "        plt.plot(steps, loss_history, label=\"Loss\", alpha=0.7)\n",
        "\n",
        "        # Mark valley detections\n",
        "        valley_steps = [det[0] for det in talt_opt._visualization_data['valley_detections']\n",
        "                      if det[0] < len(loss_history)]\n",
        "\n",
        "        for step in valley_steps:\n",
        "            plt.axvline(step, color=\"r\", linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "        # Add bifurcation points with labels\n",
        "        bifurcations = [b for b in talt_opt.bifurcations if b < len(loss_history)]\n",
        "        if bifurcations:\n",
        "            for i, step in enumerate(bifurcations):\n",
        "                if i < 5:  # Only label the first few for clarity\n",
        "                    plt.axvline(step, color=\"g\", linestyle=\"-\", alpha=0.5,\n",
        "                               label=\"Valley\" if i == 0 else \"\")\n",
        "                else:\n",
        "                    plt.axvline(step, color=\"g\", linestyle=\"-\", alpha=0.5)\n",
        "\n",
        "        plt.title(\"Loss Landscape with Valley Detections\")\n",
        "        plt.xlabel(\"Step\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path)\n",
        "\n",
        "        if show:\n",
        "            plt.show()\n",
        "\n",
        "        # Close the figure\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def visualize_gradient_statistics(\n",
        "        talt_opt: ImprovedTALTOptimizer,\n",
        "        save_path: Optional[str] = None,\n",
        "        show: bool = False\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Visualize gradient statistics.\n",
        "\n",
        "        Args:\n",
        "            talt_opt: Improved TALT optimizer instance\n",
        "            save_path: Path to save the figure\n",
        "            show: Whether to display the figure\n",
        "        \"\"\"\n",
        "        # Check if we have data to visualize\n",
        "        if not talt_opt._visualization_data['gradient_stats']:\n",
        "            logger.warning(\"No gradient statistics available\")\n",
        "            return\n",
        "\n",
        "        # Select a few parameters to visualize\n",
        "        param_names = list(talt_opt._visualization_data['gradient_stats'].keys())\n",
        "        if not param_names:\n",
        "            return\n",
        "\n",
        "        # Create subplots\n",
        "        fig, axes = plt.subplots(min(3, len(param_names)), 2, figsize=(14, 12))\n",
        "\n",
        "        # Handle case where we have only one parameter\n",
        "        if len(param_names) == 1:\n",
        "            axes = np.array([axes])\n",
        "\n",
        "        for i, name in enumerate(param_names[:3]):  # Show up to 3 parameters\n",
        "            stats = list(talt_opt._visualization_data['gradient_stats'][name])\n",
        "            if not stats:\n",
        "                continue\n",
        "\n",
        "            # Extract data\n",
        "            steps = [stat['step'] for stat in stats]\n",
        "            eigenvalues = [stat['eigenvalues'] for stat in stats]\n",
        "            grad_norms = [stat['grad_norm'] for stat in stats]\n",
        "\n",
        "            # Plot eigenvalues\n",
        "            for j in range(min(3, len(eigenvalues[0]))):\n",
        "                eig_j = [eig[j] for eig in eigenvalues]\n",
        "                axes[i, 0].plot(steps, eig_j, label=f\"λ{j+1}\")\n",
        "\n",
        "            axes[i, 0].set_title(f\"Eigenvalues: {name}\")\n",
        "            axes[i, 0].set_xlabel(\"Step\")\n",
        "            axes[i, 0].set_ylabel(\"Eigenvalue\")\n",
        "            axes[i, 0].legend()\n",
        "            axes[i, 0].grid(True, alpha=0.3)\n",
        "\n",
        "            # Plot gradient norms\n",
        "            axes[i, 1].plot(steps, grad_norms, label=\"Gradient Norm\")\n",
        "            axes[i, 1].set_title(f\"Gradient Norm: {name}\")\n",
        "            axes[i, 1].set_xlabel(\"Step\")\n",
        "            axes[i, 1].set_ylabel(\"Norm\")\n",
        "            axes[i, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path)\n",
        "\n",
        "        if show:\n",
        "            plt.show()\n",
        "\n",
        "        # Close the figure\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# TRAINING FUNCTIONS\n",
        "# ===================================\n",
        "\n",
        "def get_loaders(\n",
        "    dataset_name: str,\n",
        "    batch_size: int = 128\n",
        ") -> Tuple[DataLoader, DataLoader, int, int]:\n",
        "    \"\"\"\n",
        "    Get data loaders for the specified dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset_name: Name of the dataset (\"MNIST\" or \"CIFAR10\")\n",
        "        batch_size: Batch size\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (train_loader, test_loader, num_channels, image_size)\n",
        "    \"\"\"\n",
        "    if dataset_name.upper() == \"MNIST\":\n",
        "        num_channels = 1\n",
        "        image_size = 28\n",
        "        dataset_class = datasets.MNIST\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "    elif dataset_name.upper() == \"CIFAR10\":\n",
        "        num_channels = 3\n",
        "        image_size = 32\n",
        "        dataset_class = datasets.CIFAR10\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
        "\n",
        "    # Load datasets\n",
        "    train_dataset = dataset_class(\"./data\", train=True, download=True, transform=transform)\n",
        "    test_dataset = dataset_class(\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader, num_channels, image_size\n",
        "\n",
        "\n",
        "def _train_epoch(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    loss_fn: nn.Module,\n",
        "    optimizer: optim.Optimizer,\n",
        "    device: torch.device,\n",
        "    epoch: int\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Train for one epoch with a standard optimizer.\n",
        "\n",
        "    Args:\n",
        "        model: Model to train\n",
        "        loader: Data loader\n",
        "        loss_fn: Loss function\n",
        "        optimizer: Optimizer\n",
        "        device: Device to train on\n",
        "        epoch: Current epoch number\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (average loss, accuracy)\n",
        "    \"\"\"\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Timing statistics\n",
        "    forward_times = []\n",
        "    backward_times = []\n",
        "    optim_times = []\n",
        "    batch_times = []\n",
        "\n",
        "    # Print epoch header\n",
        "    print(f\"\\n{'='*20} STANDARD OPTIMIZER - EPOCH {epoch} {'='*20}\")\n",
        "    print(f\"Device: {device}, Batches: {len(loader)}, Batch size: {loader.batch_size}\")\n",
        "    print_memory_usage(\"Initial \")\n",
        "\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        batch_start = time.time()\n",
        "\n",
        "        # Transfer data to device\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        forward_start = time.time()\n",
        "        outputs = model(x)\n",
        "        loss = loss_fn(outputs, y)\n",
        "        forward_time = time.time() - forward_start\n",
        "        forward_times.append(forward_time)\n",
        "\n",
        "        # Backward pass\n",
        "        backward_start = time.time()\n",
        "        loss.backward()\n",
        "        backward_time = time.time() - backward_start\n",
        "        backward_times.append(backward_time)\n",
        "\n",
        "        # Update parameters\n",
        "        optim_start = time.time()\n",
        "        optimizer.step()\n",
        "        optim_time = time.time() - optim_start\n",
        "        optim_times.append(optim_time)\n",
        "\n",
        "        # Update metrics\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += y.size(0)\n",
        "        correct += predicted.eq(y).sum().item()\n",
        "\n",
        "        # Record batch time\n",
        "        batch_time = time.time() - batch_start\n",
        "        batch_times.append(batch_time)\n",
        "\n",
        "        # Detailed logging every few batches\n",
        "        if idx % 20 == 0 or idx == len(loader) - 1:\n",
        "            progress = idx / len(loader) * 100\n",
        "            accuracy = 100.0 * correct / total\n",
        "            avg_loss = total_loss / (idx + 1)\n",
        "\n",
        "            # Current memory usage\n",
        "            if torch.cuda.is_available():\n",
        "                mem_allocated = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
        "                mem_str = f\"GPU: {mem_allocated:.1f}MB\"\n",
        "            else:\n",
        "                process = psutil.Process(os.getpid())\n",
        "                mem_usage = process.memory_info().rss / (1024 * 1024)  # MB\n",
        "                mem_str = f\"RAM: {mem_usage:.1f}MB\"\n",
        "\n",
        "            print(f\"Batch {idx:4d}/{len(loader):4d} ({progress:5.1f}%) | \"\n",
        "                  f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}% | \"\n",
        "                  f\"{mem_str} | Batch time: {batch_time:.4f}s\")\n",
        "\n",
        "        # Free memory every few batches\n",
        "        if idx % 20 == 0 and idx > 0:\n",
        "            del outputs, predicted\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Calculate final metrics\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    avg_forward = sum(forward_times) / len(forward_times)\n",
        "    avg_backward = sum(backward_times) / len(backward_times)\n",
        "    avg_optim = sum(optim_times) / len(optim_times)\n",
        "    avg_batch = sum(batch_times) / len(batch_times)\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f\"\\n{'-'*20} STANDARD OPTIMIZER - SUMMARY {'-'*20}\")\n",
        "    print(f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Time: {epoch_time:.2f}s total, {avg_batch:.4f}s per batch\")\n",
        "    print(f\"  - Forward: {avg_forward:.4f}s, Backward: {avg_backward:.4f}s, Optimizer: {avg_optim:.4f}s\")\n",
        "    print_memory_usage(\"Final \")\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def _train_epoch_improved_talt(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    loss_fn: nn.Module,\n",
        "    optimizer: ImprovedTALTOptimizer,\n",
        "    device: torch.device,\n",
        "    epoch: int\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Train for one epoch with the improved TALT optimizer.\n",
        "\n",
        "    Args:\n",
        "        model: Model to train\n",
        "        loader: Data loader\n",
        "        loss_fn: Loss function\n",
        "        optimizer: Improved TALT optimizer\n",
        "        device: Device to train on\n",
        "        epoch: Current epoch number\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (average loss, accuracy)\n",
        "    \"\"\"\n",
        "    # Initialize tracking\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batch_times = []\n",
        "\n",
        "    # Create performance tracker\n",
        "    perf_tracker = PerformanceTracker()\n",
        "\n",
        "    # Print epoch header\n",
        "    print(f\"\\n{'='*20} EPOCH {epoch} TRAINING {'='*20}\")\n",
        "    print(f\"Device: {device}, Batches: {len(loader)}, Batch size: {loader.batch_size}\")\n",
        "    print_memory_usage(\"Initial \")\n",
        "\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    # Process in smaller chunks to avoid memory buildup\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        batch_start = time.time()\n",
        "\n",
        "        try:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # Perform optimization step (timing is handled inside)\n",
        "            loss, outputs = optimizer.step(loss_fn, x, y)\n",
        "\n",
        "            # Update metrics\n",
        "            total_loss += loss\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += y.size(0)\n",
        "            correct += predicted.eq(y).sum().item()\n",
        "\n",
        "            # Record batch time\n",
        "            batch_time = time.time() - batch_start\n",
        "            batch_times.append(batch_time)\n",
        "\n",
        "            # Detailed logging every few batches\n",
        "            if idx % 20 == 0:\n",
        "                progress = idx / len(loader) * 100\n",
        "                accuracy = 100.0 * correct / total if total > 0 else 0.0\n",
        "                avg_loss = total_loss / (idx + 1)\n",
        "\n",
        "                print(f\"Batch {idx:4d}/{len(loader):4d} ({progress:5.1f}%) | \"\n",
        "                      f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}% | \"\n",
        "                      f\"Batch time: {batch_time:.4f}s\")\n",
        "\n",
        "                # Record memory usage\n",
        "                perf_tracker.record_memory()\n",
        "\n",
        "            # Periodically free up memory\n",
        "            if idx % 20 == 0:\n",
        "                # Move tensors back to CPU or delete them\n",
        "                del outputs, predicted\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in improved TALT training step: {e}\")\n",
        "            # Continue training despite errors\n",
        "            continue\n",
        "\n",
        "    # Calculate final metrics\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = 100.0 * correct / total if total > 0 else 0.0\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    avg_batch_time = sum(batch_times) / len(batch_times) if batch_times else 0\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f\"\\n{'-'*20} EPOCH {epoch} SUMMARY {'-'*20}\")\n",
        "    print(f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Time: {epoch_time:.2f}s total, {avg_batch_time:.4f}s per batch\")\n",
        "    print_memory_usage(\"Final \")\n",
        "    perf_tracker.print_summary()\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def _evaluate(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    loss_fn: nn.Module,\n",
        "    device: torch.device\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Evaluate the model.\n",
        "\n",
        "    Args:\n",
        "        model: Model to evaluate\n",
        "        loader: Data loader\n",
        "        loss_fn: Loss function\n",
        "        device: Device to evaluate on\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (average loss, accuracy)\n",
        "    \"\"\"\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batch_times = []\n",
        "\n",
        "    # Print evaluation header\n",
        "    print(f\"\\n{'='*20} EVALUATION {'='*20}\")\n",
        "    print(f\"Device: {device}, Batches: {len(loader)}, Batch size: {loader.batch_size}\")\n",
        "\n",
        "    eval_start = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (x, y) in enumerate(loader):\n",
        "            batch_start = time.time()\n",
        "\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(x)\n",
        "            loss = loss_fn(outputs, y)\n",
        "\n",
        "            # Update metrics\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += y.size(0)\n",
        "            correct += predicted.eq(y).sum().item()\n",
        "\n",
        "            # Record batch time\n",
        "            batch_time = time.time() - batch_start\n",
        "            batch_times.append(batch_time)\n",
        "\n",
        "            # Detailed logging every few batches\n",
        "            if idx % 50 == 0 and idx > 0:\n",
        "                progress = idx / len(loader) * 100\n",
        "                accuracy = 100.0 * correct / total\n",
        "                avg_loss = total_loss / (idx + 1)\n",
        "\n",
        "                print(f\"Batch {idx:4d}/{len(loader):4d} ({progress:5.1f}%) | \"\n",
        "                      f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}% | \"\n",
        "                      f\"Batch time: {batch_time:.4f}s\")\n",
        "\n",
        "            # Free memory every few batches\n",
        "            if idx % 50 == 0 and idx > 0:\n",
        "                del outputs, predicted\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    # Calculate final metrics\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    eval_time = time.time() - eval_start\n",
        "    avg_batch_time = sum(batch_times) / len(batch_times) if batch_times else 0\n",
        "\n",
        "    # Print evaluation summary\n",
        "    print(f\"\\n{'-'*20} EVALUATION SUMMARY {'-'*20}\")\n",
        "    print(f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Time: {eval_time:.2f}s total, {avg_batch_time:.4f}s per batch\")\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def train_and_evaluate_improved(\n",
        "    dataset_name: str,\n",
        "    epochs: int = 5,\n",
        "    batch_size: int = 16,\n",
        "    device: Union[str, torch.device] = \"cuda\",\n",
        "    visualize: bool = False,\n",
        "    save_plots: bool = True,\n",
        "    plots_dir: str = \"./plots\"\n",
        ") -> Tuple[Dict[str, Dict[str, List[float]]], ImprovedTALTOptimizer]:\n",
        "    \"\"\"\n",
        "    Train and evaluate models with standard and improved TALT optimizers.\n",
        "\n",
        "    Args:\n",
        "        dataset_name: Name of the dataset (\"MNIST\" or \"CIFAR10\")\n",
        "        epochs: Number of epochs to train\n",
        "        batch_size: Batch size\n",
        "        device: Device to train on\n",
        "        visualize: Whether to display visualizations\n",
        "        save_plots: Whether to save plots to disk\n",
        "        plots_dir: Directory to save plots\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (results dictionary, ImprovedTALTOptimizer instance)\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*30} TRAINING ON {dataset_name} {'='*30}\")\n",
        "    print(f\"Configuration: epochs={epochs}, batch_size={batch_size}, device={device}\")\n",
        "\n",
        "    # Create plots directory if needed\n",
        "    if save_plots and not os.path.exists(plots_dir):\n",
        "        os.makedirs(plots_dir)\n",
        "        print(f\"Created plots directory: {plots_dir}\")\n",
        "\n",
        "    # Ensure device is a torch.device\n",
        "    device = device if isinstance(device, torch.device) else torch.device(device)\n",
        "\n",
        "    # Initialize timers\n",
        "    total_start_time = time.time()\n",
        "    data_loading_start = time.time()\n",
        "\n",
        "    # Get data loaders\n",
        "    print(\"Loading datasets...\")\n",
        "    train_loader, test_loader, num_channels, image_size = get_loaders(dataset_name, batch_size)\n",
        "    data_loading_time = time.time() - data_loading_start\n",
        "    print(f\"Datasets loaded in {data_loading_time:.2f}s\")\n",
        "    print(f\"Train set: {len(train_loader.dataset)} samples, {len(train_loader)} batches\")\n",
        "    print(f\"Test set: {len(test_loader.dataset)} samples, {len(test_loader)} batches\")\n",
        "\n",
        "    # Print initial memory usage\n",
        "    print_memory_usage(\"After data loading \")\n",
        "\n",
        "    # Initialize models\n",
        "    print(\"Initializing models...\")\n",
        "    model_init_start = time.time()\n",
        "    model_std = SimpleCNN(num_channels=num_channels, image_size=image_size).to(device)\n",
        "    model_talt = SimpleCNN(num_channels=num_channels, image_size=image_size).to(device)\n",
        "    model_init_time = time.time() - model_init_start\n",
        "    print(f\"Models initialized in {model_init_time:.2f}s\")\n",
        "\n",
        "    # Count parameters\n",
        "    std_params = sum(p.numel() for p in model_std.parameters())\n",
        "    talt_params = sum(p.numel() for p in model_talt.parameters())\n",
        "    print(f\"Standard model parameters: {std_params:,}\")\n",
        "    print(f\"TALT model parameters: {talt_params:,}\")\n",
        "\n",
        "    # Loss function\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimizers\n",
        "    print(\"Setting up optimizers...\")\n",
        "    opt_init_start = time.time()\n",
        "    opt_std = optim.SGD(model_std.parameters(), lr=0.01, momentum=0.9)\n",
        "    opt_talt = ImprovedTALTOptimizer(\n",
        "        model_talt,\n",
        "        optim.SGD,\n",
        "        lr=0.01,\n",
        "        projection_dim=32,  # Reduce dimensions for efficiency\n",
        "        memory_size=10,\n",
        "        update_interval=20,\n",
        "        valley_strength=0.2,\n",
        "        smoothing_factor=0.3,\n",
        "        grad_store_interval=5,\n",
        "        device=device,\n",
        "        max_stored_steps=500,\n",
        "        max_visualization_points=100\n",
        "    )\n",
        "    opt_init_time = time.time() - opt_init_start\n",
        "    print(f\"Optimizers set up in {opt_init_time:.2f}s\")\n",
        "\n",
        "    # Print initial memory usage\n",
        "    print_memory_usage(\"Before training \")\n",
        "\n",
        "    # Results tracking\n",
        "    results = {\n",
        "        \"standard\": {\"train_loss\": [], \"test_loss\": [], \"train_acc\": [], \"test_acc\": []},\n",
        "        \"talt\": {\"train_loss\": [], \"test_loss\": [], \"train_acc\": [], \"test_acc\": []},\n",
        "    }\n",
        "\n",
        "    # Training loop\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"STARTING TRAINING FOR {epochs} EPOCHS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # Train standard model\n",
        "        print(f\"\\n{'-'*25} Standard Model: Epoch {epoch}/{epochs} {'-'*25}\")\n",
        "        model_std.train()\n",
        "        with Timer(\"Standard model training\"):\n",
        "            std_train_loss, std_train_acc = _train_epoch(\n",
        "                model_std, train_loader, loss_fn, opt_std, device, epoch\n",
        "            )\n",
        "        results[\"standard\"][\"train_loss\"].append(std_train_loss)\n",
        "        results[\"standard\"][\"train_acc\"].append(std_train_acc)\n",
        "\n",
        "        # Train improved TALT model\n",
        "        print(f\"\\n{'-'*25} Improved TALT Model: Epoch {epoch}/{epochs} {'-'*25}\")\n",
        "        model_talt.train()\n",
        "        with Timer(\"TALT model training\"):\n",
        "            talt_train_loss, talt_train_acc = _train_epoch_improved_talt(\n",
        "                model_talt, train_loader, loss_fn, opt_talt, device, epoch\n",
        "            )\n",
        "        results[\"talt\"][\"train_loss\"].append(talt_train_loss)\n",
        "        results[\"talt\"][\"train_acc\"].append(talt_train_acc)\n",
        "\n",
        "        # Memory cleanup\n",
        "        print(\"\\nCleaning up memory after training...\")\n",
        "        with Timer(\"Memory cleanup\"):\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "        print_memory_usage(\"After training \")\n",
        "\n",
        "        # Evaluate standard model\n",
        "        print(f\"\\n{'-'*25} Standard Model: Evaluation {'-'*25}\")\n",
        "        model_std.eval()\n",
        "        with Timer(\"Standard model evaluation\"):\n",
        "            std_test_loss, std_test_acc = _evaluate(\n",
        "                model_std, test_loader, loss_fn, device\n",
        "            )\n",
        "        results[\"standard\"][\"test_loss\"].append(std_test_loss)\n",
        "        results[\"standard\"][\"test_acc\"].append(std_test_acc)\n",
        "\n",
        "        # Evaluate TALT model\n",
        "        print(f\"\\n{'-'*25} Improved TALT Model: Evaluation {'-'*25}\")\n",
        "        model_talt.eval()\n",
        "        with Timer(\"TALT model evaluation\"):\n",
        "            talt_test_loss, talt_test_acc = _evaluate(\n",
        "                model_talt, test_loader, loss_fn, device\n",
        "            )\n",
        "        results[\"talt\"][\"test_loss\"].append(talt_test_loss)\n",
        "        results[\"talt\"][\"test_acc\"].append(talt_test_acc)\n",
        "\n",
        "        # Epoch summary\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        print(f\"\\n{'-'*25} EPOCH {epoch} SUMMARY {'-'*25}\")\n",
        "        print(f\"Time: {epoch_time:.2f}s\")\n",
        "        print(\"Standard Model:\")\n",
        "        print(f\"  - Train Loss: {std_train_loss:.6f}, Accuracy: {std_train_acc:.2f}%\")\n",
        "        print(f\"  - Test Loss:  {std_test_loss:.6f}, Accuracy: {std_test_acc:.2f}%\")\n",
        "        print(\"Improved TALT Model:\")\n",
        "        print(f\"  - Train Loss: {talt_train_loss:.6f}, Accuracy: {talt_train_acc:.2f}%\")\n",
        "        print(f\"  - Test Loss:  {talt_test_loss:.6f}, Accuracy: {talt_test_acc:.2f}%\")\n",
        "\n",
        "        # Print performance comparison\n",
        "        std_perf = std_test_acc / std_train_acc if std_train_acc > 0 else 0\n",
        "        talt_perf = talt_test_acc / talt_train_acc if talt_train_acc > 0 else 0\n",
        "\n",
        "        if talt_test_acc > std_test_acc:\n",
        "            diff = talt_test_acc - std_test_acc\n",
        "            print(f\"\\n📈 TALT outperforms standard by {diff:.2f}% on test accuracy\")\n",
        "\n",
        "        if talt_perf > std_perf:\n",
        "            print(f\"📈 TALT shows better generalization (test/train ratio: {talt_perf:.3f} vs {std_perf:.3f})\")\n",
        "\n",
        "        # Memory cleanup after each epoch\n",
        "        print(\"\\nCleaning up memory after epoch...\")\n",
        "        with Timer(\"Memory cleanup\"):\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "        print_memory_usage(\"After epoch \")\n",
        "\n",
        "    # Training complete\n",
        "    total_time = time.time() - total_start_time\n",
        "\n",
        "    print(f\"\\n{'='*30} TRAINING COMPLETED {'='*30}\")\n",
        "    print(f\"Total training time: {total_time:.2f}s\")\n",
        "    print(f\"Final results on {dataset_name}:\")\n",
        "    print(f\"Standard Model: {std_test_acc:.2f}% test accuracy\")\n",
        "    print(f\"Improved TALT: {talt_test_acc:.2f}% test accuracy\")\n",
        "\n",
        "    if talt_test_acc > std_test_acc:\n",
        "        print(f\"✅ Improved TALT outperformed standard by {talt_test_acc - std_test_acc:.2f}%\")\n",
        "    else:\n",
        "        print(f\"❌ Standard model outperformed Improved TALT by {std_test_acc - talt_test_acc:.2f}%\")\n",
        "\n",
        "    # Visualize results after training completes\n",
        "    if visualize or save_plots:\n",
        "        print(\"\\nGenerating visualizations...\")\n",
        "\n",
        "        # Define save paths if saving plots\n",
        "        results_path = f\"{plots_dir}/{dataset_name}_results.png\" if save_plots else None\n",
        "        valleys_path = f\"{plots_dir}/{dataset_name}_valleys.png\" if save_plots else None\n",
        "        gradients_path = f\"{plots_dir}/{dataset_name}_gradients.png\" if save_plots else None\n",
        "\n",
        "        # Plot results with memory cleanup between visualizations\n",
        "        with Timer(\"Plotting comparative results\"):\n",
        "            ImprovedTALTVisualizer.plot_results(\n",
        "                results[\"standard\"], results[\"talt\"],\n",
        "                save_path=results_path, show=visualize\n",
        "            )\n",
        "        gc.collect()\n",
        "\n",
        "        with Timer(\"Plotting valley detections\"):\n",
        "            ImprovedTALTVisualizer.visualize_valley_detections(\n",
        "                opt_talt, save_path=valleys_path, show=visualize\n",
        "            )\n",
        "        gc.collect()\n",
        "\n",
        "        with Timer(\"Plotting gradient statistics\"):\n",
        "            ImprovedTALTVisualizer.visualize_gradient_statistics(\n",
        "                opt_talt, save_path=gradients_path, show=visualize\n",
        "            )\n",
        "\n",
        "        if save_plots:\n",
        "            print(f\"Plots saved to {plots_dir}\")\n",
        "\n",
        "    # Clean up resources\n",
        "    print(\"\\nShutting down optimizers and cleaning up...\")\n",
        "    opt_talt.shutdown()\n",
        "\n",
        "    # Final memory cleanup\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    print_memory_usage(\"Final \")\n",
        "\n",
        "    return results, opt_talt\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# MAIN ENTRY POINT\n",
        "# ===================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Check for CUDA availability\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logger.info(f\"Using device: {device}\")\n",
        "\n",
        "    # Set torch memory management options\n",
        "    if torch.cuda.is_available():\n",
        "        # Clear cache\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Limit memory usage\n",
        "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128,garbage_collection_threshold:0.6'\n",
        "\n",
        "        try:\n",
        "            # Limit GPU memory fraction\n",
        "            torch.cuda.set_per_process_memory_fraction(0.5)\n",
        "        except Exception:\n",
        "            logger.info(\"Per-process memory fraction setting not available\")\n",
        "\n",
        "    try:\n",
        "        # Train on MNIST with improved optimizer\n",
        "        logger.info(\"Starting MNIST training with improved TALT optimizer\")\n",
        "        train_and_evaluate_improved(\n",
        "            \"CIFAR10\",\n",
        "            epochs=3,\n",
        "            batch_size=16,\n",
        "            device=device,\n",
        "            visualize=False,\n",
        "            save_plots=True,\n",
        "            plots_dir=\"./plots/improved_mnist\"\n",
        "        )\n",
        "\n",
        "        # Clear memory before starting CIFAR10\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        logger.info(\"Memory cleared successfully after MNIST\")\n",
        "\n",
        "        # Train on CIFAR10 if MNIST succeeds\n",
        "        logger.info(\"Starting CIFAR10 training with improved TALT optimizer\")\n",
        "        train_and_evaluate_improved(\n",
        "            \"CIFAR10\",\n",
        "            epochs=3,\n",
        "            batch_size=16,\n",
        "            device=device,\n",
        "            visualize=False,\n",
        "            save_plots=True,\n",
        "            plots_dir=\"./plots/improved_cifar10\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during training: {e}\")\n",
        "        # Clean up on error\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1CgtISsnhHmu",
        "outputId": "7c372c6b-538a-4c46-f94b-ef0a00131e45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================== TRAINING ON CIFAR10 ==============================\n",
            "Configuration: epochs=3, batch_size=16, device=cuda\n",
            "Loading datasets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:06<00:00, 27.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets loaded in 11.38s\n",
            "Train set: 50000 samples, 3125 batches\n",
            "Test set: 10000 samples, 625 batches\n",
            "🔄 After data loading Memory - RAM: 8173.4MB, GPU: 27.6MB allocated, 44.0MB reserved\n",
            "Initializing models...\n",
            "Models initialized in 0.04s\n",
            "Standard model parameters: 545,290\n",
            "TALT model parameters: 545,290\n",
            "Setting up optimizers...\n",
            "Optimizers set up in 2.01s\n",
            "🔄 Before training Memory - RAM: 8237.5MB, GPU: 32.5MB allocated, 44.0MB reserved\n",
            "\n",
            "======================================================================\n",
            "STARTING TRAINING FOR 3 EPOCHS\n",
            "======================================================================\n",
            "\n",
            "------------------------- Standard Model: Epoch 1/3 -------------------------\n",
            "\n",
            "==================== STANDARD OPTIMIZER - EPOCH 1 ====================\n",
            "Device: cuda, Batches: 3125, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 8237.5MB, GPU: 32.5MB allocated, 44.0MB reserved\n",
            "Batch    0/3125 (  0.0%) | Loss: 2.364260 | Accuracy: 0.00% | GPU: 37.6MB | Batch time: 0.0511s\n",
            "Batch   20/3125 (  0.6%) | Loss: 2.420816 | Accuracy: 15.18% | GPU: 36.8MB | Batch time: 0.0095s\n",
            "Batch   40/3125 (  1.3%) | Loss: 2.315466 | Accuracy: 17.23% | GPU: 36.8MB | Batch time: 0.0050s\n",
            "Batch   60/3125 (  1.9%) | Loss: 2.291656 | Accuracy: 16.60% | GPU: 36.8MB | Batch time: 0.0039s\n",
            "Batch   80/3125 (  2.6%) | Loss: 2.272853 | Accuracy: 16.13% | GPU: 36.8MB | Batch time: 0.0036s\n",
            "Batch  100/3125 (  3.2%) | Loss: 2.265035 | Accuracy: 15.78% | GPU: 36.8MB | Batch time: 0.0041s\n",
            "Batch  120/3125 (  3.8%) | Loss: 2.257242 | Accuracy: 15.81% | GPU: 36.8MB | Batch time: 0.0153s\n",
            "Batch  140/3125 (  4.5%) | Loss: 2.259866 | Accuracy: 15.16% | GPU: 36.8MB | Batch time: 0.0048s\n",
            "Batch  160/3125 (  5.1%) | Loss: 2.252768 | Accuracy: 15.49% | GPU: 36.8MB | Batch time: 0.0040s\n",
            "Batch  180/3125 (  5.8%) | Loss: 2.258245 | Accuracy: 15.06% | GPU: 36.8MB | Batch time: 0.0040s\n",
            "Batch  200/3125 (  6.4%) | Loss: 2.256086 | Accuracy: 14.74% | GPU: 36.8MB | Batch time: 0.0056s\n",
            "Batch  220/3125 (  7.0%) | Loss: 2.255681 | Accuracy: 14.99% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch  240/3125 (  7.7%) | Loss: 2.255704 | Accuracy: 15.15% | GPU: 36.8MB | Batch time: 0.0058s\n",
            "Batch  260/3125 (  8.3%) | Loss: 2.251352 | Accuracy: 15.11% | GPU: 36.8MB | Batch time: 0.0036s\n",
            "Batch  280/3125 (  9.0%) | Loss: 2.252680 | Accuracy: 14.90% | GPU: 36.8MB | Batch time: 0.0105s\n",
            "Batch  300/3125 (  9.6%) | Loss: 2.253492 | Accuracy: 14.53% | GPU: 36.8MB | Batch time: 0.0071s\n",
            "Batch  320/3125 ( 10.2%) | Loss: 2.256416 | Accuracy: 14.33% | GPU: 36.8MB | Batch time: 0.0092s\n",
            "Batch  340/3125 ( 10.9%) | Loss: 2.258602 | Accuracy: 14.19% | GPU: 36.8MB | Batch time: 0.0083s\n",
            "Batch  360/3125 ( 11.5%) | Loss: 2.257899 | Accuracy: 14.18% | GPU: 36.8MB | Batch time: 0.0053s\n",
            "Batch  380/3125 ( 12.2%) | Loss: 2.259787 | Accuracy: 13.98% | GPU: 36.8MB | Batch time: 0.0097s\n",
            "Batch  400/3125 ( 12.8%) | Loss: 2.259409 | Accuracy: 14.07% | GPU: 36.8MB | Batch time: 0.0041s\n",
            "Batch  420/3125 ( 13.4%) | Loss: 2.258615 | Accuracy: 14.10% | GPU: 36.8MB | Batch time: 0.0036s\n",
            "Batch  440/3125 ( 14.1%) | Loss: 2.258797 | Accuracy: 14.17% | GPU: 36.8MB | Batch time: 0.0036s\n",
            "Batch  460/3125 ( 14.7%) | Loss: 2.256343 | Accuracy: 14.21% | GPU: 36.8MB | Batch time: 0.0035s\n",
            "Batch  480/3125 ( 15.4%) | Loss: 2.254874 | Accuracy: 14.33% | GPU: 36.8MB | Batch time: 0.0035s\n",
            "Batch  500/3125 ( 16.0%) | Loss: 2.255346 | Accuracy: 14.30% | GPU: 36.8MB | Batch time: 0.0040s\n",
            "Batch  520/3125 ( 16.6%) | Loss: 2.258327 | Accuracy: 14.23% | GPU: 36.8MB | Batch time: 0.0085s\n",
            "Batch  540/3125 ( 17.3%) | Loss: 2.258048 | Accuracy: 14.24% | GPU: 36.8MB | Batch time: 0.0109s\n",
            "Batch  560/3125 ( 17.9%) | Loss: 2.258411 | Accuracy: 14.25% | GPU: 36.8MB | Batch time: 0.0071s\n",
            "Batch  580/3125 ( 18.6%) | Loss: 2.257294 | Accuracy: 14.33% | GPU: 36.8MB | Batch time: 0.0042s\n",
            "Batch  600/3125 ( 19.2%) | Loss: 2.256102 | Accuracy: 14.39% | GPU: 36.8MB | Batch time: 0.0041s\n",
            "Batch  620/3125 ( 19.8%) | Loss: 2.255354 | Accuracy: 14.29% | GPU: 36.8MB | Batch time: 0.0039s\n",
            "Batch  640/3125 ( 20.5%) | Loss: 2.254224 | Accuracy: 14.28% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch  660/3125 ( 21.1%) | Loss: 2.253663 | Accuracy: 14.33% | GPU: 36.8MB | Batch time: 0.0035s\n",
            "Batch  680/3125 ( 21.8%) | Loss: 2.251340 | Accuracy: 14.33% | GPU: 36.8MB | Batch time: 0.0035s\n",
            "Batch  700/3125 ( 22.4%) | Loss: 2.249759 | Accuracy: 14.34% | GPU: 36.8MB | Batch time: 0.0046s\n",
            "Batch  720/3125 ( 23.0%) | Loss: 2.248967 | Accuracy: 14.32% | GPU: 36.8MB | Batch time: 0.0041s\n",
            "Batch  740/3125 ( 23.7%) | Loss: 2.248944 | Accuracy: 14.39% | GPU: 36.8MB | Batch time: 0.0042s\n",
            "Batch  760/3125 ( 24.3%) | Loss: 2.246953 | Accuracy: 14.47% | GPU: 36.8MB | Batch time: 0.0046s\n",
            "Batch  780/3125 ( 25.0%) | Loss: 2.246377 | Accuracy: 14.50% | GPU: 36.8MB | Batch time: 0.0048s\n",
            "Batch  800/3125 ( 25.6%) | Loss: 2.245496 | Accuracy: 14.54% | GPU: 36.8MB | Batch time: 0.0046s\n",
            "Batch  820/3125 ( 26.2%) | Loss: 2.245577 | Accuracy: 14.49% | GPU: 36.8MB | Batch time: 0.0042s\n",
            "Batch  840/3125 ( 26.9%) | Loss: 2.245685 | Accuracy: 14.54% | GPU: 36.8MB | Batch time: 0.0053s\n",
            "Batch  860/3125 ( 27.5%) | Loss: 2.245017 | Accuracy: 14.58% | GPU: 36.8MB | Batch time: 0.0054s\n",
            "Batch  880/3125 ( 28.2%) | Loss: 2.244563 | Accuracy: 14.54% | GPU: 36.8MB | Batch time: 0.0046s\n",
            "Batch  900/3125 ( 28.8%) | Loss: 2.244577 | Accuracy: 14.44% | GPU: 36.8MB | Batch time: 0.0092s\n",
            "Batch  920/3125 ( 29.4%) | Loss: 2.243804 | Accuracy: 14.47% | GPU: 36.8MB | Batch time: 0.0041s\n",
            "Batch  940/3125 ( 30.1%) | Loss: 2.242362 | Accuracy: 14.49% | GPU: 36.8MB | Batch time: 0.0040s\n",
            "Batch  960/3125 ( 30.7%) | Loss: 2.241224 | Accuracy: 14.54% | GPU: 36.8MB | Batch time: 0.0050s\n",
            "Batch  980/3125 ( 31.4%) | Loss: 2.239329 | Accuracy: 14.62% | GPU: 36.8MB | Batch time: 0.0042s\n",
            "Batch 1000/3125 ( 32.0%) | Loss: 2.237551 | Accuracy: 14.67% | GPU: 36.8MB | Batch time: 0.0080s\n",
            "Batch 1020/3125 ( 32.6%) | Loss: 2.234380 | Accuracy: 14.67% | GPU: 36.8MB | Batch time: 0.0142s\n",
            "Batch 1040/3125 ( 33.3%) | Loss: 2.232615 | Accuracy: 14.72% | GPU: 36.8MB | Batch time: 0.0064s\n",
            "Batch 1060/3125 ( 33.9%) | Loss: 2.229499 | Accuracy: 14.73% | GPU: 36.8MB | Batch time: 0.0331s\n",
            "Batch 1080/3125 ( 34.6%) | Loss: 2.226742 | Accuracy: 14.74% | GPU: 36.8MB | Batch time: 0.0030s\n",
            "Batch 1100/3125 ( 35.2%) | Loss: 2.224333 | Accuracy: 14.84% | GPU: 36.8MB | Batch time: 0.0032s\n",
            "Batch 1120/3125 ( 35.8%) | Loss: 2.222791 | Accuracy: 14.90% | GPU: 36.8MB | Batch time: 0.0031s\n",
            "Batch 1140/3125 ( 36.5%) | Loss: 2.221368 | Accuracy: 14.95% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 1160/3125 ( 37.1%) | Loss: 2.219817 | Accuracy: 15.00% | GPU: 36.8MB | Batch time: 0.0026s\n",
            "Batch 1180/3125 ( 37.8%) | Loss: 2.218040 | Accuracy: 15.06% | GPU: 36.8MB | Batch time: 0.0051s\n",
            "Batch 1200/3125 ( 38.4%) | Loss: 2.217468 | Accuracy: 15.10% | GPU: 36.8MB | Batch time: 0.0042s\n",
            "Batch 1220/3125 ( 39.0%) | Loss: 2.216126 | Accuracy: 15.15% | GPU: 36.8MB | Batch time: 0.0154s\n",
            "Batch 1240/3125 ( 39.7%) | Loss: 2.215575 | Accuracy: 15.16% | GPU: 36.8MB | Batch time: 0.0076s\n",
            "Batch 1260/3125 ( 40.3%) | Loss: 2.214494 | Accuracy: 15.21% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 1280/3125 ( 41.0%) | Loss: 2.213206 | Accuracy: 15.25% | GPU: 36.8MB | Batch time: 0.0048s\n",
            "Batch 1300/3125 ( 41.6%) | Loss: 2.212125 | Accuracy: 15.34% | GPU: 36.8MB | Batch time: 0.0039s\n",
            "Batch 1320/3125 ( 42.2%) | Loss: 2.210510 | Accuracy: 15.41% | GPU: 36.8MB | Batch time: 0.0043s\n",
            "Batch 1340/3125 ( 42.9%) | Loss: 2.208627 | Accuracy: 15.51% | GPU: 36.8MB | Batch time: 0.0057s\n",
            "Batch 1360/3125 ( 43.5%) | Loss: 2.206547 | Accuracy: 15.57% | GPU: 36.8MB | Batch time: 0.0048s\n",
            "Batch 1380/3125 ( 44.2%) | Loss: 2.205067 | Accuracy: 15.63% | GPU: 36.8MB | Batch time: 0.0054s\n",
            "Batch 1400/3125 ( 44.8%) | Loss: 2.204382 | Accuracy: 15.73% | GPU: 36.8MB | Batch time: 0.0075s\n",
            "Batch 1420/3125 ( 45.4%) | Loss: 2.204501 | Accuracy: 15.75% | GPU: 36.8MB | Batch time: 0.0093s\n",
            "Batch 1440/3125 ( 46.1%) | Loss: 2.203344 | Accuracy: 15.79% | GPU: 36.8MB | Batch time: 0.0035s\n",
            "Batch 1460/3125 ( 46.7%) | Loss: 2.203030 | Accuracy: 15.82% | GPU: 36.8MB | Batch time: 0.0048s\n",
            "Batch 1480/3125 ( 47.4%) | Loss: 2.200816 | Accuracy: 15.85% | GPU: 36.8MB | Batch time: 0.0043s\n",
            "Batch 1500/3125 ( 48.0%) | Loss: 2.199389 | Accuracy: 15.86% | GPU: 36.8MB | Batch time: 0.0039s\n",
            "Batch 1520/3125 ( 48.6%) | Loss: 2.197804 | Accuracy: 15.92% | GPU: 36.8MB | Batch time: 0.0046s\n",
            "Batch 1540/3125 ( 49.3%) | Loss: 2.196312 | Accuracy: 15.98% | GPU: 36.8MB | Batch time: 0.0145s\n",
            "Batch 1560/3125 ( 49.9%) | Loss: 2.194479 | Accuracy: 16.04% | GPU: 36.8MB | Batch time: 0.0084s\n",
            "Batch 1580/3125 ( 50.6%) | Loss: 2.192879 | Accuracy: 16.08% | GPU: 36.8MB | Batch time: 0.0040s\n",
            "Batch 1600/3125 ( 51.2%) | Loss: 2.191239 | Accuracy: 16.13% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 1620/3125 ( 51.8%) | Loss: 2.189383 | Accuracy: 16.24% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 1640/3125 ( 52.5%) | Loss: 2.187791 | Accuracy: 16.30% | GPU: 36.8MB | Batch time: 0.0038s\n",
            "Batch 1660/3125 ( 53.1%) | Loss: 2.185154 | Accuracy: 16.41% | GPU: 36.8MB | Batch time: 0.0093s\n",
            "Batch 1680/3125 ( 53.8%) | Loss: 2.183535 | Accuracy: 16.42% | GPU: 36.8MB | Batch time: 0.0081s\n",
            "Batch 1700/3125 ( 54.4%) | Loss: 2.182368 | Accuracy: 16.44% | GPU: 36.8MB | Batch time: 0.0039s\n",
            "Batch 1720/3125 ( 55.0%) | Loss: 2.179642 | Accuracy: 16.53% | GPU: 36.8MB | Batch time: 0.0039s\n",
            "Batch 1740/3125 ( 55.7%) | Loss: 2.177807 | Accuracy: 16.62% | GPU: 36.8MB | Batch time: 0.0049s\n",
            "Batch 1760/3125 ( 56.3%) | Loss: 2.176758 | Accuracy: 16.66% | GPU: 36.8MB | Batch time: 0.0049s\n",
            "Batch 1780/3125 ( 57.0%) | Loss: 2.175378 | Accuracy: 16.73% | GPU: 36.8MB | Batch time: 0.0045s\n",
            "Batch 1800/3125 ( 57.6%) | Loss: 2.173546 | Accuracy: 16.83% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 1820/3125 ( 58.2%) | Loss: 2.172303 | Accuracy: 16.88% | GPU: 36.8MB | Batch time: 0.0056s\n",
            "Batch 1840/3125 ( 58.9%) | Loss: 2.170518 | Accuracy: 16.95% | GPU: 36.8MB | Batch time: 0.0068s\n",
            "Batch 1860/3125 ( 59.5%) | Loss: 2.168196 | Accuracy: 17.03% | GPU: 36.8MB | Batch time: 0.0042s\n",
            "Batch 1880/3125 ( 60.2%) | Loss: 2.166834 | Accuracy: 17.07% | GPU: 36.8MB | Batch time: 0.0041s\n",
            "Batch 1900/3125 ( 60.8%) | Loss: 2.164885 | Accuracy: 17.12% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 1920/3125 ( 61.4%) | Loss: 2.164364 | Accuracy: 17.22% | GPU: 36.8MB | Batch time: 0.0070s\n",
            "Batch 1940/3125 ( 62.1%) | Loss: 2.162727 | Accuracy: 17.30% | GPU: 36.8MB | Batch time: 0.0064s\n",
            "Batch 1960/3125 ( 62.7%) | Loss: 2.162256 | Accuracy: 17.34% | GPU: 36.8MB | Batch time: 0.0051s\n",
            "Batch 1980/3125 ( 63.4%) | Loss: 2.159941 | Accuracy: 17.47% | GPU: 36.8MB | Batch time: 0.0058s\n",
            "Batch 2000/3125 ( 64.0%) | Loss: 2.159022 | Accuracy: 17.55% | GPU: 36.8MB | Batch time: 0.0089s\n",
            "Batch 2020/3125 ( 64.6%) | Loss: 2.157521 | Accuracy: 17.59% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 2040/3125 ( 65.3%) | Loss: 2.156455 | Accuracy: 17.62% | GPU: 36.8MB | Batch time: 0.0039s\n",
            "Batch 2060/3125 ( 65.9%) | Loss: 2.153931 | Accuracy: 17.72% | GPU: 36.8MB | Batch time: 0.0039s\n",
            "Batch 2080/3125 ( 66.6%) | Loss: 2.152707 | Accuracy: 17.79% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 2100/3125 ( 67.2%) | Loss: 2.150864 | Accuracy: 17.87% | GPU: 36.8MB | Batch time: 0.0038s\n",
            "Batch 2120/3125 ( 67.8%) | Loss: 2.148728 | Accuracy: 17.94% | GPU: 36.8MB | Batch time: 0.0213s\n",
            "Batch 2140/3125 ( 68.5%) | Loss: 2.146773 | Accuracy: 18.00% | GPU: 36.8MB | Batch time: 0.0046s\n",
            "Batch 2160/3125 ( 69.1%) | Loss: 2.145081 | Accuracy: 18.06% | GPU: 36.8MB | Batch time: 0.0041s\n",
            "Batch 2180/3125 ( 69.8%) | Loss: 2.143001 | Accuracy: 18.15% | GPU: 36.8MB | Batch time: 0.0049s\n",
            "Batch 2200/3125 ( 70.4%) | Loss: 2.141275 | Accuracy: 18.20% | GPU: 36.8MB | Batch time: 0.0191s\n",
            "Batch 2220/3125 ( 71.0%) | Loss: 2.140765 | Accuracy: 18.24% | GPU: 36.8MB | Batch time: 0.0077s\n",
            "Batch 2240/3125 ( 71.7%) | Loss: 2.139694 | Accuracy: 18.30% | GPU: 36.8MB | Batch time: 0.0158s\n",
            "Batch 2260/3125 ( 72.3%) | Loss: 2.138312 | Accuracy: 18.37% | GPU: 36.8MB | Batch time: 0.0087s\n",
            "Batch 2280/3125 ( 73.0%) | Loss: 2.136144 | Accuracy: 18.42% | GPU: 36.8MB | Batch time: 0.0027s\n",
            "Batch 2300/3125 ( 73.6%) | Loss: 2.134987 | Accuracy: 18.44% | GPU: 36.8MB | Batch time: 0.0030s\n",
            "Batch 2320/3125 ( 74.2%) | Loss: 2.133121 | Accuracy: 18.51% | GPU: 36.8MB | Batch time: 0.0050s\n",
            "Batch 2340/3125 ( 74.9%) | Loss: 2.132093 | Accuracy: 18.55% | GPU: 36.8MB | Batch time: 0.0029s\n",
            "Batch 2360/3125 ( 75.5%) | Loss: 2.130387 | Accuracy: 18.59% | GPU: 36.8MB | Batch time: 0.0116s\n",
            "Batch 2380/3125 ( 76.2%) | Loss: 2.128885 | Accuracy: 18.66% | GPU: 36.8MB | Batch time: 0.0195s\n",
            "Batch 2400/3125 ( 76.8%) | Loss: 2.127814 | Accuracy: 18.70% | GPU: 36.8MB | Batch time: 0.0047s\n",
            "Batch 2420/3125 ( 77.4%) | Loss: 2.127137 | Accuracy: 18.74% | GPU: 36.8MB | Batch time: 0.0094s\n",
            "Batch 2440/3125 ( 78.1%) | Loss: 2.125230 | Accuracy: 18.83% | GPU: 36.8MB | Batch time: 0.0035s\n",
            "Batch 2460/3125 ( 78.7%) | Loss: 2.124087 | Accuracy: 18.88% | GPU: 36.8MB | Batch time: 0.0040s\n",
            "Batch 2480/3125 ( 79.4%) | Loss: 2.122216 | Accuracy: 18.97% | GPU: 36.8MB | Batch time: 0.0074s\n",
            "Batch 2500/3125 ( 80.0%) | Loss: 2.120967 | Accuracy: 19.02% | GPU: 36.8MB | Batch time: 0.0036s\n",
            "Batch 2520/3125 ( 80.6%) | Loss: 2.118569 | Accuracy: 19.12% | GPU: 36.8MB | Batch time: 0.0038s\n",
            "Batch 2540/3125 ( 81.3%) | Loss: 2.116300 | Accuracy: 19.24% | GPU: 36.8MB | Batch time: 0.0085s\n",
            "Batch 2560/3125 ( 81.9%) | Loss: 2.115746 | Accuracy: 19.27% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 2580/3125 ( 82.6%) | Loss: 2.114287 | Accuracy: 19.32% | GPU: 36.8MB | Batch time: 0.0036s\n",
            "Batch 2600/3125 ( 83.2%) | Loss: 2.112713 | Accuracy: 19.38% | GPU: 36.8MB | Batch time: 0.0039s\n",
            "Batch 2620/3125 ( 83.8%) | Loss: 2.110295 | Accuracy: 19.47% | GPU: 36.8MB | Batch time: 0.0051s\n",
            "Batch 2640/3125 ( 84.5%) | Loss: 2.108045 | Accuracy: 19.55% | GPU: 36.8MB | Batch time: 0.0039s\n",
            "Batch 2660/3125 ( 85.1%) | Loss: 2.106352 | Accuracy: 19.62% | GPU: 36.8MB | Batch time: 0.0073s\n",
            "Batch 2680/3125 ( 85.8%) | Loss: 2.105217 | Accuracy: 19.66% | GPU: 36.8MB | Batch time: 0.0040s\n",
            "Batch 2700/3125 ( 86.4%) | Loss: 2.102866 | Accuracy: 19.74% | GPU: 36.8MB | Batch time: 0.0078s\n",
            "Batch 2720/3125 ( 87.0%) | Loss: 2.101351 | Accuracy: 19.78% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 2740/3125 ( 87.7%) | Loss: 2.099807 | Accuracy: 19.85% | GPU: 36.8MB | Batch time: 0.0035s\n",
            "Batch 2760/3125 ( 88.3%) | Loss: 2.097866 | Accuracy: 19.92% | GPU: 36.8MB | Batch time: 0.0045s\n",
            "Batch 2780/3125 ( 89.0%) | Loss: 2.095900 | Accuracy: 20.01% | GPU: 36.8MB | Batch time: 0.0043s\n",
            "Batch 2800/3125 ( 89.6%) | Loss: 2.093870 | Accuracy: 20.11% | GPU: 36.8MB | Batch time: 0.0071s\n",
            "Batch 2820/3125 ( 90.2%) | Loss: 2.092124 | Accuracy: 20.17% | GPU: 36.8MB | Batch time: 0.0046s\n",
            "Batch 2840/3125 ( 90.9%) | Loss: 2.090338 | Accuracy: 20.25% | GPU: 36.8MB | Batch time: 0.0043s\n",
            "Batch 2860/3125 ( 91.5%) | Loss: 2.088557 | Accuracy: 20.34% | GPU: 36.8MB | Batch time: 0.0092s\n",
            "Batch 2880/3125 ( 92.2%) | Loss: 2.086871 | Accuracy: 20.44% | GPU: 36.8MB | Batch time: 0.0050s\n",
            "Batch 2900/3125 ( 92.8%) | Loss: 2.085437 | Accuracy: 20.50% | GPU: 36.8MB | Batch time: 0.0038s\n",
            "Batch 2920/3125 ( 93.4%) | Loss: 2.083726 | Accuracy: 20.55% | GPU: 36.8MB | Batch time: 0.0042s\n",
            "Batch 2940/3125 ( 94.1%) | Loss: 2.082358 | Accuracy: 20.59% | GPU: 36.8MB | Batch time: 0.0054s\n",
            "Batch 2960/3125 ( 94.7%) | Loss: 2.080502 | Accuracy: 20.66% | GPU: 36.8MB | Batch time: 0.0047s\n",
            "Batch 2980/3125 ( 95.4%) | Loss: 2.078882 | Accuracy: 20.73% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 3000/3125 ( 96.0%) | Loss: 2.076544 | Accuracy: 20.82% | GPU: 36.8MB | Batch time: 0.0040s\n",
            "Batch 3020/3125 ( 96.6%) | Loss: 2.074954 | Accuracy: 20.90% | GPU: 36.8MB | Batch time: 0.0038s\n",
            "Batch 3040/3125 ( 97.3%) | Loss: 2.073849 | Accuracy: 20.95% | GPU: 36.8MB | Batch time: 0.0039s\n",
            "Batch 3060/3125 ( 97.9%) | Loss: 2.071325 | Accuracy: 21.07% | GPU: 36.8MB | Batch time: 0.0085s\n",
            "Batch 3080/3125 ( 98.6%) | Loss: 2.069613 | Accuracy: 21.14% | GPU: 36.8MB | Batch time: 0.0037s\n",
            "Batch 3100/3125 ( 99.2%) | Loss: 2.067722 | Accuracy: 21.22% | GPU: 36.8MB | Batch time: 0.0044s\n",
            "Batch 3120/3125 ( 99.8%) | Loss: 2.066009 | Accuracy: 21.26% | GPU: 36.8MB | Batch time: 0.0080s\n",
            "Batch 3124/3125 (100.0%) | Loss: 2.065733 | Accuracy: 21.27% | GPU: 36.8MB | Batch time: 0.0053s\n",
            "\n",
            "-------------------- STANDARD OPTIMIZER - SUMMARY --------------------\n",
            "Loss: 2.065733 | Accuracy: 21.27%\n",
            "Time: 35.09s total, 0.0060s per batch\n",
            "  - Forward: 0.0020s, Backward: 0.0028s, Optimizer: 0.0005s\n",
            "🔄 Final Memory - RAM: 8237.8MB, GPU: 36.8MB allocated, 68.0MB reserved\n",
            "⏱️ Standard model training took 35.0974 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Epoch 1/3 -------------------------\n",
            "\n",
            "==================== EPOCH 1 TRAINING ====================\n",
            "Device: cuda, Batches: 3125, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 8237.8MB, GPU: 36.6MB allocated, 68.0MB reserved\n",
            "Step    1 | Loss: 2.144226 | GPU: 38.9MB / 134.0MB | F: 0.0408s, B: 0.0287s, O: 0.0109s\n",
            "Batch    0/3125 (  0.0%) | Loss: 2.144226 | Accuracy: 12.50% | Batch time: 0.1525s\n",
            "Step   10 | Loss: 2.276123 | GPU: 38.9MB / 134.0MB | F: 0.0027s, B: 0.0041s, O: 0.0011s\n",
            "Step   20 | Loss: 2.113159 | GPU: 38.9MB / 134.0MB | F: 0.0017s, B: 0.0034s, O: 0.0011s\n",
            "🔄 Topology update at step 20 took 0.0005s\n",
            "Batch   20/3125 (  0.6%) | Loss: 2.279172 | Accuracy: 14.58% | Batch time: 0.0312s\n",
            "Step   30 | Loss: 2.070190 | GPU: 38.9MB / 134.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step   40 | Loss: 2.047485 | GPU: 38.9MB / 134.0MB | F: 0.0019s, B: 0.0140s, O: 0.0009s\n",
            "🔄 Topology update at step 40 took 0.0001s\n",
            "Batch   40/3125 (  1.3%) | Loss: 2.239575 | Accuracy: 15.40% | Batch time: 0.0443s\n",
            "Step   50 | Loss: 2.031555 | GPU: 38.9MB / 134.0MB | F: 0.0027s, B: 0.0063s, O: 0.0011s\n",
            "Step   60 | Loss: 2.131165 | GPU: 38.9MB / 134.0MB | F: 0.0059s, B: 0.0035s, O: 0.0010s\n",
            "🔄 Topology update at step 60 took 0.0001s\n",
            "Batch   60/3125 (  1.9%) | Loss: 2.210414 | Accuracy: 17.21% | Batch time: 0.0420s\n",
            "Step   70 | Loss: 2.213806 | GPU: 38.9MB / 134.0MB | F: 0.0017s, B: 0.0143s, O: 0.0016s\n",
            "Step   80 | Loss: 1.667976 | GPU: 38.9MB / 134.0MB | F: 0.0019s, B: 0.0128s, O: 0.0010s\n",
            "🔄 Topology update at step 80 took 0.0001s\n",
            "Batch   80/3125 (  2.6%) | Loss: 2.164255 | Accuracy: 19.37% | Batch time: 0.0345s\n",
            "Step   90 | Loss: 2.111206 | GPU: 38.9MB / 134.0MB | F: 0.0056s, B: 0.0056s, O: 0.0016s\n",
            "Step  100 | Loss: 2.179565 | GPU: 38.9MB / 134.0MB | F: 0.0077s, B: 0.0037s, O: 0.0006s\n",
            "🔄 Topology update at step 100 took 0.0000s\n",
            "🧹 Memory cleanup at step 100 took 0.6223s\n",
            "Batch  100/3125 (  3.2%) | Loss: 2.129182 | Accuracy: 21.84% | Batch time: 0.0461s\n",
            "Step  110 | Loss: 1.741119 | GPU: 35.7MB / 134.0MB | F: 0.0014s, B: 0.0101s, O: 0.0007s\n",
            "Step  120 | Loss: 2.093384 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0054s, O: 0.0006s\n",
            "🔄 Topology update at step 120 took 0.0000s\n",
            "Batch  120/3125 (  3.8%) | Loss: 2.103608 | Accuracy: 22.42% | Batch time: 0.0519s\n",
            "Step  130 | Loss: 1.825806 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0017s, O: 0.0006s\n",
            "Step  140 | Loss: 1.848297 | GPU: 35.7MB / 134.0MB | F: 0.0054s, B: 0.0030s, O: 0.0006s\n",
            "🔄 Topology update at step 140 took 0.0001s\n",
            "Batch  140/3125 (  4.5%) | Loss: 2.074185 | Accuracy: 23.63% | Batch time: 0.0475s\n",
            "Step  150 | Loss: 2.265320 | GPU: 35.7MB / 134.0MB | F: 0.0098s, B: 0.0030s, O: 0.0006s\n",
            "Step  160 | Loss: 2.071167 | GPU: 35.7MB / 134.0MB | F: 0.0116s, B: 0.0055s, O: 0.0008s\n",
            "🔄 Topology update at step 160 took 0.0001s\n",
            "Batch  160/3125 (  5.1%) | Loss: 2.060165 | Accuracy: 24.07% | Batch time: 0.0348s\n",
            "Step  170 | Loss: 1.971436 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0123s, O: 0.0006s\n",
            "Step  180 | Loss: 1.911774 | GPU: 35.7MB / 134.0MB | F: 0.0055s, B: 0.0038s, O: 0.0006s\n",
            "🔄 Topology update at step 180 took 0.0007s\n",
            "Batch  180/3125 (  5.8%) | Loss: 2.040671 | Accuracy: 24.38% | Batch time: 0.0878s\n",
            "Step  190 | Loss: 1.703751 | GPU: 35.7MB / 134.0MB | F: 0.0106s, B: 0.0047s, O: 0.0007s\n",
            "Step  200 | Loss: 1.657196 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0086s, O: 0.0007s\n",
            "🔄 Topology update at step 200 took 0.0000s\n",
            "🧹 Memory cleanup at step 200 took 0.2826s\n",
            "Batch  200/3125 (  6.4%) | Loss: 2.018856 | Accuracy: 25.12% | Batch time: 0.0398s\n",
            "Step  210 | Loss: 1.604401 | GPU: 35.7MB / 134.0MB | F: 0.0096s, B: 0.0041s, O: 0.0011s\n",
            "Step  220 | Loss: 1.669357 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0073s, O: 0.0007s\n",
            "🔄 Topology update at step 220 took 0.0001s\n",
            "Batch  220/3125 (  7.0%) | Loss: 2.010029 | Accuracy: 25.45% | Batch time: 0.0338s\n",
            "Step  230 | Loss: 1.744888 | GPU: 35.7MB / 134.0MB | F: 0.0108s, B: 0.0025s, O: 0.0008s\n",
            "Step  240 | Loss: 1.758270 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 240 took 0.0000s\n",
            "Batch  240/3125 (  7.7%) | Loss: 1.994152 | Accuracy: 25.91% | Batch time: 0.0297s\n",
            "Step  250 | Loss: 1.818237 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0022s, O: 0.0007s\n",
            "Step  260 | Loss: 1.617874 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 260 took 0.0000s\n",
            "Batch  260/3125 (  8.3%) | Loss: 1.977106 | Accuracy: 26.63% | Batch time: 0.0367s\n",
            "Step  270 | Loss: 1.649445 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0024s, O: 0.0025s\n",
            "Step  280 | Loss: 1.365967 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0023s, O: 0.0009s\n",
            "🔄 Topology update at step 280 took 0.0001s\n",
            "Batch  280/3125 (  9.0%) | Loss: 1.960155 | Accuracy: 27.36% | Batch time: 0.0319s\n",
            "Step  290 | Loss: 1.793388 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0023s, O: 0.0008s\n",
            "Step  300 | Loss: 1.750488 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 300 took 0.0000s\n",
            "🧹 Memory cleanup at step 300 took 0.2487s\n",
            "Batch  300/3125 (  9.6%) | Loss: 1.946392 | Accuracy: 27.72% | Batch time: 0.0417s\n",
            "Step  310 | Loss: 1.852203 | GPU: 35.7MB / 134.0MB | F: 0.0038s, B: 0.0024s, O: 0.0006s\n",
            "Step  320 | Loss: 1.276276 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0038s, O: 0.0007s\n",
            "🔄 Topology update at step 320 took 0.0000s\n",
            "Batch  320/3125 ( 10.2%) | Loss: 1.933130 | Accuracy: 28.27% | Batch time: 0.0466s\n",
            "Step  330 | Loss: 1.877441 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0073s, O: 0.0008s\n",
            "Step  340 | Loss: 1.517914 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0021s, O: 0.0007s\n",
            "🔄 Topology update at step 340 took 0.0000s\n",
            "Batch  340/3125 ( 10.9%) | Loss: 1.924175 | Accuracy: 28.59% | Batch time: 0.0268s\n",
            "Step  350 | Loss: 1.530136 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0052s, O: 0.0010s\n",
            "Step  360 | Loss: 1.610764 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0072s, O: 0.0010s\n",
            "🔄 Topology update at step 360 took 0.0001s\n",
            "Batch  360/3125 ( 11.5%) | Loss: 1.914927 | Accuracy: 28.90% | Batch time: 0.0370s\n",
            "Step  370 | Loss: 1.497162 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0027s, O: 0.0027s\n",
            "Step  380 | Loss: 1.202297 | GPU: 35.7MB / 134.0MB | F: 0.0090s, B: 0.0052s, O: 0.0011s\n",
            "🔄 Topology update at step 380 took 0.0001s\n",
            "Batch  380/3125 ( 12.2%) | Loss: 1.902208 | Accuracy: 29.40% | Batch time: 0.0371s\n",
            "Step  390 | Loss: 1.767914 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0045s, O: 0.0010s\n",
            "Step  400 | Loss: 1.564987 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0090s, O: 0.0011s\n",
            "🔄 Topology update at step 400 took 0.0001s\n",
            "🧹 Memory cleanup at step 400 took 0.2777s\n",
            "Batch  400/3125 ( 12.8%) | Loss: 1.892440 | Accuracy: 29.77% | Batch time: 0.0411s\n",
            "Step  410 | Loss: 1.703522 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0029s, O: 0.0011s\n",
            "Step  420 | Loss: 1.768677 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0049s, O: 0.0012s\n",
            "🔄 Topology update at step 420 took 0.0001s\n",
            "Batch  420/3125 ( 13.4%) | Loss: 1.885181 | Accuracy: 30.09% | Batch time: 0.0392s\n",
            "Step  430 | Loss: 2.053131 | GPU: 35.7MB / 134.0MB | F: 0.0036s, B: 0.0026s, O: 0.0009s\n",
            "Step  440 | Loss: 1.562965 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 440 took 0.0001s\n",
            "Batch  440/3125 ( 14.1%) | Loss: 1.880820 | Accuracy: 30.33% | Batch time: 0.0322s\n",
            "Step  450 | Loss: 1.666931 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0064s, O: 0.0012s\n",
            "Step  460 | Loss: 1.956726 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0057s, O: 0.0012s\n",
            "🔄 Topology update at step 460 took 0.0001s\n",
            "Batch  460/3125 ( 14.7%) | Loss: 1.873690 | Accuracy: 30.61% | Batch time: 0.0370s\n",
            "Step  470 | Loss: 1.836533 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0056s, O: 0.0011s\n",
            "Step  480 | Loss: 1.623230 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0053s, O: 0.0010s\n",
            "🔄 Topology update at step 480 took 0.0001s\n",
            "Batch  480/3125 ( 15.4%) | Loss: 1.863027 | Accuracy: 31.09% | Batch time: 0.0434s\n",
            "Step  490 | Loss: 1.766571 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0051s, O: 0.0010s\n",
            "Step  500 | Loss: 1.624557 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0026s, O: 0.0006s\n",
            "🔄 Topology update at step 500 took 0.0001s\n",
            "🧹 Memory cleanup at step 500 took 0.2727s\n",
            "Batch  500/3125 ( 16.0%) | Loss: 1.857131 | Accuracy: 31.40% | Batch time: 0.0392s\n",
            "Step  510 | Loss: 1.374683 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0064s, O: 0.0010s\n",
            "Step  520 | Loss: 1.718201 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0057s, O: 0.0011s\n",
            "🔄 Topology update at step 520 took 0.0001s\n",
            "Batch  520/3125 ( 16.6%) | Loss: 1.849748 | Accuracy: 31.75% | Batch time: 0.0418s\n",
            "Step  530 | Loss: 1.145409 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0083s, O: 0.0008s\n",
            "Step  540 | Loss: 1.763947 | GPU: 35.7MB / 134.0MB | F: 0.0037s, B: 0.0049s, O: 0.0008s\n",
            "🔄 Topology update at step 540 took 0.0001s\n",
            "Batch  540/3125 ( 17.3%) | Loss: 1.842954 | Accuracy: 32.02% | Batch time: 0.0322s\n",
            "Step  550 | Loss: 1.835464 | GPU: 35.7MB / 134.0MB | F: 0.0045s, B: 0.0033s, O: 0.0010s\n",
            "Step  560 | Loss: 1.305779 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0101s, O: 0.0009s\n",
            "🔄 Topology update at step 560 took 0.0001s\n",
            "Batch  560/3125 ( 17.9%) | Loss: 1.836684 | Accuracy: 32.31% | Batch time: 0.0367s\n",
            "Step  570 | Loss: 1.711243 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0052s, O: 0.0009s\n",
            "Step  580 | Loss: 1.927643 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0046s, O: 0.0010s\n",
            "🔄 Topology update at step 580 took 0.0001s\n",
            "Batch  580/3125 ( 18.6%) | Loss: 1.831860 | Accuracy: 32.62% | Batch time: 0.0372s\n",
            "Step  590 | Loss: 1.742584 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0047s, O: 0.0010s\n",
            "Step  600 | Loss: 1.411758 | GPU: 35.7MB / 134.0MB | F: 0.0014s, B: 0.0097s, O: 0.0010s\n",
            "🔄 Topology update at step 600 took 0.0001s\n",
            "🧹 Memory cleanup at step 600 took 0.2609s\n",
            "Batch  600/3125 ( 19.2%) | Loss: 1.823958 | Accuracy: 32.86% | Batch time: 0.0386s\n",
            "Step  610 | Loss: 1.739731 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0061s, O: 0.0006s\n",
            "Step  620 | Loss: 1.665192 | GPU: 35.7MB / 134.0MB | F: 0.0058s, B: 0.0042s, O: 0.0007s\n",
            "🔄 Topology update at step 620 took 0.0020s\n",
            "Batch  620/3125 ( 19.8%) | Loss: 1.813865 | Accuracy: 33.39% | Batch time: 0.0594s\n",
            "Step  630 | Loss: 1.388702 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0141s, O: 0.0007s\n",
            "Step  640 | Loss: 1.540558 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0129s, O: 0.0006s\n",
            "🔄 Topology update at step 640 took 0.0000s\n",
            "Batch  640/3125 ( 20.5%) | Loss: 1.808319 | Accuracy: 33.53% | Batch time: 0.0406s\n",
            "Step  650 | Loss: 1.356209 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0081s, O: 0.0006s\n",
            "Step  660 | Loss: 1.830856 | GPU: 35.7MB / 134.0MB | F: 0.0039s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 660 took 0.0000s\n",
            "Batch  660/3125 ( 21.1%) | Loss: 1.802882 | Accuracy: 33.76% | Batch time: 0.0404s\n",
            "Step  670 | Loss: 1.766151 | GPU: 35.7MB / 134.0MB | F: 0.0014s, B: 0.0042s, O: 0.0005s\n",
            "Step  680 | Loss: 1.446777 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0035s, O: 0.0006s\n",
            "🔄 Topology update at step 680 took 0.0000s\n",
            "Batch  680/3125 ( 21.8%) | Loss: 1.800656 | Accuracy: 34.05% | Batch time: 0.0395s\n",
            "Step  690 | Loss: 1.650604 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0035s, O: 0.0006s\n",
            "Step  700 | Loss: 1.609787 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0017s, O: 0.0005s\n",
            "🔄 Topology update at step 700 took 0.0055s\n",
            "🧹 Memory cleanup at step 700 took 0.3880s\n",
            "Batch  700/3125 ( 22.4%) | Loss: 1.798058 | Accuracy: 34.09% | Batch time: 0.0787s\n",
            "Step  710 | Loss: 1.286545 | GPU: 35.7MB / 134.0MB | F: 0.0036s, B: 0.0032s, O: 0.0040s\n",
            "Step  720 | Loss: 1.583298 | GPU: 35.7MB / 134.0MB | F: 0.0059s, B: 0.0090s, O: 0.0018s\n",
            "🔄 Topology update at step 720 took 0.0001s\n",
            "Batch  720/3125 ( 23.0%) | Loss: 1.791188 | Accuracy: 34.35% | Batch time: 0.0591s\n",
            "Step  730 | Loss: 1.799225 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0026s, O: 0.0009s\n",
            "Step  740 | Loss: 1.432318 | GPU: 35.7MB / 134.0MB | F: 0.0067s, B: 0.0043s, O: 0.0009s\n",
            "🔄 Topology update at step 740 took 0.0001s\n",
            "Batch  740/3125 ( 23.7%) | Loss: 1.785761 | Accuracy: 34.48% | Batch time: 0.0313s\n",
            "Step  750 | Loss: 1.324081 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0030s, O: 0.0024s\n",
            "Step  760 | Loss: 1.661835 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0039s, O: 0.0011s\n",
            "🔄 Topology update at step 760 took 0.0001s\n",
            "Batch  760/3125 ( 24.3%) | Loss: 1.781886 | Accuracy: 34.66% | Batch time: 0.0373s\n",
            "Step  770 | Loss: 1.321587 | GPU: 35.7MB / 134.0MB | F: 0.0081s, B: 0.0031s, O: 0.0009s\n",
            "Step  780 | Loss: 1.606934 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0028s, O: 0.0013s\n",
            "🔄 Topology update at step 780 took 0.0001s\n",
            "Batch  780/3125 ( 25.0%) | Loss: 1.775676 | Accuracy: 34.89% | Batch time: 0.0302s\n",
            "Step  790 | Loss: 2.114578 | GPU: 35.7MB / 134.0MB | F: 0.0034s, B: 0.0023s, O: 0.0006s\n",
            "Step  800 | Loss: 1.339951 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0049s, O: 0.0026s\n",
            "🔄 Topology update at step 800 took 0.0000s\n",
            "🧹 Memory cleanup at step 800 took 0.2568s\n",
            "Batch  800/3125 ( 25.6%) | Loss: 1.771017 | Accuracy: 35.13% | Batch time: 0.0382s\n",
            "Step  810 | Loss: 1.816040 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0037s, O: 0.0007s\n",
            "Step  820 | Loss: 1.814697 | GPU: 35.7MB / 134.0MB | F: 0.0078s, B: 0.0034s, O: 0.0010s\n",
            "🔄 Topology update at step 820 took 0.0000s\n",
            "Batch  820/3125 ( 26.2%) | Loss: 1.768515 | Accuracy: 35.19% | Batch time: 0.0411s\n",
            "Step  830 | Loss: 1.455276 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0044s, O: 0.0007s\n",
            "Step  840 | Loss: 1.675919 | GPU: 35.7MB / 134.0MB | F: 0.0038s, B: 0.0061s, O: 0.0007s\n",
            "🔄 Topology update at step 840 took 0.0000s\n",
            "Batch  840/3125 ( 26.9%) | Loss: 1.764617 | Accuracy: 35.39% | Batch time: 0.0388s\n",
            "Step  850 | Loss: 1.588577 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0036s, O: 0.0007s\n",
            "Step  860 | Loss: 1.600673 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0034s, O: 0.0006s\n",
            "🔄 Topology update at step 860 took 0.0000s\n",
            "Batch  860/3125 ( 27.5%) | Loss: 1.759769 | Accuracy: 35.57% | Batch time: 0.0384s\n",
            "Step  870 | Loss: 1.690956 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0067s, O: 0.0007s\n",
            "Step  880 | Loss: 1.442940 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 880 took 0.0000s\n",
            "Batch  880/3125 ( 28.2%) | Loss: 1.756288 | Accuracy: 35.69% | Batch time: 0.0394s\n",
            "Step  890 | Loss: 1.943390 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0036s, O: 0.0007s\n",
            "Step  900 | Loss: 1.949963 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0041s, O: 0.0007s\n",
            "🔄 Topology update at step 900 took 0.0000s\n",
            "🧹 Memory cleanup at step 900 took 0.2244s\n",
            "Batch  900/3125 ( 28.8%) | Loss: 1.751755 | Accuracy: 35.81% | Batch time: 0.0376s\n",
            "Step  910 | Loss: 1.461226 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0035s, O: 0.0022s\n",
            "Step  920 | Loss: 2.086456 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0036s, O: 0.0022s\n",
            "🔄 Topology update at step 920 took 0.0000s\n",
            "Batch  920/3125 ( 29.4%) | Loss: 1.749778 | Accuracy: 35.88% | Batch time: 0.0548s\n",
            "Step  930 | Loss: 1.915018 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0031s, O: 0.0018s\n",
            "Step  940 | Loss: 1.691252 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0033s, O: 0.0008s\n",
            "🔄 Topology update at step 940 took 0.0001s\n",
            "Batch  940/3125 ( 30.1%) | Loss: 1.745802 | Accuracy: 36.02% | Batch time: 0.0342s\n",
            "Step  950 | Loss: 1.297028 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0074s, O: 0.0007s\n",
            "Step  960 | Loss: 1.516403 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0043s, O: 0.0007s\n",
            "🔄 Topology update at step 960 took 0.0000s\n",
            "Batch  960/3125 ( 30.7%) | Loss: 1.740826 | Accuracy: 36.17% | Batch time: 0.0411s\n",
            "Step  970 | Loss: 1.226608 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0033s, O: 0.0007s\n",
            "Step  980 | Loss: 1.443970 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0074s, O: 0.0007s\n",
            "🔄 Topology update at step 980 took 0.0000s\n",
            "Batch  980/3125 ( 31.4%) | Loss: 1.736998 | Accuracy: 36.27% | Batch time: 0.0440s\n",
            "Step  990 | Loss: 1.561462 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0037s, O: 0.0006s\n",
            "Step 1000 | Loss: 1.378494 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0030s, O: 0.0007s\n",
            "🔄 Topology update at step 1000 took 0.0000s\n",
            "🧹 Memory cleanup at step 1000 took 0.2155s\n",
            "Batch 1000/3125 ( 32.0%) | Loss: 1.733814 | Accuracy: 36.38% | Batch time: 0.0295s\n",
            "Step 1010 | Loss: 1.127682 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0061s, O: 0.0008s\n",
            "Step 1020 | Loss: 1.144966 | GPU: 35.7MB / 134.0MB | F: 0.0056s, B: 0.0218s, O: 0.0007s\n",
            "🔄 Topology update at step 1020 took 0.0000s\n",
            "Batch 1020/3125 ( 32.6%) | Loss: 1.728783 | Accuracy: 36.59% | Batch time: 0.0514s\n",
            "Step 1030 | Loss: 1.623428 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0077s, O: 0.0007s\n",
            "Step 1040 | Loss: 1.756203 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0028s, O: 0.0006s\n",
            "🔄 Topology update at step 1040 took 0.0000s\n",
            "Batch 1040/3125 ( 33.3%) | Loss: 1.724584 | Accuracy: 36.68% | Batch time: 0.0398s\n",
            "Step 1050 | Loss: 1.576836 | GPU: 35.7MB / 134.0MB | F: 0.0112s, B: 0.0032s, O: 0.0010s\n",
            "Step 1060 | Loss: 1.375519 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0092s, O: 0.0009s\n",
            "🔄 Topology update at step 1060 took 0.0001s\n",
            "Batch 1060/3125 ( 33.9%) | Loss: 1.720248 | Accuracy: 36.91% | Batch time: 0.0403s\n",
            "Step 1070 | Loss: 1.131828 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0024s, O: 0.0067s\n",
            "Step 1080 | Loss: 1.280380 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0059s, O: 0.0009s\n",
            "🔄 Topology update at step 1080 took 0.0000s\n",
            "Batch 1080/3125 ( 34.6%) | Loss: 1.715431 | Accuracy: 37.11% | Batch time: 0.0481s\n",
            "Step 1090 | Loss: 1.909439 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0078s, O: 0.0007s\n",
            "Step 1100 | Loss: 1.419167 | GPU: 35.7MB / 134.0MB | F: 0.0101s, B: 0.0061s, O: 0.0010s\n",
            "🔄 Topology update at step 1100 took 0.0001s\n",
            "🧹 Memory cleanup at step 1100 took 0.2501s\n",
            "Batch 1100/3125 ( 35.2%) | Loss: 1.711623 | Accuracy: 37.29% | Batch time: 0.0423s\n",
            "Step 1110 | Loss: 1.661171 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0026s, O: 0.0048s\n",
            "Step 1120 | Loss: 1.319427 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 1120 took 0.0001s\n",
            "Batch 1120/3125 ( 35.8%) | Loss: 1.707907 | Accuracy: 37.42% | Batch time: 0.0274s\n",
            "Step 1130 | Loss: 1.515862 | GPU: 35.7MB / 134.0MB | F: 0.0044s, B: 0.0041s, O: 0.0010s\n",
            "Step 1140 | Loss: 1.898117 | GPU: 35.7MB / 134.0MB | F: 0.0111s, B: 0.0035s, O: 0.0010s\n",
            "🔄 Topology update at step 1140 took 0.0001s\n",
            "Batch 1140/3125 ( 36.5%) | Loss: 1.705772 | Accuracy: 37.46% | Batch time: 0.0364s\n",
            "Step 1150 | Loss: 1.516048 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0111s, O: 0.0010s\n",
            "Step 1160 | Loss: 1.383118 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0092s, O: 0.0009s\n",
            "🔄 Topology update at step 1160 took 0.0001s\n",
            "Batch 1160/3125 ( 37.1%) | Loss: 1.703022 | Accuracy: 37.60% | Batch time: 0.0693s\n",
            "Step 1170 | Loss: 1.299118 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0101s, O: 0.0011s\n",
            "Step 1180 | Loss: 1.284048 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0034s, O: 0.0062s\n",
            "🔄 Topology update at step 1180 took 0.0001s\n",
            "Batch 1180/3125 ( 37.8%) | Loss: 1.699112 | Accuracy: 37.71% | Batch time: 0.0808s\n",
            "Step 1190 | Loss: 1.420631 | GPU: 35.7MB / 134.0MB | F: 0.0130s, B: 0.0022s, O: 0.0020s\n",
            "Step 1200 | Loss: 1.610065 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0080s, O: 0.0005s\n",
            "🔄 Topology update at step 1200 took 0.0000s\n",
            "🧹 Memory cleanup at step 1200 took 0.2833s\n",
            "Batch 1200/3125 ( 38.4%) | Loss: 1.694784 | Accuracy: 37.89% | Batch time: 0.0451s\n",
            "Step 1210 | Loss: 1.677643 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0060s, O: 0.0006s\n",
            "Step 1220 | Loss: 1.501225 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0083s, O: 0.0006s\n",
            "🔄 Topology update at step 1220 took 0.0000s\n",
            "Batch 1220/3125 ( 39.0%) | Loss: 1.692122 | Accuracy: 37.95% | Batch time: 0.0571s\n",
            "Step 1230 | Loss: 1.462990 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0051s, O: 0.0005s\n",
            "Step 1240 | Loss: 1.365707 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0020s, O: 0.0006s\n",
            "🔄 Topology update at step 1240 took 0.0000s\n",
            "Batch 1240/3125 ( 39.7%) | Loss: 1.689683 | Accuracy: 38.05% | Batch time: 0.0424s\n",
            "Step 1250 | Loss: 1.382324 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0075s, O: 0.0006s\n",
            "Step 1260 | Loss: 1.986603 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0083s, O: 0.0009s\n",
            "🔄 Topology update at step 1260 took 0.0000s\n",
            "Batch 1260/3125 ( 40.3%) | Loss: 1.686954 | Accuracy: 38.21% | Batch time: 0.0733s\n",
            "Step 1270 | Loss: 1.595551 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0028s, O: 0.0007s\n",
            "Step 1280 | Loss: 1.480118 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0096s, O: 0.0007s\n",
            "🔄 Topology update at step 1280 took 0.0000s\n",
            "Batch 1280/3125 ( 41.0%) | Loss: 1.683375 | Accuracy: 38.38% | Batch time: 0.0534s\n",
            "Step 1290 | Loss: 1.331253 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0087s, O: 0.0007s\n",
            "Step 1300 | Loss: 1.940468 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0099s, O: 0.0022s\n",
            "🔄 Topology update at step 1300 took 0.0005s\n",
            "🧹 Memory cleanup at step 1300 took 0.2398s\n",
            "Batch 1300/3125 ( 41.6%) | Loss: 1.680900 | Accuracy: 38.48% | Batch time: 0.0428s\n",
            "Step 1310 | Loss: 1.603485 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0043s, O: 0.0020s\n",
            "Step 1320 | Loss: 1.663361 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0077s, O: 0.0010s\n",
            "🔄 Topology update at step 1320 took 0.0001s\n",
            "Batch 1320/3125 ( 42.2%) | Loss: 1.679399 | Accuracy: 38.55% | Batch time: 0.0347s\n",
            "Step 1330 | Loss: 1.472725 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0114s, O: 0.0008s\n",
            "Step 1340 | Loss: 1.323776 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0060s, O: 0.0007s\n",
            "🔄 Topology update at step 1340 took 0.0001s\n",
            "Batch 1340/3125 ( 42.9%) | Loss: 1.674552 | Accuracy: 38.77% | Batch time: 0.0354s\n",
            "Step 1350 | Loss: 1.591690 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0023s, O: 0.0007s\n",
            "Step 1360 | Loss: 1.718906 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0081s, O: 0.0010s\n",
            "🔄 Topology update at step 1360 took 0.0001s\n",
            "Batch 1360/3125 ( 43.5%) | Loss: 1.671941 | Accuracy: 38.86% | Batch time: 0.0364s\n",
            "Step 1370 | Loss: 1.991425 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0034s, O: 0.0039s\n",
            "Step 1380 | Loss: 1.478088 | GPU: 35.7MB / 134.0MB | F: 0.0079s, B: 0.0056s, O: 0.0007s\n",
            "🔄 Topology update at step 1380 took 0.0000s\n",
            "Batch 1380/3125 ( 44.2%) | Loss: 1.669041 | Accuracy: 38.97% | Batch time: 0.0433s\n",
            "Step 1390 | Loss: 1.620804 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0084s, O: 0.0010s\n",
            "Step 1400 | Loss: 1.845001 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 1400 took 0.0000s\n",
            "🧹 Memory cleanup at step 1400 took 0.2540s\n",
            "Batch 1400/3125 ( 44.8%) | Loss: 1.665714 | Accuracy: 39.12% | Batch time: 0.0335s\n",
            "Step 1410 | Loss: 1.459412 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0069s, O: 0.0027s\n",
            "Step 1420 | Loss: 1.575035 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0067s, O: 0.0020s\n",
            "🔄 Topology update at step 1420 took 0.0001s\n",
            "Batch 1420/3125 ( 45.4%) | Loss: 1.665273 | Accuracy: 39.12% | Batch time: 0.0463s\n",
            "Step 1430 | Loss: 1.628643 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0033s, O: 0.0007s\n",
            "Step 1440 | Loss: 2.084557 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0051s, O: 0.0009s\n",
            "🔄 Topology update at step 1440 took 0.0001s\n",
            "Batch 1440/3125 ( 46.1%) | Loss: 1.663913 | Accuracy: 39.18% | Batch time: 0.0364s\n",
            "Step 1450 | Loss: 1.928078 | GPU: 35.7MB / 134.0MB | F: 0.0077s, B: 0.0022s, O: 0.0007s\n",
            "Step 1460 | Loss: 1.382568 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0065s, O: 0.0025s\n",
            "🔄 Topology update at step 1460 took 0.0000s\n",
            "Batch 1460/3125 ( 46.7%) | Loss: 1.661339 | Accuracy: 39.31% | Batch time: 0.0263s\n",
            "Step 1470 | Loss: 1.722656 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0055s, O: 0.0007s\n",
            "Step 1480 | Loss: 1.792061 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0088s, O: 0.0010s\n",
            "🔄 Topology update at step 1480 took 0.0001s\n",
            "Batch 1480/3125 ( 47.4%) | Loss: 1.660016 | Accuracy: 39.40% | Batch time: 0.0400s\n",
            "Step 1490 | Loss: 1.305584 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0082s, O: 0.0020s\n",
            "Step 1500 | Loss: 1.816772 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0104s, O: 0.0010s\n",
            "🔄 Topology update at step 1500 took 0.0000s\n",
            "🧹 Memory cleanup at step 1500 took 0.2703s\n",
            "Batch 1500/3125 ( 48.0%) | Loss: 1.659306 | Accuracy: 39.42% | Batch time: 0.0388s\n",
            "Step 1510 | Loss: 1.392502 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0069s, O: 0.0061s\n",
            "Step 1520 | Loss: 2.055367 | GPU: 35.7MB / 134.0MB | F: 0.0056s, B: 0.0022s, O: 0.0008s\n",
            "🔄 Topology update at step 1520 took 0.0001s\n",
            "Batch 1520/3125 ( 48.6%) | Loss: 1.657609 | Accuracy: 39.49% | Batch time: 0.0354s\n",
            "Step 1530 | Loss: 1.443130 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0038s, O: 0.0022s\n",
            "Step 1540 | Loss: 1.581383 | GPU: 35.7MB / 134.0MB | F: 0.0044s, B: 0.0036s, O: 0.0011s\n",
            "🔄 Topology update at step 1540 took 0.0001s\n",
            "Batch 1540/3125 ( 49.3%) | Loss: 1.654789 | Accuracy: 39.58% | Batch time: 0.0355s\n",
            "Step 1550 | Loss: 1.755890 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0115s, O: 0.0007s\n",
            "Step 1560 | Loss: 1.485008 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0102s, O: 0.0021s\n",
            "🔄 Topology update at step 1560 took 0.0000s\n",
            "Batch 1560/3125 ( 49.9%) | Loss: 1.652358 | Accuracy: 39.67% | Batch time: 0.0344s\n",
            "Step 1570 | Loss: 1.674268 | GPU: 35.7MB / 134.0MB | F: 0.0079s, B: 0.0022s, O: 0.0007s\n",
            "Step 1580 | Loss: 1.324189 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 1580 took 0.0000s\n",
            "Batch 1580/3125 ( 50.6%) | Loss: 1.649279 | Accuracy: 39.78% | Batch time: 0.0288s\n",
            "Step 1590 | Loss: 1.080110 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0022s, O: 0.0006s\n",
            "Step 1600 | Loss: 1.387726 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0074s, O: 0.0022s\n",
            "🔄 Topology update at step 1600 took 0.0001s\n",
            "🧹 Memory cleanup at step 1600 took 0.2959s\n",
            "Batch 1600/3125 ( 51.2%) | Loss: 1.647522 | Accuracy: 39.90% | Batch time: 0.0370s\n",
            "Step 1610 | Loss: 1.376122 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "Step 1620 | Loss: 1.711227 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0043s, O: 0.0022s\n",
            "🔄 Topology update at step 1620 took 0.0001s\n",
            "Batch 1620/3125 ( 51.8%) | Loss: 1.644415 | Accuracy: 40.04% | Batch time: 0.0427s\n",
            "Step 1630 | Loss: 1.466473 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0044s, O: 0.0012s\n",
            "Step 1640 | Loss: 1.855560 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0043s, O: 0.0024s\n",
            "🔄 Topology update at step 1640 took 0.0001s\n",
            "Batch 1640/3125 ( 52.5%) | Loss: 1.643422 | Accuracy: 40.11% | Batch time: 0.0431s\n",
            "Step 1650 | Loss: 1.477374 | GPU: 35.7MB / 134.0MB | F: 0.0154s, B: 0.0028s, O: 0.0010s\n",
            "Step 1660 | Loss: 1.489929 | GPU: 35.7MB / 134.0MB | F: 0.0046s, B: 0.0058s, O: 0.0017s\n",
            "🔄 Topology update at step 1660 took 0.0001s\n",
            "Batch 1660/3125 ( 53.1%) | Loss: 1.640407 | Accuracy: 40.24% | Batch time: 0.0434s\n",
            "Step 1670 | Loss: 0.878914 | GPU: 35.7MB / 134.0MB | F: 0.0031s, B: 0.0023s, O: 0.0007s\n",
            "Step 1680 | Loss: 0.906860 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0068s, O: 0.0006s\n",
            "🔄 Topology update at step 1680 took 0.0000s\n",
            "Batch 1680/3125 ( 53.8%) | Loss: 1.637221 | Accuracy: 40.40% | Batch time: 0.0337s\n",
            "Step 1690 | Loss: 1.300713 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0106s, O: 0.0008s\n",
            "Step 1700 | Loss: 0.909264 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0070s, O: 0.0007s\n",
            "🔄 Topology update at step 1700 took 0.0000s\n",
            "🧹 Memory cleanup at step 1700 took 0.2410s\n",
            "Batch 1700/3125 ( 54.4%) | Loss: 1.634227 | Accuracy: 40.49% | Batch time: 0.0418s\n",
            "Step 1710 | Loss: 1.394516 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0034s, O: 0.0009s\n",
            "Step 1720 | Loss: 1.324810 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0075s, O: 0.0006s\n",
            "🔄 Topology update at step 1720 took 0.0000s\n",
            "Batch 1720/3125 ( 55.0%) | Loss: 1.633295 | Accuracy: 40.50% | Batch time: 0.0419s\n",
            "Step 1730 | Loss: 2.264898 | GPU: 35.7MB / 134.0MB | F: 0.0069s, B: 0.0060s, O: 0.0011s\n",
            "Step 1740 | Loss: 1.668518 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0019s, O: 0.0058s\n",
            "🔄 Topology update at step 1740 took 0.0000s\n",
            "Batch 1740/3125 ( 55.7%) | Loss: 1.631053 | Accuracy: 40.58% | Batch time: 0.0411s\n",
            "Step 1750 | Loss: 1.656860 | GPU: 35.7MB / 134.0MB | F: 0.0038s, B: 0.0091s, O: 0.0029s\n",
            "Step 1760 | Loss: 1.172699 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0121s, O: 0.0006s\n",
            "🔄 Topology update at step 1760 took 0.0000s\n",
            "Batch 1760/3125 ( 56.3%) | Loss: 1.630037 | Accuracy: 40.63% | Batch time: 0.0305s\n",
            "Step 1770 | Loss: 1.510574 | GPU: 35.7MB / 134.0MB | F: 0.0090s, B: 0.0034s, O: 0.0005s\n",
            "Step 1780 | Loss: 1.807846 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0080s, O: 0.0005s\n",
            "🔄 Topology update at step 1780 took 0.0000s\n",
            "Batch 1780/3125 ( 57.0%) | Loss: 1.627575 | Accuracy: 40.75% | Batch time: 0.0410s\n",
            "Step 1790 | Loss: 1.181438 | GPU: 35.7MB / 134.0MB | F: 0.0100s, B: 0.0017s, O: 0.0006s\n",
            "Step 1800 | Loss: 1.261637 | GPU: 35.7MB / 134.0MB | F: 0.0083s, B: 0.0039s, O: 0.0006s\n",
            "🔄 Topology update at step 1800 took 0.0000s\n",
            "🧹 Memory cleanup at step 1800 took 0.3367s\n",
            "Batch 1800/3125 ( 57.6%) | Loss: 1.625936 | Accuracy: 40.81% | Batch time: 0.0338s\n",
            "Step 1810 | Loss: 0.957146 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0048s, O: 0.0009s\n",
            "Step 1820 | Loss: 1.012047 | GPU: 35.7MB / 134.0MB | F: 0.0048s, B: 0.0028s, O: 0.0006s\n",
            "🔄 Topology update at step 1820 took 0.0001s\n",
            "Batch 1820/3125 ( 58.2%) | Loss: 1.624161 | Accuracy: 40.88% | Batch time: 0.0237s\n",
            "Step 1830 | Loss: 1.526443 | GPU: 35.7MB / 134.0MB | F: 0.0096s, B: 0.0051s, O: 0.0023s\n",
            "Step 1840 | Loss: 1.817522 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0021s, O: 0.0005s\n",
            "🔄 Topology update at step 1840 took 0.0000s\n",
            "Batch 1840/3125 ( 58.9%) | Loss: 1.622398 | Accuracy: 40.96% | Batch time: 0.0507s\n",
            "Step 1850 | Loss: 1.205551 | GPU: 35.7MB / 134.0MB | F: 0.0094s, B: 0.0091s, O: 0.0009s\n",
            "Step 1860 | Loss: 0.982109 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0115s, O: 0.0010s\n",
            "🔄 Topology update at step 1860 took 0.0001s\n",
            "Batch 1860/3125 ( 59.5%) | Loss: 1.620000 | Accuracy: 41.07% | Batch time: 0.0374s\n",
            "Step 1870 | Loss: 1.749786 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step 1880 | Loss: 1.067583 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1880 took 0.0000s\n",
            "Batch 1880/3125 ( 60.2%) | Loss: 1.616868 | Accuracy: 41.18% | Batch time: 0.0409s\n",
            "Step 1890 | Loss: 1.513550 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0032s, O: 0.0007s\n",
            "Step 1900 | Loss: 1.377960 | GPU: 35.7MB / 134.0MB | F: 0.0063s, B: 0.0035s, O: 0.0011s\n",
            "🔄 Topology update at step 1900 took 0.0001s\n",
            "🧹 Memory cleanup at step 1900 took 0.2638s\n",
            "Batch 1900/3125 ( 60.8%) | Loss: 1.614756 | Accuracy: 41.25% | Batch time: 0.0421s\n",
            "Step 1910 | Loss: 1.333990 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0090s, O: 0.0012s\n",
            "Step 1920 | Loss: 1.221062 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0021s, O: 0.0006s\n",
            "🔄 Topology update at step 1920 took 0.0000s\n",
            "Batch 1920/3125 ( 61.4%) | Loss: 1.611645 | Accuracy: 41.35% | Batch time: 0.0290s\n",
            "Step 1930 | Loss: 1.013718 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0046s, O: 0.0010s\n",
            "Step 1940 | Loss: 1.906097 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0056s, O: 0.0006s\n",
            "🔄 Topology update at step 1940 took 0.0000s\n",
            "Batch 1940/3125 ( 62.1%) | Loss: 1.609058 | Accuracy: 41.44% | Batch time: 0.0325s\n",
            "Step 1950 | Loss: 1.707916 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0055s, O: 0.0006s\n",
            "Step 1960 | Loss: 1.593628 | GPU: 35.7MB / 134.0MB | F: 0.0061s, B: 0.0031s, O: 0.0009s\n",
            "🔄 Topology update at step 1960 took 0.0000s\n",
            "Batch 1960/3125 ( 62.7%) | Loss: 1.607161 | Accuracy: 41.53% | Batch time: 0.0298s\n",
            "Step 1970 | Loss: 1.669793 | GPU: 35.7MB / 134.0MB | F: 0.0103s, B: 0.0032s, O: 0.0010s\n",
            "Step 1980 | Loss: 1.079435 | GPU: 35.7MB / 134.0MB | F: 0.0059s, B: 0.0148s, O: 0.0007s\n",
            "🔄 Topology update at step 1980 took 0.0000s\n",
            "Batch 1980/3125 ( 63.4%) | Loss: 1.604307 | Accuracy: 41.65% | Batch time: 0.0507s\n",
            "Step 1990 | Loss: 1.330559 | GPU: 35.7MB / 134.0MB | F: 0.0044s, B: 0.0032s, O: 0.0010s\n",
            "Step 2000 | Loss: 1.984371 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0076s, O: 0.0007s\n",
            "🔄 Topology update at step 2000 took 0.0000s\n",
            "🧹 Memory cleanup at step 2000 took 0.2489s\n",
            "Batch 2000/3125 ( 64.0%) | Loss: 1.601993 | Accuracy: 41.68% | Batch time: 0.0385s\n",
            "Step 2010 | Loss: 1.358938 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0032s, O: 0.0007s\n",
            "Step 2020 | Loss: 1.743073 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0083s, O: 0.0007s\n",
            "🔄 Topology update at step 2020 took 0.0000s\n",
            "Batch 2020/3125 ( 64.6%) | Loss: 1.600445 | Accuracy: 41.71% | Batch time: 0.0394s\n",
            "Step 2030 | Loss: 0.977011 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0069s, O: 0.0007s\n",
            "Step 2040 | Loss: 1.580963 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0060s, O: 0.0007s\n",
            "🔄 Topology update at step 2040 took 0.0001s\n",
            "Batch 2040/3125 ( 65.3%) | Loss: 1.598392 | Accuracy: 41.79% | Batch time: 0.0281s\n",
            "Step 2050 | Loss: 2.000445 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0022s, O: 0.0007s\n",
            "Step 2060 | Loss: 1.541916 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0036s, O: 0.0010s\n",
            "🔄 Topology update at step 2060 took 0.0000s\n",
            "Batch 2060/3125 ( 65.9%) | Loss: 1.596958 | Accuracy: 41.87% | Batch time: 0.0326s\n",
            "Step 2070 | Loss: 1.399628 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0034s, O: 0.0006s\n",
            "Step 2080 | Loss: 1.592134 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0084s, O: 0.0006s\n",
            "🔄 Topology update at step 2080 took 0.0001s\n",
            "Batch 2080/3125 ( 66.6%) | Loss: 1.594836 | Accuracy: 41.96% | Batch time: 0.0337s\n",
            "Step 2090 | Loss: 1.340580 | GPU: 35.7MB / 134.0MB | F: 0.0046s, B: 0.0059s, O: 0.0009s\n",
            "Step 2100 | Loss: 2.043457 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0081s, O: 0.0019s\n",
            "🔄 Topology update at step 2100 took 0.0001s\n",
            "🧹 Memory cleanup at step 2100 took 0.2650s\n",
            "Batch 2100/3125 ( 67.2%) | Loss: 1.593242 | Accuracy: 42.02% | Batch time: 0.0398s\n",
            "Step 2110 | Loss: 1.209450 | GPU: 35.7MB / 134.0MB | F: 0.0062s, B: 0.0025s, O: 0.0007s\n",
            "Step 2120 | Loss: 1.753281 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0037s, O: 0.0035s\n",
            "🔄 Topology update at step 2120 took 0.0000s\n",
            "Batch 2120/3125 ( 67.8%) | Loss: 1.591309 | Accuracy: 42.10% | Batch time: 0.0432s\n",
            "Step 2130 | Loss: 1.163122 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0023s, O: 0.0006s\n",
            "Step 2140 | Loss: 1.413031 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0025s, O: 0.0017s\n",
            "🔄 Topology update at step 2140 took 0.0001s\n",
            "Batch 2140/3125 ( 68.5%) | Loss: 1.589570 | Accuracy: 42.17% | Batch time: 0.0274s\n",
            "Step 2150 | Loss: 1.569242 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0023s, O: 0.0007s\n",
            "Step 2160 | Loss: 1.408817 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0032s, O: 0.0021s\n",
            "🔄 Topology update at step 2160 took 0.0001s\n",
            "Batch 2160/3125 ( 69.1%) | Loss: 1.588127 | Accuracy: 42.23% | Batch time: 0.0373s\n",
            "Step 2170 | Loss: 1.379536 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0020s, O: 0.0007s\n",
            "Step 2180 | Loss: 1.715668 | GPU: 35.7MB / 134.0MB | F: 0.0035s, B: 0.0034s, O: 0.0020s\n",
            "🔄 Topology update at step 2180 took 0.0000s\n",
            "Batch 2180/3125 ( 69.8%) | Loss: 1.585906 | Accuracy: 42.30% | Batch time: 0.0382s\n",
            "Step 2190 | Loss: 1.413162 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0042s, O: 0.0009s\n",
            "Step 2200 | Loss: 1.614670 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 2200 took 0.0000s\n",
            "🧹 Memory cleanup at step 2200 took 0.2608s\n",
            "Batch 2200/3125 ( 70.4%) | Loss: 1.584572 | Accuracy: 42.38% | Batch time: 0.0365s\n",
            "Step 2210 | Loss: 1.167747 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0040s, O: 0.0009s\n",
            "Step 2220 | Loss: 1.422657 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0038s, O: 0.0011s\n",
            "🔄 Topology update at step 2220 took 0.0001s\n",
            "Batch 2220/3125 ( 71.0%) | Loss: 1.582792 | Accuracy: 42.44% | Batch time: 0.0362s\n",
            "Step 2230 | Loss: 1.380360 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0033s, O: 0.0007s\n",
            "Step 2240 | Loss: 0.929137 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0090s, O: 0.0007s\n",
            "🔄 Topology update at step 2240 took 0.0001s\n",
            "Batch 2240/3125 ( 71.7%) | Loss: 1.580636 | Accuracy: 42.53% | Batch time: 0.0304s\n",
            "Step 2250 | Loss: 0.997322 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0027s, O: 0.0008s\n",
            "Step 2260 | Loss: 1.178745 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0048s, O: 0.0009s\n",
            "🔄 Topology update at step 2260 took 0.0000s\n",
            "Batch 2260/3125 ( 72.3%) | Loss: 1.578626 | Accuracy: 42.63% | Batch time: 0.0297s\n",
            "Step 2270 | Loss: 1.574882 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0032s, O: 0.0007s\n",
            "Step 2280 | Loss: 1.156155 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0045s, O: 0.0007s\n",
            "🔄 Topology update at step 2280 took 0.0001s\n",
            "Batch 2280/3125 ( 73.0%) | Loss: 1.576439 | Accuracy: 42.73% | Batch time: 0.0400s\n",
            "Step 2290 | Loss: 1.195518 | GPU: 35.7MB / 134.0MB | F: 0.0035s, B: 0.0035s, O: 0.0007s\n",
            "Step 2300 | Loss: 1.013417 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0087s, O: 0.0008s\n",
            "🔄 Topology update at step 2300 took 0.0001s\n",
            "🧹 Memory cleanup at step 2300 took 0.2654s\n",
            "Batch 2300/3125 ( 73.6%) | Loss: 1.574081 | Accuracy: 42.80% | Batch time: 0.0378s\n",
            "Step 2310 | Loss: 1.317627 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0046s, O: 0.0007s\n",
            "Step 2320 | Loss: 1.808105 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0173s, O: 0.0006s\n",
            "🔄 Topology update at step 2320 took 0.0000s\n",
            "Batch 2320/3125 ( 74.2%) | Loss: 1.571615 | Accuracy: 42.90% | Batch time: 0.0512s\n",
            "Step 2330 | Loss: 1.659546 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0034s, O: 0.0005s\n",
            "Step 2340 | Loss: 1.242903 | GPU: 35.7MB / 134.0MB | F: 0.0041s, B: 0.0033s, O: 0.0032s\n",
            "🔄 Topology update at step 2340 took 0.0000s\n",
            "Batch 2340/3125 ( 74.9%) | Loss: 1.569666 | Accuracy: 42.96% | Batch time: 0.0410s\n",
            "Step 2350 | Loss: 0.836984 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0065s, O: 0.0006s\n",
            "Step 2360 | Loss: 1.540643 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0046s, O: 0.0087s\n",
            "🔄 Topology update at step 2360 took 0.0001s\n",
            "Batch 2360/3125 ( 75.5%) | Loss: 1.567157 | Accuracy: 43.07% | Batch time: 0.0535s\n",
            "Step 2370 | Loss: 1.214197 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0063s, O: 0.0006s\n",
            "Step 2380 | Loss: 1.223633 | GPU: 35.7MB / 134.0MB | F: 0.0046s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 2380 took 0.0000s\n",
            "Batch 2380/3125 ( 76.2%) | Loss: 1.564940 | Accuracy: 43.16% | Batch time: 0.0452s\n",
            "Step 2390 | Loss: 1.812672 | GPU: 35.7MB / 134.0MB | F: 0.0075s, B: 0.0029s, O: 0.0008s\n",
            "Step 2400 | Loss: 1.857262 | GPU: 35.7MB / 134.0MB | F: 0.0078s, B: 0.0091s, O: 0.0006s\n",
            "🔄 Topology update at step 2400 took 0.0000s\n",
            "🧹 Memory cleanup at step 2400 took 0.3922s\n",
            "Batch 2400/3125 ( 76.8%) | Loss: 1.563357 | Accuracy: 43.24% | Batch time: 0.0493s\n",
            "Step 2410 | Loss: 1.965469 | GPU: 35.7MB / 134.0MB | F: 0.0118s, B: 0.0078s, O: 0.0010s\n",
            "Step 2420 | Loss: 1.187013 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0044s, O: 0.0007s\n",
            "🔄 Topology update at step 2420 took 0.0000s\n",
            "Batch 2420/3125 ( 77.4%) | Loss: 1.561569 | Accuracy: 43.32% | Batch time: 0.1145s\n",
            "Step 2430 | Loss: 1.466763 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0029s, O: 0.0006s\n",
            "Step 2440 | Loss: 1.422287 | GPU: 35.7MB / 134.0MB | F: 0.0126s, B: 0.0122s, O: 0.0008s\n",
            "🔄 Topology update at step 2440 took 0.0001s\n",
            "Batch 2440/3125 ( 78.1%) | Loss: 1.560683 | Accuracy: 43.36% | Batch time: 0.0442s\n",
            "Step 2450 | Loss: 1.215435 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0099s, O: 0.0009s\n",
            "Step 2460 | Loss: 1.346565 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0079s, O: 0.0021s\n",
            "🔄 Topology update at step 2460 took 0.0001s\n",
            "Batch 2460/3125 ( 78.7%) | Loss: 1.558997 | Accuracy: 43.43% | Batch time: 0.0357s\n",
            "Step 2470 | Loss: 1.529793 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0052s, O: 0.0010s\n",
            "Step 2480 | Loss: 1.514866 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0027s, O: 0.0011s\n",
            "🔄 Topology update at step 2480 took 0.0000s\n",
            "Batch 2480/3125 ( 79.4%) | Loss: 1.558451 | Accuracy: 43.46% | Batch time: 0.0292s\n",
            "Step 2490 | Loss: 1.382057 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 2500 | Loss: 1.273408 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0046s, O: 0.0011s\n",
            "🔄 Topology update at step 2500 took 0.0001s\n",
            "🧹 Memory cleanup at step 2500 took 0.2573s\n",
            "Batch 2500/3125 ( 80.0%) | Loss: 1.556869 | Accuracy: 43.51% | Batch time: 0.0401s\n",
            "Step 2510 | Loss: 1.226464 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 2520 | Loss: 1.297115 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0091s, O: 0.0039s\n",
            "🔄 Topology update at step 2520 took 0.0000s\n",
            "Batch 2520/3125 ( 80.6%) | Loss: 1.555716 | Accuracy: 43.55% | Batch time: 0.0380s\n",
            "Step 2530 | Loss: 1.580200 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0034s, O: 0.0007s\n",
            "Step 2540 | Loss: 1.410182 | GPU: 35.7MB / 134.0MB | F: 0.0035s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 2540 took 0.0000s\n",
            "Batch 2540/3125 ( 81.3%) | Loss: 1.554788 | Accuracy: 43.60% | Batch time: 0.0477s\n",
            "Step 2550 | Loss: 1.427294 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0054s, O: 0.0022s\n",
            "Step 2560 | Loss: 1.422752 | GPU: 35.7MB / 134.0MB | F: 0.0031s, B: 0.0043s, O: 0.0011s\n",
            "🔄 Topology update at step 2560 took 0.0001s\n",
            "Batch 2560/3125 ( 81.9%) | Loss: 1.553490 | Accuracy: 43.67% | Batch time: 0.0387s\n",
            "Step 2570 | Loss: 1.238976 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0035s, O: 0.0011s\n",
            "Step 2580 | Loss: 1.772293 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0048s, O: 0.0007s\n",
            "🔄 Topology update at step 2580 took 0.0000s\n",
            "Batch 2580/3125 ( 82.6%) | Loss: 1.551995 | Accuracy: 43.73% | Batch time: 0.0332s\n",
            "Step 2590 | Loss: 1.093597 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0023s, O: 0.0006s\n",
            "Step 2600 | Loss: 1.458740 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 2600 took 0.0000s\n",
            "🧹 Memory cleanup at step 2600 took 0.2387s\n",
            "Batch 2600/3125 ( 83.2%) | Loss: 1.550426 | Accuracy: 43.78% | Batch time: 0.0396s\n",
            "Step 2610 | Loss: 1.648158 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0078s, O: 0.0010s\n",
            "Step 2620 | Loss: 1.395788 | GPU: 35.7MB / 134.0MB | F: 0.0044s, B: 0.0031s, O: 0.0010s\n",
            "🔄 Topology update at step 2620 took 0.0001s\n",
            "Batch 2620/3125 ( 83.8%) | Loss: 1.549388 | Accuracy: 43.84% | Batch time: 0.0341s\n",
            "Step 2630 | Loss: 1.000067 | GPU: 35.7MB / 134.0MB | F: 0.0086s, B: 0.0058s, O: 0.0010s\n",
            "Step 2640 | Loss: 1.449005 | GPU: 35.7MB / 134.0MB | F: 0.0045s, B: 0.0033s, O: 0.0010s\n",
            "🔄 Topology update at step 2640 took 0.0001s\n",
            "Batch 2640/3125 ( 84.5%) | Loss: 1.548291 | Accuracy: 43.90% | Batch time: 0.0360s\n",
            "Step 2650 | Loss: 1.288116 | GPU: 35.7MB / 134.0MB | F: 0.0043s, B: 0.0031s, O: 0.0008s\n",
            "Step 2660 | Loss: 1.392235 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 2660 took 0.0001s\n",
            "Batch 2660/3125 ( 85.1%) | Loss: 1.547128 | Accuracy: 43.94% | Batch time: 0.0383s\n",
            "Step 2670 | Loss: 1.190567 | GPU: 35.7MB / 134.0MB | F: 0.0038s, B: 0.0036s, O: 0.0017s\n",
            "Step 2680 | Loss: 1.195807 | GPU: 35.7MB / 134.0MB | F: 0.0034s, B: 0.0028s, O: 0.0006s\n",
            "🔄 Topology update at step 2680 took 0.0000s\n",
            "Batch 2680/3125 ( 85.8%) | Loss: 1.546271 | Accuracy: 43.98% | Batch time: 0.0362s\n",
            "Step 2690 | Loss: 1.367118 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0022s, O: 0.0006s\n",
            "Step 2700 | Loss: 1.202923 | GPU: 35.7MB / 134.0MB | F: 0.0033s, B: 0.0020s, O: 0.0006s\n",
            "🔄 Topology update at step 2700 took 0.0001s\n",
            "🧹 Memory cleanup at step 2700 took 0.2207s\n",
            "Batch 2700/3125 ( 86.4%) | Loss: 1.545049 | Accuracy: 44.03% | Batch time: 0.0384s\n",
            "Step 2710 | Loss: 2.012543 | GPU: 35.7MB / 134.0MB | F: 0.0085s, B: 0.0059s, O: 0.0011s\n",
            "Step 2720 | Loss: 1.369800 | GPU: 35.7MB / 134.0MB | F: 0.0014s, B: 0.0056s, O: 0.0007s\n",
            "🔄 Topology update at step 2720 took 0.0000s\n",
            "Batch 2720/3125 ( 87.0%) | Loss: 1.543172 | Accuracy: 44.08% | Batch time: 0.0381s\n",
            "Step 2730 | Loss: 1.223381 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0029s, O: 0.0007s\n",
            "Step 2740 | Loss: 1.359806 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0056s, O: 0.0006s\n",
            "🔄 Topology update at step 2740 took 0.0001s\n",
            "Batch 2740/3125 ( 87.7%) | Loss: 1.542070 | Accuracy: 44.13% | Batch time: 0.0351s\n",
            "Step 2750 | Loss: 1.097326 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0083s, O: 0.0009s\n",
            "Step 2760 | Loss: 1.301537 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0049s, O: 0.0006s\n",
            "🔄 Topology update at step 2760 took 0.0000s\n",
            "Batch 2760/3125 ( 88.3%) | Loss: 1.541131 | Accuracy: 44.15% | Batch time: 0.0352s\n",
            "Step 2770 | Loss: 1.047760 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0156s, O: 0.0007s\n",
            "Step 2780 | Loss: 1.012255 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0029s, O: 0.0028s\n",
            "🔄 Topology update at step 2780 took 0.0001s\n",
            "Batch 2780/3125 ( 89.0%) | Loss: 1.538940 | Accuracy: 44.26% | Batch time: 0.0375s\n",
            "Step 2790 | Loss: 1.636539 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0088s, O: 0.0007s\n",
            "Step 2800 | Loss: 1.036682 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0082s, O: 0.0006s\n",
            "🔄 Topology update at step 2800 took 0.0001s\n",
            "🧹 Memory cleanup at step 2800 took 0.1993s\n",
            "Batch 2800/3125 ( 89.6%) | Loss: 1.537486 | Accuracy: 44.31% | Batch time: 0.0399s\n",
            "Step 2810 | Loss: 1.491539 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0121s, O: 0.0008s\n",
            "Step 2820 | Loss: 1.215607 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0098s, O: 0.0010s\n",
            "🔄 Topology update at step 2820 took 0.0001s\n",
            "Batch 2820/3125 ( 90.2%) | Loss: 1.536530 | Accuracy: 44.34% | Batch time: 0.0357s\n",
            "Step 2830 | Loss: 1.658618 | GPU: 35.7MB / 134.0MB | F: 0.0069s, B: 0.0053s, O: 0.0010s\n",
            "Step 2840 | Loss: 1.566650 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0064s, O: 0.0072s\n",
            "🔄 Topology update at step 2840 took 0.0001s\n",
            "Batch 2840/3125 ( 90.9%) | Loss: 1.535155 | Accuracy: 44.40% | Batch time: 0.0386s\n",
            "Step 2850 | Loss: 1.244053 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0019s, O: 0.0007s\n",
            "Step 2860 | Loss: 1.141108 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0050s, O: 0.0010s\n",
            "🔄 Topology update at step 2860 took 0.0001s\n",
            "Batch 2860/3125 ( 91.5%) | Loss: 1.534082 | Accuracy: 44.46% | Batch time: 0.0336s\n",
            "Step 2870 | Loss: 1.488174 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0258s, O: 0.0008s\n",
            "Step 2880 | Loss: 1.350006 | GPU: 35.7MB / 134.0MB | F: 0.0058s, B: 0.0080s, O: 0.0030s\n",
            "🔄 Topology update at step 2880 took 0.0001s\n",
            "Batch 2880/3125 ( 92.2%) | Loss: 1.533210 | Accuracy: 44.52% | Batch time: 0.0686s\n",
            "Step 2890 | Loss: 0.960136 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0088s, O: 0.0023s\n",
            "Step 2900 | Loss: 1.304081 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0032s, O: 0.0007s\n",
            "🔄 Topology update at step 2900 took 0.0000s\n",
            "🧹 Memory cleanup at step 2900 took 0.3956s\n",
            "Batch 2900/3125 ( 92.8%) | Loss: 1.532126 | Accuracy: 44.56% | Batch time: 0.0475s\n",
            "Step 2910 | Loss: 1.349137 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0119s, O: 0.0006s\n",
            "Step 2920 | Loss: 1.170418 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0083s, O: 0.0008s\n",
            "🔄 Topology update at step 2920 took 0.0000s\n",
            "Batch 2920/3125 ( 93.4%) | Loss: 1.530605 | Accuracy: 44.62% | Batch time: 0.0433s\n",
            "Step 2930 | Loss: 0.908501 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0092s, O: 0.0007s\n",
            "Step 2940 | Loss: 1.648905 | GPU: 35.7MB / 134.0MB | F: 0.0037s, B: 0.0027s, O: 0.0006s\n",
            "🔄 Topology update at step 2940 took 0.0000s\n",
            "Batch 2940/3125 ( 94.1%) | Loss: 1.529074 | Accuracy: 44.66% | Batch time: 0.0418s\n",
            "Step 2950 | Loss: 1.206879 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0064s, O: 0.0006s\n",
            "Step 2960 | Loss: 1.272499 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0096s, O: 0.0006s\n",
            "🔄 Topology update at step 2960 took 0.0000s\n",
            "Batch 2960/3125 ( 94.7%) | Loss: 1.527010 | Accuracy: 44.73% | Batch time: 0.0559s\n",
            "Step 2970 | Loss: 1.372391 | GPU: 35.7MB / 134.0MB | F: 0.0176s, B: 0.0031s, O: 0.0057s\n",
            "Step 2980 | Loss: 2.175896 | GPU: 35.7MB / 134.0MB | F: 0.0087s, B: 0.0037s, O: 0.0006s\n",
            "🔄 Topology update at step 2980 took 0.0027s\n",
            "Batch 2980/3125 ( 95.4%) | Loss: 1.526074 | Accuracy: 44.76% | Batch time: 0.0544s\n",
            "Step 2990 | Loss: 1.291800 | GPU: 35.7MB / 134.0MB | F: 0.0102s, B: 0.0021s, O: 0.0005s\n",
            "Step 3000 | Loss: 1.578362 | GPU: 35.7MB / 134.0MB | F: 0.0044s, B: 0.0033s, O: 0.0010s\n",
            "🔄 Topology update at step 3000 took 0.0001s\n",
            "🧹 Memory cleanup at step 3000 took 0.2453s\n",
            "Batch 3000/3125 ( 96.0%) | Loss: 1.524428 | Accuracy: 44.82% | Batch time: 0.0397s\n",
            "Step 3010 | Loss: 0.900955 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0020s, O: 0.0006s\n",
            "Step 3020 | Loss: 1.520283 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0082s, O: 0.0011s\n",
            "🔄 Topology update at step 3020 took 0.0001s\n",
            "Batch 3020/3125 ( 96.6%) | Loss: 1.523040 | Accuracy: 44.85% | Batch time: 0.0387s\n",
            "Step 3030 | Loss: 1.185379 | GPU: 35.7MB / 134.0MB | F: 0.0088s, B: 0.0022s, O: 0.0006s\n",
            "Step 3040 | Loss: 1.043030 | GPU: 35.7MB / 134.0MB | F: 0.0068s, B: 0.0061s, O: 0.0010s\n",
            "🔄 Topology update at step 3040 took 0.0001s\n",
            "Batch 3040/3125 ( 97.3%) | Loss: 1.522066 | Accuracy: 44.91% | Batch time: 0.0333s\n",
            "Step 3050 | Loss: 1.526520 | GPU: 35.7MB / 134.0MB | F: 0.0045s, B: 0.0031s, O: 0.0009s\n",
            "Step 3060 | Loss: 1.409374 | GPU: 35.7MB / 134.0MB | F: 0.0149s, B: 0.0037s, O: 0.0010s\n",
            "🔄 Topology update at step 3060 took 0.0001s\n",
            "Batch 3060/3125 ( 97.9%) | Loss: 1.520667 | Accuracy: 44.94% | Batch time: 0.0358s\n",
            "Step 3070 | Loss: 1.404463 | GPU: 35.7MB / 134.0MB | F: 0.0014s, B: 0.0112s, O: 0.0010s\n",
            "Step 3080 | Loss: 1.297397 | GPU: 35.7MB / 134.0MB | F: 0.0161s, B: 0.0033s, O: 0.0010s\n",
            "🔄 Topology update at step 3080 took 0.0001s\n",
            "Batch 3080/3125 ( 98.6%) | Loss: 1.519713 | Accuracy: 44.97% | Batch time: 0.0354s\n",
            "Step 3090 | Loss: 1.194794 | GPU: 35.7MB / 134.0MB | F: 0.0050s, B: 0.0117s, O: 0.0009s\n",
            "Step 3100 | Loss: 1.039032 | GPU: 35.7MB / 134.0MB | F: 0.0037s, B: 0.0032s, O: 0.0011s\n",
            "🔄 Topology update at step 3100 took 0.0001s\n",
            "🧹 Memory cleanup at step 3100 took 0.2427s\n",
            "Batch 3100/3125 ( 99.2%) | Loss: 1.518458 | Accuracy: 45.01% | Batch time: 0.0345s\n",
            "Step 3110 | Loss: 1.274343 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "Step 3120 | Loss: 1.484419 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0040s, O: 0.0015s\n",
            "🔄 Topology update at step 3120 took 0.0001s\n",
            "Batch 3120/3125 ( 99.8%) | Loss: 1.517029 | Accuracy: 45.07% | Batch time: 0.0333s\n",
            "\n",
            "-------------------- EPOCH 1 SUMMARY --------------------\n",
            "Loss: 1.516551 | Accuracy: 45.09%\n",
            "Time: 77.00s total, 0.0197s per batch\n",
            "🔄 Final Memory - RAM: 8190.5MB, GPU: 35.7MB allocated, 70.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=35.8, peak=38.9\n",
            "===============================\n",
            "\n",
            "⏱️ TALT model training took 77.0072 seconds\n",
            "\n",
            "Cleaning up memory after training...\n",
            "⏱️ Memory cleanup took 0.2566 seconds\n",
            "🔄 After training Memory - RAM: 8190.5MB, GPU: 35.5MB allocated, 64.0MB reserved\n",
            "\n",
            "------------------------- Standard Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 1.607454 | Accuracy: 38.73% | Batch time: 0.0021s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 1.567549 | Accuracy: 40.66% | Batch time: 0.0015s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 1.568860 | Accuracy: 41.39% | Batch time: 0.0012s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 1.582056 | Accuracy: 40.70% | Batch time: 0.0032s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 1.581001 | Accuracy: 40.91% | Batch time: 0.0014s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 1.582038 | Accuracy: 40.68% | Batch time: 0.0014s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 1.582290 | Accuracy: 40.81% | Batch time: 0.0017s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 1.580594 | Accuracy: 40.74% | Batch time: 0.0018s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 1.582679 | Accuracy: 40.58% | Batch time: 0.0015s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 1.579236 | Accuracy: 40.77% | Batch time: 0.0017s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 1.582206 | Accuracy: 40.49% | Batch time: 0.0013s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 1.582108 | Accuracy: 40.37% | Batch time: 0.0013s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.581645 | Accuracy: 40.24%\n",
            "Time: 5.96s total, 0.0018s per batch\n",
            "⏱️ Standard model evaluation took 5.9607 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 1.184143 | Accuracy: 56.37% | Batch time: 0.0010s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 1.159629 | Accuracy: 57.30% | Batch time: 0.0010s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 1.159140 | Accuracy: 57.99% | Batch time: 0.0019s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 1.163268 | Accuracy: 58.15% | Batch time: 0.0012s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 1.161733 | Accuracy: 58.12% | Batch time: 0.0013s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 1.163005 | Accuracy: 58.51% | Batch time: 0.0013s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 1.162549 | Accuracy: 58.71% | Batch time: 0.0012s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 1.167231 | Accuracy: 58.56% | Batch time: 0.0014s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 1.172738 | Accuracy: 58.20% | Batch time: 0.0013s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 1.165431 | Accuracy: 58.66% | Batch time: 0.0013s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 1.170672 | Accuracy: 58.48% | Batch time: 0.0014s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 1.168804 | Accuracy: 58.59% | Batch time: 0.0013s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.171169 | Accuracy: 58.51%\n",
            "Time: 6.55s total, 0.0015s per batch\n",
            "⏱️ TALT model evaluation took 6.5552 seconds\n",
            "\n",
            "------------------------- EPOCH 1 SUMMARY -------------------------\n",
            "Time: 124.88s\n",
            "Standard Model:\n",
            "  - Train Loss: 2.065733, Accuracy: 21.27%\n",
            "  - Test Loss:  1.581645, Accuracy: 40.24%\n",
            "Improved TALT Model:\n",
            "  - Train Loss: 1.516551, Accuracy: 45.09%\n",
            "  - Test Loss:  1.171169, Accuracy: 58.51%\n",
            "\n",
            "📈 TALT outperforms standard by 18.27% on test accuracy\n",
            "\n",
            "Cleaning up memory after epoch...\n",
            "⏱️ Memory cleanup took 0.2948 seconds\n",
            "🔄 After epoch Memory - RAM: 8190.5MB, GPU: 35.5MB allocated, 64.0MB reserved\n",
            "\n",
            "------------------------- Standard Model: Epoch 2/3 -------------------------\n",
            "\n",
            "==================== STANDARD OPTIMIZER - EPOCH 2 ====================\n",
            "Device: cuda, Batches: 3125, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 8190.5MB, GPU: 35.5MB allocated, 64.0MB reserved\n",
            "Batch    0/3125 (  0.0%) | Loss: 2.259252 | Accuracy: 18.75% | GPU: 35.7MB | Batch time: 0.0269s\n",
            "Batch   20/3125 (  0.6%) | Loss: 1.809342 | Accuracy: 34.52% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch   40/3125 (  1.3%) | Loss: 1.788024 | Accuracy: 34.60% | GPU: 35.7MB | Batch time: 0.0059s\n",
            "Batch   60/3125 (  1.9%) | Loss: 1.771405 | Accuracy: 34.12% | GPU: 35.7MB | Batch time: 0.0087s\n",
            "Batch   80/3125 (  2.6%) | Loss: 1.784677 | Accuracy: 32.64% | GPU: 35.7MB | Batch time: 0.0085s\n",
            "Batch  100/3125 (  3.2%) | Loss: 1.797514 | Accuracy: 31.81% | GPU: 35.7MB | Batch time: 0.0080s\n",
            "Batch  120/3125 (  3.8%) | Loss: 1.798303 | Accuracy: 31.66% | GPU: 35.7MB | Batch time: 0.0054s\n",
            "Batch  140/3125 (  4.5%) | Loss: 1.793370 | Accuracy: 32.40% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch  160/3125 (  5.1%) | Loss: 1.794416 | Accuracy: 32.03% | GPU: 35.7MB | Batch time: 0.0049s\n",
            "Batch  180/3125 (  5.8%) | Loss: 1.790329 | Accuracy: 31.91% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch  200/3125 (  6.4%) | Loss: 1.781411 | Accuracy: 32.40% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch  220/3125 (  7.0%) | Loss: 1.775606 | Accuracy: 32.58% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch  240/3125 (  7.7%) | Loss: 1.770504 | Accuracy: 32.39% | GPU: 35.7MB | Batch time: 0.0055s\n",
            "Batch  260/3125 (  8.3%) | Loss: 1.766458 | Accuracy: 32.64% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch  280/3125 (  9.0%) | Loss: 1.763341 | Accuracy: 33.05% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch  300/3125 (  9.6%) | Loss: 1.759320 | Accuracy: 33.62% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch  320/3125 ( 10.2%) | Loss: 1.756283 | Accuracy: 33.76% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch  340/3125 ( 10.9%) | Loss: 1.762273 | Accuracy: 33.50% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch  360/3125 ( 11.5%) | Loss: 1.758454 | Accuracy: 33.67% | GPU: 35.7MB | Batch time: 0.0046s\n",
            "Batch  380/3125 ( 12.2%) | Loss: 1.756430 | Accuracy: 33.65% | GPU: 35.7MB | Batch time: 0.0111s\n",
            "Batch  400/3125 ( 12.8%) | Loss: 1.753652 | Accuracy: 33.63% | GPU: 35.7MB | Batch time: 0.0046s\n",
            "Batch  420/3125 ( 13.4%) | Loss: 1.752371 | Accuracy: 33.83% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch  440/3125 ( 14.1%) | Loss: 1.754062 | Accuracy: 33.76% | GPU: 35.7MB | Batch time: 0.0054s\n",
            "Batch  460/3125 ( 14.7%) | Loss: 1.751793 | Accuracy: 34.00% | GPU: 35.7MB | Batch time: 0.0053s\n",
            "Batch  480/3125 ( 15.4%) | Loss: 1.747118 | Accuracy: 34.08% | GPU: 35.7MB | Batch time: 0.0090s\n",
            "Batch  500/3125 ( 16.0%) | Loss: 1.743202 | Accuracy: 34.27% | GPU: 35.7MB | Batch time: 0.0056s\n",
            "Batch  520/3125 ( 16.6%) | Loss: 1.740241 | Accuracy: 34.42% | GPU: 35.7MB | Batch time: 0.0048s\n",
            "Batch  540/3125 ( 17.3%) | Loss: 1.740433 | Accuracy: 34.46% | GPU: 35.7MB | Batch time: 0.0075s\n",
            "Batch  560/3125 ( 17.9%) | Loss: 1.740835 | Accuracy: 34.53% | GPU: 35.7MB | Batch time: 0.0043s\n",
            "Batch  580/3125 ( 18.6%) | Loss: 1.739009 | Accuracy: 34.60% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch  600/3125 ( 19.2%) | Loss: 1.742099 | Accuracy: 34.55% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch  620/3125 ( 19.8%) | Loss: 1.743634 | Accuracy: 34.57% | GPU: 35.7MB | Batch time: 0.0236s\n",
            "Batch  640/3125 ( 20.5%) | Loss: 1.738142 | Accuracy: 34.64% | GPU: 35.7MB | Batch time: 0.0064s\n",
            "Batch  660/3125 ( 21.1%) | Loss: 1.732401 | Accuracy: 34.77% | GPU: 35.7MB | Batch time: 0.0108s\n",
            "Batch  680/3125 ( 21.8%) | Loss: 1.734984 | Accuracy: 34.66% | GPU: 35.7MB | Batch time: 0.0029s\n",
            "Batch  700/3125 ( 22.4%) | Loss: 1.732321 | Accuracy: 34.77% | GPU: 35.7MB | Batch time: 0.0027s\n",
            "Batch  720/3125 ( 23.0%) | Loss: 1.728454 | Accuracy: 34.97% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch  740/3125 ( 23.7%) | Loss: 1.726982 | Accuracy: 35.16% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch  760/3125 ( 24.3%) | Loss: 1.725320 | Accuracy: 35.24% | GPU: 35.7MB | Batch time: 0.0071s\n",
            "Batch  780/3125 ( 25.0%) | Loss: 1.724957 | Accuracy: 35.30% | GPU: 35.7MB | Batch time: 0.0076s\n",
            "Batch  800/3125 ( 25.6%) | Loss: 1.722513 | Accuracy: 35.42% | GPU: 35.7MB | Batch time: 0.0247s\n",
            "Batch  820/3125 ( 26.2%) | Loss: 1.721231 | Accuracy: 35.45% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch  840/3125 ( 26.9%) | Loss: 1.717077 | Accuracy: 35.54% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch  860/3125 ( 27.5%) | Loss: 1.716054 | Accuracy: 35.52% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch  880/3125 ( 28.2%) | Loss: 1.715537 | Accuracy: 35.64% | GPU: 35.7MB | Batch time: 0.0053s\n",
            "Batch  900/3125 ( 28.8%) | Loss: 1.714180 | Accuracy: 35.75% | GPU: 35.7MB | Batch time: 0.0055s\n",
            "Batch  920/3125 ( 29.4%) | Loss: 1.710054 | Accuracy: 35.91% | GPU: 35.7MB | Batch time: 0.0066s\n",
            "Batch  940/3125 ( 30.1%) | Loss: 1.709897 | Accuracy: 35.88% | GPU: 35.7MB | Batch time: 0.0053s\n",
            "Batch  960/3125 ( 30.7%) | Loss: 1.710339 | Accuracy: 35.93% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch  980/3125 ( 31.4%) | Loss: 1.706494 | Accuracy: 36.11% | GPU: 35.7MB | Batch time: 0.0046s\n",
            "Batch 1000/3125 ( 32.0%) | Loss: 1.704877 | Accuracy: 36.20% | GPU: 35.7MB | Batch time: 0.0104s\n",
            "Batch 1020/3125 ( 32.6%) | Loss: 1.701795 | Accuracy: 36.30% | GPU: 35.7MB | Batch time: 0.0041s\n",
            "Batch 1040/3125 ( 33.3%) | Loss: 1.700872 | Accuracy: 36.44% | GPU: 35.7MB | Batch time: 0.0045s\n",
            "Batch 1060/3125 ( 33.9%) | Loss: 1.699507 | Accuracy: 36.53% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch 1080/3125 ( 34.6%) | Loss: 1.700492 | Accuracy: 36.51% | GPU: 35.7MB | Batch time: 0.0050s\n",
            "Batch 1100/3125 ( 35.2%) | Loss: 1.699590 | Accuracy: 36.55% | GPU: 35.7MB | Batch time: 0.0046s\n",
            "Batch 1120/3125 ( 35.8%) | Loss: 1.698673 | Accuracy: 36.64% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 1140/3125 ( 36.5%) | Loss: 1.696357 | Accuracy: 36.77% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch 1160/3125 ( 37.1%) | Loss: 1.695391 | Accuracy: 36.81% | GPU: 35.7MB | Batch time: 0.0050s\n",
            "Batch 1180/3125 ( 37.8%) | Loss: 1.694499 | Accuracy: 36.88% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch 1200/3125 ( 38.4%) | Loss: 1.693280 | Accuracy: 36.96% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 1220/3125 ( 39.0%) | Loss: 1.691175 | Accuracy: 37.04% | GPU: 35.7MB | Batch time: 0.0047s\n",
            "Batch 1240/3125 ( 39.7%) | Loss: 1.691632 | Accuracy: 37.06% | GPU: 35.7MB | Batch time: 0.0054s\n",
            "Batch 1260/3125 ( 40.3%) | Loss: 1.691008 | Accuracy: 37.02% | GPU: 35.7MB | Batch time: 0.0140s\n",
            "Batch 1280/3125 ( 41.0%) | Loss: 1.688568 | Accuracy: 37.10% | GPU: 35.7MB | Batch time: 0.0041s\n",
            "Batch 1300/3125 ( 41.6%) | Loss: 1.687567 | Accuracy: 37.18% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch 1320/3125 ( 42.2%) | Loss: 1.685918 | Accuracy: 37.22% | GPU: 35.7MB | Batch time: 0.0067s\n",
            "Batch 1340/3125 ( 42.9%) | Loss: 1.685436 | Accuracy: 37.23% | GPU: 35.7MB | Batch time: 0.0068s\n",
            "Batch 1360/3125 ( 43.5%) | Loss: 1.685050 | Accuracy: 37.28% | GPU: 35.7MB | Batch time: 0.0050s\n",
            "Batch 1380/3125 ( 44.2%) | Loss: 1.685192 | Accuracy: 37.30% | GPU: 35.7MB | Batch time: 0.0032s\n",
            "Batch 1400/3125 ( 44.8%) | Loss: 1.683364 | Accuracy: 37.42% | GPU: 35.7MB | Batch time: 0.0041s\n",
            "Batch 1420/3125 ( 45.4%) | Loss: 1.682007 | Accuracy: 37.49% | GPU: 35.7MB | Batch time: 0.0112s\n",
            "Batch 1440/3125 ( 46.1%) | Loss: 1.679110 | Accuracy: 37.60% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 1460/3125 ( 46.7%) | Loss: 1.678639 | Accuracy: 37.62% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 1480/3125 ( 47.4%) | Loss: 1.677384 | Accuracy: 37.69% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 1500/3125 ( 48.0%) | Loss: 1.676335 | Accuracy: 37.71% | GPU: 35.7MB | Batch time: 0.0101s\n",
            "Batch 1520/3125 ( 48.6%) | Loss: 1.675428 | Accuracy: 37.79% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch 1540/3125 ( 49.3%) | Loss: 1.674319 | Accuracy: 37.86% | GPU: 35.7MB | Batch time: 0.0051s\n",
            "Batch 1560/3125 ( 49.9%) | Loss: 1.672731 | Accuracy: 37.91% | GPU: 35.7MB | Batch time: 0.0050s\n",
            "Batch 1580/3125 ( 50.6%) | Loss: 1.671078 | Accuracy: 37.98% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch 1600/3125 ( 51.2%) | Loss: 1.669625 | Accuracy: 37.99% | GPU: 35.7MB | Batch time: 0.0068s\n",
            "Batch 1620/3125 ( 51.8%) | Loss: 1.668768 | Accuracy: 38.00% | GPU: 35.7MB | Batch time: 0.0044s\n",
            "Batch 1640/3125 ( 52.5%) | Loss: 1.668080 | Accuracy: 38.04% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch 1660/3125 ( 53.1%) | Loss: 1.665957 | Accuracy: 38.12% | GPU: 35.7MB | Batch time: 0.0044s\n",
            "Batch 1680/3125 ( 53.8%) | Loss: 1.667224 | Accuracy: 38.09% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch 1700/3125 ( 54.4%) | Loss: 1.666898 | Accuracy: 38.11% | GPU: 35.7MB | Batch time: 0.0092s\n",
            "Batch 1720/3125 ( 55.0%) | Loss: 1.665865 | Accuracy: 38.15% | GPU: 35.7MB | Batch time: 0.0060s\n",
            "Batch 1740/3125 ( 55.7%) | Loss: 1.663876 | Accuracy: 38.21% | GPU: 35.7MB | Batch time: 0.0058s\n",
            "Batch 1760/3125 ( 56.3%) | Loss: 1.661511 | Accuracy: 38.28% | GPU: 35.7MB | Batch time: 0.0053s\n",
            "Batch 1780/3125 ( 57.0%) | Loss: 1.660120 | Accuracy: 38.32% | GPU: 35.7MB | Batch time: 0.0043s\n",
            "Batch 1800/3125 ( 57.6%) | Loss: 1.659862 | Accuracy: 38.38% | GPU: 35.7MB | Batch time: 0.0075s\n",
            "Batch 1820/3125 ( 58.2%) | Loss: 1.660574 | Accuracy: 38.39% | GPU: 35.7MB | Batch time: 0.0067s\n",
            "Batch 1840/3125 ( 58.9%) | Loss: 1.659775 | Accuracy: 38.42% | GPU: 35.7MB | Batch time: 0.0131s\n",
            "Batch 1860/3125 ( 59.5%) | Loss: 1.658525 | Accuracy: 38.50% | GPU: 35.7MB | Batch time: 0.0153s\n",
            "Batch 1880/3125 ( 60.2%) | Loss: 1.658961 | Accuracy: 38.56% | GPU: 35.7MB | Batch time: 0.0107s\n",
            "Batch 1900/3125 ( 60.8%) | Loss: 1.658366 | Accuracy: 38.57% | GPU: 35.7MB | Batch time: 0.0184s\n",
            "Batch 1920/3125 ( 61.4%) | Loss: 1.657603 | Accuracy: 38.59% | GPU: 35.7MB | Batch time: 0.0030s\n",
            "Batch 1940/3125 ( 62.1%) | Loss: 1.657149 | Accuracy: 38.58% | GPU: 35.7MB | Batch time: 0.0033s\n",
            "Batch 1960/3125 ( 62.7%) | Loss: 1.656484 | Accuracy: 38.61% | GPU: 35.7MB | Batch time: 0.0041s\n",
            "Batch 1980/3125 ( 63.4%) | Loss: 1.654834 | Accuracy: 38.71% | GPU: 35.7MB | Batch time: 0.0052s\n",
            "Batch 2000/3125 ( 64.0%) | Loss: 1.653790 | Accuracy: 38.76% | GPU: 35.7MB | Batch time: 0.0062s\n",
            "Batch 2020/3125 ( 64.6%) | Loss: 1.651894 | Accuracy: 38.82% | GPU: 35.7MB | Batch time: 0.0043s\n",
            "Batch 2040/3125 ( 65.3%) | Loss: 1.650455 | Accuracy: 38.87% | GPU: 35.7MB | Batch time: 0.0123s\n",
            "Batch 2060/3125 ( 65.9%) | Loss: 1.649069 | Accuracy: 38.94% | GPU: 35.7MB | Batch time: 0.0080s\n",
            "Batch 2080/3125 ( 66.6%) | Loss: 1.648923 | Accuracy: 38.98% | GPU: 35.7MB | Batch time: 0.0145s\n",
            "Batch 2100/3125 ( 67.2%) | Loss: 1.648139 | Accuracy: 38.98% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 2120/3125 ( 67.8%) | Loss: 1.648382 | Accuracy: 38.97% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 2140/3125 ( 68.5%) | Loss: 1.647505 | Accuracy: 39.01% | GPU: 35.7MB | Batch time: 0.0045s\n",
            "Batch 2160/3125 ( 69.1%) | Loss: 1.648551 | Accuracy: 39.01% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch 2180/3125 ( 69.8%) | Loss: 1.647135 | Accuracy: 39.06% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch 2200/3125 ( 70.4%) | Loss: 1.646654 | Accuracy: 39.08% | GPU: 35.7MB | Batch time: 0.0069s\n",
            "Batch 2220/3125 ( 71.0%) | Loss: 1.645608 | Accuracy: 39.11% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch 2240/3125 ( 71.7%) | Loss: 1.644252 | Accuracy: 39.17% | GPU: 35.7MB | Batch time: 0.0100s\n",
            "Batch 2260/3125 ( 72.3%) | Loss: 1.642587 | Accuracy: 39.21% | GPU: 35.7MB | Batch time: 0.0048s\n",
            "Batch 2280/3125 ( 73.0%) | Loss: 1.640639 | Accuracy: 39.30% | GPU: 35.7MB | Batch time: 0.0049s\n",
            "Batch 2300/3125 ( 73.6%) | Loss: 1.640930 | Accuracy: 39.31% | GPU: 35.7MB | Batch time: 0.0065s\n",
            "Batch 2320/3125 ( 74.2%) | Loss: 1.641107 | Accuracy: 39.29% | GPU: 35.7MB | Batch time: 0.0052s\n",
            "Batch 2340/3125 ( 74.9%) | Loss: 1.639877 | Accuracy: 39.33% | GPU: 35.7MB | Batch time: 0.0048s\n",
            "Batch 2360/3125 ( 75.5%) | Loss: 1.638743 | Accuracy: 39.41% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 2380/3125 ( 76.2%) | Loss: 1.637417 | Accuracy: 39.47% | GPU: 35.7MB | Batch time: 0.0052s\n",
            "Batch 2400/3125 ( 76.8%) | Loss: 1.637105 | Accuracy: 39.48% | GPU: 35.7MB | Batch time: 0.0049s\n",
            "Batch 2420/3125 ( 77.4%) | Loss: 1.635456 | Accuracy: 39.51% | GPU: 35.7MB | Batch time: 0.0052s\n",
            "Batch 2440/3125 ( 78.1%) | Loss: 1.634239 | Accuracy: 39.56% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 2460/3125 ( 78.7%) | Loss: 1.633045 | Accuracy: 39.62% | GPU: 35.7MB | Batch time: 0.0099s\n",
            "Batch 2480/3125 ( 79.4%) | Loss: 1.631818 | Accuracy: 39.68% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 2500/3125 ( 80.0%) | Loss: 1.631476 | Accuracy: 39.69% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 2520/3125 ( 80.6%) | Loss: 1.630601 | Accuracy: 39.73% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 2540/3125 ( 81.3%) | Loss: 1.628825 | Accuracy: 39.79% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 2560/3125 ( 81.9%) | Loss: 1.626386 | Accuracy: 39.86% | GPU: 35.7MB | Batch time: 0.0045s\n",
            "Batch 2580/3125 ( 82.6%) | Loss: 1.625591 | Accuracy: 39.89% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 2600/3125 ( 83.2%) | Loss: 1.624687 | Accuracy: 39.91% | GPU: 35.7MB | Batch time: 0.0129s\n",
            "Batch 2620/3125 ( 83.8%) | Loss: 1.623629 | Accuracy: 39.97% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch 2640/3125 ( 84.5%) | Loss: 1.622936 | Accuracy: 40.01% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch 2660/3125 ( 85.1%) | Loss: 1.621975 | Accuracy: 40.06% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch 2680/3125 ( 85.8%) | Loss: 1.621351 | Accuracy: 40.08% | GPU: 35.7MB | Batch time: 0.0043s\n",
            "Batch 2700/3125 ( 86.4%) | Loss: 1.620479 | Accuracy: 40.12% | GPU: 35.7MB | Batch time: 0.0064s\n",
            "Batch 2720/3125 ( 87.0%) | Loss: 1.619463 | Accuracy: 40.16% | GPU: 35.7MB | Batch time: 0.0050s\n",
            "Batch 2740/3125 ( 87.7%) | Loss: 1.618364 | Accuracy: 40.21% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch 2760/3125 ( 88.3%) | Loss: 1.618699 | Accuracy: 40.22% | GPU: 35.7MB | Batch time: 0.0057s\n",
            "Batch 2780/3125 ( 89.0%) | Loss: 1.617764 | Accuracy: 40.26% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 2800/3125 ( 89.6%) | Loss: 1.617455 | Accuracy: 40.29% | GPU: 35.7MB | Batch time: 0.0033s\n",
            "Batch 2820/3125 ( 90.2%) | Loss: 1.616776 | Accuracy: 40.34% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 2840/3125 ( 90.9%) | Loss: 1.616091 | Accuracy: 40.38% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch 2860/3125 ( 91.5%) | Loss: 1.614777 | Accuracy: 40.42% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 2880/3125 ( 92.2%) | Loss: 1.614205 | Accuracy: 40.45% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 2900/3125 ( 92.8%) | Loss: 1.612306 | Accuracy: 40.54% | GPU: 35.7MB | Batch time: 0.0118s\n",
            "Batch 2920/3125 ( 93.4%) | Loss: 1.611742 | Accuracy: 40.55% | GPU: 35.7MB | Batch time: 0.0052s\n",
            "Batch 2940/3125 ( 94.1%) | Loss: 1.610292 | Accuracy: 40.63% | GPU: 35.7MB | Batch time: 0.0181s\n",
            "Batch 2960/3125 ( 94.7%) | Loss: 1.609876 | Accuracy: 40.65% | GPU: 35.7MB | Batch time: 0.0042s\n",
            "Batch 2980/3125 ( 95.4%) | Loss: 1.609167 | Accuracy: 40.69% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 3000/3125 ( 96.0%) | Loss: 1.608005 | Accuracy: 40.73% | GPU: 35.7MB | Batch time: 0.0042s\n",
            "Batch 3020/3125 ( 96.6%) | Loss: 1.607381 | Accuracy: 40.76% | GPU: 35.7MB | Batch time: 0.0044s\n",
            "Batch 3040/3125 ( 97.3%) | Loss: 1.606904 | Accuracy: 40.81% | GPU: 35.7MB | Batch time: 0.0185s\n",
            "Batch 3060/3125 ( 97.9%) | Loss: 1.605961 | Accuracy: 40.84% | GPU: 35.7MB | Batch time: 0.0090s\n",
            "Batch 3080/3125 ( 98.6%) | Loss: 1.604922 | Accuracy: 40.90% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch 3100/3125 ( 99.2%) | Loss: 1.604454 | Accuracy: 40.93% | GPU: 35.7MB | Batch time: 0.0071s\n",
            "Batch 3120/3125 ( 99.8%) | Loss: 1.603172 | Accuracy: 40.99% | GPU: 35.7MB | Batch time: 0.0026s\n",
            "Batch 3124/3125 (100.0%) | Loss: 1.602612 | Accuracy: 41.01% | GPU: 35.7MB | Batch time: 0.0118s\n",
            "\n",
            "-------------------- STANDARD OPTIMIZER - SUMMARY --------------------\n",
            "Loss: 1.602612 | Accuracy: 41.01%\n",
            "Time: 34.65s total, 0.0059s per batch\n",
            "  - Forward: 0.0019s, Backward: 0.0027s, Optimizer: 0.0006s\n",
            "🔄 Final Memory - RAM: 8190.7MB, GPU: 35.7MB allocated, 68.0MB reserved\n",
            "⏱️ Standard model training took 34.6620 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Epoch 2/3 -------------------------\n",
            "\n",
            "==================== EPOCH 2 TRAINING ====================\n",
            "Device: cuda, Batches: 3125, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 8190.7MB, GPU: 35.5MB allocated, 68.0MB reserved\n",
            "Batch    0/3125 (  0.0%) | Loss: 1.031207 | Accuracy: 62.50% | Batch time: 0.1016s\n",
            "Step 3130 | Loss: 1.498670 | GPU: 35.7MB / 70.0MB | F: 0.0013s, B: 0.0041s, O: 0.0005s\n",
            "Step 3140 | Loss: 1.329643 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0038s, O: 0.0006s\n",
            "🔄 Topology update at step 3140 took 0.0001s\n",
            "Batch   20/3125 (  0.6%) | Loss: 1.315083 | Accuracy: 52.98% | Batch time: 0.0572s\n",
            "Step 3150 | Loss: 1.147491 | GPU: 35.7MB / 70.0MB | F: 0.0014s, B: 0.0078s, O: 0.0009s\n",
            "Step 3160 | Loss: 0.992970 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 3160 took 0.0000s\n",
            "Batch   40/3125 (  1.3%) | Loss: 1.308680 | Accuracy: 53.35% | Batch time: 0.0341s\n",
            "Step 3170 | Loss: 1.732178 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 3180 | Loss: 0.744693 | GPU: 35.7MB / 134.0MB | F: 0.0042s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 3180 took 0.0000s\n",
            "Batch   60/3125 (  1.9%) | Loss: 1.266685 | Accuracy: 55.74% | Batch time: 0.0392s\n",
            "Step 3190 | Loss: 0.869714 | GPU: 35.7MB / 70.0MB | F: 0.0019s, B: 0.0114s, O: 0.0007s\n",
            "Step 3200 | Loss: 1.232474 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0068s, O: 0.0007s\n",
            "🔄 Topology update at step 3200 took 0.0000s\n",
            "🧹 Memory cleanup at step 3200 took 0.4954s\n",
            "Batch   80/3125 (  2.6%) | Loss: 1.248472 | Accuracy: 55.94% | Batch time: 0.0355s\n",
            "Step 3210 | Loss: 1.230039 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0058s, O: 0.0028s\n",
            "Step 3220 | Loss: 1.575737 | GPU: 35.7MB / 134.0MB | F: 0.0094s, B: 0.0047s, O: 0.0017s\n",
            "🔄 Topology update at step 3220 took 0.0001s\n",
            "Batch  100/3125 (  3.2%) | Loss: 1.263255 | Accuracy: 55.32% | Batch time: 0.0412s\n",
            "Step 3230 | Loss: 0.938541 | GPU: 35.7MB / 70.0MB | F: 0.0019s, B: 0.0097s, O: 0.0017s\n",
            "Step 3240 | Loss: 1.286776 | GPU: 35.7MB / 134.0MB | F: 0.0041s, B: 0.0058s, O: 0.0016s\n",
            "🔄 Topology update at step 3240 took 0.0001s\n",
            "Batch  120/3125 (  3.8%) | Loss: 1.280430 | Accuracy: 54.75% | Batch time: 0.0314s\n",
            "Step 3250 | Loss: 1.032298 | GPU: 35.7MB / 70.0MB | F: 0.0033s, B: 0.0025s, O: 0.0007s\n",
            "Step 3260 | Loss: 1.374378 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0048s, O: 0.0011s\n",
            "🔄 Topology update at step 3260 took 0.0001s\n",
            "Batch  140/3125 (  4.5%) | Loss: 1.281628 | Accuracy: 54.74% | Batch time: 0.0415s\n",
            "Step 3270 | Loss: 0.890383 | GPU: 35.7MB / 70.0MB | F: 0.0020s, B: 0.0091s, O: 0.0016s\n",
            "Step 3280 | Loss: 1.025002 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0038s, O: 0.0022s\n",
            "🔄 Topology update at step 3280 took 0.0001s\n",
            "Batch  160/3125 (  5.1%) | Loss: 1.277670 | Accuracy: 55.43% | Batch time: 0.0458s\n",
            "Step 3290 | Loss: 2.058872 | GPU: 35.7MB / 70.0MB | F: 0.0026s, B: 0.0045s, O: 0.0011s\n",
            "Step 3300 | Loss: 1.397842 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3300 took 0.0015s\n",
            "🧹 Memory cleanup at step 3300 took 0.2564s\n",
            "Batch  180/3125 (  5.8%) | Loss: 1.286947 | Accuracy: 54.90% | Batch time: 0.0408s\n",
            "Step 3310 | Loss: 1.439453 | GPU: 35.7MB / 70.0MB | F: 0.0019s, B: 0.0081s, O: 0.0023s\n",
            "Step 3320 | Loss: 1.492661 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 3320 took 0.0001s\n",
            "Batch  200/3125 (  6.4%) | Loss: 1.298864 | Accuracy: 54.20% | Batch time: 0.0349s\n",
            "Step 3330 | Loss: 1.302170 | GPU: 35.7MB / 70.0MB | F: 0.0043s, B: 0.0101s, O: 0.0021s\n",
            "Step 3340 | Loss: 1.213257 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 3340 took 0.0000s\n",
            "Batch  220/3125 (  7.0%) | Loss: 1.295396 | Accuracy: 54.36% | Batch time: 0.0284s\n",
            "Step 3350 | Loss: 0.744395 | GPU: 35.7MB / 70.0MB | F: 0.0032s, B: 0.0025s, O: 0.0007s\n",
            "Step 3360 | Loss: 1.253665 | GPU: 35.7MB / 134.0MB | F: 0.0119s, B: 0.0037s, O: 0.0011s\n",
            "🔄 Topology update at step 3360 took 0.0001s\n",
            "Batch  240/3125 (  7.7%) | Loss: 1.290936 | Accuracy: 54.69% | Batch time: 0.0316s\n",
            "Step 3370 | Loss: 1.523533 | GPU: 35.7MB / 70.0MB | F: 0.0048s, B: 0.0045s, O: 0.0011s\n",
            "Step 3380 | Loss: 1.185089 | GPU: 35.7MB / 134.0MB | F: 0.0057s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3380 took 0.0001s\n",
            "Batch  260/3125 (  8.3%) | Loss: 1.296897 | Accuracy: 54.53% | Batch time: 0.0326s\n",
            "Step 3390 | Loss: 1.035254 | GPU: 35.7MB / 70.0MB | F: 0.0020s, B: 0.0078s, O: 0.0037s\n",
            "Step 3400 | Loss: 1.183327 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0035s, O: 0.0021s\n",
            "🔄 Topology update at step 3400 took 0.0000s\n",
            "🧹 Memory cleanup at step 3400 took 0.2593s\n",
            "Batch  280/3125 (  9.0%) | Loss: 1.286485 | Accuracy: 54.87% | Batch time: 0.0435s\n",
            "Step 3410 | Loss: 1.350516 | GPU: 35.7MB / 70.0MB | F: 0.0023s, B: 0.0045s, O: 0.0009s\n",
            "Step 3420 | Loss: 1.025391 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0017s, O: 0.0005s\n",
            "🔄 Topology update at step 3420 took 0.0006s\n",
            "Batch  300/3125 (  9.6%) | Loss: 1.290411 | Accuracy: 54.67% | Batch time: 0.0365s\n",
            "Step 3430 | Loss: 1.525280 | GPU: 35.7MB / 70.0MB | F: 0.0028s, B: 0.0029s, O: 0.0011s\n",
            "Step 3440 | Loss: 1.588251 | GPU: 35.7MB / 134.0MB | F: 0.0060s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 3440 took 0.0001s\n",
            "Batch  320/3125 ( 10.2%) | Loss: 1.296877 | Accuracy: 54.63% | Batch time: 0.0296s\n",
            "Step 3450 | Loss: 1.536457 | GPU: 35.7MB / 70.0MB | F: 0.0027s, B: 0.0033s, O: 0.0010s\n",
            "Step 3460 | Loss: 1.459877 | GPU: 35.7MB / 134.0MB | F: 0.0079s, B: 0.0029s, O: 0.0015s\n",
            "🔄 Topology update at step 3460 took 0.0001s\n",
            "Batch  340/3125 ( 10.9%) | Loss: 1.293235 | Accuracy: 54.69% | Batch time: 0.0342s\n",
            "Step 3470 | Loss: 1.588383 | GPU: 35.7MB / 70.0MB | F: 0.0019s, B: 0.0042s, O: 0.0009s\n",
            "Step 3480 | Loss: 0.974754 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0064s, O: 0.0011s\n",
            "🔄 Topology update at step 3480 took 0.0001s\n",
            "Batch  360/3125 ( 11.5%) | Loss: 1.291666 | Accuracy: 54.74% | Batch time: 0.0374s\n",
            "Step 3490 | Loss: 1.708033 | GPU: 35.7MB / 70.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "Step 3500 | Loss: 1.659271 | GPU: 35.7MB / 134.0MB | F: 0.0059s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 3500 took 0.0000s\n",
            "🧹 Memory cleanup at step 3500 took 0.2741s\n",
            "Batch  380/3125 ( 12.2%) | Loss: 1.291525 | Accuracy: 54.81% | Batch time: 0.0392s\n",
            "Step 3510 | Loss: 1.240129 | GPU: 35.7MB / 70.0MB | F: 0.0026s, B: 0.0032s, O: 0.0010s\n",
            "Step 3520 | Loss: 0.807134 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0064s, O: 0.0025s\n",
            "🔄 Topology update at step 3520 took 0.0001s\n",
            "Batch  400/3125 ( 12.8%) | Loss: 1.289477 | Accuracy: 54.89% | Batch time: 0.0378s\n",
            "Step 3530 | Loss: 1.877968 | GPU: 35.7MB / 70.0MB | F: 0.0048s, B: 0.0030s, O: 0.0009s\n",
            "Step 3540 | Loss: 1.602844 | GPU: 35.7MB / 134.0MB | F: 0.0047s, B: 0.0025s, O: 0.0016s\n",
            "🔄 Topology update at step 3540 took 0.0001s\n",
            "Batch  420/3125 ( 13.4%) | Loss: 1.288661 | Accuracy: 54.97% | Batch time: 0.0317s\n",
            "Step 3550 | Loss: 1.252323 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0082s, O: 0.0021s\n",
            "Step 3560 | Loss: 1.597839 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0085s, O: 0.0007s\n",
            "🔄 Topology update at step 3560 took 0.0000s\n",
            "Batch  440/3125 ( 14.1%) | Loss: 1.283891 | Accuracy: 55.07% | Batch time: 0.0339s\n",
            "Step 3570 | Loss: 1.853168 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "Step 3580 | Loss: 1.480156 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0039s, O: 0.0007s\n",
            "🔄 Topology update at step 3580 took 0.0000s\n",
            "Batch  460/3125 ( 14.7%) | Loss: 1.281804 | Accuracy: 55.26% | Batch time: 0.0888s\n",
            "Step 3590 | Loss: 1.471346 | GPU: 35.7MB / 70.0MB | F: 0.0082s, B: 0.0041s, O: 0.0006s\n",
            "Step 3600 | Loss: 1.227213 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0064s, O: 0.0006s\n",
            "🔄 Topology update at step 3600 took 0.0000s\n",
            "🧹 Memory cleanup at step 3600 took 0.3740s\n",
            "Batch  480/3125 ( 15.4%) | Loss: 1.277403 | Accuracy: 55.30% | Batch time: 0.0330s\n",
            "Step 3610 | Loss: 1.381226 | GPU: 35.7MB / 70.0MB | F: 0.0013s, B: 0.0094s, O: 0.0006s\n",
            "Step 3620 | Loss: 1.919563 | GPU: 35.7MB / 134.0MB | F: 0.0189s, B: 0.0028s, O: 0.0006s\n",
            "🔄 Topology update at step 3620 took 0.0000s\n",
            "Batch  500/3125 ( 16.0%) | Loss: 1.278154 | Accuracy: 55.20% | Batch time: 0.0528s\n",
            "Step 3630 | Loss: 0.979617 | GPU: 35.7MB / 70.0MB | F: 0.0013s, B: 0.0051s, O: 0.0017s\n",
            "Step 3640 | Loss: 1.129113 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0056s, O: 0.0007s\n",
            "🔄 Topology update at step 3640 took 0.0000s\n",
            "Batch  520/3125 ( 16.6%) | Loss: 1.274857 | Accuracy: 55.34% | Batch time: 0.0450s\n",
            "Step 3650 | Loss: 1.546000 | GPU: 35.7MB / 70.0MB | F: 0.0051s, B: 0.0113s, O: 0.0011s\n",
            "Step 3660 | Loss: 1.003618 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0033s, O: 0.0016s\n",
            "🔄 Topology update at step 3660 took 0.0000s\n",
            "Batch  540/3125 ( 17.3%) | Loss: 1.274855 | Accuracy: 55.42% | Batch time: 0.0411s\n",
            "Step 3670 | Loss: 1.489412 | GPU: 35.7MB / 70.0MB | F: 0.0148s, B: 0.0068s, O: 0.0049s\n",
            "Step 3680 | Loss: 1.800315 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0033s, O: 0.0059s\n",
            "🔄 Topology update at step 3680 took 0.0001s\n",
            "Batch  560/3125 ( 17.9%) | Loss: 1.276025 | Accuracy: 55.40% | Batch time: 0.0491s\n",
            "Step 3690 | Loss: 1.500137 | GPU: 35.7MB / 70.0MB | F: 0.0014s, B: 0.0119s, O: 0.0011s\n",
            "Step 3700 | Loss: 1.057770 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0038s, O: 0.0007s\n",
            "🔄 Topology update at step 3700 took 0.0001s\n",
            "🧹 Memory cleanup at step 3700 took 0.2839s\n",
            "Batch  580/3125 ( 18.6%) | Loss: 1.278583 | Accuracy: 55.34% | Batch time: 0.0358s\n",
            "Step 3710 | Loss: 1.640022 | GPU: 35.7MB / 70.0MB | F: 0.0076s, B: 0.0031s, O: 0.0016s\n",
            "Step 3720 | Loss: 0.988925 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0040s, O: 0.0022s\n",
            "🔄 Topology update at step 3720 took 0.0001s\n",
            "Batch  600/3125 ( 19.2%) | Loss: 1.276965 | Accuracy: 55.36% | Batch time: 0.0324s\n",
            "Step 3730 | Loss: 1.176834 | GPU: 35.7MB / 70.0MB | F: 0.0027s, B: 0.0023s, O: 0.0007s\n",
            "Step 3740 | Loss: 1.185463 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 3740 took 0.0001s\n",
            "Batch  620/3125 ( 19.8%) | Loss: 1.274969 | Accuracy: 55.34% | Batch time: 0.0411s\n",
            "Step 3750 | Loss: 1.717636 | GPU: 35.7MB / 70.0MB | F: 0.0063s, B: 0.0049s, O: 0.0010s\n",
            "Step 3760 | Loss: 0.925825 | GPU: 35.7MB / 134.0MB | F: 0.0042s, B: 0.0073s, O: 0.0012s\n",
            "🔄 Topology update at step 3760 took 0.0001s\n",
            "Batch  640/3125 ( 20.5%) | Loss: 1.274131 | Accuracy: 55.30% | Batch time: 0.0419s\n",
            "Step 3770 | Loss: 1.078880 | GPU: 35.7MB / 70.0MB | F: 0.0061s, B: 0.0033s, O: 0.0010s\n",
            "Step 3780 | Loss: 1.250382 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0035s, O: 0.0010s\n",
            "🔄 Topology update at step 3780 took 0.0009s\n",
            "Batch  660/3125 ( 21.1%) | Loss: 1.276369 | Accuracy: 55.12% | Batch time: 0.0453s\n",
            "Step 3790 | Loss: 1.432333 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0052s, O: 0.0008s\n",
            "Step 3800 | Loss: 0.882139 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0032s, O: 0.0007s\n",
            "🔄 Topology update at step 3800 took 0.0000s\n",
            "🧹 Memory cleanup at step 3800 took 0.2677s\n",
            "Batch  680/3125 ( 21.8%) | Loss: 1.276735 | Accuracy: 55.11% | Batch time: 0.0390s\n",
            "Step 3810 | Loss: 1.358192 | GPU: 35.7MB / 70.0MB | F: 0.0025s, B: 0.0062s, O: 0.0010s\n",
            "Step 3820 | Loss: 1.339342 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0029s, O: 0.0028s\n",
            "🔄 Topology update at step 3820 took 0.0020s\n",
            "Batch  700/3125 ( 22.4%) | Loss: 1.275260 | Accuracy: 55.11% | Batch time: 0.0287s\n",
            "Step 3830 | Loss: 1.667557 | GPU: 35.7MB / 70.0MB | F: 0.0027s, B: 0.0064s, O: 0.0008s\n",
            "Step 3840 | Loss: 1.471518 | GPU: 35.7MB / 134.0MB | F: 0.0114s, B: 0.0036s, O: 0.0010s\n",
            "🔄 Topology update at step 3840 took 0.0001s\n",
            "Batch  720/3125 ( 23.0%) | Loss: 1.278673 | Accuracy: 54.97% | Batch time: 0.0419s\n",
            "Step 3850 | Loss: 1.070232 | GPU: 35.7MB / 70.0MB | F: 0.0025s, B: 0.0220s, O: 0.0010s\n",
            "Step 3860 | Loss: 1.310730 | GPU: 35.7MB / 134.0MB | F: 0.0099s, B: 0.0045s, O: 0.0010s\n",
            "🔄 Topology update at step 3860 took 0.0001s\n",
            "Batch  740/3125 ( 23.7%) | Loss: 1.277938 | Accuracy: 55.01% | Batch time: 0.0353s\n",
            "Step 3870 | Loss: 1.223320 | GPU: 35.7MB / 70.0MB | F: 0.0020s, B: 0.0049s, O: 0.0010s\n",
            "Step 3880 | Loss: 1.207031 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0200s, O: 0.0012s\n",
            "🔄 Topology update at step 3880 took 0.0001s\n",
            "Batch  760/3125 ( 24.3%) | Loss: 1.276983 | Accuracy: 55.08% | Batch time: 0.0445s\n",
            "Step 3890 | Loss: 1.229275 | GPU: 35.7MB / 70.0MB | F: 0.0027s, B: 0.0067s, O: 0.0011s\n",
            "Step 3900 | Loss: 1.257363 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0063s, O: 0.0010s\n",
            "🔄 Topology update at step 3900 took 0.0020s\n",
            "🧹 Memory cleanup at step 3900 took 0.2433s\n",
            "Batch  780/3125 ( 25.0%) | Loss: 1.277764 | Accuracy: 55.01% | Batch time: 0.0293s\n",
            "Step 3910 | Loss: 1.445683 | GPU: 35.7MB / 70.0MB | F: 0.0054s, B: 0.0041s, O: 0.0011s\n",
            "Step 3920 | Loss: 0.937420 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0086s, O: 0.0010s\n",
            "🔄 Topology update at step 3920 took 0.0001s\n",
            "Batch  800/3125 ( 25.6%) | Loss: 1.277838 | Accuracy: 54.97% | Batch time: 0.0373s\n",
            "Step 3930 | Loss: 1.195895 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 3940 | Loss: 0.904924 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3940 took 0.0001s\n",
            "Batch  820/3125 ( 26.2%) | Loss: 1.274928 | Accuracy: 55.02% | Batch time: 0.0435s\n",
            "Step 3950 | Loss: 1.335312 | GPU: 35.7MB / 70.0MB | F: 0.0026s, B: 0.0034s, O: 0.0009s\n",
            "Step 3960 | Loss: 1.712440 | GPU: 35.7MB / 134.0MB | F: 0.0054s, B: 0.0057s, O: 0.0010s\n",
            "🔄 Topology update at step 3960 took 0.0001s\n",
            "Batch  840/3125 ( 26.9%) | Loss: 1.275001 | Accuracy: 55.02% | Batch time: 0.0364s\n",
            "Step 3970 | Loss: 1.603372 | GPU: 35.7MB / 70.0MB | F: 0.0075s, B: 0.0087s, O: 0.0007s\n",
            "Step 3980 | Loss: 1.825706 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 3980 took 0.0000s\n",
            "Batch  860/3125 ( 27.5%) | Loss: 1.277676 | Accuracy: 54.93% | Batch time: 0.0342s\n",
            "Step 3990 | Loss: 1.096516 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 4000 | Loss: 1.585663 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 4000 took 0.0000s\n",
            "🧹 Memory cleanup at step 4000 took 0.2251s\n",
            "Batch  880/3125 ( 28.2%) | Loss: 1.277343 | Accuracy: 54.90% | Batch time: 0.0278s\n",
            "Step 4010 | Loss: 1.006378 | GPU: 35.7MB / 70.0MB | F: 0.0016s, B: 0.0022s, O: 0.0007s\n",
            "Step 4020 | Loss: 1.249496 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 4020 took 0.0000s\n",
            "Batch  900/3125 ( 28.8%) | Loss: 1.275985 | Accuracy: 54.90% | Batch time: 0.0340s\n",
            "Step 4030 | Loss: 1.097181 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "Step 4040 | Loss: 1.342628 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 4040 took 0.0000s\n",
            "Batch  920/3125 ( 29.4%) | Loss: 1.274874 | Accuracy: 54.93% | Batch time: 0.0397s\n",
            "Step 4050 | Loss: 1.436057 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0028s, O: 0.0007s\n",
            "Step 4060 | Loss: 1.427940 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 4060 took 0.0000s\n",
            "Batch  940/3125 ( 30.1%) | Loss: 1.275079 | Accuracy: 54.91% | Batch time: 0.0505s\n",
            "Step 4070 | Loss: 0.977449 | GPU: 35.7MB / 70.0MB | F: 0.0027s, B: 0.0033s, O: 0.0010s\n",
            "Step 4080 | Loss: 1.252872 | GPU: 35.7MB / 134.0MB | F: 0.0042s, B: 0.0053s, O: 0.0010s\n",
            "🔄 Topology update at step 4080 took 0.0001s\n",
            "Batch  960/3125 ( 30.7%) | Loss: 1.272849 | Accuracy: 55.01% | Batch time: 0.0399s\n",
            "Step 4090 | Loss: 1.308044 | GPU: 35.7MB / 70.0MB | F: 0.0042s, B: 0.0096s, O: 0.0006s\n",
            "Step 4100 | Loss: 1.048119 | GPU: 35.7MB / 134.0MB | F: 0.0070s, B: 0.0044s, O: 0.0011s\n",
            "🔄 Topology update at step 4100 took 0.0001s\n",
            "🧹 Memory cleanup at step 4100 took 0.2273s\n",
            "Batch  980/3125 ( 31.4%) | Loss: 1.272278 | Accuracy: 55.08% | Batch time: 0.0478s\n",
            "Step 4110 | Loss: 1.404221 | GPU: 35.7MB / 70.0MB | F: 0.0055s, B: 0.0062s, O: 0.0008s\n",
            "Step 4120 | Loss: 1.429567 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0053s, O: 0.0006s\n",
            "🔄 Topology update at step 4120 took 0.0000s\n",
            "Batch 1000/3125 ( 32.0%) | Loss: 1.274176 | Accuracy: 55.07% | Batch time: 0.0609s\n",
            "Step 4130 | Loss: 1.141750 | GPU: 35.7MB / 70.0MB | F: 0.0013s, B: 0.0249s, O: 0.0008s\n",
            "Step 4140 | Loss: 1.955963 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0031s, O: 0.0014s\n",
            "🔄 Topology update at step 4140 took 0.0001s\n",
            "Batch 1020/3125 ( 32.6%) | Loss: 1.274587 | Accuracy: 55.06% | Batch time: 0.0453s\n",
            "Step 4150 | Loss: 1.337837 | GPU: 35.7MB / 70.0MB | F: 0.0013s, B: 0.0017s, O: 0.0007s\n",
            "Step 4160 | Loss: 1.094761 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0103s, O: 0.0006s\n",
            "🔄 Topology update at step 4160 took 0.0041s\n",
            "Batch 1040/3125 ( 33.3%) | Loss: 1.273291 | Accuracy: 55.12% | Batch time: 0.0559s\n",
            "Step 4170 | Loss: 0.804318 | GPU: 35.7MB / 70.0MB | F: 0.0012s, B: 0.0068s, O: 0.0005s\n",
            "Step 4180 | Loss: 1.578434 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0094s, O: 0.0006s\n",
            "🔄 Topology update at step 4180 took 0.0001s\n",
            "Batch 1060/3125 ( 33.9%) | Loss: 1.271935 | Accuracy: 55.16% | Batch time: 0.0482s\n",
            "Step 4190 | Loss: 1.067497 | GPU: 35.7MB / 70.0MB | F: 0.0099s, B: 0.0030s, O: 0.0010s\n",
            "Step 4200 | Loss: 1.028745 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0034s, O: 0.0048s\n",
            "🔄 Topology update at step 4200 took 0.0001s\n",
            "🧹 Memory cleanup at step 4200 took 0.3612s\n",
            "Batch 1080/3125 ( 34.6%) | Loss: 1.271638 | Accuracy: 55.22% | Batch time: 0.0504s\n",
            "Step 4210 | Loss: 1.057420 | GPU: 35.7MB / 70.0MB | F: 0.0106s, B: 0.0050s, O: 0.0015s\n",
            "Step 4220 | Loss: 0.925458 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0035s, O: 0.0019s\n",
            "🔄 Topology update at step 4220 took 0.0000s\n",
            "Batch 1100/3125 ( 35.2%) | Loss: 1.269419 | Accuracy: 55.29% | Batch time: 0.0311s\n",
            "Step 4230 | Loss: 1.172602 | GPU: 35.7MB / 70.0MB | F: 0.0015s, B: 0.0019s, O: 0.0006s\n",
            "Step 4240 | Loss: 0.805807 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0067s, O: 0.0021s\n",
            "🔄 Topology update at step 4240 took 0.0001s\n",
            "Batch 1120/3125 ( 35.8%) | Loss: 1.270791 | Accuracy: 55.18% | Batch time: 0.0382s\n",
            "Step 4250 | Loss: 1.044133 | GPU: 35.7MB / 70.0MB | F: 0.0032s, B: 0.0039s, O: 0.0009s\n",
            "Step 4260 | Loss: 0.791985 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0048s, O: 0.0007s\n",
            "🔄 Topology update at step 4260 took 0.0001s\n",
            "Batch 1140/3125 ( 36.5%) | Loss: 1.270175 | Accuracy: 55.22% | Batch time: 0.0366s\n",
            "Step 4270 | Loss: 1.461205 | GPU: 35.7MB / 70.0MB | F: 0.0027s, B: 0.0050s, O: 0.0010s\n",
            "Step 4280 | Loss: 1.174804 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0058s, O: 0.0011s\n",
            "🔄 Topology update at step 4280 took 0.0001s\n",
            "Batch 1160/3125 ( 37.1%) | Loss: 1.270671 | Accuracy: 55.16% | Batch time: 0.0383s\n",
            "Step 4290 | Loss: 1.013626 | GPU: 35.7MB / 70.0MB | F: 0.0026s, B: 0.0121s, O: 0.0007s\n",
            "Step 4300 | Loss: 1.133461 | GPU: 35.7MB / 134.0MB | F: 0.0082s, B: 0.0034s, O: 0.0008s\n",
            "🔄 Topology update at step 4300 took 0.0001s\n",
            "🧹 Memory cleanup at step 4300 took 0.2721s\n",
            "Batch 1180/3125 ( 37.8%) | Loss: 1.270011 | Accuracy: 55.24% | Batch time: 0.0398s\n",
            "Step 4310 | Loss: 1.805981 | GPU: 35.7MB / 70.0MB | F: 0.0054s, B: 0.0165s, O: 0.0009s\n",
            "Step 4320 | Loss: 1.302137 | GPU: 35.7MB / 134.0MB | F: 0.0031s, B: 0.0023s, O: 0.0008s\n",
            "🔄 Topology update at step 4320 took 0.0001s\n",
            "Batch 1200/3125 ( 38.4%) | Loss: 1.270512 | Accuracy: 55.19% | Batch time: 0.0414s\n",
            "Step 4330 | Loss: 1.154503 | GPU: 35.7MB / 70.0MB | F: 0.0047s, B: 0.0034s, O: 0.0010s\n",
            "Step 4340 | Loss: 1.851084 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0034s, O: 0.0011s\n",
            "🔄 Topology update at step 4340 took 0.0009s\n",
            "Batch 1220/3125 ( 39.0%) | Loss: 1.273076 | Accuracy: 55.06% | Batch time: 0.0463s\n",
            "Step 4350 | Loss: 1.073964 | GPU: 35.7MB / 70.0MB | F: 0.0015s, B: 0.0077s, O: 0.0010s\n",
            "Step 4360 | Loss: 1.056107 | GPU: 35.7MB / 134.0MB | F: 0.0095s, B: 0.0028s, O: 0.0011s\n",
            "🔄 Topology update at step 4360 took 0.0001s\n",
            "Batch 1240/3125 ( 39.7%) | Loss: 1.272816 | Accuracy: 55.05% | Batch time: 0.0361s\n",
            "Step 4370 | Loss: 1.817757 | GPU: 35.7MB / 70.0MB | F: 0.0065s, B: 0.0036s, O: 0.0010s\n",
            "Step 4380 | Loss: 1.448452 | GPU: 35.7MB / 134.0MB | F: 0.0033s, B: 0.0042s, O: 0.0020s\n",
            "🔄 Topology update at step 4380 took 0.0001s\n",
            "Batch 1260/3125 ( 40.3%) | Loss: 1.271936 | Accuracy: 55.07% | Batch time: 0.0404s\n",
            "Step 4390 | Loss: 1.402636 | GPU: 35.7MB / 70.0MB | F: 0.0021s, B: 0.0107s, O: 0.0026s\n",
            "Step 4400 | Loss: 1.225929 | GPU: 35.7MB / 134.0MB | F: 0.0091s, B: 0.0051s, O: 0.0010s\n",
            "🔄 Topology update at step 4400 took 0.0001s\n",
            "🧹 Memory cleanup at step 4400 took 0.2691s\n",
            "Batch 1280/3125 ( 41.0%) | Loss: 1.272452 | Accuracy: 54.99% | Batch time: 0.0278s\n",
            "Step 4410 | Loss: 0.984127 | GPU: 35.7MB / 70.0MB | F: 0.0030s, B: 0.0022s, O: 0.0006s\n",
            "Step 4420 | Loss: 1.142830 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0075s, O: 0.0023s\n",
            "🔄 Topology update at step 4420 took 0.0001s\n",
            "Batch 1300/3125 ( 41.6%) | Loss: 1.271045 | Accuracy: 55.04% | Batch time: 0.0449s\n",
            "Step 4430 | Loss: 1.239943 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0131s, O: 0.0059s\n",
            "Step 4440 | Loss: 0.897807 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0068s, O: 0.0011s\n",
            "🔄 Topology update at step 4440 took 0.0001s\n",
            "Batch 1320/3125 ( 42.2%) | Loss: 1.270439 | Accuracy: 55.07% | Batch time: 0.0425s\n",
            "Step 4450 | Loss: 0.968446 | GPU: 35.7MB / 70.0MB | F: 0.0019s, B: 0.0078s, O: 0.0007s\n",
            "Step 4460 | Loss: 0.854187 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0056s, O: 0.0021s\n",
            "🔄 Topology update at step 4460 took 0.0001s\n",
            "Batch 1340/3125 ( 42.9%) | Loss: 1.268588 | Accuracy: 55.08% | Batch time: 0.0346s\n",
            "Step 4470 | Loss: 1.164439 | GPU: 35.7MB / 70.0MB | F: 0.0037s, B: 0.0087s, O: 0.0007s\n",
            "Step 4480 | Loss: 0.924567 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0056s, O: 0.0009s\n",
            "🔄 Topology update at step 4480 took 0.0001s\n",
            "Batch 1360/3125 ( 43.5%) | Loss: 1.268165 | Accuracy: 55.05% | Batch time: 0.0371s\n",
            "Step 4490 | Loss: 1.251734 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0058s, O: 0.0007s\n",
            "Step 4500 | Loss: 1.588150 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 4500 took 0.0000s\n",
            "🧹 Memory cleanup at step 4500 took 0.2740s\n",
            "Batch 1380/3125 ( 44.2%) | Loss: 1.267492 | Accuracy: 55.07% | Batch time: 0.0321s\n",
            "Step 4510 | Loss: 1.167099 | GPU: 35.7MB / 70.0MB | F: 0.0024s, B: 0.0081s, O: 0.0011s\n",
            "Step 4520 | Loss: 1.720154 | GPU: 35.7MB / 134.0MB | F: 0.0047s, B: 0.0030s, O: 0.0007s\n",
            "🔄 Topology update at step 4520 took 0.0001s\n",
            "Batch 1400/3125 ( 44.8%) | Loss: 1.265899 | Accuracy: 55.15% | Batch time: 0.0379s\n",
            "Step 4530 | Loss: 1.117236 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0031s, O: 0.0007s\n",
            "Step 4540 | Loss: 1.537384 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0099s, O: 0.0008s\n",
            "🔄 Topology update at step 4540 took 0.0000s\n",
            "Batch 1420/3125 ( 45.4%) | Loss: 1.265295 | Accuracy: 55.23% | Batch time: 0.0335s\n",
            "Step 4550 | Loss: 1.335945 | GPU: 35.7MB / 70.0MB | F: 0.0076s, B: 0.0036s, O: 0.0007s\n",
            "Step 4560 | Loss: 1.363186 | GPU: 35.7MB / 134.0MB | F: 0.0095s, B: 0.0033s, O: 0.0010s\n",
            "🔄 Topology update at step 4560 took 0.0001s\n",
            "Batch 1440/3125 ( 46.1%) | Loss: 1.265473 | Accuracy: 55.24% | Batch time: 0.0358s\n",
            "Step 4570 | Loss: 0.829555 | GPU: 35.7MB / 70.0MB | F: 0.0031s, B: 0.0047s, O: 0.0011s\n",
            "Step 4580 | Loss: 1.357849 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0041s, O: 0.0021s\n",
            "🔄 Topology update at step 4580 took 0.0001s\n",
            "Batch 1460/3125 ( 46.7%) | Loss: 1.264241 | Accuracy: 55.30% | Batch time: 0.0353s\n",
            "Step 4590 | Loss: 1.157637 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0034s, O: 0.0023s\n",
            "Step 4600 | Loss: 0.819127 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0106s, O: 0.0042s\n",
            "🔄 Topology update at step 4600 took 0.0001s\n",
            "🧹 Memory cleanup at step 4600 took 0.2209s\n",
            "Batch 1480/3125 ( 47.4%) | Loss: 1.263982 | Accuracy: 55.32% | Batch time: 0.0353s\n",
            "Step 4610 | Loss: 1.584460 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0032s, O: 0.0015s\n",
            "Step 4620 | Loss: 1.222450 | GPU: 35.7MB / 134.0MB | F: 0.0062s, B: 0.0069s, O: 0.0022s\n",
            "🔄 Topology update at step 4620 took 0.0001s\n",
            "Batch 1500/3125 ( 48.0%) | Loss: 1.264191 | Accuracy: 55.30% | Batch time: 0.0369s\n",
            "Step 4630 | Loss: 1.282859 | GPU: 35.7MB / 70.0MB | F: 0.0029s, B: 0.0023s, O: 0.0007s\n",
            "Step 4640 | Loss: 1.460098 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0033s, O: 0.0022s\n",
            "🔄 Topology update at step 4640 took 0.0001s\n",
            "Batch 1520/3125 ( 48.6%) | Loss: 1.262303 | Accuracy: 55.35% | Batch time: 0.0471s\n",
            "Step 4650 | Loss: 1.207844 | GPU: 35.7MB / 70.0MB | F: 0.0019s, B: 0.0110s, O: 0.0009s\n",
            "Step 4660 | Loss: 1.454517 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0048s, O: 0.0006s\n",
            "🔄 Topology update at step 4660 took 0.0000s\n",
            "Batch 1540/3125 ( 49.3%) | Loss: 1.261824 | Accuracy: 55.36% | Batch time: 0.0567s\n",
            "Step 4670 | Loss: 1.361412 | GPU: 35.7MB / 70.0MB | F: 0.0016s, B: 0.0038s, O: 0.0007s\n",
            "Step 4680 | Loss: 1.645069 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0016s, O: 0.0005s\n",
            "🔄 Topology update at step 4680 took 0.0000s\n",
            "Batch 1560/3125 ( 49.9%) | Loss: 1.263065 | Accuracy: 55.32% | Batch time: 0.0560s\n",
            "Step 4690 | Loss: 0.736900 | GPU: 35.7MB / 70.0MB | F: 0.0015s, B: 0.0049s, O: 0.0006s\n",
            "Step 4700 | Loss: 0.843527 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0150s, O: 0.0005s\n",
            "🔄 Topology update at step 4700 took 0.0000s\n",
            "🧹 Memory cleanup at step 4700 took 0.2552s\n",
            "Batch 1580/3125 ( 50.6%) | Loss: 1.261181 | Accuracy: 55.38% | Batch time: 0.0506s\n",
            "Step 4710 | Loss: 1.543274 | GPU: 35.7MB / 70.0MB | F: 0.0033s, B: 0.0017s, O: 0.0005s\n",
            "Step 4720 | Loss: 1.467466 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0070s, O: 0.0006s\n",
            "🔄 Topology update at step 4720 took 0.0000s\n",
            "Batch 1600/3125 ( 51.2%) | Loss: 1.260202 | Accuracy: 55.38% | Batch time: 0.0562s\n",
            "Step 4730 | Loss: 1.207054 | GPU: 35.7MB / 70.0MB | F: 0.0013s, B: 0.0109s, O: 0.0008s\n",
            "Step 4740 | Loss: 1.058059 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0088s, O: 0.0007s\n",
            "🔄 Topology update at step 4740 took 0.0000s\n",
            "Batch 1620/3125 ( 51.8%) | Loss: 1.259504 | Accuracy: 55.41% | Batch time: 0.0667s\n",
            "Step 4750 | Loss: 1.303337 | GPU: 35.7MB / 70.0MB | F: 0.0013s, B: 0.0188s, O: 0.0010s\n",
            "Step 4760 | Loss: 0.971252 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0077s, O: 0.0007s\n",
            "🔄 Topology update at step 4760 took 0.0000s\n",
            "Batch 1640/3125 ( 52.5%) | Loss: 1.259646 | Accuracy: 55.39% | Batch time: 0.0421s\n",
            "Step 4770 | Loss: 1.347137 | GPU: 35.7MB / 70.0MB | F: 0.0080s, B: 0.0073s, O: 0.0009s\n",
            "Step 4780 | Loss: 1.032652 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0078s, O: 0.0011s\n",
            "🔄 Topology update at step 4780 took 0.0001s\n",
            "Batch 1660/3125 ( 53.1%) | Loss: 1.258511 | Accuracy: 55.41% | Batch time: 0.0354s\n",
            "Step 4790 | Loss: 0.897408 | GPU: 35.7MB / 70.0MB | F: 0.0021s, B: 0.0032s, O: 0.0008s\n",
            "Step 4800 | Loss: 0.925216 | GPU: 35.7MB / 134.0MB | F: 0.0055s, B: 0.0071s, O: 0.0011s\n",
            "🔄 Topology update at step 4800 took 0.0001s\n",
            "🧹 Memory cleanup at step 4800 took 0.2405s\n",
            "Batch 1680/3125 ( 53.8%) | Loss: 1.257384 | Accuracy: 55.46% | Batch time: 0.0378s\n",
            "Step 4810 | Loss: 1.441418 | GPU: 35.7MB / 70.0MB | F: 0.0072s, B: 0.0041s, O: 0.0076s\n",
            "Step 4820 | Loss: 1.619836 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0113s, O: 0.0012s\n",
            "🔄 Topology update at step 4820 took 0.0001s\n",
            "Batch 1700/3125 ( 54.4%) | Loss: 1.257105 | Accuracy: 55.47% | Batch time: 0.0403s\n",
            "Step 4830 | Loss: 0.927603 | GPU: 35.7MB / 70.0MB | F: 0.0019s, B: 0.0029s, O: 0.0007s\n",
            "Step 4840 | Loss: 1.130184 | GPU: 35.7MB / 134.0MB | F: 0.0046s, B: 0.0033s, O: 0.0020s\n",
            "🔄 Topology update at step 4840 took 0.0001s\n",
            "Batch 1720/3125 ( 55.0%) | Loss: 1.255909 | Accuracy: 55.53% | Batch time: 0.0447s\n",
            "Step 4850 | Loss: 1.094568 | GPU: 35.7MB / 70.0MB | F: 0.0015s, B: 0.0046s, O: 0.0009s\n",
            "Step 4860 | Loss: 1.579025 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0028s, O: 0.0006s\n",
            "🔄 Topology update at step 4860 took 0.0001s\n",
            "Batch 1740/3125 ( 55.7%) | Loss: 1.255446 | Accuracy: 55.52% | Batch time: 0.0385s\n",
            "Step 4870 | Loss: 1.585449 | GPU: 35.7MB / 70.0MB | F: 0.0025s, B: 0.0069s, O: 0.0010s\n",
            "Step 4880 | Loss: 1.797195 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0028s, O: 0.0011s\n",
            "🔄 Topology update at step 4880 took 0.0000s\n",
            "Batch 1760/3125 ( 56.3%) | Loss: 1.254723 | Accuracy: 55.55% | Batch time: 0.0349s\n",
            "Step 4890 | Loss: 1.075638 | GPU: 35.7MB / 70.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step 4900 | Loss: 1.260805 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 4900 took 0.0000s\n",
            "🧹 Memory cleanup at step 4900 took 0.2259s\n",
            "Batch 1780/3125 ( 57.0%) | Loss: 1.253985 | Accuracy: 55.58% | Batch time: 0.0396s\n",
            "Step 4910 | Loss: 1.491096 | GPU: 35.7MB / 70.0MB | F: 0.0024s, B: 0.0075s, O: 0.0010s\n",
            "Step 4920 | Loss: 0.758760 | GPU: 35.7MB / 134.0MB | F: 0.0056s, B: 0.0091s, O: 0.0008s\n",
            "🔄 Topology update at step 4920 took 0.0000s\n",
            "Batch 1800/3125 ( 57.6%) | Loss: 1.252994 | Accuracy: 55.57% | Batch time: 0.0337s\n",
            "Step 4930 | Loss: 1.411797 | GPU: 35.7MB / 70.0MB | F: 0.0024s, B: 0.0058s, O: 0.0011s\n",
            "Step 4940 | Loss: 1.591568 | GPU: 35.7MB / 134.0MB | F: 0.0047s, B: 0.0032s, O: 0.0009s\n",
            "🔄 Topology update at step 4940 took 0.0000s\n",
            "Batch 1820/3125 ( 58.2%) | Loss: 1.253829 | Accuracy: 55.55% | Batch time: 0.0372s\n",
            "Step 4950 | Loss: 0.995552 | GPU: 35.7MB / 70.0MB | F: 0.0027s, B: 0.0105s, O: 0.0012s\n",
            "Step 4960 | Loss: 1.148973 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0095s, O: 0.0010s\n",
            "🔄 Topology update at step 4960 took 0.0001s\n",
            "Batch 1840/3125 ( 58.9%) | Loss: 1.252433 | Accuracy: 55.60% | Batch time: 0.0373s\n",
            "Step 4970 | Loss: 1.141285 | GPU: 35.7MB / 70.0MB | F: 0.0125s, B: 0.0037s, O: 0.0009s\n",
            "Step 4980 | Loss: 0.771906 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0028s, O: 0.0016s\n",
            "🔄 Topology update at step 4980 took 0.0000s\n",
            "Batch 1860/3125 ( 59.5%) | Loss: 1.252182 | Accuracy: 55.60% | Batch time: 0.0269s\n",
            "Step 4990 | Loss: 1.018940 | GPU: 35.7MB / 70.0MB | F: 0.0024s, B: 0.0032s, O: 0.0009s\n",
            "Step 5000 | Loss: 1.270053 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0028s, O: 0.0010s\n",
            "🔄 Topology update at step 5000 took 0.0001s\n",
            "🧹 Memory cleanup at step 5000 took 0.2454s\n",
            "Batch 1880/3125 ( 60.2%) | Loss: 1.251869 | Accuracy: 55.60% | Batch time: 0.0411s\n",
            "Step 5010 | Loss: 1.980250 | GPU: 35.7MB / 70.0MB | F: 0.0027s, B: 0.0092s, O: 0.0010s\n",
            "Step 5020 | Loss: 1.188112 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0033s, O: 0.0009s\n",
            "🔄 Topology update at step 5020 took 0.0009s\n",
            "Batch 1900/3125 ( 60.8%) | Loss: 1.250783 | Accuracy: 55.63% | Batch time: 0.0362s\n",
            "Step 5030 | Loss: 1.262039 | GPU: 35.7MB / 70.0MB | F: 0.0044s, B: 0.0044s, O: 0.0022s\n",
            "Step 5040 | Loss: 1.421432 | GPU: 35.7MB / 134.0MB | F: 0.0036s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 5040 took 0.0007s\n",
            "Batch 1920/3125 ( 61.4%) | Loss: 1.250989 | Accuracy: 55.60% | Batch time: 0.0406s\n",
            "Step 5050 | Loss: 1.005559 | GPU: 35.7MB / 70.0MB | F: 0.0091s, B: 0.0091s, O: 0.0032s\n",
            "Step 5060 | Loss: 1.225994 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 5060 took 0.0000s\n",
            "Batch 1940/3125 ( 62.1%) | Loss: 1.250564 | Accuracy: 55.61% | Batch time: 0.0288s\n",
            "Step 5070 | Loss: 1.858532 | GPU: 35.7MB / 70.0MB | F: 0.0036s, B: 0.0021s, O: 0.0007s\n",
            "Step 5080 | Loss: 1.171241 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0033s, O: 0.0010s\n",
            "🔄 Topology update at step 5080 took 0.0001s\n",
            "Batch 1960/3125 ( 62.7%) | Loss: 1.249805 | Accuracy: 55.60% | Batch time: 0.0431s\n",
            "Step 5090 | Loss: 0.964680 | GPU: 35.7MB / 70.0MB | F: 0.0021s, B: 0.0036s, O: 0.0009s\n",
            "Step 5100 | Loss: 1.181524 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0032s, O: 0.0007s\n",
            "🔄 Topology update at step 5100 took 0.0001s\n",
            "🧹 Memory cleanup at step 5100 took 0.2980s\n",
            "Batch 1980/3125 ( 63.4%) | Loss: 1.248787 | Accuracy: 55.61% | Batch time: 0.0377s\n",
            "Step 5110 | Loss: 0.958012 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0044s, O: 0.0007s\n",
            "Step 5120 | Loss: 0.916805 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0071s, O: 0.0023s\n",
            "🔄 Topology update at step 5120 took 0.0001s\n",
            "Batch 2000/3125 ( 64.0%) | Loss: 1.247979 | Accuracy: 55.63% | Batch time: 0.0377s\n",
            "Step 5130 | Loss: 0.929832 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0032s, O: 0.0007s\n",
            "Step 5140 | Loss: 1.193289 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0079s, O: 0.0010s\n",
            "🔄 Topology update at step 5140 took 0.0001s\n",
            "Batch 2020/3125 ( 64.6%) | Loss: 1.246800 | Accuracy: 55.67% | Batch time: 0.0491s\n",
            "Step 5150 | Loss: 1.328631 | GPU: 35.7MB / 70.0MB | F: 0.0016s, B: 0.0043s, O: 0.0007s\n",
            "Step 5160 | Loss: 0.756788 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0023s, O: 0.0013s\n",
            "🔄 Topology update at step 5160 took 0.0001s\n",
            "Batch 2040/3125 ( 65.3%) | Loss: 1.245833 | Accuracy: 55.69% | Batch time: 0.0322s\n",
            "Step 5170 | Loss: 1.270558 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0033s, O: 0.0006s\n",
            "Step 5180 | Loss: 1.144260 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0081s, O: 0.0007s\n",
            "🔄 Topology update at step 5180 took 0.0000s\n",
            "Batch 2060/3125 ( 65.9%) | Loss: 1.245014 | Accuracy: 55.73% | Batch time: 0.0407s\n",
            "Step 5190 | Loss: 1.297552 | GPU: 35.7MB / 70.0MB | F: 0.0026s, B: 0.0050s, O: 0.0018s\n",
            "Step 5200 | Loss: 1.135273 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0060s, O: 0.0006s\n",
            "🔄 Topology update at step 5200 took 0.0000s\n",
            "🧹 Memory cleanup at step 5200 took 0.4089s\n",
            "Batch 2080/3125 ( 66.6%) | Loss: 1.245667 | Accuracy: 55.69% | Batch time: 0.0728s\n",
            "Step 5210 | Loss: 1.161247 | GPU: 35.7MB / 70.0MB | F: 0.0034s, B: 0.0153s, O: 0.0006s\n",
            "Step 5220 | Loss: 1.295273 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0048s, O: 0.0005s\n",
            "🔄 Topology update at step 5220 took 0.0000s\n",
            "Batch 2100/3125 ( 67.2%) | Loss: 1.245086 | Accuracy: 55.70% | Batch time: 0.0458s\n",
            "Step 5230 | Loss: 1.084896 | GPU: 35.7MB / 70.0MB | F: 0.0014s, B: 0.0032s, O: 0.0005s\n",
            "Step 5240 | Loss: 1.848358 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0055s, O: 0.0006s\n",
            "🔄 Topology update at step 5240 took 0.0000s\n",
            "Batch 2120/3125 ( 67.8%) | Loss: 1.246166 | Accuracy: 55.66% | Batch time: 0.0458s\n",
            "Step 5250 | Loss: 1.165157 | GPU: 35.7MB / 70.0MB | F: 0.0014s, B: 0.0017s, O: 0.0006s\n",
            "Step 5260 | Loss: 1.515133 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0034s, O: 0.0005s\n",
            "🔄 Topology update at step 5260 took 0.0000s\n",
            "Batch 2140/3125 ( 68.5%) | Loss: 1.245796 | Accuracy: 55.69% | Batch time: 0.0455s\n",
            "Step 5270 | Loss: 1.559990 | GPU: 35.7MB / 70.0MB | F: 0.0029s, B: 0.0066s, O: 0.0006s\n",
            "Step 5280 | Loss: 1.406967 | GPU: 35.7MB / 134.0MB | F: 0.0051s, B: 0.0033s, O: 0.0006s\n",
            "🔄 Topology update at step 5280 took 0.0000s\n",
            "Batch 2160/3125 ( 69.1%) | Loss: 1.245645 | Accuracy: 55.70% | Batch time: 0.0637s\n",
            "Step 5290 | Loss: 1.374546 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0075s, O: 0.0006s\n",
            "Step 5300 | Loss: 1.368067 | GPU: 35.7MB / 134.0MB | F: 0.0068s, B: 0.0063s, O: 0.0010s\n",
            "🔄 Topology update at step 5300 took 0.0001s\n",
            "🧹 Memory cleanup at step 5300 took 0.4085s\n",
            "Batch 2180/3125 ( 69.8%) | Loss: 1.245363 | Accuracy: 55.68% | Batch time: 0.0532s\n",
            "Step 5310 | Loss: 1.557694 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0025s, O: 0.0006s\n",
            "Step 5320 | Loss: 1.156921 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0037s, O: 0.0006s\n",
            "🔄 Topology update at step 5320 took 0.0000s\n",
            "Batch 2200/3125 ( 70.4%) | Loss: 1.246128 | Accuracy: 55.66% | Batch time: 0.0370s\n",
            "Step 5330 | Loss: 1.449623 | GPU: 35.7MB / 70.0MB | F: 0.0023s, B: 0.0062s, O: 0.0021s\n",
            "Step 5340 | Loss: 1.365562 | GPU: 35.7MB / 134.0MB | F: 0.0051s, B: 0.0044s, O: 0.0042s\n",
            "🔄 Topology update at step 5340 took 0.0001s\n",
            "Batch 2220/3125 ( 71.0%) | Loss: 1.245784 | Accuracy: 55.68% | Batch time: 0.0733s\n",
            "Step 5350 | Loss: 1.203789 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0092s, O: 0.0026s\n",
            "Step 5360 | Loss: 1.066726 | GPU: 35.7MB / 134.0MB | F: 0.0034s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 5360 took 0.0001s\n",
            "Batch 2240/3125 ( 71.7%) | Loss: 1.245484 | Accuracy: 55.69% | Batch time: 0.0320s\n",
            "Step 5370 | Loss: 1.199167 | GPU: 35.7MB / 70.0MB | F: 0.0070s, B: 0.0041s, O: 0.0008s\n",
            "Step 5380 | Loss: 0.926344 | GPU: 35.7MB / 134.0MB | F: 0.0037s, B: 0.0033s, O: 0.0010s\n",
            "🔄 Topology update at step 5380 took 0.0001s\n",
            "Batch 2260/3125 ( 72.3%) | Loss: 1.245210 | Accuracy: 55.69% | Batch time: 0.0332s\n",
            "Step 5390 | Loss: 1.357704 | GPU: 35.7MB / 70.0MB | F: 0.0033s, B: 0.0030s, O: 0.0015s\n",
            "Step 5400 | Loss: 0.830600 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0286s, O: 0.0007s\n",
            "🔄 Topology update at step 5400 took 0.0001s\n",
            "🧹 Memory cleanup at step 5400 took 0.2426s\n",
            "Batch 2280/3125 ( 73.0%) | Loss: 1.244692 | Accuracy: 55.71% | Batch time: 0.0380s\n",
            "Step 5410 | Loss: 1.284500 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "Step 5420 | Loss: 1.309235 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 5420 took 0.0000s\n",
            "Batch 2300/3125 ( 73.6%) | Loss: 1.243603 | Accuracy: 55.76% | Batch time: 0.0374s\n",
            "Step 5430 | Loss: 1.007538 | GPU: 35.7MB / 70.0MB | F: 0.0016s, B: 0.0025s, O: 0.0007s\n",
            "Step 5440 | Loss: 1.109791 | GPU: 35.7MB / 134.0MB | F: 0.0046s, B: 0.0029s, O: 0.0027s\n",
            "🔄 Topology update at step 5440 took 0.0001s\n",
            "Batch 2320/3125 ( 74.2%) | Loss: 1.243023 | Accuracy: 55.77% | Batch time: 0.0334s\n",
            "Step 5450 | Loss: 1.138594 | GPU: 35.7MB / 70.0MB | F: 0.0035s, B: 0.0025s, O: 0.0013s\n",
            "Step 5460 | Loss: 1.280315 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0038s, O: 0.0007s\n",
            "🔄 Topology update at step 5460 took 0.0001s\n",
            "Batch 2340/3125 ( 74.9%) | Loss: 1.244078 | Accuracy: 55.77% | Batch time: 0.0276s\n",
            "Step 5470 | Loss: 1.688332 | GPU: 35.7MB / 70.0MB | F: 0.0025s, B: 0.0029s, O: 0.0006s\n",
            "Step 5480 | Loss: 1.095799 | GPU: 35.7MB / 134.0MB | F: 0.0077s, B: 0.0058s, O: 0.0010s\n",
            "🔄 Topology update at step 5480 took 0.0001s\n",
            "Batch 2360/3125 ( 75.5%) | Loss: 1.243302 | Accuracy: 55.77% | Batch time: 0.0574s\n",
            "Step 5490 | Loss: 1.180665 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 5500 | Loss: 0.970518 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 5500 took 0.0001s\n",
            "🧹 Memory cleanup at step 5500 took 0.2627s\n",
            "Batch 2380/3125 ( 76.2%) | Loss: 1.242803 | Accuracy: 55.78% | Batch time: 0.0314s\n",
            "Step 5510 | Loss: 1.038360 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0053s, O: 0.0007s\n",
            "Step 5520 | Loss: 1.268304 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 5520 took 0.0000s\n",
            "Batch 2400/3125 ( 76.8%) | Loss: 1.242608 | Accuracy: 55.76% | Batch time: 0.0423s\n",
            "Step 5530 | Loss: 1.004862 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0050s, O: 0.0007s\n",
            "Step 5540 | Loss: 0.766987 | GPU: 35.7MB / 134.0MB | F: 0.0041s, B: 0.0025s, O: 0.0024s\n",
            "🔄 Topology update at step 5540 took 0.0001s\n",
            "Batch 2420/3125 ( 77.4%) | Loss: 1.241248 | Accuracy: 55.80% | Batch time: 0.0418s\n",
            "Step 5550 | Loss: 1.468460 | GPU: 35.7MB / 70.0MB | F: 0.0044s, B: 0.0037s, O: 0.0021s\n",
            "Step 5560 | Loss: 0.840297 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0021s, O: 0.0006s\n",
            "🔄 Topology update at step 5560 took 0.0000s\n",
            "Batch 2440/3125 ( 78.1%) | Loss: 1.240340 | Accuracy: 55.84% | Batch time: 0.0294s\n",
            "Step 5570 | Loss: 1.126756 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0031s, O: 0.0015s\n",
            "Step 5580 | Loss: 1.537263 | GPU: 35.7MB / 134.0MB | F: 0.0110s, B: 0.0033s, O: 0.0009s\n",
            "🔄 Topology update at step 5580 took 0.0001s\n",
            "Batch 2460/3125 ( 78.7%) | Loss: 1.239723 | Accuracy: 55.87% | Batch time: 0.0337s\n",
            "Step 5590 | Loss: 1.242447 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0059s, O: 0.0010s\n",
            "Step 5600 | Loss: 0.727005 | GPU: 35.7MB / 134.0MB | F: 0.0052s, B: 0.0025s, O: 0.0005s\n",
            "🔄 Topology update at step 5600 took 0.0000s\n",
            "🧹 Memory cleanup at step 5600 took 0.2933s\n",
            "Batch 2480/3125 ( 79.4%) | Loss: 1.239838 | Accuracy: 55.88% | Batch time: 0.0390s\n",
            "Step 5610 | Loss: 1.111524 | GPU: 35.7MB / 70.0MB | F: 0.0053s, B: 0.0027s, O: 0.0006s\n",
            "Step 5620 | Loss: 1.164008 | GPU: 35.7MB / 134.0MB | F: 0.0077s, B: 0.0051s, O: 0.0006s\n",
            "🔄 Topology update at step 5620 took 0.0001s\n",
            "Batch 2500/3125 ( 80.0%) | Loss: 1.239604 | Accuracy: 55.90% | Batch time: 0.0441s\n",
            "Step 5630 | Loss: 2.040176 | GPU: 35.7MB / 70.0MB | F: 0.0019s, B: 0.0035s, O: 0.0007s\n",
            "Step 5640 | Loss: 1.492720 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 5640 took 0.0001s\n",
            "Batch 2520/3125 ( 80.6%) | Loss: 1.239877 | Accuracy: 55.90% | Batch time: 0.0326s\n",
            "Step 5650 | Loss: 1.569244 | GPU: 35.7MB / 70.0MB | F: 0.0079s, B: 0.0051s, O: 0.0049s\n",
            "Step 5660 | Loss: 0.888798 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 5660 took 0.0001s\n",
            "Batch 2540/3125 ( 81.3%) | Loss: 1.239378 | Accuracy: 55.91% | Batch time: 0.0348s\n",
            "Step 5670 | Loss: 1.002259 | GPU: 35.7MB / 70.0MB | F: 0.0066s, B: 0.0051s, O: 0.0009s\n",
            "Step 5680 | Loss: 1.105453 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 5680 took 0.0000s\n",
            "Batch 2560/3125 ( 81.9%) | Loss: 1.239283 | Accuracy: 55.93% | Batch time: 0.0367s\n",
            "Step 5690 | Loss: 1.006342 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0049s, O: 0.0010s\n",
            "Step 5700 | Loss: 1.255062 | GPU: 35.7MB / 134.0MB | F: 0.0035s, B: 0.0031s, O: 0.0009s\n",
            "🔄 Topology update at step 5700 took 0.0001s\n",
            "🧹 Memory cleanup at step 5700 took 0.2408s\n",
            "Batch 2580/3125 ( 82.6%) | Loss: 1.238349 | Accuracy: 55.97% | Batch time: 0.0347s\n",
            "Step 5710 | Loss: 0.655346 | GPU: 35.7MB / 70.0MB | F: 0.0113s, B: 0.0044s, O: 0.0010s\n",
            "Step 5720 | Loss: 1.362916 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0021s, O: 0.0007s\n",
            "🔄 Topology update at step 5720 took 0.0001s\n",
            "Batch 2600/3125 ( 83.2%) | Loss: 1.238648 | Accuracy: 55.96% | Batch time: 0.0289s\n",
            "Step 5730 | Loss: 0.817292 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 5740 | Loss: 1.068962 | GPU: 35.7MB / 134.0MB | F: 0.0100s, B: 0.0035s, O: 0.0010s\n",
            "🔄 Topology update at step 5740 took 0.0001s\n",
            "Batch 2620/3125 ( 83.8%) | Loss: 1.237233 | Accuracy: 56.03% | Batch time: 0.0325s\n",
            "Step 5750 | Loss: 1.564145 | GPU: 35.7MB / 70.0MB | F: 0.0017s, B: 0.0033s, O: 0.0007s\n",
            "Step 5760 | Loss: 1.589569 | GPU: 35.7MB / 134.0MB | F: 0.0052s, B: 0.0149s, O: 0.0008s\n",
            "🔄 Topology update at step 5760 took 0.0000s\n",
            "Batch 2640/3125 ( 84.5%) | Loss: 1.236755 | Accuracy: 56.05% | Batch time: 0.0557s\n",
            "Step 5770 | Loss: 1.527628 | GPU: 35.7MB / 70.0MB | F: 0.0028s, B: 0.0048s, O: 0.0007s\n",
            "Step 5780 | Loss: 1.226040 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0113s, O: 0.0006s\n",
            "🔄 Topology update at step 5780 took 0.0001s\n",
            "Batch 2660/3125 ( 85.1%) | Loss: 1.236816 | Accuracy: 56.06% | Batch time: 0.0493s\n",
            "Step 5790 | Loss: 1.374306 | GPU: 35.7MB / 70.0MB | F: 0.0078s, B: 0.0017s, O: 0.0006s\n",
            "Step 5800 | Loss: 0.935071 | GPU: 35.7MB / 134.0MB | F: 0.0012s, B: 0.0087s, O: 0.0006s\n",
            "🔄 Topology update at step 5800 took 0.0000s\n",
            "🧹 Memory cleanup at step 5800 took 0.4494s\n",
            "Batch 2680/3125 ( 85.8%) | Loss: 1.237204 | Accuracy: 56.06% | Batch time: 0.0480s\n",
            "Step 5810 | Loss: 0.896325 | GPU: 35.7MB / 70.0MB | F: 0.0012s, B: 0.0079s, O: 0.0005s\n",
            "Step 5820 | Loss: 0.852838 | GPU: 35.7MB / 134.0MB | F: 0.0014s, B: 0.0019s, O: 0.0006s\n",
            "🔄 Topology update at step 5820 took 0.0001s\n",
            "Batch 2700/3125 ( 86.4%) | Loss: 1.236261 | Accuracy: 56.09% | Batch time: 0.0362s\n",
            "Step 5830 | Loss: 1.066474 | GPU: 35.7MB / 70.0MB | F: 0.0014s, B: 0.0044s, O: 0.0005s\n",
            "Step 5840 | Loss: 1.206894 | GPU: 35.7MB / 134.0MB | F: 0.0035s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 5840 took 0.0001s\n",
            "Batch 2720/3125 ( 87.0%) | Loss: 1.235904 | Accuracy: 56.11% | Batch time: 0.0348s\n",
            "Step 5850 | Loss: 0.987130 | GPU: 35.7MB / 70.0MB | F: 0.0042s, B: 0.0073s, O: 0.0007s\n",
            "Step 5860 | Loss: 1.135963 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0110s, O: 0.0007s\n",
            "🔄 Topology update at step 5860 took 0.0001s\n",
            "Batch 2740/3125 ( 87.7%) | Loss: 1.234994 | Accuracy: 56.15% | Batch time: 0.0802s\n",
            "Step 5870 | Loss: 1.022320 | GPU: 35.7MB / 70.0MB | F: 0.0012s, B: 0.0061s, O: 0.0005s\n",
            "Step 5880 | Loss: 1.551012 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0081s, O: 0.0007s\n",
            "🔄 Topology update at step 5880 took 0.0000s\n",
            "Batch 2760/3125 ( 88.3%) | Loss: 1.235278 | Accuracy: 56.13% | Batch time: 0.0408s\n",
            "Step 5890 | Loss: 1.091919 | GPU: 35.7MB / 70.0MB | F: 0.0068s, B: 0.0046s, O: 0.0010s\n",
            "Step 5900 | Loss: 1.224501 | GPU: 35.7MB / 134.0MB | F: 0.0036s, B: 0.0031s, O: 0.0009s\n",
            "🔄 Topology update at step 5900 took 0.0001s\n",
            "🧹 Memory cleanup at step 5900 took 0.2414s\n",
            "Batch 2780/3125 ( 89.0%) | Loss: 1.234525 | Accuracy: 56.17% | Batch time: 0.0407s\n",
            "Step 5910 | Loss: 1.172630 | GPU: 35.7MB / 70.0MB | F: 0.0013s, B: 0.0083s, O: 0.0014s\n",
            "Step 5920 | Loss: 1.204807 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0036s, O: 0.0019s\n",
            "🔄 Topology update at step 5920 took 0.0000s\n",
            "Batch 2800/3125 ( 89.6%) | Loss: 1.234152 | Accuracy: 56.18% | Batch time: 0.0338s\n",
            "Step 5930 | Loss: 0.642104 | GPU: 35.7MB / 70.0MB | F: 0.0016s, B: 0.0084s, O: 0.0006s\n",
            "Step 5940 | Loss: 1.118625 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0026s, O: 0.0017s\n",
            "🔄 Topology update at step 5940 took 0.0000s\n",
            "Batch 2820/3125 ( 90.2%) | Loss: 1.233134 | Accuracy: 56.22% | Batch time: 0.0261s\n",
            "Step 5950 | Loss: 0.822943 | GPU: 35.7MB / 70.0MB | F: 0.0035s, B: 0.0029s, O: 0.0008s\n",
            "Step 5960 | Loss: 1.458161 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0041s, O: 0.0009s\n",
            "🔄 Topology update at step 5960 took 0.0001s\n",
            "Batch 2840/3125 ( 90.9%) | Loss: 1.231752 | Accuracy: 56.29% | Batch time: 0.0405s\n",
            "Step 5970 | Loss: 1.182510 | GPU: 35.7MB / 70.0MB | F: 0.0078s, B: 0.0140s, O: 0.0007s\n",
            "Step 5980 | Loss: 1.309685 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0034s, O: 0.0020s\n",
            "🔄 Topology update at step 5980 took 0.0001s\n",
            "Batch 2860/3125 ( 91.5%) | Loss: 1.231047 | Accuracy: 56.33% | Batch time: 0.0392s\n",
            "Step 5990 | Loss: 1.179535 | GPU: 35.7MB / 70.0MB | F: 0.0076s, B: 0.0033s, O: 0.0009s\n",
            "Step 6000 | Loss: 0.704300 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0035s, O: 0.0022s\n",
            "🔄 Topology update at step 6000 took 0.0001s\n",
            "🧹 Memory cleanup at step 6000 took 0.2635s\n",
            "Batch 2880/3125 ( 92.2%) | Loss: 1.229761 | Accuracy: 56.37% | Batch time: 0.0551s\n",
            "Step 6010 | Loss: 0.862455 | GPU: 35.7MB / 70.0MB | F: 0.0026s, B: 0.0030s, O: 0.0022s\n",
            "Step 6020 | Loss: 1.341235 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0024s, O: 0.0014s\n",
            "🔄 Topology update at step 6020 took 0.0000s\n",
            "Batch 2900/3125 ( 92.8%) | Loss: 1.228951 | Accuracy: 56.40% | Batch time: 0.0631s\n",
            "Step 6030 | Loss: 0.790802 | GPU: 35.7MB / 70.0MB | F: 0.0024s, B: 0.0075s, O: 0.0019s\n",
            "Step 6040 | Loss: 0.964731 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0047s, O: 0.0006s\n",
            "🔄 Topology update at step 6040 took 0.0000s\n",
            "Batch 2920/3125 ( 93.4%) | Loss: 1.228475 | Accuracy: 56.42% | Batch time: 0.0348s\n",
            "Step 6050 | Loss: 1.118536 | GPU: 35.7MB / 70.0MB | F: 0.0025s, B: 0.0055s, O: 0.0007s\n",
            "Step 6060 | Loss: 1.105099 | GPU: 35.7MB / 134.0MB | F: 0.0040s, B: 0.0043s, O: 0.0018s\n",
            "🔄 Topology update at step 6060 took 0.0001s\n",
            "Batch 2940/3125 ( 94.1%) | Loss: 1.228632 | Accuracy: 56.42% | Batch time: 0.0388s\n",
            "Step 6070 | Loss: 1.533506 | GPU: 35.7MB / 70.0MB | F: 0.0016s, B: 0.0049s, O: 0.0007s\n",
            "Step 6080 | Loss: 1.079065 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0071s, O: 0.0007s\n",
            "🔄 Topology update at step 6080 took 0.0001s\n",
            "Batch 2960/3125 ( 94.7%) | Loss: 1.227863 | Accuracy: 56.43% | Batch time: 0.0336s\n",
            "Step 6090 | Loss: 1.423256 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0070s, O: 0.0006s\n",
            "Step 6100 | Loss: 0.958481 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 6100 took 0.0001s\n",
            "🧹 Memory cleanup at step 6100 took 0.2479s\n",
            "Batch 2980/3125 ( 95.4%) | Loss: 1.227113 | Accuracy: 56.46% | Batch time: 0.0289s\n",
            "Step 6110 | Loss: 1.018503 | GPU: 35.7MB / 70.0MB | F: 0.0016s, B: 0.0026s, O: 0.0014s\n",
            "Step 6120 | Loss: 1.221363 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0102s, O: 0.0010s\n",
            "🔄 Topology update at step 6120 took 0.0001s\n",
            "Batch 3000/3125 ( 96.0%) | Loss: 1.226719 | Accuracy: 56.49% | Batch time: 0.0366s\n",
            "Step 6130 | Loss: 1.601502 | GPU: 35.7MB / 70.0MB | F: 0.0023s, B: 0.0030s, O: 0.0009s\n",
            "Step 6140 | Loss: 1.184835 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0039s, O: 0.0015s\n",
            "🔄 Topology update at step 6140 took 0.0001s\n",
            "Batch 3020/3125 ( 96.6%) | Loss: 1.226185 | Accuracy: 56.53% | Batch time: 0.0361s\n",
            "Step 6150 | Loss: 1.445259 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0018s, O: 0.0006s\n",
            "Step 6160 | Loss: 1.747972 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0032s, O: 0.0010s\n",
            "🔄 Topology update at step 6160 took 0.0001s\n",
            "Batch 3040/3125 ( 97.3%) | Loss: 1.225847 | Accuracy: 56.53% | Batch time: 0.0326s\n",
            "Step 6170 | Loss: 0.722425 | GPU: 35.7MB / 70.0MB | F: 0.0119s, B: 0.0038s, O: 0.0009s\n",
            "Step 6180 | Loss: 0.805121 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0031s, O: 0.0023s\n",
            "🔄 Topology update at step 6180 took 0.0001s\n",
            "Batch 3060/3125 ( 97.9%) | Loss: 1.224756 | Accuracy: 56.57% | Batch time: 0.0367s\n",
            "Step 6190 | Loss: 1.355769 | GPU: 35.7MB / 70.0MB | F: 0.0018s, B: 0.0044s, O: 0.0018s\n",
            "Step 6200 | Loss: 1.264276 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 6200 took 0.0001s\n",
            "🧹 Memory cleanup at step 6200 took 0.2449s\n",
            "Batch 3080/3125 ( 98.6%) | Loss: 1.225197 | Accuracy: 56.54% | Batch time: 0.0360s\n",
            "Step 6210 | Loss: 1.335294 | GPU: 35.7MB / 70.0MB | F: 0.0082s, B: 0.0026s, O: 0.0007s\n",
            "Step 6220 | Loss: 0.976620 | GPU: 35.7MB / 134.0MB | F: 0.0031s, B: 0.0030s, O: 0.0022s\n",
            "🔄 Topology update at step 6220 took 0.0011s\n",
            "Batch 3100/3125 ( 99.2%) | Loss: 1.225661 | Accuracy: 56.54% | Batch time: 0.0302s\n",
            "Step 6230 | Loss: 1.112836 | GPU: 35.7MB / 70.0MB | F: 0.0019s, B: 0.0029s, O: 0.0006s\n",
            "Step 6240 | Loss: 1.055175 | GPU: 35.7MB / 134.0MB | F: 0.0047s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 6240 took 0.0001s\n",
            "Batch 3120/3125 ( 99.8%) | Loss: 1.225501 | Accuracy: 56.56% | Batch time: 0.0353s\n",
            "Step 6250 | Loss: 1.184830 | GPU: 35.7MB / 70.0MB | F: 0.0024s, B: 0.0033s, O: 0.0010s\n",
            "\n",
            "-------------------- EPOCH 2 SUMMARY --------------------\n",
            "Loss: 1.225208 | Accuracy: 56.57%\n",
            "Time: 77.12s total, 0.0194s per batch\n",
            "🔄 Final Memory - RAM: 8190.8MB, GPU: 35.7MB allocated, 70.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=35.7, peak=35.7\n",
            "===============================\n",
            "\n",
            "⏱️ TALT model training took 77.1273 seconds\n",
            "\n",
            "Cleaning up memory after training...\n",
            "⏱️ Memory cleanup took 0.2467 seconds\n",
            "🔄 After training Memory - RAM: 8190.8MB, GPU: 35.5MB allocated, 64.0MB reserved\n",
            "\n",
            "------------------------- Standard Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 1.190223 | Accuracy: 56.74% | Batch time: 0.0014s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 1.178809 | Accuracy: 56.44% | Batch time: 0.0010s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 1.178815 | Accuracy: 57.41% | Batch time: 0.0030s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 1.188138 | Accuracy: 56.84% | Batch time: 0.0039s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 1.189277 | Accuracy: 56.47% | Batch time: 0.0012s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 1.190779 | Accuracy: 56.83% | Batch time: 0.0013s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 1.191010 | Accuracy: 57.07% | Batch time: 0.0020s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 1.191094 | Accuracy: 56.86% | Batch time: 0.0014s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 1.197607 | Accuracy: 56.58% | Batch time: 0.0011s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 1.193801 | Accuracy: 56.67% | Batch time: 0.0014s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 1.195975 | Accuracy: 56.67% | Batch time: 0.0019s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 1.195092 | Accuracy: 56.65% | Batch time: 0.0019s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.197721 | Accuracy: 56.39%\n",
            "Time: 7.02s total, 0.0018s per batch\n",
            "⏱️ Standard model evaluation took 7.0166 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 1.068519 | Accuracy: 62.50% | Batch time: 0.0019s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 1.040862 | Accuracy: 63.00% | Batch time: 0.0017s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 1.043990 | Accuracy: 62.42% | Batch time: 0.0013s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 1.052409 | Accuracy: 61.97% | Batch time: 0.0014s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 1.048018 | Accuracy: 62.18% | Batch time: 0.0014s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 1.043227 | Accuracy: 62.60% | Batch time: 0.0012s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 1.044493 | Accuracy: 62.54% | Batch time: 0.0015s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 1.049811 | Accuracy: 62.41% | Batch time: 0.0014s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 1.055047 | Accuracy: 62.21% | Batch time: 0.0014s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 1.050339 | Accuracy: 62.33% | Batch time: 0.0012s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 1.055440 | Accuracy: 62.02% | Batch time: 0.0014s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 1.054380 | Accuracy: 62.02% | Batch time: 0.0015s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.059518 | Accuracy: 61.91%\n",
            "Time: 6.01s total, 0.0016s per batch\n",
            "⏱️ TALT model evaluation took 6.0141 seconds\n",
            "\n",
            "------------------------- EPOCH 2 SUMMARY -------------------------\n",
            "Time: 125.07s\n",
            "Standard Model:\n",
            "  - Train Loss: 1.602612, Accuracy: 41.01%\n",
            "  - Test Loss:  1.197721, Accuracy: 56.39%\n",
            "Improved TALT Model:\n",
            "  - Train Loss: 1.225208, Accuracy: 56.57%\n",
            "  - Test Loss:  1.059518, Accuracy: 61.91%\n",
            "\n",
            "📈 TALT outperforms standard by 5.52% on test accuracy\n",
            "\n",
            "Cleaning up memory after epoch...\n",
            "⏱️ Memory cleanup took 0.2756 seconds\n",
            "🔄 After epoch Memory - RAM: 8190.8MB, GPU: 35.5MB allocated, 64.0MB reserved\n",
            "\n",
            "------------------------- Standard Model: Epoch 3/3 -------------------------\n",
            "\n",
            "==================== STANDARD OPTIMIZER - EPOCH 3 ====================\n",
            "Device: cuda, Batches: 3125, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 8190.8MB, GPU: 35.5MB allocated, 64.0MB reserved\n",
            "Batch    0/3125 (  0.0%) | Loss: 1.264126 | Accuracy: 50.00% | GPU: 35.7MB | Batch time: 0.0248s\n",
            "Batch   20/3125 (  0.6%) | Loss: 1.390657 | Accuracy: 47.92% | GPU: 35.7MB | Batch time: 0.0071s\n",
            "Batch   40/3125 (  1.3%) | Loss: 1.432725 | Accuracy: 46.80% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch   60/3125 (  1.9%) | Loss: 1.431561 | Accuracy: 46.72% | GPU: 35.7MB | Batch time: 0.0027s\n",
            "Batch   80/3125 (  2.6%) | Loss: 1.469172 | Accuracy: 45.68% | GPU: 35.7MB | Batch time: 0.0027s\n",
            "Batch  100/3125 (  3.2%) | Loss: 1.458583 | Accuracy: 45.85% | GPU: 35.7MB | Batch time: 0.0081s\n",
            "Batch  120/3125 (  3.8%) | Loss: 1.461510 | Accuracy: 45.92% | GPU: 35.7MB | Batch time: 0.0030s\n",
            "Batch  140/3125 (  4.5%) | Loss: 1.455127 | Accuracy: 46.28% | GPU: 35.7MB | Batch time: 0.0027s\n",
            "Batch  160/3125 (  5.1%) | Loss: 1.459276 | Accuracy: 45.89% | GPU: 35.7MB | Batch time: 0.0041s\n",
            "Batch  180/3125 (  5.8%) | Loss: 1.461807 | Accuracy: 46.17% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch  200/3125 (  6.4%) | Loss: 1.455314 | Accuracy: 46.05% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch  220/3125 (  7.0%) | Loss: 1.457824 | Accuracy: 45.96% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch  240/3125 (  7.7%) | Loss: 1.459859 | Accuracy: 45.70% | GPU: 35.7MB | Batch time: 0.0102s\n",
            "Batch  260/3125 (  8.3%) | Loss: 1.463400 | Accuracy: 45.59% | GPU: 35.7MB | Batch time: 0.0198s\n",
            "Batch  280/3125 (  9.0%) | Loss: 1.461739 | Accuracy: 45.80% | GPU: 35.7MB | Batch time: 0.0107s\n",
            "Batch  300/3125 (  9.6%) | Loss: 1.461532 | Accuracy: 45.99% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch  320/3125 ( 10.2%) | Loss: 1.468142 | Accuracy: 46.05% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch  340/3125 ( 10.9%) | Loss: 1.465314 | Accuracy: 46.19% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch  360/3125 ( 11.5%) | Loss: 1.456306 | Accuracy: 46.33% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch  380/3125 ( 12.2%) | Loss: 1.459833 | Accuracy: 46.47% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch  400/3125 ( 12.8%) | Loss: 1.453706 | Accuracy: 46.74% | GPU: 35.7MB | Batch time: 0.0046s\n",
            "Batch  420/3125 ( 13.4%) | Loss: 1.447799 | Accuracy: 47.08% | GPU: 35.7MB | Batch time: 0.0054s\n",
            "Batch  440/3125 ( 14.1%) | Loss: 1.444406 | Accuracy: 47.12% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch  460/3125 ( 14.7%) | Loss: 1.443606 | Accuracy: 47.14% | GPU: 35.7MB | Batch time: 0.0049s\n",
            "Batch  480/3125 ( 15.4%) | Loss: 1.442213 | Accuracy: 47.31% | GPU: 35.7MB | Batch time: 0.0041s\n",
            "Batch  500/3125 ( 16.0%) | Loss: 1.440852 | Accuracy: 47.26% | GPU: 35.7MB | Batch time: 0.0056s\n",
            "Batch  520/3125 ( 16.6%) | Loss: 1.443397 | Accuracy: 47.11% | GPU: 35.7MB | Batch time: 0.0045s\n",
            "Batch  540/3125 ( 17.3%) | Loss: 1.444729 | Accuracy: 47.26% | GPU: 35.7MB | Batch time: 0.0045s\n",
            "Batch  560/3125 ( 17.9%) | Loss: 1.442645 | Accuracy: 47.35% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch  580/3125 ( 18.6%) | Loss: 1.440449 | Accuracy: 47.42% | GPU: 35.7MB | Batch time: 0.0042s\n",
            "Batch  600/3125 ( 19.2%) | Loss: 1.441675 | Accuracy: 47.40% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch  620/3125 ( 19.8%) | Loss: 1.445917 | Accuracy: 47.37% | GPU: 35.7MB | Batch time: 0.0050s\n",
            "Batch  640/3125 ( 20.5%) | Loss: 1.444207 | Accuracy: 47.34% | GPU: 35.7MB | Batch time: 0.0033s\n",
            "Batch  660/3125 ( 21.1%) | Loss: 1.443248 | Accuracy: 47.42% | GPU: 35.7MB | Batch time: 0.0065s\n",
            "Batch  680/3125 ( 21.8%) | Loss: 1.441053 | Accuracy: 47.58% | GPU: 35.7MB | Batch time: 0.0057s\n",
            "Batch  700/3125 ( 22.4%) | Loss: 1.439431 | Accuracy: 47.58% | GPU: 35.7MB | Batch time: 0.0034s\n",
            "Batch  720/3125 ( 23.0%) | Loss: 1.438097 | Accuracy: 47.64% | GPU: 35.7MB | Batch time: 0.0045s\n",
            "Batch  740/3125 ( 23.7%) | Loss: 1.438248 | Accuracy: 47.68% | GPU: 35.7MB | Batch time: 0.0063s\n",
            "Batch  760/3125 ( 24.3%) | Loss: 1.442335 | Accuracy: 47.54% | GPU: 35.7MB | Batch time: 0.0047s\n",
            "Batch  780/3125 ( 25.0%) | Loss: 1.442803 | Accuracy: 47.57% | GPU: 35.7MB | Batch time: 0.0062s\n",
            "Batch  800/3125 ( 25.6%) | Loss: 1.440953 | Accuracy: 47.64% | GPU: 35.7MB | Batch time: 0.0049s\n",
            "Batch  820/3125 ( 26.2%) | Loss: 1.440499 | Accuracy: 47.71% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch  840/3125 ( 26.9%) | Loss: 1.440118 | Accuracy: 47.75% | GPU: 35.7MB | Batch time: 0.0051s\n",
            "Batch  860/3125 ( 27.5%) | Loss: 1.437846 | Accuracy: 47.87% | GPU: 35.7MB | Batch time: 0.0082s\n",
            "Batch  880/3125 ( 28.2%) | Loss: 1.438058 | Accuracy: 47.82% | GPU: 35.7MB | Batch time: 0.0063s\n",
            "Batch  900/3125 ( 28.8%) | Loss: 1.435065 | Accuracy: 47.93% | GPU: 35.7MB | Batch time: 0.0049s\n",
            "Batch  920/3125 ( 29.4%) | Loss: 1.435605 | Accuracy: 47.93% | GPU: 35.7MB | Batch time: 0.0044s\n",
            "Batch  940/3125 ( 30.1%) | Loss: 1.433879 | Accuracy: 48.07% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch  960/3125 ( 30.7%) | Loss: 1.433948 | Accuracy: 48.13% | GPU: 35.7MB | Batch time: 0.0066s\n",
            "Batch  980/3125 ( 31.4%) | Loss: 1.435386 | Accuracy: 48.06% | GPU: 35.7MB | Batch time: 0.0033s\n",
            "Batch 1000/3125 ( 32.0%) | Loss: 1.435336 | Accuracy: 48.06% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch 1020/3125 ( 32.6%) | Loss: 1.435189 | Accuracy: 48.05% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 1040/3125 ( 33.3%) | Loss: 1.435056 | Accuracy: 48.07% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch 1060/3125 ( 33.9%) | Loss: 1.433149 | Accuracy: 48.19% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch 1080/3125 ( 34.6%) | Loss: 1.431843 | Accuracy: 48.20% | GPU: 35.7MB | Batch time: 0.0056s\n",
            "Batch 1100/3125 ( 35.2%) | Loss: 1.430157 | Accuracy: 48.23% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch 1120/3125 ( 35.8%) | Loss: 1.429382 | Accuracy: 48.28% | GPU: 35.7MB | Batch time: 0.0111s\n",
            "Batch 1140/3125 ( 36.5%) | Loss: 1.429721 | Accuracy: 48.27% | GPU: 35.7MB | Batch time: 0.0103s\n",
            "Batch 1160/3125 ( 37.1%) | Loss: 1.428001 | Accuracy: 48.26% | GPU: 35.7MB | Batch time: 0.0119s\n",
            "Batch 1180/3125 ( 37.8%) | Loss: 1.425116 | Accuracy: 48.40% | GPU: 35.7MB | Batch time: 0.0045s\n",
            "Batch 1200/3125 ( 38.4%) | Loss: 1.423492 | Accuracy: 48.43% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 1220/3125 ( 39.0%) | Loss: 1.423503 | Accuracy: 48.33% | GPU: 35.7MB | Batch time: 0.0034s\n",
            "Batch 1240/3125 ( 39.7%) | Loss: 1.422730 | Accuracy: 48.29% | GPU: 35.7MB | Batch time: 0.0044s\n",
            "Batch 1260/3125 ( 40.3%) | Loss: 1.421518 | Accuracy: 48.33% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch 1280/3125 ( 41.0%) | Loss: 1.423227 | Accuracy: 48.22% | GPU: 35.7MB | Batch time: 0.0093s\n",
            "Batch 1300/3125 ( 41.6%) | Loss: 1.423339 | Accuracy: 48.18% | GPU: 35.7MB | Batch time: 0.0077s\n",
            "Batch 1320/3125 ( 42.2%) | Loss: 1.423063 | Accuracy: 48.22% | GPU: 35.7MB | Batch time: 0.0068s\n",
            "Batch 1340/3125 ( 42.9%) | Loss: 1.423072 | Accuracy: 48.26% | GPU: 35.7MB | Batch time: 0.0029s\n",
            "Batch 1360/3125 ( 43.5%) | Loss: 1.421406 | Accuracy: 48.36% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 1380/3125 ( 44.2%) | Loss: 1.420958 | Accuracy: 48.44% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch 1400/3125 ( 44.8%) | Loss: 1.419589 | Accuracy: 48.49% | GPU: 35.7MB | Batch time: 0.0081s\n",
            "Batch 1420/3125 ( 45.4%) | Loss: 1.420133 | Accuracy: 48.45% | GPU: 35.7MB | Batch time: 0.0029s\n",
            "Batch 1440/3125 ( 46.1%) | Loss: 1.420083 | Accuracy: 48.50% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch 1460/3125 ( 46.7%) | Loss: 1.419342 | Accuracy: 48.53% | GPU: 35.7MB | Batch time: 0.0095s\n",
            "Batch 1480/3125 ( 47.4%) | Loss: 1.419053 | Accuracy: 48.54% | GPU: 35.7MB | Batch time: 0.0105s\n",
            "Batch 1500/3125 ( 48.0%) | Loss: 1.418585 | Accuracy: 48.57% | GPU: 35.7MB | Batch time: 0.0107s\n",
            "Batch 1520/3125 ( 48.6%) | Loss: 1.419308 | Accuracy: 48.52% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 1540/3125 ( 49.3%) | Loss: 1.419594 | Accuracy: 48.51% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 1560/3125 ( 49.9%) | Loss: 1.419536 | Accuracy: 48.51% | GPU: 35.7MB | Batch time: 0.0096s\n",
            "Batch 1580/3125 ( 50.6%) | Loss: 1.418807 | Accuracy: 48.56% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch 1600/3125 ( 51.2%) | Loss: 1.416628 | Accuracy: 48.64% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 1620/3125 ( 51.8%) | Loss: 1.415190 | Accuracy: 48.69% | GPU: 35.7MB | Batch time: 0.0046s\n",
            "Batch 1640/3125 ( 52.5%) | Loss: 1.414576 | Accuracy: 48.72% | GPU: 35.7MB | Batch time: 0.0042s\n",
            "Batch 1660/3125 ( 53.1%) | Loss: 1.413784 | Accuracy: 48.75% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 1680/3125 ( 53.8%) | Loss: 1.413703 | Accuracy: 48.74% | GPU: 35.7MB | Batch time: 0.0074s\n",
            "Batch 1700/3125 ( 54.4%) | Loss: 1.411783 | Accuracy: 48.81% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch 1720/3125 ( 55.0%) | Loss: 1.411505 | Accuracy: 48.81% | GPU: 35.7MB | Batch time: 0.0059s\n",
            "Batch 1740/3125 ( 55.7%) | Loss: 1.410368 | Accuracy: 48.87% | GPU: 35.7MB | Batch time: 0.0047s\n",
            "Batch 1760/3125 ( 56.3%) | Loss: 1.409915 | Accuracy: 48.89% | GPU: 35.7MB | Batch time: 0.0090s\n",
            "Batch 1780/3125 ( 57.0%) | Loss: 1.408249 | Accuracy: 48.92% | GPU: 35.7MB | Batch time: 0.0047s\n",
            "Batch 1800/3125 ( 57.6%) | Loss: 1.408732 | Accuracy: 48.93% | GPU: 35.7MB | Batch time: 0.0034s\n",
            "Batch 1820/3125 ( 58.2%) | Loss: 1.407659 | Accuracy: 48.97% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch 1840/3125 ( 58.9%) | Loss: 1.408373 | Accuracy: 48.96% | GPU: 35.7MB | Batch time: 0.0078s\n",
            "Batch 1860/3125 ( 59.5%) | Loss: 1.407948 | Accuracy: 48.96% | GPU: 35.7MB | Batch time: 0.0041s\n",
            "Batch 1880/3125 ( 60.2%) | Loss: 1.406971 | Accuracy: 49.00% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch 1900/3125 ( 60.8%) | Loss: 1.407447 | Accuracy: 48.99% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch 1920/3125 ( 61.4%) | Loss: 1.406874 | Accuracy: 49.00% | GPU: 35.7MB | Batch time: 0.0081s\n",
            "Batch 1940/3125 ( 62.1%) | Loss: 1.405636 | Accuracy: 49.04% | GPU: 35.7MB | Batch time: 0.0048s\n",
            "Batch 1960/3125 ( 62.7%) | Loss: 1.405852 | Accuracy: 49.02% | GPU: 35.7MB | Batch time: 0.0046s\n",
            "Batch 1980/3125 ( 63.4%) | Loss: 1.405094 | Accuracy: 49.03% | GPU: 35.7MB | Batch time: 0.0041s\n",
            "Batch 2000/3125 ( 64.0%) | Loss: 1.404655 | Accuracy: 49.06% | GPU: 35.7MB | Batch time: 0.0034s\n",
            "Batch 2020/3125 ( 64.6%) | Loss: 1.404276 | Accuracy: 49.07% | GPU: 35.7MB | Batch time: 0.0071s\n",
            "Batch 2040/3125 ( 65.3%) | Loss: 1.403865 | Accuracy: 49.09% | GPU: 35.7MB | Batch time: 0.0047s\n",
            "Batch 2060/3125 ( 65.9%) | Loss: 1.404094 | Accuracy: 49.09% | GPU: 35.7MB | Batch time: 0.0044s\n",
            "Batch 2080/3125 ( 66.6%) | Loss: 1.402871 | Accuracy: 49.11% | GPU: 35.7MB | Batch time: 0.0087s\n",
            "Batch 2100/3125 ( 67.2%) | Loss: 1.403035 | Accuracy: 49.11% | GPU: 35.7MB | Batch time: 0.0043s\n",
            "Batch 2120/3125 ( 67.8%) | Loss: 1.403164 | Accuracy: 49.11% | GPU: 35.7MB | Batch time: 0.0061s\n",
            "Batch 2140/3125 ( 68.5%) | Loss: 1.402303 | Accuracy: 49.16% | GPU: 35.7MB | Batch time: 0.0050s\n",
            "Batch 2160/3125 ( 69.1%) | Loss: 1.401874 | Accuracy: 49.20% | GPU: 35.7MB | Batch time: 0.0052s\n",
            "Batch 2180/3125 ( 69.8%) | Loss: 1.402164 | Accuracy: 49.21% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch 2200/3125 ( 70.4%) | Loss: 1.402166 | Accuracy: 49.21% | GPU: 35.7MB | Batch time: 0.0052s\n",
            "Batch 2220/3125 ( 71.0%) | Loss: 1.401998 | Accuracy: 49.21% | GPU: 35.7MB | Batch time: 0.0077s\n",
            "Batch 2240/3125 ( 71.7%) | Loss: 1.401496 | Accuracy: 49.22% | GPU: 35.7MB | Batch time: 0.0044s\n",
            "Batch 2260/3125 ( 72.3%) | Loss: 1.402254 | Accuracy: 49.19% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch 2280/3125 ( 73.0%) | Loss: 1.402341 | Accuracy: 49.19% | GPU: 35.7MB | Batch time: 0.0047s\n",
            "Batch 2300/3125 ( 73.6%) | Loss: 1.402289 | Accuracy: 49.19% | GPU: 35.7MB | Batch time: 0.0046s\n",
            "Batch 2320/3125 ( 74.2%) | Loss: 1.403286 | Accuracy: 49.17% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch 2340/3125 ( 74.9%) | Loss: 1.403795 | Accuracy: 49.14% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 2360/3125 ( 75.5%) | Loss: 1.403043 | Accuracy: 49.16% | GPU: 35.7MB | Batch time: 0.0074s\n",
            "Batch 2380/3125 ( 76.2%) | Loss: 1.402473 | Accuracy: 49.18% | GPU: 35.7MB | Batch time: 0.0116s\n",
            "Batch 2400/3125 ( 76.8%) | Loss: 1.401856 | Accuracy: 49.19% | GPU: 35.7MB | Batch time: 0.0063s\n",
            "Batch 2420/3125 ( 77.4%) | Loss: 1.401145 | Accuracy: 49.21% | GPU: 35.7MB | Batch time: 0.0049s\n",
            "Batch 2440/3125 ( 78.1%) | Loss: 1.401318 | Accuracy: 49.23% | GPU: 35.7MB | Batch time: 0.0051s\n",
            "Batch 2460/3125 ( 78.7%) | Loss: 1.400046 | Accuracy: 49.26% | GPU: 35.7MB | Batch time: 0.0058s\n",
            "Batch 2480/3125 ( 79.4%) | Loss: 1.400247 | Accuracy: 49.28% | GPU: 35.7MB | Batch time: 0.0043s\n",
            "Batch 2500/3125 ( 80.0%) | Loss: 1.399251 | Accuracy: 49.30% | GPU: 35.7MB | Batch time: 0.0131s\n",
            "Batch 2520/3125 ( 80.6%) | Loss: 1.399267 | Accuracy: 49.31% | GPU: 35.7MB | Batch time: 0.0066s\n",
            "Batch 2540/3125 ( 81.3%) | Loss: 1.398287 | Accuracy: 49.36% | GPU: 35.7MB | Batch time: 0.0028s\n",
            "Batch 2560/3125 ( 81.9%) | Loss: 1.398412 | Accuracy: 49.37% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch 2580/3125 ( 82.6%) | Loss: 1.398041 | Accuracy: 49.39% | GPU: 35.7MB | Batch time: 0.0044s\n",
            "Batch 2600/3125 ( 83.2%) | Loss: 1.398822 | Accuracy: 49.36% | GPU: 35.7MB | Batch time: 0.0041s\n",
            "Batch 2620/3125 ( 83.8%) | Loss: 1.398936 | Accuracy: 49.37% | GPU: 35.7MB | Batch time: 0.0033s\n",
            "Batch 2640/3125 ( 84.5%) | Loss: 1.398424 | Accuracy: 49.39% | GPU: 35.7MB | Batch time: 0.0031s\n",
            "Batch 2660/3125 ( 85.1%) | Loss: 1.397682 | Accuracy: 49.43% | GPU: 35.7MB | Batch time: 0.0035s\n",
            "Batch 2680/3125 ( 85.8%) | Loss: 1.397494 | Accuracy: 49.47% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch 2700/3125 ( 86.4%) | Loss: 1.397195 | Accuracy: 49.49% | GPU: 35.7MB | Batch time: 0.0116s\n",
            "Batch 2720/3125 ( 87.0%) | Loss: 1.396881 | Accuracy: 49.52% | GPU: 35.7MB | Batch time: 0.0071s\n",
            "Batch 2740/3125 ( 87.7%) | Loss: 1.395829 | Accuracy: 49.60% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch 2760/3125 ( 88.3%) | Loss: 1.395612 | Accuracy: 49.62% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 2780/3125 ( 89.0%) | Loss: 1.394771 | Accuracy: 49.66% | GPU: 35.7MB | Batch time: 0.0044s\n",
            "Batch 2800/3125 ( 89.6%) | Loss: 1.394429 | Accuracy: 49.66% | GPU: 35.7MB | Batch time: 0.0064s\n",
            "Batch 2820/3125 ( 90.2%) | Loss: 1.394047 | Accuracy: 49.68% | GPU: 35.7MB | Batch time: 0.0053s\n",
            "Batch 2840/3125 ( 90.9%) | Loss: 1.394473 | Accuracy: 49.67% | GPU: 35.7MB | Batch time: 0.0037s\n",
            "Batch 2860/3125 ( 91.5%) | Loss: 1.394080 | Accuracy: 49.68% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch 2880/3125 ( 92.2%) | Loss: 1.393909 | Accuracy: 49.71% | GPU: 35.7MB | Batch time: 0.0156s\n",
            "Batch 2900/3125 ( 92.8%) | Loss: 1.393648 | Accuracy: 49.68% | GPU: 35.7MB | Batch time: 0.0040s\n",
            "Batch 2920/3125 ( 93.4%) | Loss: 1.393903 | Accuracy: 49.67% | GPU: 35.7MB | Batch time: 0.0038s\n",
            "Batch 2940/3125 ( 94.1%) | Loss: 1.393689 | Accuracy: 49.70% | GPU: 35.7MB | Batch time: 0.0036s\n",
            "Batch 2960/3125 ( 94.7%) | Loss: 1.393462 | Accuracy: 49.72% | GPU: 35.7MB | Batch time: 0.0047s\n",
            "Batch 2980/3125 ( 95.4%) | Loss: 1.393265 | Accuracy: 49.75% | GPU: 35.7MB | Batch time: 0.0046s\n",
            "Batch 3000/3125 ( 96.0%) | Loss: 1.392992 | Accuracy: 49.78% | GPU: 35.7MB | Batch time: 0.0034s\n",
            "Batch 3020/3125 ( 96.6%) | Loss: 1.392533 | Accuracy: 49.78% | GPU: 35.7MB | Batch time: 0.0044s\n",
            "Batch 3040/3125 ( 97.3%) | Loss: 1.392457 | Accuracy: 49.81% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch 3060/3125 ( 97.9%) | Loss: 1.392388 | Accuracy: 49.81% | GPU: 35.7MB | Batch time: 0.0039s\n",
            "Batch 3080/3125 ( 98.6%) | Loss: 1.391736 | Accuracy: 49.83% | GPU: 35.7MB | Batch time: 0.0069s\n",
            "Batch 3100/3125 ( 99.2%) | Loss: 1.391384 | Accuracy: 49.86% | GPU: 35.7MB | Batch time: 0.0058s\n",
            "Batch 3120/3125 ( 99.8%) | Loss: 1.391315 | Accuracy: 49.88% | GPU: 35.7MB | Batch time: 0.0045s\n",
            "Batch 3124/3125 (100.0%) | Loss: 1.391103 | Accuracy: 49.90% | GPU: 35.7MB | Batch time: 0.0055s\n",
            "\n",
            "-------------------- STANDARD OPTIMIZER - SUMMARY --------------------\n",
            "Loss: 1.391103 | Accuracy: 49.90%\n",
            "Time: 34.73s total, 0.0056s per batch\n",
            "  - Forward: 0.0018s, Backward: 0.0026s, Optimizer: 0.0005s\n",
            "🔄 Final Memory - RAM: 8190.8MB, GPU: 35.7MB allocated, 68.0MB reserved\n",
            "⏱️ Standard model training took 34.7349 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Epoch 3/3 -------------------------\n",
            "\n",
            "==================== EPOCH 3 TRAINING ====================\n",
            "Device: cuda, Batches: 3125, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 8190.8MB, GPU: 35.5MB allocated, 68.0MB reserved\n",
            "Batch    0/3125 (  0.0%) | Loss: 1.072666 | Accuracy: 62.50% | Batch time: 0.0522s\n",
            "Step 6260 | Loss: 0.898910 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0066s, O: 0.0012s\n",
            "🔄 Topology update at step 6260 took 0.0003s\n",
            "Step 6270 | Loss: 1.127438 | GPU: 35.7MB / 134.0MB | F: 0.0059s, B: 0.0117s, O: 0.0011s\n",
            "Batch   20/3125 (  0.6%) | Loss: 1.126727 | Accuracy: 61.01% | Batch time: 0.0377s\n",
            "Step 6280 | Loss: 0.993716 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0024s, O: 0.0013s\n",
            "🔄 Topology update at step 6280 took 0.0006s\n",
            "Step 6290 | Loss: 1.305828 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0032s, O: 0.0010s\n",
            "Batch   40/3125 (  1.3%) | Loss: 1.137891 | Accuracy: 59.76% | Batch time: 0.0390s\n",
            "Step 6300 | Loss: 1.283663 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0030s, O: 0.0019s\n",
            "🔄 Topology update at step 6300 took 0.0001s\n",
            "🧹 Memory cleanup at step 6300 took 0.4699s\n",
            "Step 6310 | Loss: 1.623207 | GPU: 35.7MB / 134.0MB | F: 0.0080s, B: 0.0059s, O: 0.0016s\n",
            "Batch   60/3125 (  1.9%) | Loss: 1.188526 | Accuracy: 58.71% | Batch time: 0.0495s\n",
            "Step 6320 | Loss: 1.186311 | GPU: 35.7MB / 134.0MB | F: 0.0086s, B: 0.0058s, O: 0.0016s\n",
            "🔄 Topology update at step 6320 took 0.0001s\n",
            "Step 6330 | Loss: 1.149569 | GPU: 35.7MB / 134.0MB | F: 0.0151s, B: 0.0053s, O: 0.0016s\n",
            "Batch   80/3125 (  2.6%) | Loss: 1.178416 | Accuracy: 58.56% | Batch time: 0.0629s\n",
            "Step 6340 | Loss: 1.106461 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 6340 took 0.0000s\n",
            "Step 6350 | Loss: 1.498587 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0045s, O: 0.0014s\n",
            "Batch  100/3125 (  3.2%) | Loss: 1.160243 | Accuracy: 59.28% | Batch time: 0.0450s\n",
            "Step 6360 | Loss: 1.273453 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0035s, O: 0.0022s\n",
            "🔄 Topology update at step 6360 took 0.0001s\n",
            "Step 6370 | Loss: 1.064873 | GPU: 35.7MB / 134.0MB | F: 0.0031s, B: 0.0034s, O: 0.0009s\n",
            "Batch  120/3125 (  3.8%) | Loss: 1.144587 | Accuracy: 60.07% | Batch time: 0.0327s\n",
            "Step 6380 | Loss: 1.023453 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0045s, O: 0.0009s\n",
            "🔄 Topology update at step 6380 took 0.0001s\n",
            "Step 6390 | Loss: 0.918168 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0044s, O: 0.0009s\n",
            "Batch  140/3125 (  4.5%) | Loss: 1.143973 | Accuracy: 59.80% | Batch time: 0.0337s\n",
            "Step 6400 | Loss: 1.672508 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0031s, O: 0.0006s\n",
            "🔄 Topology update at step 6400 took 0.0015s\n",
            "🧹 Memory cleanup at step 6400 took 0.2551s\n",
            "Step 6410 | Loss: 1.161556 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0098s, O: 0.0006s\n",
            "Batch  160/3125 (  5.1%) | Loss: 1.137048 | Accuracy: 60.13% | Batch time: 0.0321s\n",
            "Step 6420 | Loss: 1.341105 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0051s, O: 0.0029s\n",
            "🔄 Topology update at step 6420 took 0.0000s\n",
            "Step 6430 | Loss: 1.058379 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0077s, O: 0.0010s\n",
            "Batch  180/3125 (  5.8%) | Loss: 1.131007 | Accuracy: 59.77% | Batch time: 0.0344s\n",
            "Step 6440 | Loss: 1.205137 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0050s, O: 0.0018s\n",
            "🔄 Topology update at step 6440 took 0.0001s\n",
            "Step 6450 | Loss: 1.519859 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0092s, O: 0.0007s\n",
            "Batch  200/3125 (  6.4%) | Loss: 1.133474 | Accuracy: 59.73% | Batch time: 0.0298s\n",
            "Step 6460 | Loss: 1.467897 | GPU: 35.7MB / 134.0MB | F: 0.0052s, B: 0.0031s, O: 0.0006s\n",
            "🔄 Topology update at step 6460 took 0.0000s\n",
            "Step 6470 | Loss: 1.067500 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0067s, O: 0.0020s\n",
            "Batch  220/3125 (  7.0%) | Loss: 1.126720 | Accuracy: 59.98% | Batch time: 0.0379s\n",
            "Step 6480 | Loss: 0.854997 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0071s, O: 0.0006s\n",
            "🔄 Topology update at step 6480 took 0.0000s\n",
            "Step 6490 | Loss: 1.144425 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0032s, O: 0.0007s\n",
            "Batch  240/3125 (  7.7%) | Loss: 1.122117 | Accuracy: 60.17% | Batch time: 0.0425s\n",
            "Step 6500 | Loss: 1.172478 | GPU: 35.7MB / 134.0MB | F: 0.0067s, B: 0.0052s, O: 0.0005s\n",
            "🔄 Topology update at step 6500 took 0.0001s\n",
            "🧹 Memory cleanup at step 6500 took 0.3528s\n",
            "Step 6510 | Loss: 1.015677 | GPU: 35.7MB / 134.0MB | F: 0.0069s, B: 0.0020s, O: 0.0009s\n",
            "Batch  260/3125 (  8.3%) | Loss: 1.122055 | Accuracy: 60.13% | Batch time: 0.0554s\n",
            "Step 6520 | Loss: 0.901100 | GPU: 35.7MB / 134.0MB | F: 0.0045s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 6520 took 0.0073s\n",
            "Step 6530 | Loss: 1.378429 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0019s, O: 0.0005s\n",
            "Batch  280/3125 (  9.0%) | Loss: 1.125764 | Accuracy: 60.01% | Batch time: 0.0420s\n",
            "Step 6540 | Loss: 1.306562 | GPU: 35.7MB / 134.0MB | F: 0.0051s, B: 0.0039s, O: 0.0007s\n",
            "🔄 Topology update at step 6540 took 0.0000s\n",
            "Step 6550 | Loss: 1.201652 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0055s, O: 0.0007s\n",
            "Batch  300/3125 (  9.6%) | Loss: 1.122881 | Accuracy: 60.07% | Batch time: 0.0487s\n",
            "Step 6560 | Loss: 0.887884 | GPU: 35.7MB / 134.0MB | F: 0.0040s, B: 0.0028s, O: 0.0010s\n",
            "🔄 Topology update at step 6560 took 0.0001s\n",
            "Step 6570 | Loss: 0.976902 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0028s, O: 0.0026s\n",
            "Batch  320/3125 ( 10.2%) | Loss: 1.122939 | Accuracy: 60.01% | Batch time: 0.0731s\n",
            "Step 6580 | Loss: 0.745299 | GPU: 35.7MB / 134.0MB | F: 0.0037s, B: 0.0045s, O: 0.0006s\n",
            "🔄 Topology update at step 6580 took 0.0000s\n",
            "Step 6590 | Loss: 0.795208 | GPU: 35.7MB / 134.0MB | F: 0.0085s, B: 0.0049s, O: 0.0007s\n",
            "Batch  340/3125 ( 10.9%) | Loss: 1.121498 | Accuracy: 60.15% | Batch time: 0.0443s\n",
            "Step 6600 | Loss: 1.213409 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0062s, O: 0.0011s\n",
            "🔄 Topology update at step 6600 took 0.0001s\n",
            "🧹 Memory cleanup at step 6600 took 0.2549s\n",
            "Step 6610 | Loss: 0.981086 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0031s, O: 0.0008s\n",
            "Batch  360/3125 ( 11.5%) | Loss: 1.122076 | Accuracy: 60.11% | Batch time: 0.0378s\n",
            "Step 6620 | Loss: 1.028113 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0034s, O: 0.0016s\n",
            "🔄 Topology update at step 6620 took 0.0000s\n",
            "Step 6630 | Loss: 0.858307 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0039s, O: 0.0007s\n",
            "Batch  380/3125 ( 12.2%) | Loss: 1.125473 | Accuracy: 60.09% | Batch time: 0.0430s\n",
            "Step 6640 | Loss: 0.949305 | GPU: 35.7MB / 134.0MB | F: 0.0082s, B: 0.0076s, O: 0.0008s\n",
            "🔄 Topology update at step 6640 took 0.0000s\n",
            "Step 6650 | Loss: 1.507753 | GPU: 35.7MB / 134.0MB | F: 0.0063s, B: 0.0034s, O: 0.0010s\n",
            "Batch  400/3125 ( 12.8%) | Loss: 1.128648 | Accuracy: 59.99% | Batch time: 0.0378s\n",
            "Step 6660 | Loss: 1.001505 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0033s, O: 0.0010s\n",
            "🔄 Topology update at step 6660 took 0.0001s\n",
            "Step 6670 | Loss: 0.655277 | GPU: 35.7MB / 134.0MB | F: 0.0071s, B: 0.0027s, O: 0.0008s\n",
            "Batch  420/3125 ( 13.4%) | Loss: 1.128804 | Accuracy: 60.08% | Batch time: 0.1029s\n",
            "Step 6680 | Loss: 1.128690 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0046s, O: 0.0007s\n",
            "🔄 Topology update at step 6680 took 0.0001s\n",
            "Step 6690 | Loss: 1.103920 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0054s, O: 0.0019s\n",
            "Batch  440/3125 ( 14.1%) | Loss: 1.126018 | Accuracy: 60.18% | Batch time: 0.0288s\n",
            "Step 6700 | Loss: 1.300554 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0045s, O: 0.0018s\n",
            "🔄 Topology update at step 6700 took 0.0000s\n",
            "🧹 Memory cleanup at step 6700 took 0.2680s\n",
            "Step 6710 | Loss: 0.866440 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0182s, O: 0.0013s\n",
            "Batch  460/3125 ( 14.7%) | Loss: 1.131632 | Accuracy: 60.07% | Batch time: 0.0473s\n",
            "Step 6720 | Loss: 0.673542 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0035s, O: 0.0042s\n",
            "🔄 Topology update at step 6720 took 0.0001s\n",
            "Step 6730 | Loss: 0.869523 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0028s, O: 0.0009s\n",
            "Batch  480/3125 ( 15.4%) | Loss: 1.128411 | Accuracy: 60.19% | Batch time: 0.0377s\n",
            "Step 6740 | Loss: 0.997477 | GPU: 35.7MB / 134.0MB | F: 0.0125s, B: 0.0034s, O: 0.0013s\n",
            "🔄 Topology update at step 6740 took 0.0001s\n",
            "Step 6750 | Loss: 1.010129 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0113s, O: 0.0010s\n",
            "Batch  500/3125 ( 16.0%) | Loss: 1.124981 | Accuracy: 60.23% | Batch time: 0.0379s\n",
            "Step 6760 | Loss: 1.119034 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0069s, O: 0.0012s\n",
            "🔄 Topology update at step 6760 took 0.0001s\n",
            "Step 6770 | Loss: 0.820556 | GPU: 35.7MB / 134.0MB | F: 0.0119s, B: 0.0030s, O: 0.0009s\n",
            "Batch  520/3125 ( 16.6%) | Loss: 1.120003 | Accuracy: 60.47% | Batch time: 0.0302s\n",
            "Step 6780 | Loss: 1.259859 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0037s, O: 0.0011s\n",
            "🔄 Topology update at step 6780 took 0.0001s\n",
            "Step 6790 | Loss: 1.358584 | GPU: 35.7MB / 134.0MB | F: 0.0062s, B: 0.0082s, O: 0.0010s\n",
            "Batch  540/3125 ( 17.3%) | Loss: 1.121613 | Accuracy: 60.44% | Batch time: 0.0445s\n",
            "Step 6800 | Loss: 0.972933 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0030s, O: 0.0023s\n",
            "🔄 Topology update at step 6800 took 0.0001s\n",
            "🧹 Memory cleanup at step 6800 took 0.2619s\n",
            "Step 6810 | Loss: 2.180038 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0053s, O: 0.0010s\n",
            "Batch  560/3125 ( 17.9%) | Loss: 1.123165 | Accuracy: 60.18% | Batch time: 0.0428s\n",
            "Step 6820 | Loss: 1.041260 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0034s, O: 0.0010s\n",
            "🔄 Topology update at step 6820 took 0.0001s\n",
            "Step 6830 | Loss: 1.411392 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0033s, O: 0.0019s\n",
            "Batch  580/3125 ( 18.6%) | Loss: 1.119734 | Accuracy: 60.26% | Batch time: 0.0456s\n",
            "Step 6840 | Loss: 1.092585 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0053s, O: 0.0007s\n",
            "🔄 Topology update at step 6840 took 0.0001s\n",
            "Step 6850 | Loss: 1.518398 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0092s, O: 0.0018s\n",
            "Batch  600/3125 ( 19.2%) | Loss: 1.122794 | Accuracy: 60.18% | Batch time: 0.0357s\n",
            "Step 6860 | Loss: 1.320351 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 6860 took 0.0000s\n",
            "Step 6870 | Loss: 1.445495 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0033s, O: 0.0010s\n",
            "Batch  620/3125 ( 19.8%) | Loss: 1.121326 | Accuracy: 60.21% | Batch time: 0.0362s\n",
            "Step 6880 | Loss: 1.655951 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0100s, O: 0.0048s\n",
            "🔄 Topology update at step 6880 took 0.0001s\n",
            "Step 6890 | Loss: 1.313760 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0032s, O: 0.0015s\n",
            "Batch  640/3125 ( 20.5%) | Loss: 1.125375 | Accuracy: 60.16% | Batch time: 0.0355s\n",
            "Step 6900 | Loss: 1.361578 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0039s, O: 0.0023s\n",
            "🔄 Topology update at step 6900 took 0.0001s\n",
            "🧹 Memory cleanup at step 6900 took 0.2683s\n",
            "Step 6910 | Loss: 0.803309 | GPU: 35.7MB / 134.0MB | F: 0.0172s, B: 0.0137s, O: 0.0011s\n",
            "Batch  660/3125 ( 21.1%) | Loss: 1.124663 | Accuracy: 60.20% | Batch time: 0.0319s\n",
            "Step 6920 | Loss: 1.276099 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0087s, O: 0.0007s\n",
            "🔄 Topology update at step 6920 took 0.0000s\n",
            "Step 6930 | Loss: 1.177132 | GPU: 35.7MB / 134.0MB | F: 0.0191s, B: 0.0085s, O: 0.0018s\n",
            "Batch  680/3125 ( 21.8%) | Loss: 1.121491 | Accuracy: 60.46% | Batch time: 0.0344s\n",
            "Step 6940 | Loss: 0.889371 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0033s, O: 0.0021s\n",
            "🔄 Topology update at step 6940 took 0.0001s\n",
            "Step 6950 | Loss: 0.986971 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Batch  700/3125 ( 22.4%) | Loss: 1.122018 | Accuracy: 60.50% | Batch time: 0.0371s\n",
            "Step 6960 | Loss: 0.978570 | GPU: 35.7MB / 134.0MB | F: 0.0046s, B: 0.0145s, O: 0.0011s\n",
            "🔄 Topology update at step 6960 took 0.0001s\n",
            "Step 6970 | Loss: 1.158595 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0069s, O: 0.0011s\n",
            "Batch  720/3125 ( 23.0%) | Loss: 1.120071 | Accuracy: 60.68% | Batch time: 0.0364s\n",
            "Step 6980 | Loss: 1.083466 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0066s, O: 0.0010s\n",
            "🔄 Topology update at step 6980 took 0.0001s\n",
            "Step 6990 | Loss: 1.148478 | GPU: 35.7MB / 134.0MB | F: 0.0050s, B: 0.0156s, O: 0.0007s\n",
            "Batch  740/3125 ( 23.7%) | Loss: 1.122471 | Accuracy: 60.58% | Batch time: 0.0534s\n",
            "Step 7000 | Loss: 1.118210 | GPU: 35.7MB / 134.0MB | F: 0.0050s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 7000 took 0.0000s\n",
            "🧹 Memory cleanup at step 7000 took 0.2866s\n",
            "Step 7010 | Loss: 1.188560 | GPU: 35.7MB / 134.0MB | F: 0.0045s, B: 0.0025s, O: 0.0008s\n",
            "Batch  760/3125 ( 24.3%) | Loss: 1.120991 | Accuracy: 60.57% | Batch time: 0.0838s\n",
            "Step 7020 | Loss: 1.124352 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0074s, O: 0.0005s\n",
            "🔄 Topology update at step 7020 took 0.0000s\n",
            "Step 7030 | Loss: 1.059369 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0017s, O: 0.0005s\n",
            "Batch  780/3125 ( 25.0%) | Loss: 1.121062 | Accuracy: 60.58% | Batch time: 0.0429s\n",
            "Step 7040 | Loss: 1.157452 | GPU: 35.7MB / 134.0MB | F: 0.0038s, B: 0.0017s, O: 0.0005s\n",
            "🔄 Topology update at step 7040 took 0.0000s\n",
            "Step 7050 | Loss: 1.286136 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0103s, O: 0.0008s\n",
            "Batch  800/3125 ( 25.6%) | Loss: 1.121953 | Accuracy: 60.58% | Batch time: 0.0486s\n",
            "Step 7060 | Loss: 0.758691 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0028s, O: 0.0007s\n",
            "🔄 Topology update at step 7060 took 0.0000s\n",
            "Step 7070 | Loss: 1.681187 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0103s, O: 0.0006s\n",
            "Batch  820/3125 ( 26.2%) | Loss: 1.122915 | Accuracy: 60.56% | Batch time: 0.0470s\n",
            "Step 7080 | Loss: 0.585172 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 7080 took 0.0000s\n",
            "Step 7090 | Loss: 1.065430 | GPU: 35.7MB / 134.0MB | F: 0.0099s, B: 0.0048s, O: 0.0018s\n",
            "Batch  840/3125 ( 26.9%) | Loss: 1.122076 | Accuracy: 60.66% | Batch time: 0.0508s\n",
            "Step 7100 | Loss: 0.839470 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0114s, O: 0.0007s\n",
            "🔄 Topology update at step 7100 took 0.0000s\n",
            "🧹 Memory cleanup at step 7100 took 0.3187s\n",
            "Step 7110 | Loss: 1.258278 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0034s, O: 0.0016s\n",
            "Batch  860/3125 ( 27.5%) | Loss: 1.120133 | Accuracy: 60.73% | Batch time: 0.0426s\n",
            "Step 7120 | Loss: 0.925928 | GPU: 35.7MB / 134.0MB | F: 0.0170s, B: 0.0065s, O: 0.0011s\n",
            "🔄 Topology update at step 7120 took 0.0001s\n",
            "Step 7130 | Loss: 0.977396 | GPU: 35.7MB / 134.0MB | F: 0.0060s, B: 0.0029s, O: 0.0023s\n",
            "Batch  880/3125 ( 28.2%) | Loss: 1.120030 | Accuracy: 60.70% | Batch time: 0.0436s\n",
            "Step 7140 | Loss: 1.142894 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0074s, O: 0.0007s\n",
            "🔄 Topology update at step 7140 took 0.0000s\n",
            "Step 7150 | Loss: 1.111310 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0032s, O: 0.0007s\n",
            "Batch  900/3125 ( 28.8%) | Loss: 1.118923 | Accuracy: 60.75% | Batch time: 0.0361s\n",
            "Step 7160 | Loss: 1.172189 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0074s, O: 0.0007s\n",
            "🔄 Topology update at step 7160 took 0.0000s\n",
            "Step 7170 | Loss: 1.707420 | GPU: 35.7MB / 134.0MB | F: 0.0033s, B: 0.0035s, O: 0.0008s\n",
            "Batch  920/3125 ( 29.4%) | Loss: 1.119885 | Accuracy: 60.72% | Batch time: 0.0489s\n",
            "Step 7180 | Loss: 0.944361 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0060s, O: 0.0010s\n",
            "🔄 Topology update at step 7180 took 0.0001s\n",
            "Step 7190 | Loss: 1.249279 | GPU: 35.7MB / 134.0MB | F: 0.0043s, B: 0.0057s, O: 0.0011s\n",
            "Batch  940/3125 ( 30.1%) | Loss: 1.121886 | Accuracy: 60.71% | Batch time: 0.0341s\n",
            "Step 7200 | Loss: 1.312315 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0042s, O: 0.0007s\n",
            "🔄 Topology update at step 7200 took 0.0000s\n",
            "🧹 Memory cleanup at step 7200 took 0.2275s\n",
            "Step 7210 | Loss: 1.305779 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0033s, O: 0.0007s\n",
            "Batch  960/3125 ( 30.7%) | Loss: 1.122828 | Accuracy: 60.64% | Batch time: 0.0521s\n",
            "Step 7220 | Loss: 1.554923 | GPU: 35.7MB / 134.0MB | F: 0.0111s, B: 0.0055s, O: 0.0011s\n",
            "🔄 Topology update at step 7220 took 0.0001s\n",
            "Step 7230 | Loss: 1.005299 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0114s, O: 0.0007s\n",
            "Batch  980/3125 ( 31.4%) | Loss: 1.122871 | Accuracy: 60.65% | Batch time: 0.0406s\n",
            "Step 7240 | Loss: 0.908802 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0037s, O: 0.0018s\n",
            "🔄 Topology update at step 7240 took 0.0001s\n",
            "Step 7250 | Loss: 1.213332 | GPU: 35.7MB / 134.0MB | F: 0.0063s, B: 0.0055s, O: 0.0011s\n",
            "Batch 1000/3125 ( 32.0%) | Loss: 1.120500 | Accuracy: 60.70% | Batch time: 0.0363s\n",
            "Step 7260 | Loss: 1.099366 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 7260 took 0.0000s\n",
            "Step 7270 | Loss: 1.276936 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0061s, O: 0.0010s\n",
            "Batch 1020/3125 ( 32.6%) | Loss: 1.120563 | Accuracy: 60.65% | Batch time: 0.0418s\n",
            "Step 7280 | Loss: 0.859801 | GPU: 35.7MB / 134.0MB | F: 0.0048s, B: 0.0066s, O: 0.0011s\n",
            "🔄 Topology update at step 7280 took 0.0001s\n",
            "Step 7290 | Loss: 0.666055 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0041s, O: 0.0007s\n",
            "Batch 1040/3125 ( 33.3%) | Loss: 1.120650 | Accuracy: 60.66% | Batch time: 0.0287s\n",
            "Step 7300 | Loss: 1.557673 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0079s, O: 0.0009s\n",
            "🔄 Topology update at step 7300 took 0.0001s\n",
            "🧹 Memory cleanup at step 7300 took 0.2485s\n",
            "Step 7310 | Loss: 1.454308 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0088s, O: 0.0011s\n",
            "Batch 1060/3125 ( 33.9%) | Loss: 1.119714 | Accuracy: 60.71% | Batch time: 0.0359s\n",
            "Step 7320 | Loss: 1.053105 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0069s, O: 0.0009s\n",
            "🔄 Topology update at step 7320 took 0.0001s\n",
            "Step 7330 | Loss: 1.129173 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0057s, O: 0.0009s\n",
            "Batch 1080/3125 ( 34.6%) | Loss: 1.121089 | Accuracy: 60.63% | Batch time: 0.0331s\n",
            "Step 7340 | Loss: 0.851074 | GPU: 35.7MB / 134.0MB | F: 0.0045s, B: 0.0033s, O: 0.0010s\n",
            "🔄 Topology update at step 7340 took 0.0000s\n",
            "Step 7350 | Loss: 1.133260 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0084s, O: 0.0006s\n",
            "Batch 1100/3125 ( 35.2%) | Loss: 1.120468 | Accuracy: 60.63% | Batch time: 0.0434s\n",
            "Step 7360 | Loss: 0.799319 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0023s, O: 0.0008s\n",
            "🔄 Topology update at step 7360 took 0.0000s\n",
            "Step 7370 | Loss: 1.046007 | GPU: 35.7MB / 134.0MB | F: 0.0050s, B: 0.0043s, O: 0.0011s\n",
            "Batch 1120/3125 ( 35.8%) | Loss: 1.119397 | Accuracy: 60.66% | Batch time: 0.0316s\n",
            "Step 7380 | Loss: 1.266627 | GPU: 35.7MB / 134.0MB | F: 0.0044s, B: 0.0034s, O: 0.0010s\n",
            "🔄 Topology update at step 7380 took 0.0001s\n",
            "Step 7390 | Loss: 1.234856 | GPU: 35.7MB / 134.0MB | F: 0.0037s, B: 0.0033s, O: 0.0007s\n",
            "Batch 1140/3125 ( 36.5%) | Loss: 1.117586 | Accuracy: 60.72% | Batch time: 0.0394s\n",
            "Step 7400 | Loss: 0.585555 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0086s, O: 0.0011s\n",
            "🔄 Topology update at step 7400 took 0.0001s\n",
            "🧹 Memory cleanup at step 7400 took 0.2787s\n",
            "Step 7410 | Loss: 1.088124 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0117s, O: 0.0008s\n",
            "Batch 1160/3125 ( 37.1%) | Loss: 1.116448 | Accuracy: 60.77% | Batch time: 0.0455s\n",
            "Step 7420 | Loss: 1.203499 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0209s, O: 0.0009s\n",
            "🔄 Topology update at step 7420 took 0.0001s\n",
            "Step 7430 | Loss: 1.258228 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0037s, O: 0.0007s\n",
            "Batch 1180/3125 ( 37.8%) | Loss: 1.117337 | Accuracy: 60.71% | Batch time: 0.0268s\n",
            "Step 7440 | Loss: 1.403829 | GPU: 35.7MB / 134.0MB | F: 0.0056s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 7440 took 0.0001s\n",
            "Step 7450 | Loss: 1.487051 | GPU: 35.7MB / 134.0MB | F: 0.0034s, B: 0.0047s, O: 0.0010s\n",
            "Batch 1200/3125 ( 38.4%) | Loss: 1.117229 | Accuracy: 60.66% | Batch time: 0.0370s\n",
            "Step 7460 | Loss: 1.635391 | GPU: 35.7MB / 134.0MB | F: 0.0034s, B: 0.0060s, O: 0.0021s\n",
            "🔄 Topology update at step 7460 took 0.0001s\n",
            "Step 7470 | Loss: 0.880836 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0065s, O: 0.0007s\n",
            "Batch 1220/3125 ( 39.0%) | Loss: 1.116709 | Accuracy: 60.65% | Batch time: 0.0379s\n",
            "Step 7480 | Loss: 1.395942 | GPU: 35.7MB / 134.0MB | F: 0.0117s, B: 0.0031s, O: 0.0025s\n",
            "🔄 Topology update at step 7480 took 0.0001s\n",
            "Step 7490 | Loss: 1.323868 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0045s, O: 0.0009s\n",
            "Batch 1240/3125 ( 39.7%) | Loss: 1.116559 | Accuracy: 60.70% | Batch time: 0.0363s\n",
            "Step 7500 | Loss: 1.271427 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0030s, O: 0.0026s\n",
            "🔄 Topology update at step 7500 took 0.0001s\n",
            "🧹 Memory cleanup at step 7500 took 0.2373s\n",
            "Step 7510 | Loss: 1.019535 | GPU: 35.7MB / 134.0MB | F: 0.0065s, B: 0.0043s, O: 0.0020s\n",
            "Batch 1260/3125 ( 40.3%) | Loss: 1.116656 | Accuracy: 60.69% | Batch time: 0.0372s\n",
            "Step 7520 | Loss: 1.392678 | GPU: 35.7MB / 134.0MB | F: 0.0035s, B: 0.0105s, O: 0.0009s\n",
            "🔄 Topology update at step 7520 took 0.0000s\n",
            "Step 7530 | Loss: 0.925671 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0026s, O: 0.0008s\n",
            "Batch 1280/3125 ( 41.0%) | Loss: 1.114891 | Accuracy: 60.74% | Batch time: 0.0369s\n",
            "Step 7540 | Loss: 0.981152 | GPU: 35.7MB / 134.0MB | F: 0.0025s, B: 0.0067s, O: 0.0009s\n",
            "🔄 Topology update at step 7540 took 0.0001s\n",
            "Step 7550 | Loss: 1.418495 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0268s, O: 0.0009s\n",
            "Batch 1300/3125 ( 41.6%) | Loss: 1.115285 | Accuracy: 60.75% | Batch time: 0.0538s\n",
            "Step 7560 | Loss: 1.018064 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0088s, O: 0.0007s\n",
            "🔄 Topology update at step 7560 took 0.0000s\n",
            "Step 7570 | Loss: 0.763546 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0046s, O: 0.0006s\n",
            "Batch 1320/3125 ( 42.2%) | Loss: 1.113564 | Accuracy: 60.83% | Batch time: 0.0459s\n",
            "Step 7580 | Loss: 1.300133 | GPU: 35.7MB / 134.0MB | F: 0.0049s, B: 0.0098s, O: 0.0008s\n",
            "🔄 Topology update at step 7580 took 0.0000s\n",
            "Step 7590 | Loss: 0.920799 | GPU: 35.7MB / 134.0MB | F: 0.0089s, B: 0.0062s, O: 0.0013s\n",
            "Batch 1340/3125 ( 42.9%) | Loss: 1.114556 | Accuracy: 60.78% | Batch time: 0.0423s\n",
            "Step 7600 | Loss: 1.033177 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0050s, O: 0.0007s\n",
            "🔄 Topology update at step 7600 took 0.0001s\n",
            "🧹 Memory cleanup at step 7600 took 0.3827s\n",
            "Step 7610 | Loss: 1.238926 | GPU: 35.7MB / 134.0MB | F: 0.0078s, B: 0.0032s, O: 0.0031s\n",
            "Batch 1360/3125 ( 43.5%) | Loss: 1.116650 | Accuracy: 60.68% | Batch time: 0.0462s\n",
            "Step 7620 | Loss: 0.914377 | GPU: 35.7MB / 134.0MB | F: 0.0080s, B: 0.0032s, O: 0.0022s\n",
            "🔄 Topology update at step 7620 took 0.0011s\n",
            "Step 7630 | Loss: 0.652359 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0076s, O: 0.0012s\n",
            "Batch 1380/3125 ( 44.2%) | Loss: 1.116354 | Accuracy: 60.71% | Batch time: 0.0314s\n",
            "Step 7640 | Loss: 1.316322 | GPU: 35.7MB / 134.0MB | F: 0.0060s, B: 0.0028s, O: 0.0011s\n",
            "🔄 Topology update at step 7640 took 0.0001s\n",
            "Step 7650 | Loss: 1.402164 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0073s, O: 0.0027s\n",
            "Batch 1400/3125 ( 44.8%) | Loss: 1.117933 | Accuracy: 60.64% | Batch time: 0.0380s\n",
            "Step 7660 | Loss: 1.000238 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0060s, O: 0.0019s\n",
            "🔄 Topology update at step 7660 took 0.0001s\n",
            "Step 7670 | Loss: 1.038237 | GPU: 35.7MB / 134.0MB | F: 0.0039s, B: 0.0037s, O: 0.0008s\n",
            "Batch 1420/3125 ( 45.4%) | Loss: 1.119914 | Accuracy: 60.59% | Batch time: 0.0406s\n",
            "Step 7680 | Loss: 1.410225 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0046s, O: 0.0008s\n",
            "🔄 Topology update at step 7680 took 0.0001s\n",
            "Step 7690 | Loss: 1.058102 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0051s, O: 0.0008s\n",
            "Batch 1440/3125 ( 46.1%) | Loss: 1.120633 | Accuracy: 60.57% | Batch time: 0.0343s\n",
            "Step 7700 | Loss: 1.147839 | GPU: 35.7MB / 134.0MB | F: 0.0146s, B: 0.0037s, O: 0.0012s\n",
            "🔄 Topology update at step 7700 took 0.0001s\n",
            "🧹 Memory cleanup at step 7700 took 0.2949s\n",
            "Step 7710 | Loss: 1.053280 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0088s, O: 0.0032s\n",
            "Batch 1460/3125 ( 46.7%) | Loss: 1.121160 | Accuracy: 60.56% | Batch time: 0.0373s\n",
            "Step 7720 | Loss: 0.890977 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0034s, O: 0.0008s\n",
            "🔄 Topology update at step 7720 took 0.0000s\n",
            "Step 7730 | Loss: 1.228456 | GPU: 35.7MB / 134.0MB | F: 0.0052s, B: 0.0038s, O: 0.0011s\n",
            "Batch 1480/3125 ( 47.4%) | Loss: 1.120789 | Accuracy: 60.58% | Batch time: 0.0422s\n",
            "Step 7740 | Loss: 1.251765 | GPU: 35.7MB / 134.0MB | F: 0.0037s, B: 0.0031s, O: 0.0011s\n",
            "🔄 Topology update at step 7740 took 0.0001s\n",
            "Step 7750 | Loss: 0.747398 | GPU: 35.7MB / 134.0MB | F: 0.0081s, B: 0.0029s, O: 0.0008s\n",
            "Batch 1500/3125 ( 48.0%) | Loss: 1.120696 | Accuracy: 60.60% | Batch time: 0.0346s\n",
            "Step 7760 | Loss: 1.076691 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0041s, O: 0.0007s\n",
            "🔄 Topology update at step 7760 took 0.0001s\n",
            "Step 7770 | Loss: 1.523626 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0085s, O: 0.0013s\n",
            "Batch 1520/3125 ( 48.6%) | Loss: 1.119588 | Accuracy: 60.64% | Batch time: 0.0428s\n",
            "Step 7780 | Loss: 1.171368 | GPU: 35.7MB / 134.0MB | F: 0.0031s, B: 0.0068s, O: 0.0012s\n",
            "🔄 Topology update at step 7780 took 0.0006s\n",
            "Step 7790 | Loss: 1.160611 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0030s, O: 0.0008s\n",
            "Batch 1540/3125 ( 49.3%) | Loss: 1.118516 | Accuracy: 60.65% | Batch time: 0.0408s\n",
            "Step 7800 | Loss: 1.267386 | GPU: 35.7MB / 134.0MB | F: 0.0039s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 7800 took 0.0000s\n",
            "🧹 Memory cleanup at step 7800 took 0.2871s\n",
            "Step 7810 | Loss: 1.280356 | GPU: 35.7MB / 134.0MB | F: 0.0094s, B: 0.0100s, O: 0.0014s\n",
            "Batch 1560/3125 ( 49.9%) | Loss: 1.116977 | Accuracy: 60.70% | Batch time: 0.0355s\n",
            "Step 7820 | Loss: 1.029936 | GPU: 35.7MB / 134.0MB | F: 0.0139s, B: 0.0083s, O: 0.0009s\n",
            "🔄 Topology update at step 7820 took 0.0000s\n",
            "Step 7830 | Loss: 1.013111 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0084s, O: 0.0010s\n",
            "Batch 1580/3125 ( 50.6%) | Loss: 1.118278 | Accuracy: 60.66% | Batch time: 0.0440s\n",
            "Step 7840 | Loss: 1.151833 | GPU: 35.7MB / 134.0MB | F: 0.0115s, B: 0.0037s, O: 0.0012s\n",
            "🔄 Topology update at step 7840 took 0.0001s\n",
            "Step 7850 | Loss: 1.271344 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0028s, O: 0.0008s\n",
            "Batch 1600/3125 ( 51.2%) | Loss: 1.118147 | Accuracy: 60.65% | Batch time: 0.0504s\n",
            "Step 7860 | Loss: 0.955211 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0023s, O: 0.0008s\n",
            "🔄 Topology update at step 7860 took 0.0001s\n",
            "Step 7870 | Loss: 1.190672 | GPU: 35.7MB / 134.0MB | F: 0.0050s, B: 0.0039s, O: 0.0013s\n",
            "Batch 1620/3125 ( 51.8%) | Loss: 1.118445 | Accuracy: 60.62% | Batch time: 0.0419s\n",
            "Step 7880 | Loss: 0.513632 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0034s, O: 0.0012s\n",
            "🔄 Topology update at step 7880 took 0.0001s\n",
            "Step 7890 | Loss: 0.884257 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0038s, O: 0.0024s\n",
            "Batch 1640/3125 ( 52.5%) | Loss: 1.118835 | Accuracy: 60.58% | Batch time: 0.0460s\n",
            "Step 7900 | Loss: 0.960103 | GPU: 35.7MB / 134.0MB | F: 0.0038s, B: 0.0028s, O: 0.0009s\n",
            "🔄 Topology update at step 7900 took 0.0000s\n",
            "🧹 Memory cleanup at step 7900 took 0.2574s\n",
            "Step 7910 | Loss: 1.315768 | GPU: 35.7MB / 134.0MB | F: 0.0163s, B: 0.0053s, O: 0.0012s\n",
            "Batch 1660/3125 ( 53.1%) | Loss: 1.118980 | Accuracy: 60.57% | Batch time: 0.0372s\n",
            "Step 7920 | Loss: 1.198705 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0105s, O: 0.0023s\n",
            "🔄 Topology update at step 7920 took 0.0001s\n",
            "Step 7930 | Loss: 0.562740 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0049s, O: 0.0021s\n",
            "Batch 1680/3125 ( 53.8%) | Loss: 1.118128 | Accuracy: 60.63% | Batch time: 0.0448s\n",
            "Step 7940 | Loss: 0.814084 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0031s, O: 0.0009s\n",
            "🔄 Topology update at step 7940 took 0.0001s\n",
            "Step 7950 | Loss: 1.414246 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1700/3125 ( 54.4%) | Loss: 1.117699 | Accuracy: 60.66% | Batch time: 0.0454s\n",
            "Step 7960 | Loss: 1.063602 | GPU: 35.7MB / 134.0MB | F: 0.0035s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 7960 took 0.0001s\n",
            "Step 7970 | Loss: 1.462846 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0035s, O: 0.0009s\n",
            "Batch 1720/3125 ( 55.0%) | Loss: 1.116718 | Accuracy: 60.67% | Batch time: 0.0320s\n",
            "Step 7980 | Loss: 1.564331 | GPU: 35.7MB / 134.0MB | F: 0.0024s, B: 0.0033s, O: 0.0037s\n",
            "🔄 Topology update at step 7980 took 0.0000s\n",
            "Step 7990 | Loss: 0.914482 | GPU: 35.7MB / 134.0MB | F: 0.0220s, B: 0.0083s, O: 0.0014s\n",
            "Batch 1740/3125 ( 55.7%) | Loss: 1.117853 | Accuracy: 60.61% | Batch time: 0.0507s\n",
            "Step 8000 | Loss: 0.833312 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0070s, O: 0.0012s\n",
            "🔄 Topology update at step 8000 took 0.0027s\n",
            "🧹 Memory cleanup at step 8000 took 0.2795s\n",
            "Step 8010 | Loss: 1.019679 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0171s, O: 0.0011s\n",
            "Batch 1760/3125 ( 56.3%) | Loss: 1.117778 | Accuracy: 60.60% | Batch time: 0.0463s\n",
            "Step 8020 | Loss: 1.387595 | GPU: 35.7MB / 134.0MB | F: 0.0048s, B: 0.0043s, O: 0.0006s\n",
            "🔄 Topology update at step 8020 took 0.0000s\n",
            "Step 8030 | Loss: 1.160215 | GPU: 35.7MB / 134.0MB | F: 0.0076s, B: 0.0069s, O: 0.0012s\n",
            "Batch 1780/3125 ( 57.0%) | Loss: 1.117383 | Accuracy: 60.61% | Batch time: 0.0906s\n",
            "Step 8040 | Loss: 0.964081 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0144s, O: 0.0008s\n",
            "🔄 Topology update at step 8040 took 0.0000s\n",
            "Step 8050 | Loss: 1.634377 | GPU: 35.7MB / 134.0MB | F: 0.0085s, B: 0.0031s, O: 0.0006s\n",
            "Batch 1800/3125 ( 57.6%) | Loss: 1.118254 | Accuracy: 60.58% | Batch time: 0.0553s\n",
            "Step 8060 | Loss: 0.825053 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0056s, O: 0.0007s\n",
            "🔄 Topology update at step 8060 took 0.0000s\n",
            "Step 8070 | Loss: 0.661393 | GPU: 35.7MB / 134.0MB | F: 0.0036s, B: 0.0046s, O: 0.0006s\n",
            "Batch 1820/3125 ( 58.2%) | Loss: 1.117972 | Accuracy: 60.60% | Batch time: 0.0499s\n",
            "Step 8080 | Loss: 0.993734 | GPU: 35.7MB / 134.0MB | F: 0.0092s, B: 0.0050s, O: 0.0008s\n",
            "🔄 Topology update at step 8080 took 0.0001s\n",
            "Step 8090 | Loss: 1.823411 | GPU: 35.7MB / 134.0MB | F: 0.0014s, B: 0.0257s, O: 0.0008s\n",
            "Batch 1840/3125 ( 58.9%) | Loss: 1.119511 | Accuracy: 60.61% | Batch time: 0.0712s\n",
            "Step 8100 | Loss: 0.964983 | GPU: 35.7MB / 134.0MB | F: 0.0063s, B: 0.0038s, O: 0.0008s\n",
            "🔄 Topology update at step 8100 took 0.0000s\n",
            "🧹 Memory cleanup at step 8100 took 0.4289s\n",
            "Step 8110 | Loss: 1.058436 | GPU: 35.7MB / 134.0MB | F: 0.0103s, B: 0.0064s, O: 0.0012s\n",
            "Batch 1860/3125 ( 59.5%) | Loss: 1.119083 | Accuracy: 60.62% | Batch time: 0.0477s\n",
            "Step 8120 | Loss: 1.212324 | GPU: 35.7MB / 134.0MB | F: 0.0030s, B: 0.0035s, O: 0.0009s\n",
            "🔄 Topology update at step 8120 took 0.0001s\n",
            "Step 8130 | Loss: 1.042474 | GPU: 35.7MB / 134.0MB | F: 0.0065s, B: 0.0037s, O: 0.0011s\n",
            "Batch 1880/3125 ( 60.2%) | Loss: 1.117781 | Accuracy: 60.65% | Batch time: 0.0407s\n",
            "Step 8140 | Loss: 1.013072 | GPU: 35.7MB / 134.0MB | F: 0.0048s, B: 0.0035s, O: 0.0011s\n",
            "🔄 Topology update at step 8140 took 0.0001s\n",
            "Step 8150 | Loss: 1.157813 | GPU: 35.7MB / 134.0MB | F: 0.0054s, B: 0.0028s, O: 0.0063s\n",
            "Batch 1900/3125 ( 60.8%) | Loss: 1.118697 | Accuracy: 60.61% | Batch time: 0.0403s\n",
            "Step 8160 | Loss: 1.098150 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0033s, O: 0.0008s\n",
            "🔄 Topology update at step 8160 took 0.0000s\n",
            "Step 8170 | Loss: 0.681697 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0058s, O: 0.0010s\n",
            "Batch 1920/3125 ( 61.4%) | Loss: 1.117911 | Accuracy: 60.63% | Batch time: 0.0387s\n",
            "Step 8180 | Loss: 1.190637 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0052s, O: 0.0011s\n",
            "🔄 Topology update at step 8180 took 0.0001s\n",
            "Step 8190 | Loss: 0.775087 | GPU: 35.7MB / 134.0MB | F: 0.0042s, B: 0.0035s, O: 0.0012s\n",
            "Batch 1940/3125 ( 62.1%) | Loss: 1.117411 | Accuracy: 60.68% | Batch time: 0.0370s\n",
            "Step 8200 | Loss: 0.884886 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0032s, O: 0.0008s\n",
            "🔄 Topology update at step 8200 took 0.0000s\n",
            "🧹 Memory cleanup at step 8200 took 0.2987s\n",
            "Step 8210 | Loss: 0.984015 | GPU: 35.7MB / 134.0MB | F: 0.0092s, B: 0.0024s, O: 0.0007s\n",
            "Batch 1960/3125 ( 62.7%) | Loss: 1.117327 | Accuracy: 60.69% | Batch time: 0.0363s\n",
            "Step 8220 | Loss: 1.027805 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0120s, O: 0.0012s\n",
            "🔄 Topology update at step 8220 took 0.0001s\n",
            "Step 8230 | Loss: 1.286148 | GPU: 35.7MB / 134.0MB | F: 0.0154s, B: 0.0038s, O: 0.0013s\n",
            "Batch 1980/3125 ( 63.4%) | Loss: 1.118074 | Accuracy: 60.65% | Batch time: 0.0386s\n",
            "Step 8240 | Loss: 0.929819 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0095s, O: 0.0012s\n",
            "🔄 Topology update at step 8240 took 0.0001s\n",
            "Step 8250 | Loss: 1.090870 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0059s, O: 0.0012s\n",
            "Batch 2000/3125 ( 64.0%) | Loss: 1.116811 | Accuracy: 60.68% | Batch time: 0.0379s\n",
            "Step 8260 | Loss: 0.814065 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0055s, O: 0.0012s\n",
            "🔄 Topology update at step 8260 took 0.0001s\n",
            "Step 8270 | Loss: 1.099509 | GPU: 35.7MB / 134.0MB | F: 0.0039s, B: 0.0094s, O: 0.0009s\n",
            "Batch 2020/3125 ( 64.6%) | Loss: 1.115766 | Accuracy: 60.70% | Batch time: 0.0305s\n",
            "Step 8280 | Loss: 1.472137 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0029s, O: 0.0009s\n",
            "🔄 Topology update at step 8280 took 0.0001s\n",
            "Step 8290 | Loss: 0.510961 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0087s, O: 0.0009s\n",
            "Batch 2040/3125 ( 65.3%) | Loss: 1.115282 | Accuracy: 60.72% | Batch time: 0.0445s\n",
            "Step 8300 | Loss: 0.587142 | GPU: 35.7MB / 134.0MB | F: 0.0026s, B: 0.0050s, O: 0.0008s\n",
            "🔄 Topology update at step 8300 took 0.0001s\n",
            "🧹 Memory cleanup at step 8300 took 0.2933s\n",
            "Step 8310 | Loss: 1.150842 | GPU: 35.7MB / 134.0MB | F: 0.0068s, B: 0.0029s, O: 0.0007s\n",
            "Batch 2060/3125 ( 65.9%) | Loss: 1.116294 | Accuracy: 60.67% | Batch time: 0.0432s\n",
            "Step 8320 | Loss: 1.356393 | GPU: 35.7MB / 134.0MB | F: 0.0069s, B: 0.0038s, O: 0.0012s\n",
            "🔄 Topology update at step 8320 took 0.0001s\n",
            "Step 8330 | Loss: 0.870486 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0048s, O: 0.0011s\n",
            "Batch 2080/3125 ( 66.6%) | Loss: 1.116060 | Accuracy: 60.69% | Batch time: 0.0377s\n",
            "Step 8340 | Loss: 1.035203 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0026s, O: 0.0025s\n",
            "🔄 Topology update at step 8340 took 0.0001s\n",
            "Step 8350 | Loss: 0.956180 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0026s, O: 0.0008s\n",
            "Batch 2100/3125 ( 67.2%) | Loss: 1.116098 | Accuracy: 60.70% | Batch time: 0.0455s\n",
            "Step 8360 | Loss: 0.952963 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 8360 took 0.0001s\n",
            "Step 8370 | Loss: 1.692907 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0082s, O: 0.0014s\n",
            "Batch 2120/3125 ( 67.8%) | Loss: 1.116578 | Accuracy: 60.67% | Batch time: 0.0384s\n",
            "Step 8380 | Loss: 1.132793 | GPU: 35.7MB / 134.0MB | F: 0.0045s, B: 0.0117s, O: 0.0014s\n",
            "🔄 Topology update at step 8380 took 0.0001s\n",
            "Step 8390 | Loss: 1.061099 | GPU: 35.7MB / 134.0MB | F: 0.0074s, B: 0.0039s, O: 0.0012s\n",
            "Batch 2140/3125 ( 68.5%) | Loss: 1.116484 | Accuracy: 60.66% | Batch time: 0.0464s\n",
            "Step 8400 | Loss: 0.808546 | GPU: 35.7MB / 134.0MB | F: 0.0045s, B: 0.0035s, O: 0.0011s\n",
            "🔄 Topology update at step 8400 took 0.0001s\n",
            "🧹 Memory cleanup at step 8400 took 0.2731s\n",
            "Step 8410 | Loss: 1.039893 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0064s, O: 0.0008s\n",
            "Batch 2160/3125 ( 69.1%) | Loss: 1.115928 | Accuracy: 60.68% | Batch time: 0.0440s\n",
            "Step 8420 | Loss: 0.934936 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0070s, O: 0.0008s\n",
            "🔄 Topology update at step 8420 took 0.0001s\n",
            "Step 8430 | Loss: 1.365997 | GPU: 35.7MB / 134.0MB | F: 0.0046s, B: 0.0025s, O: 0.0008s\n",
            "Batch 2180/3125 ( 69.8%) | Loss: 1.116172 | Accuracy: 60.64% | Batch time: 0.0303s\n",
            "Step 8440 | Loss: 0.946655 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0069s, O: 0.0012s\n",
            "🔄 Topology update at step 8440 took 0.0001s\n",
            "Step 8450 | Loss: 0.781076 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0025s, O: 0.0008s\n",
            "Batch 2200/3125 ( 70.4%) | Loss: 1.115693 | Accuracy: 60.70% | Batch time: 0.0435s\n",
            "Step 8460 | Loss: 1.421082 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 8460 took 0.0001s\n",
            "Step 8470 | Loss: 1.325470 | GPU: 35.7MB / 134.0MB | F: 0.0039s, B: 0.0026s, O: 0.0007s\n",
            "Batch 2220/3125 ( 71.0%) | Loss: 1.114662 | Accuracy: 60.75% | Batch time: 0.0430s\n",
            "Step 8480 | Loss: 1.146057 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0050s, O: 0.0011s\n",
            "🔄 Topology update at step 8480 took 0.0001s\n",
            "Step 8490 | Loss: 1.039028 | GPU: 35.7MB / 134.0MB | F: 0.0045s, B: 0.0036s, O: 0.0011s\n",
            "Batch 2240/3125 ( 71.7%) | Loss: 1.114898 | Accuracy: 60.71% | Batch time: 0.0431s\n",
            "Step 8500 | Loss: 1.443432 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0025s, O: 0.0023s\n",
            "🔄 Topology update at step 8500 took 0.0000s\n",
            "🧹 Memory cleanup at step 8500 took 0.2835s\n",
            "Step 8510 | Loss: 1.202183 | GPU: 35.7MB / 134.0MB | F: 0.0070s, B: 0.0097s, O: 0.0025s\n",
            "Batch 2260/3125 ( 72.3%) | Loss: 1.114888 | Accuracy: 60.70% | Batch time: 0.0412s\n",
            "Step 8520 | Loss: 0.949775 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0105s, O: 0.0009s\n",
            "🔄 Topology update at step 8520 took 0.0000s\n",
            "Step 8530 | Loss: 0.589180 | GPU: 35.7MB / 134.0MB | F: 0.0014s, B: 0.0050s, O: 0.0006s\n",
            "Batch 2280/3125 ( 73.0%) | Loss: 1.113991 | Accuracy: 60.72% | Batch time: 0.0660s\n",
            "Step 8540 | Loss: 1.068600 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 8540 took 0.0052s\n",
            "Step 8550 | Loss: 0.915966 | GPU: 35.7MB / 134.0MB | F: 0.0055s, B: 0.0052s, O: 0.0017s\n",
            "Batch 2300/3125 ( 73.6%) | Loss: 1.113275 | Accuracy: 60.72% | Batch time: 0.0521s\n",
            "Step 8560 | Loss: 0.774529 | GPU: 35.7MB / 134.0MB | F: 0.0033s, B: 0.0109s, O: 0.0007s\n",
            "🔄 Topology update at step 8560 took 0.0000s\n",
            "Step 8570 | Loss: 0.916871 | GPU: 35.7MB / 134.0MB | F: 0.0117s, B: 0.0075s, O: 0.0008s\n",
            "Batch 2320/3125 ( 74.2%) | Loss: 1.113692 | Accuracy: 60.70% | Batch time: 0.0611s\n",
            "Step 8580 | Loss: 0.422470 | GPU: 35.7MB / 134.0MB | F: 0.0079s, B: 0.0080s, O: 0.0009s\n",
            "🔄 Topology update at step 8580 took 0.0000s\n",
            "Step 8590 | Loss: 1.703911 | GPU: 35.7MB / 134.0MB | F: 0.0077s, B: 0.0025s, O: 0.0010s\n",
            "Batch 2340/3125 ( 74.9%) | Loss: 1.113885 | Accuracy: 60.72% | Batch time: 0.0445s\n",
            "Step 8600 | Loss: 0.752144 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0029s, O: 0.0006s\n",
            "🔄 Topology update at step 8600 took 0.0000s\n",
            "🧹 Memory cleanup at step 8600 took 0.4857s\n",
            "Step 8610 | Loss: 1.289334 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0056s, O: 0.0019s\n",
            "Batch 2360/3125 ( 75.5%) | Loss: 1.113998 | Accuracy: 60.72% | Batch time: 0.0440s\n",
            "Step 8620 | Loss: 0.963021 | GPU: 35.7MB / 134.0MB | F: 0.0017s, B: 0.0021s, O: 0.0009s\n",
            "🔄 Topology update at step 8620 took 0.0001s\n",
            "Step 8630 | Loss: 1.215403 | GPU: 35.7MB / 134.0MB | F: 0.0043s, B: 0.0029s, O: 0.0011s\n",
            "Batch 2380/3125 ( 76.2%) | Loss: 1.113829 | Accuracy: 60.73% | Batch time: 0.0363s\n",
            "Step 8640 | Loss: 1.147653 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 8640 took 0.0001s\n",
            "Step 8650 | Loss: 1.372192 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0024s, O: 0.0007s\n",
            "Batch 2400/3125 ( 76.8%) | Loss: 1.113031 | Accuracy: 60.78% | Batch time: 0.0416s\n",
            "Step 8660 | Loss: 1.073727 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 8660 took 0.0001s\n",
            "Step 8670 | Loss: 0.838372 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0042s, O: 0.0011s\n",
            "Batch 2420/3125 ( 77.4%) | Loss: 1.112742 | Accuracy: 60.78% | Batch time: 0.0441s\n",
            "Step 8680 | Loss: 1.153873 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0098s, O: 0.0009s\n",
            "🔄 Topology update at step 8680 took 0.0001s\n",
            "Step 8690 | Loss: 0.899125 | GPU: 35.7MB / 134.0MB | F: 0.0106s, B: 0.0023s, O: 0.0010s\n",
            "Batch 2440/3125 ( 78.1%) | Loss: 1.113416 | Accuracy: 60.78% | Batch time: 0.0375s\n",
            "Step 8700 | Loss: 0.934618 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 8700 took 0.0000s\n",
            "🧹 Memory cleanup at step 8700 took 0.2764s\n",
            "Step 8710 | Loss: 1.070116 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0055s, O: 0.0011s\n",
            "Batch 2460/3125 ( 78.7%) | Loss: 1.113130 | Accuracy: 60.78% | Batch time: 0.0419s\n",
            "Step 8720 | Loss: 0.887006 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0032s, O: 0.0010s\n",
            "🔄 Topology update at step 8720 took 0.0001s\n",
            "Step 8730 | Loss: 1.496430 | GPU: 35.7MB / 134.0MB | F: 0.0076s, B: 0.0029s, O: 0.0009s\n",
            "Batch 2480/3125 ( 79.4%) | Loss: 1.111330 | Accuracy: 60.85% | Batch time: 0.0471s\n",
            "Step 8740 | Loss: 1.065443 | GPU: 35.7MB / 134.0MB | F: 0.0060s, B: 0.0038s, O: 0.0013s\n",
            "🔄 Topology update at step 8740 took 0.0001s\n",
            "Step 8750 | Loss: 1.245074 | GPU: 35.7MB / 134.0MB | F: 0.0051s, B: 0.0026s, O: 0.0008s\n",
            "Batch 2500/3125 ( 80.0%) | Loss: 1.110494 | Accuracy: 60.86% | Batch time: 0.0351s\n",
            "Step 8760 | Loss: 0.612727 | GPU: 35.7MB / 134.0MB | F: 0.0054s, B: 0.0040s, O: 0.0009s\n",
            "🔄 Topology update at step 8760 took 0.0001s\n",
            "Step 8770 | Loss: 0.760392 | GPU: 35.7MB / 134.0MB | F: 0.0046s, B: 0.0058s, O: 0.0012s\n",
            "Batch 2520/3125 ( 80.6%) | Loss: 1.110079 | Accuracy: 60.88% | Batch time: 0.0348s\n",
            "Step 8780 | Loss: 0.844658 | GPU: 35.7MB / 134.0MB | F: 0.0038s, B: 0.0049s, O: 0.0009s\n",
            "🔄 Topology update at step 8780 took 0.0001s\n",
            "Step 8790 | Loss: 1.431618 | GPU: 35.7MB / 134.0MB | F: 0.0083s, B: 0.0086s, O: 0.0012s\n",
            "Batch 2540/3125 ( 81.3%) | Loss: 1.110201 | Accuracy: 60.87% | Batch time: 0.0356s\n",
            "Step 8800 | Loss: 0.451948 | GPU: 35.7MB / 134.0MB | F: 0.0078s, B: 0.0040s, O: 0.0012s\n",
            "🔄 Topology update at step 8800 took 0.0001s\n",
            "🧹 Memory cleanup at step 8800 took 0.2921s\n",
            "Step 8810 | Loss: 1.328758 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0074s, O: 0.0012s\n",
            "Batch 2560/3125 ( 81.9%) | Loss: 1.110081 | Accuracy: 60.86% | Batch time: 0.0358s\n",
            "Step 8820 | Loss: 1.204418 | GPU: 35.7MB / 134.0MB | F: 0.0120s, B: 0.0067s, O: 0.0015s\n",
            "🔄 Topology update at step 8820 took 0.0001s\n",
            "Step 8830 | Loss: 1.077617 | GPU: 35.7MB / 134.0MB | F: 0.0062s, B: 0.0027s, O: 0.0008s\n",
            "Batch 2580/3125 ( 82.6%) | Loss: 1.109593 | Accuracy: 60.88% | Batch time: 0.0330s\n",
            "Step 8840 | Loss: 1.331436 | GPU: 35.7MB / 134.0MB | F: 0.0043s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 8840 took 0.0001s\n",
            "Step 8850 | Loss: 1.397508 | GPU: 35.7MB / 134.0MB | F: 0.0031s, B: 0.0069s, O: 0.0012s\n",
            "Batch 2600/3125 ( 83.2%) | Loss: 1.109346 | Accuracy: 60.90% | Batch time: 0.0344s\n",
            "Step 8860 | Loss: 0.648233 | GPU: 35.7MB / 134.0MB | F: 0.0060s, B: 0.0069s, O: 0.0011s\n",
            "🔄 Topology update at step 8860 took 0.0001s\n",
            "Step 8870 | Loss: 0.975393 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0084s, O: 0.0009s\n",
            "Batch 2620/3125 ( 83.8%) | Loss: 1.109224 | Accuracy: 60.88% | Batch time: 0.0358s\n",
            "Step 8880 | Loss: 1.042175 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0043s, O: 0.0025s\n",
            "🔄 Topology update at step 8880 took 0.0001s\n",
            "Step 8890 | Loss: 1.378519 | GPU: 35.7MB / 134.0MB | F: 0.0081s, B: 0.0084s, O: 0.0012s\n",
            "Batch 2640/3125 ( 84.5%) | Loss: 1.109312 | Accuracy: 60.89% | Batch time: 0.0426s\n",
            "Step 8900 | Loss: 0.827615 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0039s, O: 0.0069s\n",
            "🔄 Topology update at step 8900 took 0.0011s\n",
            "🧹 Memory cleanup at step 8900 took 0.2738s\n",
            "Step 8910 | Loss: 2.193246 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "Batch 2660/3125 ( 85.1%) | Loss: 1.109429 | Accuracy: 60.89% | Batch time: 0.0478s\n",
            "Step 8920 | Loss: 0.801409 | GPU: 35.7MB / 134.0MB | F: 0.0018s, B: 0.0026s, O: 0.0062s\n",
            "🔄 Topology update at step 8920 took 0.0001s\n",
            "Step 8930 | Loss: 0.929264 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0028s, O: 0.0008s\n",
            "Batch 2680/3125 ( 85.8%) | Loss: 1.109797 | Accuracy: 60.87% | Batch time: 0.0492s\n",
            "Step 8940 | Loss: 1.492276 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 8940 took 0.0001s\n",
            "Step 8950 | Loss: 1.216070 | GPU: 35.7MB / 134.0MB | F: 0.0016s, B: 0.0021s, O: 0.0009s\n",
            "Batch 2700/3125 ( 86.4%) | Loss: 1.109853 | Accuracy: 60.88% | Batch time: 0.0402s\n",
            "Step 8960 | Loss: 1.147566 | GPU: 35.7MB / 134.0MB | F: 0.0039s, B: 0.0114s, O: 0.0012s\n",
            "🔄 Topology update at step 8960 took 0.0001s\n",
            "Step 8970 | Loss: 1.339856 | GPU: 35.7MB / 134.0MB | F: 0.0099s, B: 0.0046s, O: 0.0028s\n",
            "Batch 2720/3125 ( 87.0%) | Loss: 1.109945 | Accuracy: 60.87% | Batch time: 0.0390s\n",
            "Step 8980 | Loss: 0.896783 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0034s, O: 0.0008s\n",
            "🔄 Topology update at step 8980 took 0.0000s\n",
            "Step 8990 | Loss: 1.036517 | GPU: 35.7MB / 134.0MB | F: 0.0041s, B: 0.0025s, O: 0.0008s\n",
            "Batch 2740/3125 ( 87.7%) | Loss: 1.108661 | Accuracy: 60.93% | Batch time: 0.0294s\n",
            "Step 9000 | Loss: 1.513042 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0169s, O: 0.0010s\n",
            "🔄 Topology update at step 9000 took 0.0012s\n",
            "🧹 Memory cleanup at step 9000 took 0.2878s\n",
            "Step 9010 | Loss: 0.527673 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0032s, O: 0.0011s\n",
            "Batch 2760/3125 ( 88.3%) | Loss: 1.108167 | Accuracy: 60.94% | Batch time: 0.0349s\n",
            "Step 9020 | Loss: 1.216091 | GPU: 35.7MB / 134.0MB | F: 0.0053s, B: 0.0037s, O: 0.0011s\n",
            "🔄 Topology update at step 9020 took 0.0001s\n",
            "Step 9030 | Loss: 1.112406 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0202s, O: 0.0009s\n",
            "Batch 2780/3125 ( 89.0%) | Loss: 1.107722 | Accuracy: 60.93% | Batch time: 0.0587s\n",
            "Step 9040 | Loss: 1.320449 | GPU: 35.7MB / 134.0MB | F: 0.0015s, B: 0.0056s, O: 0.0007s\n",
            "🔄 Topology update at step 9040 took 0.0095s\n",
            "Step 9050 | Loss: 0.752631 | GPU: 35.7MB / 134.0MB | F: 0.0013s, B: 0.0018s, O: 0.0006s\n",
            "Batch 2800/3125 ( 89.6%) | Loss: 1.107047 | Accuracy: 60.95% | Batch time: 0.0416s\n",
            "Step 9060 | Loss: 1.304535 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 9060 took 0.0001s\n",
            "Step 9070 | Loss: 1.534405 | GPU: 35.7MB / 134.0MB | F: 0.0014s, B: 0.0099s, O: 0.0006s\n",
            "Batch 2820/3125 ( 90.2%) | Loss: 1.107906 | Accuracy: 60.93% | Batch time: 0.0459s\n",
            "Step 9080 | Loss: 0.744099 | GPU: 35.7MB / 134.0MB | F: 0.0048s, B: 0.0177s, O: 0.0012s\n",
            "🔄 Topology update at step 9080 took 0.0000s\n",
            "Step 9090 | Loss: 1.044153 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0029s, O: 0.0006s\n",
            "Batch 2840/3125 ( 90.9%) | Loss: 1.106917 | Accuracy: 60.99% | Batch time: 0.0517s\n",
            "Step 9100 | Loss: 1.101671 | GPU: 35.7MB / 134.0MB | F: 0.0043s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 9100 took 0.0001s\n",
            "🧹 Memory cleanup at step 9100 took 0.3422s\n",
            "Step 9110 | Loss: 0.789210 | GPU: 35.7MB / 134.0MB | F: 0.0034s, B: 0.0021s, O: 0.0009s\n",
            "Batch 2860/3125 ( 91.5%) | Loss: 1.107023 | Accuracy: 60.98% | Batch time: 0.0541s\n",
            "Step 9120 | Loss: 1.013125 | GPU: 35.7MB / 134.0MB | F: 0.0157s, B: 0.0144s, O: 0.0010s\n",
            "🔄 Topology update at step 9120 took 0.0000s\n",
            "Step 9130 | Loss: 1.793970 | GPU: 35.7MB / 134.0MB | F: 0.0223s, B: 0.0116s, O: 0.0008s\n",
            "Batch 2880/3125 ( 92.2%) | Loss: 1.107140 | Accuracy: 60.97% | Batch time: 0.0433s\n",
            "Step 9140 | Loss: 0.943901 | GPU: 35.7MB / 134.0MB | F: 0.0074s, B: 0.0038s, O: 0.0009s\n",
            "🔄 Topology update at step 9140 took 0.0001s\n",
            "Step 9150 | Loss: 1.433926 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0075s, O: 0.0009s\n",
            "Batch 2900/3125 ( 92.8%) | Loss: 1.106909 | Accuracy: 60.96% | Batch time: 0.0372s\n",
            "Step 9160 | Loss: 0.716717 | GPU: 35.7MB / 134.0MB | F: 0.0020s, B: 0.0042s, O: 0.0008s\n",
            "🔄 Topology update at step 9160 took 0.0000s\n",
            "Step 9170 | Loss: 0.799223 | GPU: 35.7MB / 134.0MB | F: 0.0023s, B: 0.0053s, O: 0.0033s\n",
            "Batch 2920/3125 ( 93.4%) | Loss: 1.106094 | Accuracy: 60.99% | Batch time: 0.0353s\n",
            "Step 9180 | Loss: 1.156758 | GPU: 35.7MB / 134.0MB | F: 0.0031s, B: 0.0066s, O: 0.0012s\n",
            "🔄 Topology update at step 9180 took 0.0001s\n",
            "Step 9190 | Loss: 0.892770 | GPU: 35.7MB / 134.0MB | F: 0.0105s, B: 0.0037s, O: 0.0012s\n",
            "Batch 2940/3125 ( 94.1%) | Loss: 1.105078 | Accuracy: 61.00% | Batch time: 0.0359s\n",
            "Step 9200 | Loss: 1.162912 | GPU: 35.7MB / 134.0MB | F: 0.0031s, B: 0.0046s, O: 0.0027s\n",
            "🔄 Topology update at step 9200 took 0.0001s\n",
            "🧹 Memory cleanup at step 9200 took 0.2965s\n",
            "Step 9210 | Loss: 1.388156 | GPU: 35.7MB / 134.0MB | F: 0.0130s, B: 0.0037s, O: 0.0010s\n",
            "Batch 2960/3125 ( 94.7%) | Loss: 1.104641 | Accuracy: 61.01% | Batch time: 0.0387s\n",
            "Step 9220 | Loss: 1.474115 | GPU: 35.7MB / 134.0MB | F: 0.0031s, B: 0.0079s, O: 0.0027s\n",
            "🔄 Topology update at step 9220 took 0.0001s\n",
            "Step 9230 | Loss: 1.202112 | GPU: 35.7MB / 134.0MB | F: 0.0046s, B: 0.0026s, O: 0.0008s\n",
            "Batch 2980/3125 ( 95.4%) | Loss: 1.104236 | Accuracy: 61.02% | Batch time: 0.0404s\n",
            "Step 9240 | Loss: 0.918962 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0071s, O: 0.0012s\n",
            "🔄 Topology update at step 9240 took 0.0001s\n",
            "Step 9250 | Loss: 1.156441 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0040s, O: 0.0008s\n",
            "Batch 3000/3125 ( 96.0%) | Loss: 1.104327 | Accuracy: 61.00% | Batch time: 0.0391s\n",
            "Step 9260 | Loss: 1.360992 | GPU: 35.7MB / 134.0MB | F: 0.0021s, B: 0.0121s, O: 0.0013s\n",
            "🔄 Topology update at step 9260 took 0.0001s\n",
            "Step 9270 | Loss: 1.296137 | GPU: 35.7MB / 134.0MB | F: 0.0067s, B: 0.0040s, O: 0.0012s\n",
            "Batch 3020/3125 ( 96.6%) | Loss: 1.104263 | Accuracy: 61.00% | Batch time: 0.0482s\n",
            "Step 9280 | Loss: 0.564981 | GPU: 35.7MB / 134.0MB | F: 0.0032s, B: 0.0060s, O: 0.0027s\n",
            "🔄 Topology update at step 9280 took 0.0001s\n",
            "Step 9290 | Loss: 0.703852 | GPU: 35.7MB / 134.0MB | F: 0.0069s, B: 0.0039s, O: 0.0009s\n",
            "Batch 3040/3125 ( 97.3%) | Loss: 1.104010 | Accuracy: 61.02% | Batch time: 0.0356s\n",
            "Step 9300 | Loss: 1.747347 | GPU: 35.7MB / 134.0MB | F: 0.0022s, B: 0.0062s, O: 0.0023s\n",
            "🔄 Topology update at step 9300 took 0.0011s\n",
            "🧹 Memory cleanup at step 9300 took 0.2439s\n",
            "Step 9310 | Loss: 1.140873 | GPU: 35.7MB / 134.0MB | F: 0.0028s, B: 0.0060s, O: 0.0025s\n",
            "Batch 3060/3125 ( 97.9%) | Loss: 1.104427 | Accuracy: 60.99% | Batch time: 0.0365s\n",
            "Step 9320 | Loss: 1.252947 | GPU: 35.7MB / 134.0MB | F: 0.0029s, B: 0.0068s, O: 0.0030s\n",
            "🔄 Topology update at step 9320 took 0.0001s\n",
            "Step 9330 | Loss: 1.226960 | GPU: 35.7MB / 134.0MB | F: 0.0027s, B: 0.0029s, O: 0.0008s\n",
            "Batch 3080/3125 ( 98.6%) | Loss: 1.104200 | Accuracy: 60.98% | Batch time: 0.0454s\n",
            "Step 9340 | Loss: 0.914371 | GPU: 35.7MB / 134.0MB | F: 0.0049s, B: 0.0060s, O: 0.0012s\n",
            "🔄 Topology update at step 9340 took 0.0001s\n",
            "Step 9350 | Loss: 1.000055 | GPU: 35.7MB / 134.0MB | F: 0.0083s, B: 0.0037s, O: 0.0012s\n",
            "Batch 3100/3125 ( 99.2%) | Loss: 1.104007 | Accuracy: 60.98% | Batch time: 0.0449s\n",
            "Step 9360 | Loss: 1.315776 | GPU: 35.7MB / 134.0MB | F: 0.0019s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 9360 took 0.0001s\n",
            "Step 9370 | Loss: 0.880966 | GPU: 35.7MB / 134.0MB | F: 0.0043s, B: 0.0042s, O: 0.0007s\n",
            "Batch 3120/3125 ( 99.8%) | Loss: 1.103746 | Accuracy: 60.98% | Batch time: 0.0424s\n",
            "\n",
            "-------------------- EPOCH 3 SUMMARY --------------------\n",
            "Loss: 1.103851 | Accuracy: 60.97%\n",
            "Time: 83.14s total, 0.0211s per batch\n",
            "🔄 Final Memory - RAM: 8190.8MB, GPU: 35.7MB allocated, 70.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=35.7, peak=35.7\n",
            "===============================\n",
            "\n",
            "⏱️ TALT model training took 83.1443 seconds\n",
            "\n",
            "Cleaning up memory after training...\n",
            "⏱️ Memory cleanup took 0.2661 seconds\n",
            "🔄 After training Memory - RAM: 8190.8MB, GPU: 35.5MB allocated, 64.0MB reserved\n",
            "\n",
            "------------------------- Standard Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 1.093527 | Accuracy: 61.52% | Batch time: 0.0015s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 1.099489 | Accuracy: 60.21% | Batch time: 0.0020s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 1.108435 | Accuracy: 60.55% | Batch time: 0.0020s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 1.118763 | Accuracy: 60.73% | Batch time: 0.0043s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 1.125498 | Accuracy: 60.63% | Batch time: 0.0033s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 1.120591 | Accuracy: 61.11% | Batch time: 0.0024s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 1.119003 | Accuracy: 61.22% | Batch time: 0.0013s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 1.119228 | Accuracy: 61.19% | Batch time: 0.0013s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 1.121705 | Accuracy: 61.09% | Batch time: 0.0010s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 1.119196 | Accuracy: 60.99% | Batch time: 0.0019s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 1.121559 | Accuracy: 61.07% | Batch time: 0.0018s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 1.120259 | Accuracy: 61.10% | Batch time: 0.0021s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.120404 | Accuracy: 60.93%\n",
            "Time: 7.53s total, 0.0023s per batch\n",
            "⏱️ Standard model evaluation took 7.5322 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 0.940376 | Accuracy: 66.42% | Batch time: 0.0019s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 0.912074 | Accuracy: 67.39% | Batch time: 0.0017s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 0.914952 | Accuracy: 67.76% | Batch time: 0.0049s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 0.924292 | Accuracy: 67.63% | Batch time: 0.0022s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 0.930578 | Accuracy: 66.91% | Batch time: 0.0014s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 0.927946 | Accuracy: 67.34% | Batch time: 0.0031s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 0.928427 | Accuracy: 67.45% | Batch time: 0.0029s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 0.930484 | Accuracy: 67.21% | Batch time: 0.0019s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 0.938185 | Accuracy: 67.06% | Batch time: 0.0017s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 0.933882 | Accuracy: 67.39% | Batch time: 0.0017s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 0.936584 | Accuracy: 67.24% | Batch time: 0.0039s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 0.933933 | Accuracy: 67.44% | Batch time: 0.0019s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error during training: num must be an integer with 1 <= num <= 4, not 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.936174 | Accuracy: 67.29%\n",
            "Time: 6.64s total, 0.0022s per batch\n",
            "⏱️ TALT model evaluation took 6.6372 seconds\n",
            "\n",
            "------------------------- EPOCH 3 SUMMARY -------------------------\n",
            "Time: 132.32s\n",
            "Standard Model:\n",
            "  - Train Loss: 1.391103, Accuracy: 49.90%\n",
            "  - Test Loss:  1.120404, Accuracy: 60.93%\n",
            "Improved TALT Model:\n",
            "  - Train Loss: 1.103851, Accuracy: 60.97%\n",
            "  - Test Loss:  0.936174, Accuracy: 67.29%\n",
            "\n",
            "📈 TALT outperforms standard by 6.36% on test accuracy\n",
            "\n",
            "Cleaning up memory after epoch...\n",
            "⏱️ Memory cleanup took 0.3013 seconds\n",
            "🔄 After epoch Memory - RAM: 8190.8MB, GPU: 35.5MB allocated, 64.0MB reserved\n",
            "\n",
            "============================== TRAINING COMPLETED ==============================\n",
            "Total training time: 396.60s\n",
            "Final results on CIFAR10:\n",
            "Standard Model: 60.93% test accuracy\n",
            "Improved TALT: 67.29% test accuracy\n",
            "✅ Improved TALT outperformed standard by 6.36%\n",
            "\n",
            "Generating visualizations...\n",
            "⏱️ Plotting comparative results took 0.0020 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_multiple_optimizers(\n",
        "    dataset_name: str,\n",
        "    epochs: int = 5,\n",
        "    batch_size: int = 16,\n",
        "    device: Union[str, torch.device] = \"cuda\",\n",
        "    save_dir: str = \"./results\",\n",
        "    plots_dir: str = \"./plots\"\n",
        ") -> Dict[str, Dict[str, List[float]]]:\n",
        "    \"\"\"\n",
        "    Train and evaluate models with multiple optimizers for comparison.\n",
        "\n",
        "    Args:\n",
        "        dataset_name: Name of the dataset (\"MNIST\" or \"CIFAR10\")\n",
        "        epochs: Number of epochs to train\n",
        "        batch_size: Batch size\n",
        "        device: Device to train on\n",
        "        save_dir: Directory to save numerical results\n",
        "        plots_dir: Directory to save plots\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with results for all optimizers\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*30} OPTIMIZER COMPARISON ON {dataset_name} {'='*30}\")\n",
        "    print(f\"Configuration: epochs={epochs}, batch_size={batch_size}, device={device}\")\n",
        "\n",
        "    # Create directories if needed\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "        print(f\"Created results directory: {save_dir}\")\n",
        "\n",
        "    if not os.path.exists(plots_dir):\n",
        "        os.makedirs(plots_dir)\n",
        "        print(f\"Created plots directory: {plots_dir}\")\n",
        "\n",
        "    # Ensure device is a torch.device\n",
        "    device = device if isinstance(device, torch.device) else torch.device(device)\n",
        "\n",
        "    # Get data loaders\n",
        "    print(\"\\nLoading datasets...\")\n",
        "    train_loader, test_loader, num_channels, image_size = get_loaders(dataset_name, batch_size)\n",
        "    print(f\"Train set: {len(train_loader.dataset)} samples, {len(train_loader)} batches\")\n",
        "    print(f\"Test set: {len(test_loader.dataset)} samples, {len(test_loader)} batches\")\n",
        "\n",
        "    # Loss function\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Define optimizers to compare\n",
        "    optimizers = {}\n",
        "    models = {}\n",
        "    results = {}\n",
        "\n",
        "    # Initialize models and optimizers\n",
        "    print(\"\\nInitializing models and optimizers...\")\n",
        "\n",
        "    # 1. SGD with momentum\n",
        "    models[\"SGD\"] = SimpleCNN(num_channels=num_channels, image_size=image_size).to(device)\n",
        "    optimizers[\"SGD\"] = optim.SGD(models[\"SGD\"].parameters(), lr=0.01, momentum=0.9)\n",
        "    results[\"SGD\"] = {\"train_loss\": [], \"test_loss\": [], \"train_acc\": [], \"test_acc\": []}\n",
        "\n",
        "    # 2. Adam\n",
        "    models[\"Adam\"] = SimpleCNN(num_channels=num_channels, image_size=image_size).to(device)\n",
        "    optimizers[\"Adam\"] = optim.Adam(models[\"Adam\"].parameters(), lr=0.001)\n",
        "    results[\"Adam\"] = {\"train_loss\": [], \"test_loss\": [], \"train_acc\": [], \"test_acc\": []}\n",
        "\n",
        "    # 3. AdamW\n",
        "    models[\"AdamW\"] = SimpleCNN(num_channels=num_channels, image_size=image_size).to(device)\n",
        "    optimizers[\"AdamW\"] = optim.AdamW(models[\"AdamW\"].parameters(), lr=0.001, weight_decay=0.01)\n",
        "    results[\"AdamW\"] = {\"train_loss\": [], \"test_loss\": [], \"train_acc\": [], \"test_acc\": []}\n",
        "\n",
        "    # 4. ImprovedTALT\n",
        "    models[\"ImprovedTALT\"] = SimpleCNN(num_channels=num_channels, image_size=image_size).to(device)\n",
        "    talt_optimizer = ImprovedTALTOptimizer(\n",
        "        models[\"ImprovedTALT\"],\n",
        "        optim.SGD,\n",
        "        lr=0.01,\n",
        "        projection_dim=32,\n",
        "        memory_size=10,\n",
        "        update_interval=20,\n",
        "        valley_strength=0.2,\n",
        "        smoothing_factor=0.3,\n",
        "        grad_store_interval=5,\n",
        "        device=device,\n",
        "        max_stored_steps=500,\n",
        "        max_visualization_points=100\n",
        "    )\n",
        "    optimizers[\"ImprovedTALT\"] = talt_optimizer\n",
        "    results[\"ImprovedTALT\"] = {\"train_loss\": [], \"test_loss\": [], \"train_acc\": [], \"test_acc\": []}\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in models[\"SGD\"].parameters())\n",
        "    print(f\"Model parameters: {total_params:,}\")\n",
        "\n",
        "    # Training loop\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"STARTING TRAINING FOR {epochs} EPOCHS WITH {len(optimizers)} OPTIMIZERS\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    training_start_time = time.time()\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start = time.time()\n",
        "        print(f\"\\n{'='*30} EPOCH {epoch}/{epochs} {'='*30}\")\n",
        "\n",
        "        # Train and evaluate with each optimizer\n",
        "        for opt_name, optimizer in optimizers.items():\n",
        "            print(f\"\\n{'-'*25} {opt_name} Optimizer {'-'*25}\")\n",
        "            model = models[opt_name]\n",
        "\n",
        "            # Training\n",
        "            model.train()\n",
        "            with Timer(f\"{opt_name} training\"):\n",
        "                if opt_name == \"ImprovedTALT\":\n",
        "                    train_loss, train_acc = _train_epoch_improved_talt(\n",
        "                        model, train_loader, loss_fn, optimizer, device, epoch\n",
        "                    )\n",
        "                else:\n",
        "                    train_loss, train_acc = _train_epoch_standard(\n",
        "                        model, train_loader, loss_fn, optimizer, device, epoch\n",
        "                    )\n",
        "\n",
        "            results[opt_name][\"train_loss\"].append(train_loss)\n",
        "            results[opt_name][\"train_acc\"].append(train_acc)\n",
        "\n",
        "            # Evaluation\n",
        "            model.eval()\n",
        "            with Timer(f\"{opt_name} evaluation\"):\n",
        "                test_loss, test_acc = _evaluate(\n",
        "                    model, test_loader, loss_fn, device\n",
        "                )\n",
        "\n",
        "            results[opt_name][\"test_loss\"].append(test_loss)\n",
        "            results[opt_name][\"test_acc\"].append(test_acc)\n",
        "\n",
        "            # Print summary\n",
        "            print(f\"{opt_name} - Epoch {epoch}:\")\n",
        "            print(f\"  Train Loss: {train_loss:.6f}, Train Acc: {train_acc:.2f}%\")\n",
        "            print(f\"  Test Loss:  {test_loss:.6f}, Test Acc:  {test_acc:.2f}%\")\n",
        "\n",
        "            # Memory cleanup\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        print(f\"\\nEpoch {epoch} completed in {epoch_time:.2f}s\")\n",
        "\n",
        "        # Save intermediate results\n",
        "        with open(f\"{save_dir}/epoch_{epoch}_results.json\", \"w\") as f:\n",
        "            # Convert values to Python native types for JSON serialization\n",
        "            serializable_results = {}\n",
        "            for opt_name, metrics in results.items():\n",
        "                serializable_results[opt_name] = {\n",
        "                    k: [float(val) for val in v] for k, v in metrics.items()\n",
        "                }\n",
        "            json.dump(serializable_results, f, indent=2)\n",
        "\n",
        "        print(f\"Results saved to {save_dir}/epoch_{epoch}_results.json\")\n",
        "\n",
        "    # Training complete\n",
        "    total_time = time.time() - training_start_time\n",
        "\n",
        "    print(f\"\\n{'='*30} TRAINING COMPLETED {'='*30}\")\n",
        "    print(f\"Total training time: {total_time:.2f}s\")\n",
        "\n",
        "    # Print final comparison\n",
        "    print(\"\\nFinal Test Accuracy Comparison:\")\n",
        "    for opt_name in results:\n",
        "        final_acc = results[opt_name][\"test_acc\"][-1]\n",
        "        print(f\"  {opt_name}: {final_acc:.2f}%\")\n",
        "\n",
        "    # Find best optimizer\n",
        "    best_opt = max(results.keys(), key=lambda k: results[k][\"test_acc\"][-1])\n",
        "    best_acc = results[best_opt][\"test_acc\"][-1]\n",
        "    print(f\"\\n🏆 Best optimizer: {best_opt} with {best_acc:.2f}% test accuracy\")\n",
        "\n",
        "    # Create comparative visualization\n",
        "    print(\"\\nCreating comparative plots...\")\n",
        "\n",
        "    # 1. Training Loss\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for opt_name in results:\n",
        "        plt.plot(range(1, epochs+1), results[opt_name][\"train_loss\"], marker='o', label=opt_name)\n",
        "    plt.title(f\"Training Loss Comparison on {dataset_name}\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.savefig(f\"{plots_dir}/train_loss_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # 2. Test Loss\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for opt_name in results:\n",
        "        plt.plot(range(1, epochs+1), results[opt_name][\"test_loss\"], marker='o', label=opt_name)\n",
        "    plt.title(f\"Test Loss Comparison on {dataset_name}\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.savefig(f\"{plots_dir}/test_loss_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # 3. Training Accuracy\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for opt_name in results:\n",
        "        plt.plot(range(1, epochs+1), results[opt_name][\"train_acc\"], marker='o', label=opt_name)\n",
        "    plt.title(f\"Training Accuracy Comparison on {dataset_name}\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.savefig(f\"{plots_dir}/train_acc_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # 4. Test Accuracy\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for opt_name in results:\n",
        "        plt.plot(range(1, epochs+1), results[opt_name][\"test_acc\"], marker='o', label=opt_name)\n",
        "    plt.title(f\"Test Accuracy Comparison on {dataset_name}\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.savefig(f\"{plots_dir}/test_acc_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Comparison plots saved to {plots_dir}\")\n",
        "\n",
        "    # Save final results\n",
        "    results_file = f\"{save_dir}/final_results.json\"\n",
        "    with open(results_file, \"w\") as f:\n",
        "        # Convert values to Python native types for JSON serialization\n",
        "        serializable_results = {}\n",
        "        for opt_name, metrics in results.items():\n",
        "            serializable_results[opt_name] = {\n",
        "                k: [float(val) for val in v] for k, v in metrics.items()\n",
        "            }\n",
        "        json.dump(serializable_results, f, indent=2)\n",
        "\n",
        "    print(f\"Final results saved to {results_file}\")\n",
        "\n",
        "    # Clean up\n",
        "    if isinstance(optimizers[\"ImprovedTALT\"], ImprovedTALTOptimizer):\n",
        "        optimizers[\"ImprovedTALT\"].shutdown()\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def _train_epoch_standard(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    loss_fn: nn.Module,\n",
        "    optimizer: optim.Optimizer,\n",
        "    device: torch.device,\n",
        "    epoch: int\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Train for one epoch with a standard optimizer.\n",
        "\n",
        "    Args:\n",
        "        model: Model to train\n",
        "        loader: Data loader\n",
        "        loss_fn: Loss function\n",
        "        optimizer: Optimizer\n",
        "        device: Device to train on\n",
        "        epoch: Current epoch number\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (average loss, accuracy)\n",
        "    \"\"\"\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Timing statistics\n",
        "    forward_times = []\n",
        "    backward_times = []\n",
        "    optim_times = []\n",
        "    batch_times = []\n",
        "\n",
        "    # Print initial stats\n",
        "    print(f\"Training with standard optimizer - Epoch {epoch}\")\n",
        "    print(f\"Batches: {len(loader)}, Batch size: {loader.batch_size}\")\n",
        "\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        batch_start = time.time()\n",
        "\n",
        "        # Transfer data to device\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        forward_start = time.time()\n",
        "        outputs = model(x)\n",
        "        loss = loss_fn(outputs, y)\n",
        "        forward_time = time.time() - forward_start\n",
        "        forward_times.append(forward_time)\n",
        "\n",
        "        # Backward pass\n",
        "        backward_start = time.time()\n",
        "        loss.backward()\n",
        "        backward_time = time.time() - backward_start\n",
        "        backward_times.append(backward_time)\n",
        "\n",
        "        # Update parameters\n",
        "        optim_start = time.time()\n",
        "        optimizer.step()\n",
        "        optim_time = time.time() - optim_start\n",
        "        optim_times.append(optim_time)\n",
        "\n",
        "        # Update metrics\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += y.size(0)\n",
        "        correct += predicted.eq(y).sum().item()\n",
        "\n",
        "        # Record batch time\n",
        "        batch_time = time.time() - batch_start\n",
        "        batch_times.append(batch_time)\n",
        "\n",
        "        # Print progress periodically\n",
        "        if idx % 50 == 0 and idx > 0:\n",
        "            progress = idx / len(loader) * 100\n",
        "            current_loss = total_loss / (idx + 1)\n",
        "            current_acc = 100.0 * correct / total\n",
        "\n",
        "            print(f\"Batch {idx:4d}/{len(loader):4d} ({progress:5.1f}%) | \"\n",
        "                  f\"Loss: {current_loss:.6f} | Acc: {current_acc:.2f}% | \"\n",
        "                  f\"Batch time: {batch_time:.4f}s\")\n",
        "\n",
        "        # Free memory periodically\n",
        "        if idx % 50 == 0 and idx > 0:\n",
        "            del outputs, predicted\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    # Calculate final metrics\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\nStandard optimizer - Epoch {epoch} summary:\")\n",
        "    print(f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return avg_loss, accuracy# ===================================\n",
        "# PERFORMANCE MONITORING\n",
        "# ===================================\n",
        "\n",
        "class Timer:\n",
        "    \"\"\"Simple timer for measuring execution time of code blocks.\"\"\"\n",
        "\n",
        "    def __init__(self, name: str = \"Operation\"):\n",
        "        \"\"\"\n",
        "        Initialize timer.\n",
        "\n",
        "        Args:\n",
        "            name: Name of the operation being timed\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.start_time = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        \"\"\"Start timer when entering context.\"\"\"\n",
        "        self.start_time = time.time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        \"\"\"Print elapsed time when exiting context.\"\"\"\n",
        "        elapsed = time.time() - self.start_time\n",
        "        print(f\"⏱️ {self.name} took {elapsed:.4f} seconds\")\n",
        "\n",
        "def print_memory_usage(prefix: str = \"\"):\n",
        "    \"\"\"\n",
        "    Print current memory usage statistics.\n",
        "\n",
        "    Args:\n",
        "        prefix: Optional prefix for the output message\n",
        "    \"\"\"\n",
        "    # System memory (RAM)\n",
        "    process = psutil.Process(os.getpid())\n",
        "    ram_usage = process.memory_info().rss / (1024 * 1024)  # MB\n",
        "\n",
        "    # GPU memory if available\n",
        "    gpu_memory = \"\"\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_allocated = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
        "        gpu_reserved = torch.cuda.memory_reserved() / (1024 * 1024)  # MB\n",
        "        gpu_memory = f\", GPU: {gpu_allocated:.1f}MB allocated, {gpu_reserved:.1f}MB reserved\"\n",
        "\n",
        "    print(f\"🔄 {prefix}Memory - RAM: {ram_usage:.1f}MB{gpu_memory}\")\n",
        "\n",
        "class PerformanceTracker:\n",
        "    \"\"\"Tracks performance metrics during training.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize performance tracker.\"\"\"\n",
        "        self.timings = {\n",
        "            \"forward_pass\": [],\n",
        "            \"backward_pass\": [],\n",
        "            \"optimizer_step\": [],\n",
        "            \"topology_update\": [],\n",
        "            \"batch_total\": []\n",
        "        }\n",
        "        self.memory_usage = []\n",
        "\n",
        "    def record_timing(self, operation: str, elapsed: float):\n",
        "        \"\"\"\n",
        "        Record timing for an operation.\n",
        "\n",
        "        Args:\n",
        "            operation: Name of the operation\n",
        "            elapsed: Time taken in seconds\n",
        "        \"\"\"\n",
        "        if operation in self.timings:\n",
        "            self.timings[operation].append(elapsed)\n",
        "\n",
        "    def record_memory(self):\n",
        "        \"\"\"Record current memory usage.\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            gpu_allocated = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
        "            self.memory_usage.append(gpu_allocated)\n",
        "        else:\n",
        "            process = psutil.Process(os.getpid())\n",
        "            ram_usage = process.memory_info().rss / (1024 * 1024)  # MB\n",
        "            self.memory_usage.append(ram_usage)\n",
        "\n",
        "    def print_summary(self):\n",
        "        \"\"\"Print summary of performance statistics.\"\"\"\n",
        "        print(\"\\n===== PERFORMANCE SUMMARY =====\")\n",
        "\n",
        "        print(\"⏱️ Timing Statistics (in seconds):\")\n",
        "        for operation, times in self.timings.items():\n",
        "            if times:\n",
        "                avg_time = sum(times) / len(times)\n",
        "                max_time = max(times)\n",
        "                print(f\"  - {operation:15s}: avg={avg_time:.4f}, max={max_time:.4f}\")\n",
        "\n",
        "        if self.memory_usage:\n",
        "            avg_memory = sum(self.memory_usage) / len(self.memory_usage)\n",
        "            peak_memory = max(self.memory_usage)\n",
        "            print(f\"🔄 Memory Usage (MB): avg={avg_memory:.1f}, peak={peak_memory:.1f}\")\n",
        "\n",
        "        print(\"===============================\\n\")\n",
        "\"\"\"\n",
        "Improved Topology-Aware Learning Trajectory (TALT) Optimizer\n",
        "\n",
        "This module implements an enhanced version of the TALT optimizer that uses\n",
        "dimensionality reduction, robust eigendecomposition, and non-parametric\n",
        "valley detection to improve optimization performance while reducing memory usage.\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import psutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from torch.amp import autocast, GradScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import Dict, List, Tuple, Optional, Union, Callable, Any\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import gc\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ===================================\n",
        "# MODEL DEFINITION\n",
        "# ===================================\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple convolutional neural network for image classification.\n",
        "\n",
        "    Features a convolutional feature extractor followed by a fully-connected\n",
        "    classifier with dropout for regularization.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_channels: int, image_size: int, num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        # Convolutional layers with BatchNorm\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(num_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Calculate flattened dimension after convolutions\n",
        "        flat_dim = (image_size // 4) ** 2 * 64\n",
        "\n",
        "        # Classifier layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(flat_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass through the network.\"\"\"\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# DIMENSIONALITY REDUCTION\n",
        "# ===================================\n",
        "\n",
        "class RandomProjection:\n",
        "    \"\"\"\n",
        "    Implements sparse random projection for dimension reduction.\n",
        "\n",
        "    Uses a memory-efficient sparse random projection matrix to reduce\n",
        "    the dimensionality of input data while approximately preserving\n",
        "    distances between points.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, original_dim: int, target_dim: int, seed: int = 42):\n",
        "        \"\"\"\n",
        "        Initialize random projection matrix.\n",
        "\n",
        "        Args:\n",
        "            original_dim: Original dimension\n",
        "            target_dim: Target dimension after projection\n",
        "            seed: Random seed for reproducibility\n",
        "        \"\"\"\n",
        "        self.original_dim = original_dim\n",
        "        self.target_dim = min(target_dim, original_dim)\n",
        "\n",
        "        # Set random seed for reproducibility\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        # Create sparse random projection matrix\n",
        "        sparsity = 1.0 / math.sqrt(self.original_dim)\n",
        "        self.projection = self._create_sparse_projection(sparsity)\n",
        "\n",
        "    def _create_sparse_projection(self, sparsity: float) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Create a sparse random projection matrix.\n",
        "\n",
        "        Uses the 'very sparse' random projection method where most values\n",
        "        are 0, and non-zero values are +/- sqrt(3) with equal probability.\n",
        "\n",
        "        Args:\n",
        "            sparsity: Sparsity level (fraction of non-zero elements)\n",
        "\n",
        "        Returns:\n",
        "            Sparse projection matrix\n",
        "        \"\"\"\n",
        "        # Create a mask for non-zero elements\n",
        "        mask = torch.rand(self.target_dim, self.original_dim) < sparsity\n",
        "\n",
        "        # Create random signs: 1 or -1\n",
        "        signs = torch.randint(0, 2, (self.target_dim, self.original_dim)) * 2 - 1\n",
        "\n",
        "        # Scale factor for unit variance\n",
        "        scale = math.sqrt(1.0 / sparsity)\n",
        "\n",
        "        # Create projection matrix\n",
        "        projection = (mask.float() * signs.float() * scale) / math.sqrt(self.target_dim)\n",
        "        return projection\n",
        "\n",
        "    def project(self, data: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Project data from original dimension to target dimension.\n",
        "\n",
        "        Args:\n",
        "            data: Data tensor of shape (batch_size, original_dim) or (original_dim,)\n",
        "\n",
        "        Returns:\n",
        "            Projected data of shape (batch_size, target_dim) or (target_dim,)\n",
        "        \"\"\"\n",
        "        # Check if data is 1D or 2D\n",
        "        is_1d = data.dim() == 1\n",
        "\n",
        "        # Ensure data is 2D for matrix multiplication\n",
        "        if is_1d:\n",
        "            data = data.unsqueeze(0)\n",
        "\n",
        "        # Move projection matrix to same device as data\n",
        "        projection = self.projection.to(data.device)\n",
        "\n",
        "        # Project data\n",
        "        projected = torch.matmul(data, projection.t())\n",
        "\n",
        "        # Return in original shape\n",
        "        return projected.squeeze(0) if is_1d else projected\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# COVARIANCE ESTIMATION\n",
        "# ===================================\n",
        "\n",
        "class IncrementalCovariance:\n",
        "    \"\"\"\n",
        "    Computes covariance matrix incrementally to save memory.\n",
        "\n",
        "    Allows for updating the covariance estimate one sample at a time,\n",
        "    with exponential forgetting to give more weight to recent samples.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim: int, decay: float = 0.95):\n",
        "        \"\"\"\n",
        "        Initialize incremental covariance estimator.\n",
        "\n",
        "        Args:\n",
        "            dim: Dimension of data\n",
        "            decay: Decay factor for old observations (0-1)\n",
        "        \"\"\"\n",
        "        self.dim = dim\n",
        "        self.decay = decay\n",
        "        self.n_samples = 0\n",
        "        self.mean = torch.zeros(dim)\n",
        "        self.cov = torch.zeros(dim, dim)\n",
        "\n",
        "    def update(self, x: torch.Tensor) -> None:\n",
        "        \"\"\"\n",
        "        Update covariance estimate with new data.\n",
        "\n",
        "        Args:\n",
        "            x: New data point(s) of shape (batch_size, dim) or (dim,)\n",
        "        \"\"\"\n",
        "        # Ensure input is on CPU and 2D\n",
        "        x = x.cpu()\n",
        "        if x.dim() == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            x_i = x[i]\n",
        "\n",
        "            # Apply decay to previous statistics\n",
        "            if self.n_samples > 0:\n",
        "                self.mean *= self.decay\n",
        "                self.cov *= self.decay**2\n",
        "\n",
        "            # Update sample count with decay\n",
        "            self.n_samples = self.decay * self.n_samples + 1\n",
        "\n",
        "            # Update mean\n",
        "            delta = x_i - self.mean\n",
        "            self.mean += delta / self.n_samples\n",
        "\n",
        "            # Update covariance\n",
        "            delta2 = x_i - self.mean\n",
        "            self.cov += torch.outer(delta, delta2) / max(1, self.n_samples - 1)\n",
        "\n",
        "    def get_covariance(self, reg: float = 1e-6) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Get current covariance estimate with regularization.\n",
        "\n",
        "        Args:\n",
        "            reg: Regularization parameter\n",
        "\n",
        "        Returns:\n",
        "            Covariance matrix with regularization\n",
        "        \"\"\"\n",
        "        if self.n_samples < 2:\n",
        "            # Not enough samples, return identity matrix\n",
        "            return torch.eye(self.dim) * reg\n",
        "\n",
        "        # Add regularization\n",
        "        cov = self.cov + torch.eye(self.dim) * reg\n",
        "\n",
        "        # Ensure symmetry\n",
        "        cov = 0.5 * (cov + cov.t())\n",
        "\n",
        "        return cov\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# EIGENDECOMPOSITION\n",
        "# ===================================\n",
        "\n",
        "class PowerIteration:\n",
        "    \"\"\"\n",
        "    Computes top eigenvectors using power iteration method.\n",
        "\n",
        "    A more stable alternative to direct eigendecomposition that\n",
        "    iteratively finds principal eigenvectors and eigenvalues.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_iter: int = 20, tol: float = 1e-6):\n",
        "        \"\"\"\n",
        "        Initialize power iteration.\n",
        "\n",
        "        Args:\n",
        "            max_iter: Maximum number of iterations\n",
        "            tol: Convergence tolerance\n",
        "        \"\"\"\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "\n",
        "    def compute_eigenpairs(self, matrix: torch.Tensor, k: int = 5) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Compute top k eigenvectors and eigenvalues.\n",
        "\n",
        "        Args:\n",
        "            matrix: Square matrix\n",
        "            k: Number of eigenpairs to compute\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (eigenvalues, eigenvectors)\n",
        "        \"\"\"\n",
        "        n = matrix.shape[0]\n",
        "        k = min(k, n)\n",
        "\n",
        "        # Initialize storage for eigenvectors and eigenvalues\n",
        "        eigenvectors = torch.zeros((n, k), device=matrix.device)\n",
        "        eigenvalues = torch.zeros(k, device=matrix.device)\n",
        "\n",
        "        # Initial random vectors, orthogonalized\n",
        "        vecs = torch.randn(n, k, device=matrix.device)\n",
        "        vecs, _ = torch.linalg.qr(vecs)\n",
        "\n",
        "        # Deflation approach: find eigenvectors one by one\n",
        "        for i in range(k):\n",
        "            # Current vector\n",
        "            v = vecs[:, i].clone()\n",
        "\n",
        "            # Power iteration\n",
        "            for _ in range(self.max_iter):\n",
        "                prev_v = v.clone()\n",
        "\n",
        "                # Apply matrix\n",
        "                v = torch.mv(matrix, v)\n",
        "\n",
        "                # Orthogonalize against previous eigenvectors\n",
        "                for j in range(i):\n",
        "                    v = v - torch.dot(v, eigenvectors[:, j]) * eigenvectors[:, j]\n",
        "\n",
        "                # Normalize\n",
        "                norm = torch.norm(v)\n",
        "                if norm > 1e-10:\n",
        "                    v = v / norm\n",
        "                else:\n",
        "                    # If vector is close to zero, reset with random\n",
        "                    v = torch.randn_like(v)\n",
        "                    v = v / torch.norm(v)\n",
        "\n",
        "                # Check convergence\n",
        "                cosine = torch.abs(torch.dot(v, prev_v))\n",
        "                if cosine > 1 - self.tol:\n",
        "                    break\n",
        "\n",
        "            # Compute Rayleigh quotient for eigenvalue\n",
        "            eigenvalues[i] = torch.dot(v, torch.mv(matrix, v))\n",
        "            eigenvectors[:, i] = v\n",
        "\n",
        "            # Deflate matrix to find next eigenvector\n",
        "            matrix = matrix - eigenvalues[i] * torch.outer(v, v)\n",
        "\n",
        "        return eigenvalues, eigenvectors\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# VALLEY DETECTION\n",
        "# ===================================\n",
        "\n",
        "class ValleyDetector:\n",
        "    \"\"\"\n",
        "    Non-parametric valley detection using gradient consistency.\n",
        "\n",
        "    Analyzes gradient direction changes to identify valleys in the\n",
        "    loss landscape without relying on eigendecomposition.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size: int = 5, threshold: float = 0.2):\n",
        "        \"\"\"\n",
        "        Initialize valley detector.\n",
        "\n",
        "        Args:\n",
        "            window_size: Size of window for gradient analysis\n",
        "            threshold: Threshold for valley detection\n",
        "        \"\"\"\n",
        "        self.window_size = window_size\n",
        "        self.threshold = threshold\n",
        "        self.grad_history = deque(maxlen=window_size)\n",
        "\n",
        "    def update(self, grad: torch.Tensor) -> None:\n",
        "        \"\"\"\n",
        "        Update gradient history.\n",
        "\n",
        "        Args:\n",
        "            grad: Current gradient\n",
        "        \"\"\"\n",
        "        # Store normalized gradient\n",
        "        grad_norm = grad / (torch.norm(grad) + 1e-10)\n",
        "        self.grad_history.append(grad_norm.cpu())\n",
        "\n",
        "    def detect_valley(self) -> Tuple[bool, Optional[torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        Detect if current point is in a valley.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (is_valley, valley_direction)\n",
        "        \"\"\"\n",
        "        if len(self.grad_history) < self.window_size:\n",
        "            return False, None\n",
        "\n",
        "        # Convert history to tensor\n",
        "        grads = torch.stack(list(self.grad_history))\n",
        "\n",
        "        # Compute gradient consistency (average cosine similarity)\n",
        "        n = len(self.grad_history)\n",
        "        cosine_sum = 0.0\n",
        "        count = 0\n",
        "\n",
        "        for i in range(n):\n",
        "            for j in range(i+1, n):\n",
        "                cos = torch.dot(grads[i], grads[j])\n",
        "                cosine_sum += cos.item()\n",
        "                count += 1\n",
        "\n",
        "        avg_cosine = cosine_sum / max(1, count)\n",
        "\n",
        "        # If gradients are inconsistent (pointing in different directions)\n",
        "        # then we might be in a valley\n",
        "        is_valley = avg_cosine < self.threshold\n",
        "\n",
        "        # If in valley, compute valley direction using PCA\n",
        "        if is_valley:\n",
        "            try:\n",
        "                # Center gradients\n",
        "                centered = grads - grads.mean(dim=0, keepdim=True)\n",
        "\n",
        "                # Compute covariance\n",
        "                cov = torch.matmul(centered.t(), centered) / (n - 1)\n",
        "\n",
        "                # Get eigenvector with smallest eigenvalue (valley direction)\n",
        "                eigenvalues, eigenvectors = torch.linalg.eigh(cov)\n",
        "                valley_dir = eigenvectors[:, 0]  # Direction of smallest eigenvalue\n",
        "                return True, valley_dir\n",
        "            except Exception:\n",
        "                return is_valley, None\n",
        "\n",
        "        return is_valley, None\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# IMPROVED TALT OPTIMIZER\n",
        "# ===================================\n",
        "\n",
        "class ImprovedTALTOptimizer:\n",
        "    \"\"\"\n",
        "    Improved Topology-Aware Learning Trajectory Optimizer\n",
        "\n",
        "    This optimizer implements an enhanced version of TALT with:\n",
        "    1. Dimension reduction via random projections\n",
        "    2. Incremental covariance estimation\n",
        "    3. Robust eigendecomposition via power iteration\n",
        "    4. Non-parametric valley detection\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        base_optimizer: Callable,\n",
        "        *,\n",
        "        lr: float = 1e-2,\n",
        "        projection_dim: int = 32,\n",
        "        memory_size: int = 10,\n",
        "        update_interval: int = 20,\n",
        "        valley_strength: float = 0.2,\n",
        "        smoothing_factor: float = 0.3,\n",
        "        grad_store_interval: int = 5,\n",
        "        min_param_size: int = 100,\n",
        "        cov_decay: float = 0.95,\n",
        "        adaptive_reg: bool = True,\n",
        "        device: Union[str, torch.device] = \"cuda\",\n",
        "        max_stored_steps: int = 1000,\n",
        "        max_visualization_points: int = 100\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the improved TALT optimizer.\n",
        "\n",
        "        Args:\n",
        "            model: Neural network model\n",
        "            base_optimizer: Base optimizer class (e.g., optim.SGD)\n",
        "            lr: Learning rate\n",
        "            projection_dim: Dimension after random projection\n",
        "            memory_size: Number of past gradients to store\n",
        "            update_interval: Steps between topology updates\n",
        "            valley_strength: Strength of valley acceleration\n",
        "            smoothing_factor: Factor for smoothing high-curvature directions\n",
        "            grad_store_interval: Steps between gradient storage\n",
        "            min_param_size: Minimum parameter size to track\n",
        "            cov_decay: Decay factor for incremental covariance\n",
        "            adaptive_reg: Whether to use adaptive regularization\n",
        "            device: Device to perform computations on\n",
        "            max_stored_steps: Maximum steps to store in history\n",
        "            max_visualization_points: Maximum visualization datapoints\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.optimizer = base_optimizer(model.parameters(), lr=lr)\n",
        "        self.projection_dim = projection_dim\n",
        "        self.memory_size = memory_size\n",
        "        self.update_interval = update_interval\n",
        "        self.valley_strength = valley_strength\n",
        "        self.smoothing_factor = smoothing_factor\n",
        "        self.store_interval = grad_store_interval\n",
        "        self.min_param_size = min_param_size\n",
        "        self.cov_decay = cov_decay\n",
        "        self.adaptive_reg = adaptive_reg\n",
        "        self.device = device if isinstance(device, torch.device) else torch.device(device)\n",
        "        self.max_stored_steps = max_stored_steps\n",
        "        self.max_visualization_points = max_visualization_points\n",
        "\n",
        "        # Initialize GradScaler for mixed precision\n",
        "        self.scaler = GradScaler('cuda')\n",
        "\n",
        "        # Tracking variables\n",
        "        self.steps = 0\n",
        "        self.loss_history = deque(maxlen=max_stored_steps)\n",
        "        self.bifurcations = deque(maxlen=100)  # Track bifurcation points\n",
        "\n",
        "        # Thread pool for asynchronous operations\n",
        "        self.executor = ThreadPoolExecutor(max_workers=1)\n",
        "        self._topology_update_future = None\n",
        "\n",
        "        # Visualization data with limited history\n",
        "        self._visualization_data = {\n",
        "            'loss_values': deque(maxlen=max_visualization_points),\n",
        "            'valley_detections': deque(maxlen=max_visualization_points),\n",
        "            'gradient_stats': {}\n",
        "        }\n",
        "\n",
        "        # Parameter-specific structures\n",
        "        self.param_data = {}\n",
        "\n",
        "        # Register hooks for parameters of sufficient size\n",
        "        for name, p in model.named_parameters():\n",
        "            if p.requires_grad and p.numel() > self.min_param_size:\n",
        "                # Create dimension-reduced representation\n",
        "                dim = p.numel()\n",
        "                target_dim = min(self.projection_dim, dim // 4)  # No more than 1/4 of original\n",
        "\n",
        "                self.param_data[name] = {\n",
        "                    'projector': RandomProjection(dim, target_dim),\n",
        "                    'covariance': IncrementalCovariance(target_dim, decay=cov_decay),\n",
        "                    'valley_detector': ValleyDetector(window_size=5, threshold=0.2),\n",
        "                    'valley_dirs': None,\n",
        "                    'transformation': None,\n",
        "                    'gradient_norm_history': deque(maxlen=50),\n",
        "                    'consistency_history': deque(maxlen=50)\n",
        "                }\n",
        "\n",
        "                self._visualization_data['gradient_stats'][name] = deque(maxlen=max_visualization_points)\n",
        "\n",
        "                # Register gradient hook\n",
        "                p.register_hook(lambda grad, name=name: self._transform_gradient(grad, name))\n",
        "\n",
        "    def _transform_gradient(self, grad: torch.Tensor, name: str) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Transform gradient using learned topology information.\n",
        "\n",
        "        Args:\n",
        "            grad: Original gradient\n",
        "            name: Parameter name\n",
        "\n",
        "        Returns:\n",
        "            Transformed gradient\n",
        "        \"\"\"\n",
        "        if name not in self.param_data:\n",
        "            return grad\n",
        "\n",
        "        # Make a copy of original gradient\n",
        "        orig_grad = grad.clone()\n",
        "        flat_grad = grad.view(-1)\n",
        "\n",
        "        # Get parameter data\n",
        "        param_info = self.param_data[name]\n",
        "        transformation = param_info['transformation']\n",
        "\n",
        "        # If no transformation available, just return original\n",
        "        if transformation is None:\n",
        "            return grad\n",
        "\n",
        "        try:\n",
        "            # Update valley detector with current gradient\n",
        "            param_info['valley_detector'].update(flat_grad.detach().cpu())\n",
        "\n",
        "            # Store gradient norm\n",
        "            grad_norm = torch.norm(flat_grad).item()\n",
        "            param_info['gradient_norm_history'].append(grad_norm)\n",
        "\n",
        "            # Apply learned transformation\n",
        "            is_valley, valley_dir = param_info['valley_detector'].detect_valley()\n",
        "\n",
        "            if is_valley and valley_dir is not None:\n",
        "                # Record bifurcation point\n",
        "                if len(self.bifurcations) < self.max_stored_steps:\n",
        "                    self.bifurcations.append(self.steps)\n",
        "\n",
        "                # Store detection for visualization\n",
        "                self._visualization_data['valley_detections'].append(\n",
        "                    (self.steps, name, 'valley')\n",
        "                )\n",
        "\n",
        "                # Project valley direction to original space if needed\n",
        "                if valley_dir.shape[0] != flat_grad.shape[0]:\n",
        "                    # This would happen if we're using dimension reduction\n",
        "                    # We need an approximate mapping back to original space\n",
        "                    # For now, we just rely on the transformation matrix\n",
        "                    pass\n",
        "\n",
        "                # Transform the gradient\n",
        "                # First, compute the component in valley direction\n",
        "                valley_dir = valley_dir.to(self.device)\n",
        "                valley_component = torch.dot(flat_grad, valley_dir) * valley_dir\n",
        "\n",
        "                # Amplify the valley component\n",
        "                flat_grad = flat_grad + self.valley_strength * valley_component\n",
        "\n",
        "            # Apply curvature-based transformation\n",
        "            transformed_grad = torch.matmul(transformation, flat_grad.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "            # Check if transformation is reasonable\n",
        "            cos_sim = nn.functional.cosine_similarity(\n",
        "                transformed_grad.view(-1), orig_grad.view(-1), dim=0\n",
        "            )\n",
        "\n",
        "            # If very different from original, blend back\n",
        "            if cos_sim < 0.6:\n",
        "                blend_factor = 0.6 - cos_sim\n",
        "                transformed_grad = (1.0 - blend_factor) * transformed_grad.view_as(orig_grad) + blend_factor * orig_grad\n",
        "            else:\n",
        "                transformed_grad = transformed_grad.view_as(orig_grad)\n",
        "\n",
        "            # Safety check for NaN or Inf\n",
        "            if torch.isnan(transformed_grad).any() or torch.isinf(transformed_grad).any():\n",
        "                logger.warning(f\"NaN or Inf in transformed gradient for {name}\")\n",
        "                return orig_grad\n",
        "\n",
        "            return transformed_grad\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error transforming gradient for {name}: {e}\")\n",
        "            return orig_grad\n",
        "\n",
        "    def _update_topology(self) -> None:\n",
        "        \"\"\"Update topology information for all tracked parameters.\"\"\"\n",
        "        for name, param_info in self.param_data.items():\n",
        "            # Skip if not enough data\n",
        "            if len(param_info['gradient_norm_history']) < 3:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Get the covariance matrix\n",
        "                cov = param_info['covariance'].get_covariance()\n",
        "\n",
        "                # Adaptive regularization based on condition number\n",
        "                if self.adaptive_reg:\n",
        "                    try:\n",
        "                        eigs = torch.linalg.eigvalsh(cov)\n",
        "                        if eigs[0] > 0:  # Avoid division by zero\n",
        "                            condition_number = eigs[-1] / eigs[0]\n",
        "                            reg = max(1e-6, min(1e-2, 1e-5 * condition_number))\n",
        "                            cov = cov + reg * torch.eye(cov.shape[0], device=cov.device)\n",
        "                    except Exception:\n",
        "                        # Fallback: add standard regularization\n",
        "                        cov = cov + 1e-6 * torch.eye(cov.shape[0], device=cov.device)\n",
        "\n",
        "                # Use power iteration for more stable eigendecomposition\n",
        "                power_iter = PowerIteration(max_iter=20, tol=1e-5)\n",
        "                eigenvalues, eigenvectors = power_iter.compute_eigenpairs(cov, k=min(5, cov.shape[0]))\n",
        "\n",
        "                # Create transformation matrix for gradient adjustment\n",
        "                # This is like a preconditioner based on the eigenstructure\n",
        "                transform = torch.eye(cov.shape[0], device=cov.device)\n",
        "\n",
        "                for i, val in enumerate(eigenvalues):\n",
        "                    vec = eigenvectors[:, i].unsqueeze(1)\n",
        "                    abs_val = abs(val.item())\n",
        "\n",
        "                    if abs_val > 1.0:\n",
        "                        # Reduce step size in high-curvature directions\n",
        "                        scale = 1.0 / np.sqrt(abs_val) * self.smoothing_factor\n",
        "                    elif abs_val < 0.2:\n",
        "                        # Boost step size in flat regions\n",
        "                        scale = 1.5\n",
        "                    else:\n",
        "                        scale = 1.0\n",
        "\n",
        "                    transform += (scale - 1.0) * torch.matmul(vec, vec.t())\n",
        "\n",
        "                # Store transformation matrix\n",
        "                param_info['transformation'] = transform.to(self.device)\n",
        "\n",
        "                # Store top eigenvalues for visualization if needed\n",
        "                top_vals = eigenvalues[:min(3, len(eigenvalues))].detach().cpu().numpy()\n",
        "                self._visualization_data['gradient_stats'][name].append({\n",
        "                    'step': self.steps,\n",
        "                    'eigenvalues': top_vals,\n",
        "                    'grad_norm': np.mean([n for n in param_info['gradient_norm_history']])\n",
        "                })\n",
        "\n",
        "                # Clean up to avoid memory leaks\n",
        "                del cov, eigenvalues, eigenvectors, transform\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error updating topology for {name}: {e}\")\n",
        "\n",
        "    def _update_topology_async(self) -> None:\n",
        "        \"\"\"Update topology asynchronously.\"\"\"\n",
        "        if self._topology_update_future and not self._topology_update_future.done():\n",
        "            return\n",
        "\n",
        "        self._topology_update_future = self.executor.submit(self._update_topology)\n",
        "\n",
        "    def step(self, loss_fn: Callable, x: torch.Tensor, y: torch.Tensor) -> Tuple[float, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Perform an optimization step.\n",
        "\n",
        "        Args:\n",
        "            loss_fn: Loss function\n",
        "            x: Input data\n",
        "            y: Target data\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (loss value, model output)\n",
        "        \"\"\"\n",
        "        # Initialize timers\n",
        "        timings = {}\n",
        "        batch_start = time.time()\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        self.model.train()\n",
        "\n",
        "        # Forward pass\n",
        "        forward_start = time.time()\n",
        "        with autocast('cuda'):\n",
        "            out = self.model(x)\n",
        "            loss = loss_fn(out, y)\n",
        "        forward_time = time.time() - forward_start\n",
        "        timings['forward_pass'] = forward_time\n",
        "\n",
        "        # Backward pass\n",
        "        backward_start = time.time()\n",
        "        self.scaler.scale(loss).backward()\n",
        "        backward_time = time.time() - backward_start\n",
        "        timings['backward_pass'] = backward_time\n",
        "\n",
        "        # Store and analyze gradients periodically\n",
        "        grad_start = time.time()\n",
        "        if self.steps % self.store_interval == 0:\n",
        "            for name, p in self.model.named_parameters():\n",
        "                if p.grad is not None and name in self.param_data:\n",
        "                    flat_grad = p.grad.detach().view(-1)\n",
        "\n",
        "                    # Update covariance with projected gradient\n",
        "                    projected_grad = self.param_data[name]['projector'].project(flat_grad)\n",
        "                    self.param_data[name]['covariance'].update(projected_grad)\n",
        "        grad_time = time.time() - grad_start\n",
        "        timings['gradient_processing'] = grad_time\n",
        "\n",
        "        # Update parameters\n",
        "        optim_start = time.time()\n",
        "        self.scaler.step(self.optimizer)\n",
        "        self.scaler.update()\n",
        "        optim_time = time.time() - optim_start\n",
        "        timings['optimizer_step'] = optim_time\n",
        "\n",
        "        # Track progress\n",
        "        self.steps += 1\n",
        "        loss_value = loss.item()\n",
        "        self.loss_history.append(loss_value)\n",
        "        self._visualization_data['loss_values'].append(loss_value)\n",
        "\n",
        "        # Print progress\n",
        "        if self.steps % 10 == 0 or self.steps == 1:\n",
        "            # Current memory usage\n",
        "            if torch.cuda.is_available():\n",
        "                mem_allocated = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
        "                mem_reserved = torch.cuda.memory_reserved() / (1024 * 1024)  # MB\n",
        "                mem_str = f\"GPU: {mem_allocated:.1f}MB / {mem_reserved:.1f}MB\"\n",
        "            else:\n",
        "                process = psutil.Process(os.getpid())\n",
        "                mem_usage = process.memory_info().rss / (1024 * 1024)  # MB\n",
        "                mem_str = f\"RAM: {mem_usage:.1f}MB\"\n",
        "\n",
        "            print(f\"Step {self.steps:4d} | Loss: {loss_value:.6f} | {mem_str} | \"\n",
        "                  f\"F: {forward_time:.4f}s, B: {backward_time:.4f}s, O: {optim_time:.4f}s\")\n",
        "\n",
        "        # Update topology information periodically\n",
        "        topo_time = 0\n",
        "        if self.steps % self.update_interval == 0:\n",
        "            topo_start = time.time()\n",
        "            self._update_topology_async()\n",
        "            topo_time = time.time() - topo_start\n",
        "            timings['topology_update'] = topo_time\n",
        "\n",
        "            # Log topology update\n",
        "            print(f\"🔄 Topology update at step {self.steps} took {topo_time:.4f}s\")\n",
        "\n",
        "        # Periodic cleanup\n",
        "        if self.steps % 100 == 0:\n",
        "            cleanup_start = time.time()\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            cleanup_time = time.time() - cleanup_start\n",
        "\n",
        "            print(f\"🧹 Memory cleanup at step {self.steps} took {cleanup_time:.4f}s\")\n",
        "\n",
        "        # Total batch time\n",
        "        batch_time = time.time() - batch_start\n",
        "        timings['batch_total'] = batch_time\n",
        "\n",
        "        return loss_value, out\n",
        "\n",
        "    def shutdown(self) -> None:\n",
        "        \"\"\"Clean up resources.\"\"\"\n",
        "        # Cancel any pending tasks\n",
        "        if self._topology_update_future and not self._topology_update_future.done():\n",
        "            self._topology_update_future.cancel()\n",
        "\n",
        "        # Shut down executor\n",
        "        self.executor.shutdown(wait=False)\n",
        "\n",
        "        # Clear memory\n",
        "        self.param_data.clear()\n",
        "        self._visualization_data.clear()\n",
        "\n",
        "        # Force garbage collection\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# VISUALIZATION\n",
        "# ===================================\n",
        "\n",
        "class ImprovedTALTVisualizer:\n",
        "    \"\"\"Visualization utilities for the Improved TALT optimizer.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_results(\n",
        "        std_res: Dict[str, List[float]],\n",
        "        talt_res: Dict[str, List[float]],\n",
        "        save_path: Optional[str] = None,\n",
        "        show: bool = False\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Plot comparative results between standard and TALT optimizers.\n",
        "\n",
        "        Args:\n",
        "            std_res: Results from standard optimizer\n",
        "            talt_res: Results from TALT optimizer\n",
        "            save_path: Path to save the figure\n",
        "            show: Whether to display the figure\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        titles = [\"Train Loss\", \"Test Loss\", \"Train Acc\", \"Test Acc\"]\n",
        "\n",
        "        for i, (k1, k2) in enumerate([(\"train_loss\", \"train_acc\"), (\"test_loss\", \"test_acc\")], 1):\n",
        "            plt.subplot(2, 2, i * 1 - 1)\n",
        "            plt.plot(std_res[k1], label=\"Standard\")\n",
        "            plt.plot(talt_res[k1], label=\"Improved TALT\")\n",
        "            plt.title(titles[(i - 1) * 2])\n",
        "            plt.xlabel(\"Epoch\")\n",
        "            plt.ylabel(\"Loss\" if \"loss\" in k1 else \"Accuracy (%)\")\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "            plt.subplot(2, 2, i * 1)\n",
        "            plt.plot(std_res[k2], label=\"Standard\")\n",
        "            plt.plot(talt_res[k2], label=\"Improved TALT\")\n",
        "            plt.title(titles[(i - 1) * 2 + 1])\n",
        "            plt.xlabel(\"Epoch\")\n",
        "            plt.ylabel(\"Accuracy (%)\" if \"acc\" in k2 else \"Loss\")\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path)\n",
        "\n",
        "        if show:\n",
        "            plt.show()\n",
        "\n",
        "        # Close the figure to free memory\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def visualize_valley_detections(\n",
        "        talt_opt: ImprovedTALTOptimizer,\n",
        "        save_path: Optional[str] = None,\n",
        "        show: bool = False\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Visualize valley detections.\n",
        "\n",
        "        Args:\n",
        "            talt_opt: Improved TALT optimizer instance\n",
        "            save_path: Path to save the figure\n",
        "            show: Whether to display the figure\n",
        "        \"\"\"\n",
        "        if not talt_opt._visualization_data['valley_detections']:\n",
        "            logger.warning(\"No valley detection data available\")\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Plot loss history\n",
        "        loss_history = list(talt_opt.loss_history)\n",
        "        steps = range(len(loss_history))\n",
        "        plt.plot(steps, loss_history, label=\"Loss\", alpha=0.7)\n",
        "\n",
        "        # Mark valley detections\n",
        "        valley_steps = [det[0] for det in talt_opt._visualization_data['valley_detections']\n",
        "                      if det[0] < len(loss_history)]\n",
        "\n",
        "        for step in valley_steps:\n",
        "            plt.axvline(step, color=\"r\", linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "        # Add bifurcation points with labels\n",
        "        bifurcations = [b for b in talt_opt.bifurcations if b < len(loss_history)]\n",
        "        if bifurcations:\n",
        "            for i, step in enumerate(bifurcations):\n",
        "                if i < 5:  # Only label the first few for clarity\n",
        "                    plt.axvline(step, color=\"g\", linestyle=\"-\", alpha=0.5,\n",
        "                               label=\"Valley\" if i == 0 else \"\")\n",
        "                else:\n",
        "                    plt.axvline(step, color=\"g\", linestyle=\"-\", alpha=0.5)\n",
        "\n",
        "        plt.title(\"Loss Landscape with Valley Detections\")\n",
        "        plt.xlabel(\"Step\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path)\n",
        "\n",
        "        if show:\n",
        "            plt.show()\n",
        "\n",
        "        # Close the figure\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def visualize_gradient_statistics(\n",
        "        talt_opt: ImprovedTALTOptimizer,\n",
        "        save_path: Optional[str] = None,\n",
        "        show: bool = False\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Visualize gradient statistics.\n",
        "\n",
        "        Args:\n",
        "            talt_opt: Improved TALT optimizer instance\n",
        "            save_path: Path to save the figure\n",
        "            show: Whether to display the figure\n",
        "        \"\"\"\n",
        "        # Check if we have data to visualize\n",
        "        if not talt_opt._visualization_data['gradient_stats']:\n",
        "            logger.warning(\"No gradient statistics available\")\n",
        "            return\n",
        "\n",
        "        # Select a few parameters to visualize\n",
        "        param_names = list(talt_opt._visualization_data['gradient_stats'].keys())\n",
        "        if not param_names:\n",
        "            return\n",
        "\n",
        "        # Create subplots\n",
        "        fig, axes = plt.subplots(min(3, len(param_names)), 2, figsize=(14, 12))\n",
        "\n",
        "        # Handle case where we have only one parameter\n",
        "        if len(param_names) == 1:\n",
        "            axes = np.array([axes])\n",
        "\n",
        "        for i, name in enumerate(param_names[:3]):  # Show up to 3 parameters\n",
        "            stats = list(talt_opt._visualization_data['gradient_stats'][name])\n",
        "            if not stats:\n",
        "                continue\n",
        "\n",
        "            # Extract data\n",
        "            steps = [stat['step'] for stat in stats]\n",
        "            eigenvalues = [stat['eigenvalues'] for stat in stats]\n",
        "            grad_norms = [stat['grad_norm'] for stat in stats]\n",
        "\n",
        "            # Plot eigenvalues\n",
        "            for j in range(min(3, len(eigenvalues[0]))):\n",
        "                eig_j = [eig[j] for eig in eigenvalues]\n",
        "                axes[i, 0].plot(steps, eig_j, label=f\"λ{j+1}\")\n",
        "\n",
        "            axes[i, 0].set_title(f\"Eigenvalues: {name}\")\n",
        "            axes[i, 0].set_xlabel(\"Step\")\n",
        "            axes[i, 0].set_ylabel(\"Eigenvalue\")\n",
        "            axes[i, 0].legend()\n",
        "            axes[i, 0].grid(True, alpha=0.3)\n",
        "\n",
        "            # Plot gradient norms\n",
        "            axes[i, 1].plot(steps, grad_norms, label=\"Gradient Norm\")\n",
        "            axes[i, 1].set_title(f\"Gradient Norm: {name}\")\n",
        "            axes[i, 1].set_xlabel(\"Step\")\n",
        "            axes[i, 1].set_ylabel(\"Norm\")\n",
        "            axes[i, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path)\n",
        "\n",
        "        if show:\n",
        "            plt.show()\n",
        "\n",
        "        # Close the figure\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# TRAINING FUNCTIONS\n",
        "# ===================================\n",
        "\n",
        "def get_loaders(\n",
        "    dataset_name: str,\n",
        "    batch_size: int = 128\n",
        ") -> Tuple[DataLoader, DataLoader, int, int]:\n",
        "    \"\"\"\n",
        "    Get data loaders for the specified dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset_name: Name of the dataset (\"MNIST\" or \"CIFAR10\")\n",
        "        batch_size: Batch size\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (train_loader, test_loader, num_channels, image_size)\n",
        "    \"\"\"\n",
        "    if dataset_name.upper() == \"MNIST\":\n",
        "        num_channels = 1\n",
        "        image_size = 28\n",
        "        dataset_class = datasets.MNIST\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "    elif dataset_name.upper() == \"CIFAR10\":\n",
        "        num_channels = 3\n",
        "        image_size = 32\n",
        "        dataset_class = datasets.CIFAR10\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
        "\n",
        "    # Load datasets\n",
        "    train_dataset = dataset_class(\"./data\", train=True, download=True, transform=transform)\n",
        "    test_dataset = dataset_class(\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader, num_channels, image_size\n",
        "\n",
        "\n",
        "def _train_epoch(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    loss_fn: nn.Module,\n",
        "    optimizer: optim.Optimizer,\n",
        "    device: torch.device,\n",
        "    epoch: int\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Train for one epoch with a standard optimizer.\n",
        "\n",
        "    Args:\n",
        "        model: Model to train\n",
        "        loader: Data loader\n",
        "        loss_fn: Loss function\n",
        "        optimizer: Optimizer\n",
        "        device: Device to train on\n",
        "        epoch: Current epoch number\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (average loss, accuracy)\n",
        "    \"\"\"\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Timing statistics\n",
        "    forward_times = []\n",
        "    backward_times = []\n",
        "    optim_times = []\n",
        "    batch_times = []\n",
        "\n",
        "    # Print epoch header\n",
        "    print(f\"\\n{'='*20} STANDARD OPTIMIZER - EPOCH {epoch} {'='*20}\")\n",
        "    print(f\"Device: {device}, Batches: {len(loader)}, Batch size: {loader.batch_size}\")\n",
        "    print_memory_usage(\"Initial \")\n",
        "\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        batch_start = time.time()\n",
        "\n",
        "        # Transfer data to device\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        forward_start = time.time()\n",
        "        outputs = model(x)\n",
        "        loss = loss_fn(outputs, y)\n",
        "        forward_time = time.time() - forward_start\n",
        "        forward_times.append(forward_time)\n",
        "\n",
        "        # Backward pass\n",
        "        backward_start = time.time()\n",
        "        loss.backward()\n",
        "        backward_time = time.time() - backward_start\n",
        "        backward_times.append(backward_time)\n",
        "\n",
        "        # Update parameters\n",
        "        optim_start = time.time()\n",
        "        optimizer.step()\n",
        "        optim_time = time.time() - optim_start\n",
        "        optim_times.append(optim_time)\n",
        "\n",
        "        # Update metrics\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += y.size(0)\n",
        "        correct += predicted.eq(y).sum().item()\n",
        "\n",
        "        # Record batch time\n",
        "        batch_time = time.time() - batch_start\n",
        "        batch_times.append(batch_time)\n",
        "\n",
        "        # Detailed logging every few batches\n",
        "        if idx % 20 == 0 or idx == len(loader) - 1:\n",
        "            progress = idx / len(loader) * 100\n",
        "            accuracy = 100.0 * correct / total\n",
        "            avg_loss = total_loss / (idx + 1)\n",
        "\n",
        "            # Current memory usage\n",
        "            if torch.cuda.is_available():\n",
        "                mem_allocated = torch.cuda.memory_allocated() / (1024 * 1024)  # MB\n",
        "                mem_str = f\"GPU: {mem_allocated:.1f}MB\"\n",
        "            else:\n",
        "                process = psutil.Process(os.getpid())\n",
        "                mem_usage = process.memory_info().rss / (1024 * 1024)  # MB\n",
        "                mem_str = f\"RAM: {mem_usage:.1f}MB\"\n",
        "\n",
        "            print(f\"Batch {idx:4d}/{len(loader):4d} ({progress:5.1f}%) | \"\n",
        "                  f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}% | \"\n",
        "                  f\"{mem_str} | Batch time: {batch_time:.4f}s\")\n",
        "\n",
        "        # Free memory every few batches\n",
        "        if idx % 20 == 0 and idx > 0:\n",
        "            del outputs, predicted\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Calculate final metrics\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    avg_forward = sum(forward_times) / len(forward_times)\n",
        "    avg_backward = sum(backward_times) / len(backward_times)\n",
        "    avg_optim = sum(optim_times) / len(optim_times)\n",
        "    avg_batch = sum(batch_times) / len(batch_times)\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f\"\\n{'-'*20} STANDARD OPTIMIZER - SUMMARY {'-'*20}\")\n",
        "    print(f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Time: {epoch_time:.2f}s total, {avg_batch:.4f}s per batch\")\n",
        "    print(f\"  - Forward: {avg_forward:.4f}s, Backward: {avg_backward:.4f}s, Optimizer: {avg_optim:.4f}s\")\n",
        "    print_memory_usage(\"Final \")\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def _train_epoch_improved_talt(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    loss_fn: nn.Module,\n",
        "    optimizer: ImprovedTALTOptimizer,\n",
        "    device: torch.device,\n",
        "    epoch: int\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Train for one epoch with the improved TALT optimizer.\n",
        "\n",
        "    Args:\n",
        "        model: Model to train\n",
        "        loader: Data loader\n",
        "        loss_fn: Loss function\n",
        "        optimizer: Improved TALT optimizer\n",
        "        device: Device to train on\n",
        "        epoch: Current epoch number\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (average loss, accuracy)\n",
        "    \"\"\"\n",
        "    # Initialize tracking\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batch_times = []\n",
        "\n",
        "    # Create performance tracker\n",
        "    perf_tracker = PerformanceTracker()\n",
        "\n",
        "    # Print epoch header\n",
        "    print(f\"\\n{'='*20} EPOCH {epoch} TRAINING {'='*20}\")\n",
        "    print(f\"Device: {device}, Batches: {len(loader)}, Batch size: {loader.batch_size}\")\n",
        "    print_memory_usage(\"Initial \")\n",
        "\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    # Process in smaller chunks to avoid memory buildup\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        batch_start = time.time()\n",
        "\n",
        "        try:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # Perform optimization step (timing is handled inside)\n",
        "            loss, outputs = optimizer.step(loss_fn, x, y)\n",
        "\n",
        "            # Update metrics\n",
        "            total_loss += loss\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += y.size(0)\n",
        "            correct += predicted.eq(y).sum().item()\n",
        "\n",
        "            # Record batch time\n",
        "            batch_time = time.time() - batch_start\n",
        "            batch_times.append(batch_time)\n",
        "\n",
        "            # Detailed logging every few batches\n",
        "            if idx % 20 == 0:\n",
        "                progress = idx / len(loader) * 100\n",
        "                accuracy = 100.0 * correct / total if total > 0 else 0.0\n",
        "                avg_loss = total_loss / (idx + 1)\n",
        "\n",
        "                print(f\"Batch {idx:4d}/{len(loader):4d} ({progress:5.1f}%) | \"\n",
        "                      f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}% | \"\n",
        "                      f\"Batch time: {batch_time:.4f}s\")\n",
        "\n",
        "                # Record memory usage\n",
        "                perf_tracker.record_memory()\n",
        "\n",
        "            # Periodically free up memory\n",
        "            if idx % 20 == 0:\n",
        "                # Move tensors back to CPU or delete them\n",
        "                del outputs, predicted\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in improved TALT training step: {e}\")\n",
        "            # Continue training despite errors\n",
        "            continue\n",
        "\n",
        "    # Calculate final metrics\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = 100.0 * correct / total if total > 0 else 0.0\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    avg_batch_time = sum(batch_times) / len(batch_times) if batch_times else 0\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f\"\\n{'-'*20} EPOCH {epoch} SUMMARY {'-'*20}\")\n",
        "    print(f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Time: {epoch_time:.2f}s total, {avg_batch_time:.4f}s per batch\")\n",
        "    print_memory_usage(\"Final \")\n",
        "    perf_tracker.print_summary()\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def _evaluate(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    loss_fn: nn.Module,\n",
        "    device: torch.device\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Evaluate the model.\n",
        "\n",
        "    Args:\n",
        "        model: Model to evaluate\n",
        "        loader: Data loader\n",
        "        loss_fn: Loss function\n",
        "        device: Device to evaluate on\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (average loss, accuracy)\n",
        "    \"\"\"\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    batch_times = []\n",
        "\n",
        "    # Print evaluation header\n",
        "    print(f\"\\n{'='*20} EVALUATION {'='*20}\")\n",
        "    print(f\"Device: {device}, Batches: {len(loader)}, Batch size: {loader.batch_size}\")\n",
        "\n",
        "    eval_start = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (x, y) in enumerate(loader):\n",
        "            batch_start = time.time()\n",
        "\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(x)\n",
        "            loss = loss_fn(outputs, y)\n",
        "\n",
        "            # Update metrics\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += y.size(0)\n",
        "            correct += predicted.eq(y).sum().item()\n",
        "\n",
        "            # Record batch time\n",
        "            batch_time = time.time() - batch_start\n",
        "            batch_times.append(batch_time)\n",
        "\n",
        "            # Detailed logging every few batches\n",
        "            if idx % 50 == 0 and idx > 0:\n",
        "                progress = idx / len(loader) * 100\n",
        "                accuracy = 100.0 * correct / total\n",
        "                avg_loss = total_loss / (idx + 1)\n",
        "\n",
        "                print(f\"Batch {idx:4d}/{len(loader):4d} ({progress:5.1f}%) | \"\n",
        "                      f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}% | \"\n",
        "                      f\"Batch time: {batch_time:.4f}s\")\n",
        "\n",
        "            # Free memory every few batches\n",
        "            if idx % 50 == 0 and idx > 0:\n",
        "                del outputs, predicted\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    # Calculate final metrics\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    eval_time = time.time() - eval_start\n",
        "    avg_batch_time = sum(batch_times) / len(batch_times) if batch_times else 0\n",
        "\n",
        "    # Print evaluation summary\n",
        "    print(f\"\\n{'-'*20} EVALUATION SUMMARY {'-'*20}\")\n",
        "    print(f\"Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Time: {eval_time:.2f}s total, {avg_batch_time:.4f}s per batch\")\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def train_and_evaluate_improved(\n",
        "    dataset_name: str,\n",
        "    epochs: int = 5,\n",
        "    batch_size: int = 16,\n",
        "    device: Union[str, torch.device] = \"cuda\",\n",
        "    visualize: bool = False,\n",
        "    save_plots: bool = True,\n",
        "    plots_dir: str = \"./plots\"\n",
        ") -> Tuple[Dict[str, Dict[str, List[float]]], ImprovedTALTOptimizer]:\n",
        "    \"\"\"\n",
        "    Train and evaluate models with standard and improved TALT optimizers.\n",
        "\n",
        "    Args:\n",
        "        dataset_name: Name of the dataset (\"MNIST\" or \"CIFAR10\")\n",
        "        epochs: Number of epochs to train\n",
        "        batch_size: Batch size\n",
        "        device: Device to train on\n",
        "        visualize: Whether to display visualizations\n",
        "        save_plots: Whether to save plots to disk\n",
        "        plots_dir: Directory to save plots\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (results dictionary, ImprovedTALTOptimizer instance)\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*30} TRAINING ON {dataset_name} {'='*30}\")\n",
        "    print(f\"Configuration: epochs={epochs}, batch_size={batch_size}, device={device}\")\n",
        "\n",
        "    # Create plots directory if needed\n",
        "    if save_plots and not os.path.exists(plots_dir):\n",
        "        os.makedirs(plots_dir)\n",
        "        print(f\"Created plots directory: {plots_dir}\")\n",
        "\n",
        "    # Ensure device is a torch.device\n",
        "    device = device if isinstance(device, torch.device) else torch.device(device)\n",
        "\n",
        "    # Initialize timers\n",
        "    total_start_time = time.time()\n",
        "    data_loading_start = time.time()\n",
        "\n",
        "    # Get data loaders\n",
        "    print(\"Loading datasets...\")\n",
        "    train_loader, test_loader, num_channels, image_size = get_loaders(dataset_name, batch_size)\n",
        "    data_loading_time = time.time() - data_loading_start\n",
        "    print(f\"Datasets loaded in {data_loading_time:.2f}s\")\n",
        "    print(f\"Train set: {len(train_loader.dataset)} samples, {len(train_loader)} batches\")\n",
        "    print(f\"Test set: {len(test_loader.dataset)} samples, {len(test_loader)} batches\")\n",
        "\n",
        "    # Print initial memory usage\n",
        "    print_memory_usage(\"After data loading \")\n",
        "\n",
        "    # Initialize models\n",
        "    print(\"Initializing models...\")\n",
        "    model_init_start = time.time()\n",
        "    model_std = SimpleCNN(num_channels=num_channels, image_size=image_size).to(device)\n",
        "    model_talt = SimpleCNN(num_channels=num_channels, image_size=image_size).to(device)\n",
        "    model_init_time = time.time() - model_init_start\n",
        "    print(f\"Models initialized in {model_init_time:.2f}s\")\n",
        "\n",
        "    # Count parameters\n",
        "    std_params = sum(p.numel() for p in model_std.parameters())\n",
        "    talt_params = sum(p.numel() for p in model_talt.parameters())\n",
        "    print(f\"Standard model parameters: {std_params:,}\")\n",
        "    print(f\"TALT model parameters: {talt_params:,}\")\n",
        "\n",
        "    # Loss function\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimizers\n",
        "    print(\"Setting up optimizers...\")\n",
        "    opt_init_start = time.time()\n",
        "    opt_std = optim.SGD(model_std.parameters(), lr=0.01, momentum=0.9)\n",
        "    opt_talt = ImprovedTALTOptimizer(\n",
        "        model_talt,\n",
        "        optim.SGD,\n",
        "        lr=0.01,\n",
        "        projection_dim=32,  # Reduce dimensions for efficiency\n",
        "        memory_size=10,\n",
        "        update_interval=20,\n",
        "        valley_strength=0.2,\n",
        "        smoothing_factor=0.3,\n",
        "        grad_store_interval=5,\n",
        "        device=device,\n",
        "        max_stored_steps=500,\n",
        "        max_visualization_points=100\n",
        "    )\n",
        "    opt_init_time = time.time() - opt_init_start\n",
        "    print(f\"Optimizers set up in {opt_init_time:.2f}s\")\n",
        "\n",
        "    # Print initial memory usage\n",
        "    print_memory_usage(\"Before training \")\n",
        "\n",
        "    # Results tracking\n",
        "    results = {\n",
        "        \"standard\": {\"train_loss\": [], \"test_loss\": [], \"train_acc\": [], \"test_acc\": []},\n",
        "        \"talt\": {\"train_loss\": [], \"test_loss\": [], \"train_acc\": [], \"test_acc\": []},\n",
        "    }\n",
        "\n",
        "    # Training loop\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"STARTING TRAINING FOR {epochs} EPOCHS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # Train standard model\n",
        "        print(f\"\\n{'-'*25} Standard Model: Epoch {epoch}/{epochs} {'-'*25}\")\n",
        "        model_std.train()\n",
        "        with Timer(\"Standard model training\"):\n",
        "            std_train_loss, std_train_acc = _train_epoch(\n",
        "                model_std, train_loader, loss_fn, opt_std, device, epoch\n",
        "            )\n",
        "        results[\"standard\"][\"train_loss\"].append(std_train_loss)\n",
        "        results[\"standard\"][\"train_acc\"].append(std_train_acc)\n",
        "\n",
        "        # Train improved TALT model\n",
        "        print(f\"\\n{'-'*25} Improved TALT Model: Epoch {epoch}/{epochs} {'-'*25}\")\n",
        "        model_talt.train()\n",
        "        with Timer(\"TALT model training\"):\n",
        "            talt_train_loss, talt_train_acc = _train_epoch_improved_talt(\n",
        "                model_talt, train_loader, loss_fn, opt_talt, device, epoch\n",
        "            )\n",
        "        results[\"talt\"][\"train_loss\"].append(talt_train_loss)\n",
        "        results[\"talt\"][\"train_acc\"].append(talt_train_acc)\n",
        "\n",
        "        # Memory cleanup\n",
        "        print(\"\\nCleaning up memory after training...\")\n",
        "        with Timer(\"Memory cleanup\"):\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "        print_memory_usage(\"After training \")\n",
        "\n",
        "        # Evaluate standard model\n",
        "        print(f\"\\n{'-'*25} Standard Model: Evaluation {'-'*25}\")\n",
        "        model_std.eval()\n",
        "        with Timer(\"Standard model evaluation\"):\n",
        "            std_test_loss, std_test_acc = _evaluate(\n",
        "                model_std, test_loader, loss_fn, device\n",
        "            )\n",
        "        results[\"standard\"][\"test_loss\"].append(std_test_loss)\n",
        "        results[\"standard\"][\"test_acc\"].append(std_test_acc)\n",
        "\n",
        "        # Evaluate TALT model\n",
        "        print(f\"\\n{'-'*25} Improved TALT Model: Evaluation {'-'*25}\")\n",
        "        model_talt.eval()\n",
        "        with Timer(\"TALT model evaluation\"):\n",
        "            talt_test_loss, talt_test_acc = _evaluate(\n",
        "                model_talt, test_loader, loss_fn, device\n",
        "            )\n",
        "        results[\"talt\"][\"test_loss\"].append(talt_test_loss)\n",
        "        results[\"talt\"][\"test_acc\"].append(talt_test_acc)\n",
        "\n",
        "        # Epoch summary\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        print(f\"\\n{'-'*25} EPOCH {epoch} SUMMARY {'-'*25}\")\n",
        "        print(f\"Time: {epoch_time:.2f}s\")\n",
        "        print(\"Standard Model:\")\n",
        "        print(f\"  - Train Loss: {std_train_loss:.6f}, Accuracy: {std_train_acc:.2f}%\")\n",
        "        print(f\"  - Test Loss:  {std_test_loss:.6f}, Accuracy: {std_test_acc:.2f}%\")\n",
        "        print(\"Improved TALT Model:\")\n",
        "        print(f\"  - Train Loss: {talt_train_loss:.6f}, Accuracy: {talt_train_acc:.2f}%\")\n",
        "        print(f\"  - Test Loss:  {talt_test_loss:.6f}, Accuracy: {talt_test_acc:.2f}%\")\n",
        "\n",
        "        # Print performance comparison\n",
        "        std_perf = std_test_acc / std_train_acc if std_train_acc > 0 else 0\n",
        "        talt_perf = talt_test_acc / talt_train_acc if talt_train_acc > 0 else 0\n",
        "\n",
        "        if talt_test_acc > std_test_acc:\n",
        "            diff = talt_test_acc - std_test_acc\n",
        "            print(f\"\\n📈 TALT outperforms standard by {diff:.2f}% on test accuracy\")\n",
        "\n",
        "        if talt_perf > std_perf:\n",
        "            print(f\"📈 TALT shows better generalization (test/train ratio: {talt_perf:.3f} vs {std_perf:.3f})\")\n",
        "\n",
        "        # Memory cleanup after each epoch\n",
        "        print(\"\\nCleaning up memory after epoch...\")\n",
        "        with Timer(\"Memory cleanup\"):\n",
        "            gc.collect()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "        print_memory_usage(\"After epoch \")\n",
        "\n",
        "    # Training complete\n",
        "    total_time = time.time() - total_start_time\n",
        "\n",
        "    print(f\"\\n{'='*30} TRAINING COMPLETED {'='*30}\")\n",
        "    print(f\"Total training time: {total_time:.2f}s\")\n",
        "    print(f\"Final results on {dataset_name}:\")\n",
        "    print(f\"Standard Model: {std_test_acc:.2f}% test accuracy\")\n",
        "    print(f\"Improved TALT: {talt_test_acc:.2f}% test accuracy\")\n",
        "\n",
        "    if talt_test_acc > std_test_acc:\n",
        "        print(f\"✅ Improved TALT outperformed standard by {talt_test_acc - std_test_acc:.2f}%\")\n",
        "    else:\n",
        "        print(f\"❌ Standard model outperformed Improved TALT by {std_test_acc - talt_test_acc:.2f}%\")\n",
        "\n",
        "    # Save visualizations\n",
        "    if save_plots:\n",
        "        print(\"\\nSaving visualizations to disk...\")\n",
        "\n",
        "        # Create directory if it doesn't exist\n",
        "        if not os.path.exists(plots_dir):\n",
        "            os.makedirs(plots_dir)\n",
        "\n",
        "        # Define paths for plots\n",
        "        results_path = f\"{plots_dir}/{dataset_name}_results.png\"\n",
        "        valleys_path = f\"{plots_dir}/{dataset_name}_valleys.png\"\n",
        "        gradients_path = f\"{plots_dir}/{dataset_name}_gradients.png\"\n",
        "\n",
        "        # Save plots\n",
        "        with Timer(\"Saving comparative results plot\"):\n",
        "            ImprovedTALTVisualizer.plot_results(\n",
        "                results[\"standard\"], results[\"talt\"],\n",
        "                save_path=results_path, show=visualize\n",
        "            )\n",
        "\n",
        "        with Timer(\"Saving valley detections plot\"):\n",
        "            ImprovedTALTVisualizer.visualize_valley_detections(\n",
        "                opt_talt, save_path=valleys_path, show=visualize\n",
        "            )\n",
        "\n",
        "        with Timer(\"Saving gradient statistics plot\"):\n",
        "            ImprovedTALTVisualizer.visualize_gradient_statistics(\n",
        "                opt_talt, save_path=gradients_path, show=visualize\n",
        "            )\n",
        "\n",
        "        print(f\"Plots saved to {plots_dir}\")\n",
        "\n",
        "    # Clean up resources\n",
        "    print(\"\\nShutting down optimizers and cleaning up...\")\n",
        "    opt_talt.shutdown()\n",
        "\n",
        "    # Final memory cleanup\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    print_memory_usage(\"Final \")\n",
        "\n",
        "    return results, opt_talt\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# MAIN ENTRY POINT\n",
        "# ===================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Check for CUDA availability\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logger.info(f\"Using device: {device}\")\n",
        "\n",
        "    # Set torch memory management options\n",
        "    if torch.cuda.is_available():\n",
        "        # Clear cache\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Limit memory usage\n",
        "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128,garbage_collection_threshold:0.6'\n",
        "\n",
        "        try:\n",
        "            # Limit GPU memory fraction\n",
        "            torch.cuda.set_per_process_memory_fraction(0.5)\n",
        "        except Exception:\n",
        "            logger.info(\"Per-process memory fraction setting not available\")\n",
        "\n",
        "    try:\n",
        "        # Train on MNIST with improved optimizer\n",
        "        logger.info(\"Starting MNIST training with improved TALT optimizer\")\n",
        "        train_and_evaluate_improved(\n",
        "            \"MNIST\",\n",
        "            epochs=3,\n",
        "            batch_size=16,\n",
        "            device=device,\n",
        "            visualize=False,\n",
        "            save_plots=True,\n",
        "            plots_dir=\"./plots/improved_mnist\"\n",
        "        )\n",
        "\n",
        "        # Clear memory before starting CIFAR10\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        logger.info(\"Memory cleared successfully after MNIST\")\n",
        "\n",
        "        # Train on CIFAR10 if MNIST succeeds\n",
        "        logger.info(\"Starting CIFAR10 training with improved TALT optimizer\")\n",
        "        train_and_evaluate_improved(\n",
        "            \"CIFAR10\",\n",
        "            epochs=3,\n",
        "            batch_size=16,\n",
        "            device=device,\n",
        "            visualize=False,\n",
        "            save_plots=True,\n",
        "            plots_dir=\"./plots/improved_cifar10\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during training: {e}\")\n",
        "        # Clean up on error\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CB95pOTKvCkX",
        "outputId": "9eef9c0c-84a5-47fe-d69a-8e2575d5e51a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================== TRAINING ON MNIST ==============================\n",
            "Configuration: epochs=3, batch_size=16, device=cuda\n",
            "Loading datasets...\n",
            "Datasets loaded in 0.13s\n",
            "Train set: 60000 samples, 3750 batches\n",
            "Test set: 10000 samples, 625 batches\n",
            "🔄 After data loading Memory - RAM: 1307.4MB, GPU: 16.2MB allocated, 40.0MB reserved\n",
            "Initializing models...\n",
            "Models initialized in 0.01s\n",
            "Standard model parameters: 421,834\n",
            "TALT model parameters: 421,834\n",
            "Setting up optimizers...\n",
            "Optimizers set up in 0.66s\n",
            "🔄 Before training Memory - RAM: 1368.7MB, GPU: 19.5MB allocated, 42.0MB reserved\n",
            "\n",
            "======================================================================\n",
            "STARTING TRAINING FOR 3 EPOCHS\n",
            "======================================================================\n",
            "\n",
            "------------------------- Standard Model: Epoch 1/3 -------------------------\n",
            "\n",
            "==================== STANDARD OPTIMIZER - EPOCH 1 ====================\n",
            "Device: cuda, Batches: 3750, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 1368.7MB, GPU: 19.5MB allocated, 42.0MB reserved\n",
            "Batch    0/3750 (  0.0%) | Loss: 2.315766 | Accuracy: 6.25% | GPU: 22.8MB | Batch time: 0.0204s\n",
            "Batch   20/3750 (  0.5%) | Loss: 2.002214 | Accuracy: 31.55% | GPU: 22.8MB | Batch time: 0.0035s\n",
            "Batch   40/3750 (  1.1%) | Loss: 1.737172 | Accuracy: 40.55% | GPU: 22.8MB | Batch time: 0.0038s\n",
            "Batch   60/3750 (  1.6%) | Loss: 1.611757 | Accuracy: 43.95% | GPU: 22.8MB | Batch time: 0.0049s\n",
            "Batch   80/3750 (  2.1%) | Loss: 1.510901 | Accuracy: 48.07% | GPU: 22.8MB | Batch time: 0.0040s\n",
            "Batch  100/3750 (  2.7%) | Loss: 1.447313 | Accuracy: 50.93% | GPU: 22.8MB | Batch time: 0.0051s\n",
            "Batch  120/3750 (  3.2%) | Loss: 1.387837 | Accuracy: 52.94% | GPU: 22.8MB | Batch time: 0.0047s\n",
            "Batch  140/3750 (  3.7%) | Loss: 1.352961 | Accuracy: 53.99% | GPU: 22.8MB | Batch time: 0.0055s\n",
            "Batch  160/3750 (  4.3%) | Loss: 1.307195 | Accuracy: 55.59% | GPU: 22.8MB | Batch time: 0.0079s\n",
            "Batch  180/3750 (  4.8%) | Loss: 1.268691 | Accuracy: 56.84% | GPU: 22.8MB | Batch time: 0.0037s\n",
            "Batch  200/3750 (  5.3%) | Loss: 1.262707 | Accuracy: 57.03% | GPU: 22.8MB | Batch time: 0.0035s\n",
            "Batch  220/3750 (  5.9%) | Loss: 1.245071 | Accuracy: 57.75% | GPU: 22.8MB | Batch time: 0.0047s\n",
            "Batch  240/3750 (  6.4%) | Loss: 1.225105 | Accuracy: 58.43% | GPU: 22.8MB | Batch time: 0.0056s\n",
            "Batch  260/3750 (  6.9%) | Loss: 1.198791 | Accuracy: 59.36% | GPU: 22.8MB | Batch time: 0.0037s\n",
            "Batch  280/3750 (  7.5%) | Loss: 1.179315 | Accuracy: 60.34% | GPU: 22.8MB | Batch time: 0.0034s\n",
            "Batch  300/3750 (  8.0%) | Loss: 1.162395 | Accuracy: 60.94% | GPU: 22.8MB | Batch time: 0.0048s\n",
            "Batch  320/3750 (  8.5%) | Loss: 1.158652 | Accuracy: 61.23% | GPU: 22.8MB | Batch time: 0.0048s\n",
            "Batch  340/3750 (  9.1%) | Loss: 1.153356 | Accuracy: 61.53% | GPU: 22.8MB | Batch time: 0.0035s\n",
            "Batch  360/3750 (  9.6%) | Loss: 1.140574 | Accuracy: 62.02% | GPU: 22.8MB | Batch time: 0.0065s\n",
            "Batch  380/3750 ( 10.1%) | Loss: 1.126266 | Accuracy: 62.47% | GPU: 22.8MB | Batch time: 0.0069s\n",
            "Batch  400/3750 ( 10.7%) | Loss: 1.115176 | Accuracy: 62.89% | GPU: 22.8MB | Batch time: 0.0035s\n",
            "Batch  420/3750 ( 11.2%) | Loss: 1.097799 | Accuracy: 63.45% | GPU: 22.8MB | Batch time: 0.0037s\n",
            "Batch  440/3750 ( 11.7%) | Loss: 1.087311 | Accuracy: 63.95% | GPU: 22.8MB | Batch time: 0.0048s\n",
            "Batch  460/3750 ( 12.3%) | Loss: 1.074633 | Accuracy: 64.36% | GPU: 22.8MB | Batch time: 0.0070s\n",
            "Batch  480/3750 ( 12.8%) | Loss: 1.064621 | Accuracy: 64.79% | GPU: 22.8MB | Batch time: 0.0053s\n",
            "Batch  500/3750 ( 13.3%) | Loss: 1.059271 | Accuracy: 65.17% | GPU: 22.8MB | Batch time: 0.0085s\n",
            "Batch  520/3750 ( 13.9%) | Loss: 1.051970 | Accuracy: 65.37% | GPU: 22.8MB | Batch time: 0.0038s\n",
            "Batch  540/3750 ( 14.4%) | Loss: 1.047548 | Accuracy: 65.67% | GPU: 22.8MB | Batch time: 0.0058s\n",
            "Batch  560/3750 ( 14.9%) | Loss: 1.039712 | Accuracy: 65.94% | GPU: 22.8MB | Batch time: 0.0055s\n",
            "Batch  580/3750 ( 15.5%) | Loss: 1.032273 | Accuracy: 66.18% | GPU: 22.8MB | Batch time: 0.0036s\n",
            "Batch  600/3750 ( 16.0%) | Loss: 1.018397 | Accuracy: 66.66% | GPU: 22.8MB | Batch time: 0.0053s\n",
            "Batch  620/3750 ( 16.5%) | Loss: 1.006463 | Accuracy: 67.04% | GPU: 22.8MB | Batch time: 0.0036s\n",
            "Batch  640/3750 ( 17.1%) | Loss: 0.995263 | Accuracy: 67.51% | GPU: 22.8MB | Batch time: 0.0053s\n",
            "Batch  660/3750 ( 17.6%) | Loss: 0.987006 | Accuracy: 67.84% | GPU: 22.8MB | Batch time: 0.0032s\n",
            "Batch  680/3750 ( 18.1%) | Loss: 0.978023 | Accuracy: 68.14% | GPU: 22.8MB | Batch time: 0.0038s\n",
            "Batch  700/3750 ( 18.7%) | Loss: 0.970927 | Accuracy: 68.44% | GPU: 22.8MB | Batch time: 0.0046s\n",
            "Batch  720/3750 ( 19.2%) | Loss: 0.963714 | Accuracy: 68.64% | GPU: 22.8MB | Batch time: 0.0070s\n",
            "Batch  740/3750 ( 19.7%) | Loss: 0.954820 | Accuracy: 68.88% | GPU: 22.8MB | Batch time: 0.0035s\n",
            "Batch  760/3750 ( 20.3%) | Loss: 0.946303 | Accuracy: 69.22% | GPU: 22.8MB | Batch time: 0.0034s\n",
            "Batch  780/3750 ( 20.8%) | Loss: 0.938269 | Accuracy: 69.45% | GPU: 22.8MB | Batch time: 0.0047s\n",
            "Batch  800/3750 ( 21.3%) | Loss: 0.930263 | Accuracy: 69.72% | GPU: 22.8MB | Batch time: 0.0056s\n",
            "Batch  820/3750 ( 21.9%) | Loss: 0.920257 | Accuracy: 69.99% | GPU: 22.8MB | Batch time: 0.0049s\n",
            "Batch  840/3750 ( 22.4%) | Loss: 0.911251 | Accuracy: 70.29% | GPU: 22.8MB | Batch time: 0.0034s\n",
            "Batch  860/3750 ( 22.9%) | Loss: 0.903709 | Accuracy: 70.51% | GPU: 22.8MB | Batch time: 0.0034s\n",
            "Batch  880/3750 ( 23.5%) | Loss: 0.895727 | Accuracy: 70.80% | GPU: 22.8MB | Batch time: 0.0060s\n",
            "Batch  900/3750 ( 24.0%) | Loss: 0.885520 | Accuracy: 71.09% | GPU: 22.8MB | Batch time: 0.0055s\n",
            "Batch  920/3750 ( 24.5%) | Loss: 0.878081 | Accuracy: 71.34% | GPU: 22.8MB | Batch time: 0.0054s\n",
            "Batch  940/3750 ( 25.1%) | Loss: 0.871724 | Accuracy: 71.57% | GPU: 22.8MB | Batch time: 0.0052s\n",
            "Batch  960/3750 ( 25.6%) | Loss: 0.865513 | Accuracy: 71.74% | GPU: 22.8MB | Batch time: 0.0052s\n",
            "Batch  980/3750 ( 26.1%) | Loss: 0.859979 | Accuracy: 71.92% | GPU: 22.8MB | Batch time: 0.0054s\n",
            "Batch 1000/3750 ( 26.7%) | Loss: 0.854277 | Accuracy: 72.11% | GPU: 22.8MB | Batch time: 0.0056s\n",
            "Batch 1020/3750 ( 27.2%) | Loss: 0.846003 | Accuracy: 72.36% | GPU: 22.8MB | Batch time: 0.0055s\n",
            "Batch 1040/3750 ( 27.7%) | Loss: 0.837082 | Accuracy: 72.67% | GPU: 22.8MB | Batch time: 0.0037s\n",
            "Batch 1060/3750 ( 28.3%) | Loss: 0.828462 | Accuracy: 72.95% | GPU: 22.8MB | Batch time: 0.0050s\n",
            "Batch 1080/3750 ( 28.8%) | Loss: 0.822449 | Accuracy: 73.15% | GPU: 22.8MB | Batch time: 0.0046s\n",
            "Batch 1100/3750 ( 29.3%) | Loss: 0.814033 | Accuracy: 73.42% | GPU: 22.8MB | Batch time: 0.0035s\n",
            "Batch 1120/3750 ( 29.9%) | Loss: 0.808396 | Accuracy: 73.58% | GPU: 22.8MB | Batch time: 0.0035s\n",
            "Batch 1140/3750 ( 30.4%) | Loss: 0.803157 | Accuracy: 73.73% | GPU: 22.8MB | Batch time: 0.0037s\n",
            "Batch 1160/3750 ( 30.9%) | Loss: 0.794430 | Accuracy: 74.03% | GPU: 22.8MB | Batch time: 0.0036s\n",
            "Batch 1180/3750 ( 31.5%) | Loss: 0.789178 | Accuracy: 74.22% | GPU: 22.8MB | Batch time: 0.0044s\n",
            "Batch 1200/3750 ( 32.0%) | Loss: 0.783890 | Accuracy: 74.39% | GPU: 22.8MB | Batch time: 0.0037s\n",
            "Batch 1220/3750 ( 32.5%) | Loss: 0.777068 | Accuracy: 74.63% | GPU: 22.8MB | Batch time: 0.0064s\n",
            "Batch 1240/3750 ( 33.1%) | Loss: 0.770724 | Accuracy: 74.82% | GPU: 22.8MB | Batch time: 0.0046s\n",
            "Batch 1260/3750 ( 33.6%) | Loss: 0.765972 | Accuracy: 75.05% | GPU: 22.8MB | Batch time: 0.0034s\n",
            "Batch 1280/3750 ( 34.1%) | Loss: 0.759870 | Accuracy: 75.25% | GPU: 22.8MB | Batch time: 0.0043s\n",
            "Batch 1300/3750 ( 34.7%) | Loss: 0.753459 | Accuracy: 75.46% | GPU: 22.8MB | Batch time: 0.0045s\n",
            "Batch 1320/3750 ( 35.2%) | Loss: 0.746519 | Accuracy: 75.70% | GPU: 22.8MB | Batch time: 0.0041s\n",
            "Batch 1340/3750 ( 35.7%) | Loss: 0.742283 | Accuracy: 75.85% | GPU: 22.8MB | Batch time: 0.0058s\n",
            "Batch 1360/3750 ( 36.3%) | Loss: 0.736870 | Accuracy: 76.04% | GPU: 22.8MB | Batch time: 0.0044s\n",
            "Batch 1380/3750 ( 36.8%) | Loss: 0.731810 | Accuracy: 76.20% | GPU: 22.8MB | Batch time: 0.0052s\n",
            "Batch 1400/3750 ( 37.3%) | Loss: 0.725994 | Accuracy: 76.37% | GPU: 22.8MB | Batch time: 0.0053s\n",
            "Batch 1420/3750 ( 37.9%) | Loss: 0.720539 | Accuracy: 76.58% | GPU: 22.8MB | Batch time: 0.0041s\n",
            "Batch 1440/3750 ( 38.4%) | Loss: 0.715269 | Accuracy: 76.77% | GPU: 22.8MB | Batch time: 0.0032s\n",
            "Batch 1460/3750 ( 38.9%) | Loss: 0.709910 | Accuracy: 76.94% | GPU: 22.8MB | Batch time: 0.0030s\n",
            "Batch 1480/3750 ( 39.5%) | Loss: 0.705596 | Accuracy: 77.08% | GPU: 22.8MB | Batch time: 0.0039s\n",
            "Batch 1500/3750 ( 40.0%) | Loss: 0.700002 | Accuracy: 77.27% | GPU: 22.8MB | Batch time: 0.0063s\n",
            "Batch 1520/3750 ( 40.5%) | Loss: 0.694637 | Accuracy: 77.46% | GPU: 22.8MB | Batch time: 0.0030s\n",
            "Batch 1540/3750 ( 41.1%) | Loss: 0.688856 | Accuracy: 77.65% | GPU: 22.8MB | Batch time: 0.0027s\n",
            "Batch 1560/3750 ( 41.6%) | Loss: 0.684111 | Accuracy: 77.83% | GPU: 22.8MB | Batch time: 0.0031s\n",
            "Batch 1580/3750 ( 42.1%) | Loss: 0.678286 | Accuracy: 78.02% | GPU: 22.8MB | Batch time: 0.0031s\n",
            "Batch 1600/3750 ( 42.7%) | Loss: 0.673444 | Accuracy: 78.18% | GPU: 22.8MB | Batch time: 0.0026s\n",
            "Batch 1620/3750 ( 43.2%) | Loss: 0.668451 | Accuracy: 78.35% | GPU: 22.8MB | Batch time: 0.0039s\n",
            "Batch 1640/3750 ( 43.7%) | Loss: 0.663623 | Accuracy: 78.51% | GPU: 22.8MB | Batch time: 0.0082s\n",
            "Batch 1660/3750 ( 44.3%) | Loss: 0.658299 | Accuracy: 78.66% | GPU: 22.8MB | Batch time: 0.0043s\n",
            "Batch 1680/3750 ( 44.8%) | Loss: 0.654822 | Accuracy: 78.80% | GPU: 22.8MB | Batch time: 0.0094s\n",
            "Batch 1700/3750 ( 45.3%) | Loss: 0.650291 | Accuracy: 78.96% | GPU: 22.8MB | Batch time: 0.0038s\n",
            "Batch 1720/3750 ( 45.9%) | Loss: 0.644936 | Accuracy: 79.15% | GPU: 22.8MB | Batch time: 0.0062s\n",
            "Batch 1740/3750 ( 46.4%) | Loss: 0.640046 | Accuracy: 79.29% | GPU: 22.8MB | Batch time: 0.0043s\n",
            "Batch 1760/3750 ( 46.9%) | Loss: 0.635940 | Accuracy: 79.43% | GPU: 22.8MB | Batch time: 0.0051s\n",
            "Batch 1780/3750 ( 47.5%) | Loss: 0.632535 | Accuracy: 79.52% | GPU: 22.8MB | Batch time: 0.0037s\n",
            "Batch 1800/3750 ( 48.0%) | Loss: 0.629036 | Accuracy: 79.64% | GPU: 22.8MB | Batch time: 0.0063s\n",
            "Batch 1820/3750 ( 48.5%) | Loss: 0.625198 | Accuracy: 79.77% | GPU: 22.8MB | Batch time: 0.0063s\n",
            "Batch 1840/3750 ( 49.1%) | Loss: 0.622352 | Accuracy: 79.88% | GPU: 22.8MB | Batch time: 0.0036s\n",
            "Batch 1860/3750 ( 49.6%) | Loss: 0.618591 | Accuracy: 80.01% | GPU: 22.8MB | Batch time: 0.0051s\n",
            "Batch 1880/3750 ( 50.1%) | Loss: 0.614174 | Accuracy: 80.17% | GPU: 22.8MB | Batch time: 0.0042s\n",
            "Batch 1900/3750 ( 50.7%) | Loss: 0.610835 | Accuracy: 80.29% | GPU: 22.8MB | Batch time: 0.0098s\n",
            "Batch 1920/3750 ( 51.2%) | Loss: 0.607133 | Accuracy: 80.43% | GPU: 22.8MB | Batch time: 0.0043s\n",
            "Batch 1940/3750 ( 51.7%) | Loss: 0.603243 | Accuracy: 80.56% | GPU: 22.8MB | Batch time: 0.0047s\n",
            "Batch 1960/3750 ( 52.3%) | Loss: 0.599474 | Accuracy: 80.69% | GPU: 22.8MB | Batch time: 0.0086s\n",
            "Batch 1980/3750 ( 52.8%) | Loss: 0.595466 | Accuracy: 80.81% | GPU: 22.8MB | Batch time: 0.0067s\n",
            "Batch 2000/3750 ( 53.3%) | Loss: 0.591870 | Accuracy: 80.92% | GPU: 22.8MB | Batch time: 0.0064s\n",
            "Batch 2020/3750 ( 53.9%) | Loss: 0.588879 | Accuracy: 81.04% | GPU: 22.8MB | Batch time: 0.0037s\n",
            "Batch 2040/3750 ( 54.4%) | Loss: 0.585741 | Accuracy: 81.15% | GPU: 22.8MB | Batch time: 0.0037s\n",
            "Batch 2060/3750 ( 54.9%) | Loss: 0.582688 | Accuracy: 81.25% | GPU: 22.8MB | Batch time: 0.0053s\n",
            "Batch 2080/3750 ( 55.5%) | Loss: 0.579891 | Accuracy: 81.34% | GPU: 22.8MB | Batch time: 0.0050s\n",
            "Batch 2100/3750 ( 56.0%) | Loss: 0.576974 | Accuracy: 81.44% | GPU: 22.8MB | Batch time: 0.0035s\n",
            "Batch 2120/3750 ( 56.5%) | Loss: 0.573652 | Accuracy: 81.54% | GPU: 22.8MB | Batch time: 0.0061s\n",
            "Batch 2140/3750 ( 57.1%) | Loss: 0.570451 | Accuracy: 81.65% | GPU: 22.8MB | Batch time: 0.0063s\n",
            "Batch 2160/3750 ( 57.6%) | Loss: 0.566635 | Accuracy: 81.79% | GPU: 22.8MB | Batch time: 0.0067s\n",
            "Batch 2180/3750 ( 58.1%) | Loss: 0.563372 | Accuracy: 81.88% | GPU: 22.8MB | Batch time: 0.0046s\n",
            "Batch 2200/3750 ( 58.7%) | Loss: 0.560152 | Accuracy: 81.99% | GPU: 22.8MB | Batch time: 0.0051s\n",
            "Batch 2220/3750 ( 59.2%) | Loss: 0.556603 | Accuracy: 82.12% | GPU: 22.8MB | Batch time: 0.0052s\n",
            "Batch 2240/3750 ( 59.7%) | Loss: 0.554364 | Accuracy: 82.22% | GPU: 22.8MB | Batch time: 0.0034s\n",
            "Batch 2260/3750 ( 60.3%) | Loss: 0.551762 | Accuracy: 82.31% | GPU: 22.8MB | Batch time: 0.0084s\n",
            "Batch 2280/3750 ( 60.8%) | Loss: 0.549089 | Accuracy: 82.40% | GPU: 22.8MB | Batch time: 0.0055s\n",
            "Batch 2300/3750 ( 61.3%) | Loss: 0.546198 | Accuracy: 82.49% | GPU: 22.8MB | Batch time: 0.0053s\n",
            "Batch 2320/3750 ( 61.9%) | Loss: 0.543079 | Accuracy: 82.59% | GPU: 22.8MB | Batch time: 0.0043s\n",
            "Batch 2340/3750 ( 62.4%) | Loss: 0.539832 | Accuracy: 82.69% | GPU: 22.8MB | Batch time: 0.0038s\n",
            "Batch 2360/3750 ( 62.9%) | Loss: 0.537389 | Accuracy: 82.77% | GPU: 22.8MB | Batch time: 0.0039s\n",
            "Batch 2380/3750 ( 63.5%) | Loss: 0.534685 | Accuracy: 82.86% | GPU: 22.8MB | Batch time: 0.0070s\n",
            "Batch 2400/3750 ( 64.0%) | Loss: 0.532290 | Accuracy: 82.94% | GPU: 22.8MB | Batch time: 0.0062s\n",
            "Batch 2420/3750 ( 64.5%) | Loss: 0.529743 | Accuracy: 83.03% | GPU: 22.8MB | Batch time: 0.0047s\n",
            "Batch 2440/3750 ( 65.1%) | Loss: 0.526699 | Accuracy: 83.14% | GPU: 22.8MB | Batch time: 0.0035s\n",
            "Batch 2460/3750 ( 65.6%) | Loss: 0.523563 | Accuracy: 83.25% | GPU: 22.8MB | Batch time: 0.0039s\n",
            "Batch 2480/3750 ( 66.1%) | Loss: 0.521838 | Accuracy: 83.31% | GPU: 22.8MB | Batch time: 0.0100s\n",
            "Batch 2500/3750 ( 66.7%) | Loss: 0.519574 | Accuracy: 83.40% | GPU: 22.8MB | Batch time: 0.0056s\n",
            "Batch 2520/3750 ( 67.2%) | Loss: 0.516546 | Accuracy: 83.49% | GPU: 22.8MB | Batch time: 0.0036s\n",
            "Batch 2540/3750 ( 67.7%) | Loss: 0.514175 | Accuracy: 83.57% | GPU: 22.8MB | Batch time: 0.0035s\n",
            "Batch 2560/3750 ( 68.3%) | Loss: 0.511898 | Accuracy: 83.65% | GPU: 22.8MB | Batch time: 0.0040s\n",
            "Batch 2580/3750 ( 68.8%) | Loss: 0.510201 | Accuracy: 83.73% | GPU: 22.8MB | Batch time: 0.0101s\n",
            "Batch 2600/3750 ( 69.3%) | Loss: 0.507797 | Accuracy: 83.80% | GPU: 22.8MB | Batch time: 0.0040s\n",
            "Batch 2620/3750 ( 69.9%) | Loss: 0.505308 | Accuracy: 83.88% | GPU: 22.8MB | Batch time: 0.0036s\n",
            "Batch 2640/3750 ( 70.4%) | Loss: 0.502549 | Accuracy: 83.96% | GPU: 22.8MB | Batch time: 0.0057s\n",
            "Batch 2660/3750 ( 70.9%) | Loss: 0.500393 | Accuracy: 84.04% | GPU: 22.8MB | Batch time: 0.0050s\n",
            "Batch 2680/3750 ( 71.5%) | Loss: 0.497966 | Accuracy: 84.12% | GPU: 22.8MB | Batch time: 0.0038s\n",
            "Batch 2700/3750 ( 72.0%) | Loss: 0.495290 | Accuracy: 84.20% | GPU: 22.8MB | Batch time: 0.0054s\n",
            "Batch 2720/3750 ( 72.5%) | Loss: 0.492990 | Accuracy: 84.28% | GPU: 22.8MB | Batch time: 0.0106s\n",
            "Batch 2740/3750 ( 73.1%) | Loss: 0.490830 | Accuracy: 84.36% | GPU: 22.8MB | Batch time: 0.0097s\n",
            "Batch 2760/3750 ( 73.6%) | Loss: 0.488785 | Accuracy: 84.42% | GPU: 22.8MB | Batch time: 0.0045s\n",
            "Batch 2780/3750 ( 74.1%) | Loss: 0.486986 | Accuracy: 84.48% | GPU: 22.8MB | Batch time: 0.0039s\n",
            "Batch 2800/3750 ( 74.7%) | Loss: 0.484599 | Accuracy: 84.56% | GPU: 22.8MB | Batch time: 0.0040s\n",
            "Batch 2820/3750 ( 75.2%) | Loss: 0.482251 | Accuracy: 84.63% | GPU: 22.8MB | Batch time: 0.0058s\n",
            "Batch 2840/3750 ( 75.7%) | Loss: 0.480242 | Accuracy: 84.69% | GPU: 22.8MB | Batch time: 0.0041s\n",
            "Batch 2860/3750 ( 76.3%) | Loss: 0.478505 | Accuracy: 84.75% | GPU: 22.8MB | Batch time: 0.0049s\n",
            "Batch 2880/3750 ( 76.8%) | Loss: 0.475918 | Accuracy: 84.83% | GPU: 22.8MB | Batch time: 0.0041s\n",
            "Batch 2900/3750 ( 77.3%) | Loss: 0.473729 | Accuracy: 84.89% | GPU: 22.8MB | Batch time: 0.0036s\n",
            "Batch 2920/3750 ( 77.9%) | Loss: 0.471619 | Accuracy: 84.95% | GPU: 22.8MB | Batch time: 0.0125s\n",
            "Batch 2940/3750 ( 78.4%) | Loss: 0.469731 | Accuracy: 85.02% | GPU: 22.8MB | Batch time: 0.0071s\n",
            "Batch 2960/3750 ( 78.9%) | Loss: 0.468076 | Accuracy: 85.09% | GPU: 22.8MB | Batch time: 0.0066s\n",
            "Batch 2980/3750 ( 79.5%) | Loss: 0.466237 | Accuracy: 85.15% | GPU: 22.8MB | Batch time: 0.0040s\n",
            "Batch 3000/3750 ( 80.0%) | Loss: 0.463999 | Accuracy: 85.22% | GPU: 22.8MB | Batch time: 0.0059s\n",
            "Batch 3020/3750 ( 80.5%) | Loss: 0.462066 | Accuracy: 85.29% | GPU: 22.8MB | Batch time: 0.0086s\n",
            "Batch 3040/3750 ( 81.1%) | Loss: 0.460695 | Accuracy: 85.34% | GPU: 22.8MB | Batch time: 0.0063s\n",
            "Batch 3060/3750 ( 81.6%) | Loss: 0.458764 | Accuracy: 85.41% | GPU: 22.8MB | Batch time: 0.0073s\n",
            "Batch 3080/3750 ( 82.1%) | Loss: 0.456860 | Accuracy: 85.46% | GPU: 22.8MB | Batch time: 0.0072s\n",
            "Batch 3100/3750 ( 82.7%) | Loss: 0.455004 | Accuracy: 85.52% | GPU: 22.8MB | Batch time: 0.0092s\n",
            "Batch 3120/3750 ( 83.2%) | Loss: 0.453461 | Accuracy: 85.56% | GPU: 22.8MB | Batch time: 0.0055s\n",
            "Batch 3140/3750 ( 83.7%) | Loss: 0.451733 | Accuracy: 85.62% | GPU: 22.8MB | Batch time: 0.0051s\n",
            "Batch 3160/3750 ( 84.3%) | Loss: 0.449993 | Accuracy: 85.68% | GPU: 22.8MB | Batch time: 0.0048s\n",
            "Batch 3180/3750 ( 84.8%) | Loss: 0.448947 | Accuracy: 85.72% | GPU: 22.8MB | Batch time: 0.0048s\n",
            "Batch 3200/3750 ( 85.3%) | Loss: 0.446923 | Accuracy: 85.79% | GPU: 22.8MB | Batch time: 0.0119s\n",
            "Batch 3220/3750 ( 85.9%) | Loss: 0.445259 | Accuracy: 85.84% | GPU: 22.8MB | Batch time: 0.0075s\n",
            "Batch 3240/3750 ( 86.4%) | Loss: 0.443385 | Accuracy: 85.90% | GPU: 22.8MB | Batch time: 0.0050s\n",
            "Batch 3260/3750 ( 86.9%) | Loss: 0.441353 | Accuracy: 85.97% | GPU: 22.8MB | Batch time: 0.0052s\n",
            "Batch 3280/3750 ( 87.5%) | Loss: 0.439802 | Accuracy: 86.03% | GPU: 22.8MB | Batch time: 0.0065s\n",
            "Batch 3300/3750 ( 88.0%) | Loss: 0.437855 | Accuracy: 86.08% | GPU: 22.8MB | Batch time: 0.0047s\n",
            "Batch 3320/3750 ( 88.5%) | Loss: 0.436153 | Accuracy: 86.14% | GPU: 22.8MB | Batch time: 0.0038s\n",
            "Batch 3340/3750 ( 89.1%) | Loss: 0.434373 | Accuracy: 86.21% | GPU: 22.8MB | Batch time: 0.0032s\n",
            "Batch 3360/3750 ( 89.6%) | Loss: 0.433755 | Accuracy: 86.24% | GPU: 22.8MB | Batch time: 0.0044s\n",
            "Batch 3380/3750 ( 90.1%) | Loss: 0.432505 | Accuracy: 86.28% | GPU: 22.8MB | Batch time: 0.0035s\n",
            "Batch 3400/3750 ( 90.7%) | Loss: 0.431018 | Accuracy: 86.31% | GPU: 22.8MB | Batch time: 0.0031s\n",
            "Batch 3420/3750 ( 91.2%) | Loss: 0.428925 | Accuracy: 86.37% | GPU: 22.8MB | Batch time: 0.0070s\n",
            "Batch 3440/3750 ( 91.7%) | Loss: 0.427506 | Accuracy: 86.42% | GPU: 22.8MB | Batch time: 0.0080s\n",
            "Batch 3460/3750 ( 92.3%) | Loss: 0.426095 | Accuracy: 86.47% | GPU: 22.8MB | Batch time: 0.0087s\n",
            "Batch 3480/3750 ( 92.8%) | Loss: 0.424260 | Accuracy: 86.52% | GPU: 22.8MB | Batch time: 0.0092s\n",
            "Batch 3500/3750 ( 93.3%) | Loss: 0.423134 | Accuracy: 86.56% | GPU: 22.8MB | Batch time: 0.0091s\n",
            "Batch 3520/3750 ( 93.9%) | Loss: 0.421771 | Accuracy: 86.61% | GPU: 22.8MB | Batch time: 0.0105s\n",
            "Batch 3540/3750 ( 94.4%) | Loss: 0.420577 | Accuracy: 86.65% | GPU: 22.8MB | Batch time: 0.0060s\n",
            "Batch 3560/3750 ( 94.9%) | Loss: 0.419111 | Accuracy: 86.71% | GPU: 22.8MB | Batch time: 0.0044s\n",
            "Batch 3580/3750 ( 95.5%) | Loss: 0.417391 | Accuracy: 86.76% | GPU: 22.8MB | Batch time: 0.0051s\n",
            "Batch 3600/3750 ( 96.0%) | Loss: 0.415864 | Accuracy: 86.82% | GPU: 22.8MB | Batch time: 0.0047s\n",
            "Batch 3620/3750 ( 96.5%) | Loss: 0.414302 | Accuracy: 86.86% | GPU: 22.8MB | Batch time: 0.0061s\n",
            "Batch 3640/3750 ( 97.1%) | Loss: 0.412938 | Accuracy: 86.91% | GPU: 22.8MB | Batch time: 0.0036s\n",
            "Batch 3660/3750 ( 97.6%) | Loss: 0.411356 | Accuracy: 86.96% | GPU: 22.8MB | Batch time: 0.0071s\n",
            "Batch 3680/3750 ( 98.1%) | Loss: 0.409686 | Accuracy: 87.01% | GPU: 22.8MB | Batch time: 0.0103s\n",
            "Batch 3700/3750 ( 98.7%) | Loss: 0.408116 | Accuracy: 87.06% | GPU: 22.8MB | Batch time: 0.0061s\n",
            "Batch 3720/3750 ( 99.2%) | Loss: 0.407154 | Accuracy: 87.10% | GPU: 22.8MB | Batch time: 0.0038s\n",
            "Batch 3740/3750 ( 99.7%) | Loss: 0.406162 | Accuracy: 87.12% | GPU: 22.8MB | Batch time: 0.0041s\n",
            "Batch 3749/3750 (100.0%) | Loss: 0.405545 | Accuracy: 87.14% | GPU: 22.8MB | Batch time: 0.0025s\n",
            "\n",
            "-------------------- STANDARD OPTIMIZER - SUMMARY --------------------\n",
            "Loss: 0.405545 | Accuracy: 87.14%\n",
            "Time: 26.91s total, 0.0055s per batch\n",
            "  - Forward: 0.0019s, Backward: 0.0022s, Optimizer: 0.0006s\n",
            "🔄 Final Memory - RAM: 1369.7MB, GPU: 22.8MB allocated, 46.0MB reserved\n",
            "⏱️ Standard model training took 26.9124 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Epoch 1/3 -------------------------\n",
            "\n",
            "==================== EPOCH 1 TRAINING ====================\n",
            "Device: cuda, Batches: 3750, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 1369.7MB, GPU: 22.7MB allocated, 46.0MB reserved\n",
            "Step    1 | Loss: 2.294006 | GPU: 24.4MB / 98.0MB | F: 0.0051s, B: 0.0045s, O: 0.0012s\n",
            "Batch    0/3750 (  0.0%) | Loss: 2.294006 | Accuracy: 18.75% | Batch time: 0.0300s\n",
            "Step   10 | Loss: 2.022705 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step   20 | Loss: 1.827480 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0026s, O: 0.0004s\n",
            "🔄 Topology update at step 20 took 0.0006s\n",
            "Batch   20/3750 (  0.5%) | Loss: 2.034490 | Accuracy: 33.04% | Batch time: 0.0229s\n",
            "Step   30 | Loss: 1.477188 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0026s, O: 0.0008s\n",
            "Step   40 | Loss: 1.243973 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 40 took 0.0001s\n",
            "Batch   40/3750 (  1.1%) | Loss: 1.820683 | Accuracy: 40.55% | Batch time: 0.0256s\n",
            "Step   50 | Loss: 1.418304 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0005s\n",
            "Step   60 | Loss: 1.016243 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 60 took 0.0001s\n",
            "Batch   60/3750 (  1.6%) | Loss: 1.603415 | Accuracy: 49.80% | Batch time: 0.0260s\n",
            "Step   70 | Loss: 0.746984 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "Step   80 | Loss: 1.103159 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 80 took 0.0001s\n",
            "Batch   80/3750 (  2.1%) | Loss: 1.438295 | Accuracy: 55.02% | Batch time: 0.0234s\n",
            "Step   90 | Loss: 0.934807 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0023s, O: 0.0007s\n",
            "Step  100 | Loss: 0.453560 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 100 took 0.0000s\n",
            "🧹 Memory cleanup at step 100 took 0.2164s\n",
            "Batch  100/3750 (  2.7%) | Loss: 1.305980 | Accuracy: 59.47% | Batch time: 0.0217s\n",
            "Step  110 | Loss: 0.402316 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0026s, O: 0.0008s\n",
            "Step  120 | Loss: 0.613050 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 120 took 0.0001s\n",
            "Batch  120/3750 (  3.2%) | Loss: 1.201732 | Accuracy: 62.96% | Batch time: 0.0213s\n",
            "Step  130 | Loss: 0.462121 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0025s, O: 0.0009s\n",
            "Step  140 | Loss: 0.625026 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0054s, O: 0.0015s\n",
            "🔄 Topology update at step 140 took 0.0000s\n",
            "Batch  140/3750 (  3.7%) | Loss: 1.118360 | Accuracy: 65.60% | Batch time: 0.0231s\n",
            "Step  150 | Loss: 0.687938 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0030s, O: 0.0007s\n",
            "Step  160 | Loss: 0.696965 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0045s, O: 0.0016s\n",
            "🔄 Topology update at step 160 took 0.0000s\n",
            "Batch  160/3750 (  4.3%) | Loss: 1.038994 | Accuracy: 68.32% | Batch time: 0.0214s\n",
            "Step  170 | Loss: 0.677413 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0025s, O: 0.0007s\n",
            "Step  180 | Loss: 0.487865 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 180 took 0.0000s\n",
            "Batch  180/3750 (  4.8%) | Loss: 0.986813 | Accuracy: 69.75% | Batch time: 0.0229s\n",
            "Step  190 | Loss: 0.941092 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0031s, O: 0.0025s\n",
            "Step  200 | Loss: 0.567706 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 200 took 0.0000s\n",
            "🧹 Memory cleanup at step 200 took 0.1418s\n",
            "Batch  200/3750 (  5.3%) | Loss: 0.943826 | Accuracy: 71.02% | Batch time: 0.0224s\n",
            "Step  210 | Loss: 0.475703 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step  220 | Loss: 0.294302 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0036s, O: 0.0008s\n",
            "🔄 Topology update at step 220 took 0.0000s\n",
            "Batch  220/3750 (  5.9%) | Loss: 0.900656 | Accuracy: 72.23% | Batch time: 0.0228s\n",
            "Step  230 | Loss: 0.407226 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0026s, O: 0.0008s\n",
            "Step  240 | Loss: 0.417811 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 240 took 0.0000s\n",
            "Batch  240/3750 (  6.4%) | Loss: 0.857984 | Accuracy: 73.47% | Batch time: 0.0210s\n",
            "Step  250 | Loss: 0.192826 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0052s, O: 0.0009s\n",
            "Step  260 | Loss: 0.779195 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0023s, O: 0.0008s\n",
            "🔄 Topology update at step 260 took 0.0000s\n",
            "Batch  260/3750 (  6.9%) | Loss: 0.827607 | Accuracy: 74.43% | Batch time: 0.0200s\n",
            "Step  270 | Loss: 0.430860 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0055s, O: 0.0004s\n",
            "Step  280 | Loss: 0.260121 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0057s, O: 0.0008s\n",
            "🔄 Topology update at step 280 took 0.0001s\n",
            "Batch  280/3750 (  7.5%) | Loss: 0.796799 | Accuracy: 75.40% | Batch time: 0.0215s\n",
            "Step  290 | Loss: 0.153085 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0026s, O: 0.0007s\n",
            "Step  300 | Loss: 0.327304 | GPU: 24.4MB / 98.0MB | F: 0.0053s, B: 0.0056s, O: 0.0007s\n",
            "🔄 Topology update at step 300 took 0.0000s\n",
            "🧹 Memory cleanup at step 300 took 0.1545s\n",
            "Batch  300/3750 (  8.0%) | Loss: 0.767469 | Accuracy: 76.39% | Batch time: 0.0212s\n",
            "Step  310 | Loss: 0.379049 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "Step  320 | Loss: 0.173878 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 320 took 0.0001s\n",
            "Batch  320/3750 (  8.5%) | Loss: 0.738116 | Accuracy: 77.38% | Batch time: 0.0212s\n",
            "Step  330 | Loss: 0.052133 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0031s, O: 0.0009s\n",
            "Step  340 | Loss: 0.221971 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 340 took 0.0000s\n",
            "Batch  340/3750 (  9.1%) | Loss: 0.712057 | Accuracy: 78.19% | Batch time: 0.0219s\n",
            "Step  350 | Loss: 0.111396 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0024s, O: 0.0006s\n",
            "Step  360 | Loss: 0.311733 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0035s, O: 0.0008s\n",
            "🔄 Topology update at step 360 took 0.0000s\n",
            "Batch  360/3750 (  9.6%) | Loss: 0.687161 | Accuracy: 79.03% | Batch time: 0.0212s\n",
            "Step  370 | Loss: 0.067718 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0024s, O: 0.0006s\n",
            "Step  380 | Loss: 0.803969 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 380 took 0.0000s\n",
            "Batch  380/3750 ( 10.1%) | Loss: 0.666750 | Accuracy: 79.68% | Batch time: 0.0212s\n",
            "Step  390 | Loss: 0.227000 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0027s, O: 0.0014s\n",
            "Step  400 | Loss: 0.833648 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0028s, O: 0.0016s\n",
            "🔄 Topology update at step 400 took 0.0000s\n",
            "🧹 Memory cleanup at step 400 took 0.1551s\n",
            "Batch  400/3750 ( 10.7%) | Loss: 0.649028 | Accuracy: 80.21% | Batch time: 0.0224s\n",
            "Step  410 | Loss: 0.216858 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0024s, O: 0.0014s\n",
            "Step  420 | Loss: 0.203925 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0048s, O: 0.0007s\n",
            "🔄 Topology update at step 420 took 0.0000s\n",
            "Batch  420/3750 ( 11.2%) | Loss: 0.635072 | Accuracy: 80.66% | Batch time: 0.0215s\n",
            "Step  430 | Loss: 0.220649 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0026s, O: 0.0007s\n",
            "Step  440 | Loss: 0.279761 | GPU: 24.4MB / 98.0MB | F: 0.0046s, B: 0.0038s, O: 0.0008s\n",
            "🔄 Topology update at step 440 took 0.0000s\n",
            "Batch  440/3750 ( 11.7%) | Loss: 0.615768 | Accuracy: 81.28% | Batch time: 0.0202s\n",
            "Step  450 | Loss: 0.175707 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "Step  460 | Loss: 0.230184 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0036s, O: 0.0007s\n",
            "🔄 Topology update at step 460 took 0.0001s\n",
            "Batch  460/3750 ( 12.3%) | Loss: 0.601384 | Accuracy: 81.74% | Batch time: 0.0205s\n",
            "Step  470 | Loss: 0.172080 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step  480 | Loss: 0.350388 | GPU: 24.4MB / 98.0MB | F: 0.0037s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 480 took 0.0001s\n",
            "Batch  480/3750 ( 12.8%) | Loss: 0.586056 | Accuracy: 82.26% | Batch time: 0.0231s\n",
            "Step  490 | Loss: 0.256196 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0029s, O: 0.0017s\n",
            "Step  500 | Loss: 0.679265 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 500 took 0.0001s\n",
            "🧹 Memory cleanup at step 500 took 0.1487s\n",
            "Batch  500/3750 ( 13.3%) | Loss: 0.574637 | Accuracy: 82.68% | Batch time: 0.0219s\n",
            "Step  510 | Loss: 0.085584 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0028s, O: 0.0008s\n",
            "Step  520 | Loss: 0.732037 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0040s, O: 0.0013s\n",
            "🔄 Topology update at step 520 took 0.0000s\n",
            "Batch  520/3750 ( 13.9%) | Loss: 0.564589 | Accuracy: 83.00% | Batch time: 0.0218s\n",
            "Step  530 | Loss: 0.209170 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0032s, O: 0.0010s\n",
            "Step  540 | Loss: 0.223654 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0042s, O: 0.0011s\n",
            "🔄 Topology update at step 540 took 0.0000s\n",
            "Batch  540/3750 ( 14.4%) | Loss: 0.555080 | Accuracy: 83.26% | Batch time: 0.0213s\n",
            "Step  550 | Loss: 0.164088 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0025s, O: 0.0014s\n",
            "Step  560 | Loss: 0.081742 | GPU: 24.4MB / 98.0MB | F: 0.0044s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 560 took 0.0000s\n",
            "Batch  560/3750 ( 14.9%) | Loss: 0.544219 | Accuracy: 83.58% | Batch time: 0.0233s\n",
            "Step  570 | Loss: 0.179041 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0008s\n",
            "Step  580 | Loss: 0.107041 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 580 took 0.0001s\n",
            "Batch  580/3750 ( 15.5%) | Loss: 0.535867 | Accuracy: 83.86% | Batch time: 0.0238s\n",
            "Step  590 | Loss: 0.322185 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0037s, O: 0.0018s\n",
            "Step  600 | Loss: 0.387606 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0036s, O: 0.0005s\n",
            "🔄 Topology update at step 600 took 0.0000s\n",
            "🧹 Memory cleanup at step 600 took 0.1541s\n",
            "Batch  600/3750 ( 16.0%) | Loss: 0.526855 | Accuracy: 84.15% | Batch time: 0.0213s\n",
            "Step  610 | Loss: 0.094626 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0025s, O: 0.0007s\n",
            "Step  620 | Loss: 0.072544 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0034s, O: 0.0018s\n",
            "🔄 Topology update at step 620 took 0.0000s\n",
            "Batch  620/3750 ( 16.5%) | Loss: 0.519772 | Accuracy: 84.36% | Batch time: 0.0200s\n",
            "Step  630 | Loss: 0.690583 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0025s, O: 0.0007s\n",
            "Step  640 | Loss: 0.203430 | GPU: 24.4MB / 98.0MB | F: 0.0041s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 640 took 0.0000s\n",
            "Batch  640/3750 ( 17.1%) | Loss: 0.509541 | Accuracy: 84.65% | Batch time: 0.0294s\n",
            "Step  650 | Loss: 0.482493 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step  660 | Loss: 0.356546 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0006s\n",
            "🔄 Topology update at step 660 took 0.0000s\n",
            "Batch  660/3750 ( 17.6%) | Loss: 0.501986 | Accuracy: 84.88% | Batch time: 0.0200s\n",
            "Step  670 | Loss: 0.094843 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0037s, O: 0.0009s\n",
            "Step  680 | Loss: 0.131661 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 680 took 0.0001s\n",
            "Batch  680/3750 ( 18.1%) | Loss: 0.496419 | Accuracy: 85.10% | Batch time: 0.0225s\n",
            "Step  690 | Loss: 0.059809 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0035s, O: 0.0008s\n",
            "Step  700 | Loss: 0.121940 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0032s, O: 0.0029s\n",
            "🔄 Topology update at step 700 took 0.0001s\n",
            "🧹 Memory cleanup at step 700 took 0.1417s\n",
            "Batch  700/3750 ( 18.7%) | Loss: 0.489470 | Accuracy: 85.28% | Batch time: 0.0218s\n",
            "Step  710 | Loss: 0.096800 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0005s\n",
            "Step  720 | Loss: 0.324728 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0024s, O: 0.0009s\n",
            "🔄 Topology update at step 720 took 0.0000s\n",
            "Batch  720/3750 ( 19.2%) | Loss: 0.483199 | Accuracy: 85.43% | Batch time: 0.0290s\n",
            "Step  730 | Loss: 0.105910 | GPU: 24.4MB / 98.0MB | F: 0.0058s, B: 0.0045s, O: 0.0007s\n",
            "Step  740 | Loss: 0.503322 | GPU: 24.4MB / 98.0MB | F: 0.0058s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 740 took 0.0000s\n",
            "Batch  740/3750 ( 19.7%) | Loss: 0.478447 | Accuracy: 85.63% | Batch time: 0.0267s\n",
            "Step  750 | Loss: 0.291663 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0017s, O: 0.0005s\n",
            "Step  760 | Loss: 0.093878 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0064s, O: 0.0006s\n",
            "🔄 Topology update at step 760 took 0.0000s\n",
            "Batch  760/3750 ( 20.3%) | Loss: 0.470585 | Accuracy: 85.87% | Batch time: 0.0202s\n",
            "Step  770 | Loss: 0.492912 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0018s, O: 0.0005s\n",
            "Step  780 | Loss: 0.139442 | GPU: 24.4MB / 98.0MB | F: 0.0132s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 780 took 0.0000s\n",
            "Batch  780/3750 ( 20.8%) | Loss: 0.463757 | Accuracy: 86.10% | Batch time: 0.0272s\n",
            "Step  790 | Loss: 0.203265 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0033s, O: 0.0005s\n",
            "Step  800 | Loss: 0.223919 | GPU: 24.4MB / 98.0MB | F: 0.0088s, B: 0.0018s, O: 0.0006s\n",
            "🔄 Topology update at step 800 took 0.0005s\n",
            "🧹 Memory cleanup at step 800 took 0.1790s\n",
            "Batch  800/3750 ( 21.3%) | Loss: 0.457769 | Accuracy: 86.25% | Batch time: 0.0199s\n",
            "Step  810 | Loss: 0.046244 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0018s, O: 0.0006s\n",
            "Step  820 | Loss: 0.919449 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 820 took 0.0000s\n",
            "Batch  820/3750 ( 21.9%) | Loss: 0.452768 | Accuracy: 86.42% | Batch time: 0.0232s\n",
            "Step  830 | Loss: 0.204745 | GPU: 24.4MB / 98.0MB | F: 0.0078s, B: 0.0020s, O: 0.0006s\n",
            "Step  840 | Loss: 0.292920 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0038s\n",
            "🔄 Topology update at step 840 took 0.0000s\n",
            "Batch  840/3750 ( 22.4%) | Loss: 0.446258 | Accuracy: 86.61% | Batch time: 0.0201s\n",
            "Step  850 | Loss: 0.152035 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0123s, O: 0.0006s\n",
            "Step  860 | Loss: 0.213297 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0030s, O: 0.0006s\n",
            "🔄 Topology update at step 860 took 0.0000s\n",
            "Batch  860/3750 ( 22.9%) | Loss: 0.440755 | Accuracy: 86.77% | Batch time: 0.0249s\n",
            "Step  870 | Loss: 0.204939 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0034s, O: 0.0007s\n",
            "Step  880 | Loss: 0.365096 | GPU: 24.4MB / 98.0MB | F: 0.0069s, B: 0.0029s, O: 0.0007s\n",
            "🔄 Topology update at step 880 took 0.0001s\n",
            "Batch  880/3750 ( 23.5%) | Loss: 0.436052 | Accuracy: 86.90% | Batch time: 0.0256s\n",
            "Step  890 | Loss: 0.232983 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0068s, O: 0.0005s\n",
            "Step  900 | Loss: 0.249178 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0029s, O: 0.0016s\n",
            "🔄 Topology update at step 900 took 0.0000s\n",
            "🧹 Memory cleanup at step 900 took 0.1278s\n",
            "Batch  900/3750 ( 24.0%) | Loss: 0.431753 | Accuracy: 87.03% | Batch time: 0.0242s\n",
            "Step  910 | Loss: 0.117239 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0023s\n",
            "Step  920 | Loss: 0.062072 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0029s, O: 0.0006s\n",
            "🔄 Topology update at step 920 took 0.0000s\n",
            "Batch  920/3750 ( 24.5%) | Loss: 0.426169 | Accuracy: 87.20% | Batch time: 0.0194s\n",
            "Step  930 | Loss: 0.268191 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0069s, O: 0.0022s\n",
            "Step  940 | Loss: 0.273544 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 940 took 0.0000s\n",
            "Batch  940/3750 ( 25.1%) | Loss: 0.420081 | Accuracy: 87.40% | Batch time: 0.0195s\n",
            "Step  950 | Loss: 0.530226 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0044s, O: 0.0009s\n",
            "Step  960 | Loss: 0.172436 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0022s, O: 0.0004s\n",
            "🔄 Topology update at step 960 took 0.0000s\n",
            "Batch  960/3750 ( 25.6%) | Loss: 0.415168 | Accuracy: 87.53% | Batch time: 0.0192s\n",
            "Step  970 | Loss: 0.565198 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0010s\n",
            "Step  980 | Loss: 0.027525 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0014s\n",
            "🔄 Topology update at step 980 took 0.0000s\n",
            "Batch  980/3750 ( 26.1%) | Loss: 0.412291 | Accuracy: 87.62% | Batch time: 0.0200s\n",
            "Step  990 | Loss: 0.063053 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0027s, O: 0.0010s\n",
            "Step 1000 | Loss: 0.133706 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0015s\n",
            "🔄 Topology update at step 1000 took 0.0000s\n",
            "🧹 Memory cleanup at step 1000 took 0.1363s\n",
            "Batch 1000/3750 ( 26.7%) | Loss: 0.408308 | Accuracy: 87.71% | Batch time: 0.0234s\n",
            "Step 1010 | Loss: 0.199147 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 1020 | Loss: 0.273130 | GPU: 24.4MB / 98.0MB | F: 0.0045s, B: 0.0057s, O: 0.0008s\n",
            "🔄 Topology update at step 1020 took 0.0000s\n",
            "Batch 1020/3750 ( 27.2%) | Loss: 0.403959 | Accuracy: 87.84% | Batch time: 0.0301s\n",
            "Step 1030 | Loss: 0.094937 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0029s, O: 0.0010s\n",
            "Step 1040 | Loss: 0.189201 | GPU: 24.4MB / 98.0MB | F: 0.0036s, B: 0.0023s, O: 0.0011s\n",
            "🔄 Topology update at step 1040 took 0.0000s\n",
            "Batch 1040/3750 ( 27.7%) | Loss: 0.399020 | Accuracy: 88.00% | Batch time: 0.0202s\n",
            "Step 1050 | Loss: 0.312613 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0034s, O: 0.0007s\n",
            "Step 1060 | Loss: 0.026193 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0030s, O: 0.0016s\n",
            "🔄 Topology update at step 1060 took 0.0000s\n",
            "Batch 1060/3750 ( 28.3%) | Loss: 0.394956 | Accuracy: 88.14% | Batch time: 0.0196s\n",
            "Step 1070 | Loss: 0.010196 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0032s, O: 0.0007s\n",
            "Step 1080 | Loss: 0.006807 | GPU: 24.4MB / 98.0MB | F: 0.0038s, B: 0.0024s, O: 0.0008s\n",
            "🔄 Topology update at step 1080 took 0.0000s\n",
            "Batch 1080/3750 ( 28.8%) | Loss: 0.389676 | Accuracy: 88.32% | Batch time: 0.0186s\n",
            "Step 1090 | Loss: 0.538696 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0034s, O: 0.0008s\n",
            "Step 1100 | Loss: 0.329476 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0004s\n",
            "🔄 Topology update at step 1100 took 0.0000s\n",
            "🧹 Memory cleanup at step 1100 took 0.1473s\n",
            "Batch 1100/3750 ( 29.3%) | Loss: 0.386166 | Accuracy: 88.42% | Batch time: 0.0218s\n",
            "Step 1110 | Loss: 0.216144 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0023s\n",
            "Step 1120 | Loss: 0.591092 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0029s, O: 0.0015s\n",
            "🔄 Topology update at step 1120 took 0.0000s\n",
            "Batch 1120/3750 ( 29.9%) | Loss: 0.382641 | Accuracy: 88.52% | Batch time: 0.0219s\n",
            "Step 1130 | Loss: 0.036896 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0007s\n",
            "Step 1140 | Loss: 0.051110 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 1140 took 0.0001s\n",
            "Batch 1140/3750 ( 30.4%) | Loss: 0.379794 | Accuracy: 88.60% | Batch time: 0.0238s\n",
            "Step 1150 | Loss: 0.230961 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 1160 | Loss: 0.087596 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0030s, O: 0.0006s\n",
            "🔄 Topology update at step 1160 took 0.0000s\n",
            "Batch 1160/3750 ( 30.9%) | Loss: 0.376299 | Accuracy: 88.69% | Batch time: 0.0202s\n",
            "Step 1170 | Loss: 0.091375 | GPU: 24.4MB / 98.0MB | F: 0.0043s, B: 0.0025s, O: 0.0008s\n",
            "Step 1180 | Loss: 0.072965 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1180 took 0.0000s\n",
            "Batch 1180/3750 ( 31.5%) | Loss: 0.373172 | Accuracy: 88.80% | Batch time: 0.0215s\n",
            "Step 1190 | Loss: 0.067149 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0026s, O: 0.0013s\n",
            "Step 1200 | Loss: 0.428668 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1200 took 0.0000s\n",
            "🧹 Memory cleanup at step 1200 took 0.1427s\n",
            "Batch 1200/3750 ( 32.0%) | Loss: 0.370163 | Accuracy: 88.91% | Batch time: 0.0215s\n",
            "Step 1210 | Loss: 0.199579 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 1220 | Loss: 0.048048 | GPU: 24.4MB / 98.0MB | F: 0.0050s, B: 0.0028s, O: 0.0011s\n",
            "🔄 Topology update at step 1220 took 0.0000s\n",
            "Batch 1220/3750 ( 32.5%) | Loss: 0.366676 | Accuracy: 89.00% | Batch time: 0.0207s\n",
            "Step 1230 | Loss: 0.119218 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0024s, O: 0.0007s\n",
            "Step 1240 | Loss: 0.044378 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0032s\n",
            "🔄 Topology update at step 1240 took 0.0000s\n",
            "Batch 1240/3750 ( 33.1%) | Loss: 0.363722 | Accuracy: 89.08% | Batch time: 0.0197s\n",
            "Step 1250 | Loss: 0.031878 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0004s\n",
            "Step 1260 | Loss: 0.033048 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0025s, O: 0.0055s\n",
            "🔄 Topology update at step 1260 took 0.0000s\n",
            "Batch 1260/3750 ( 33.6%) | Loss: 0.360580 | Accuracy: 89.15% | Batch time: 0.0205s\n",
            "Step 1270 | Loss: 0.289670 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0029s, O: 0.0007s\n",
            "Step 1280 | Loss: 0.020544 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0007s\n",
            "🔄 Topology update at step 1280 took 0.0001s\n",
            "Batch 1280/3750 ( 34.1%) | Loss: 0.357650 | Accuracy: 89.25% | Batch time: 0.0222s\n",
            "Step 1290 | Loss: 0.055586 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0038s, O: 0.0006s\n",
            "Step 1300 | Loss: 0.187737 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 1300 took 0.0000s\n",
            "🧹 Memory cleanup at step 1300 took 0.1476s\n",
            "Batch 1300/3750 ( 34.7%) | Loss: 0.354296 | Accuracy: 89.36% | Batch time: 0.0213s\n",
            "Step 1310 | Loss: 0.050668 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0026s, O: 0.0007s\n",
            "Step 1320 | Loss: 0.020997 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0036s, O: 0.0015s\n",
            "🔄 Topology update at step 1320 took 0.0000s\n",
            "Batch 1320/3750 ( 35.2%) | Loss: 0.352037 | Accuracy: 89.44% | Batch time: 0.0195s\n",
            "Step 1330 | Loss: 0.304156 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0040s, O: 0.0007s\n",
            "Step 1340 | Loss: 0.271703 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0032s, O: 0.0016s\n",
            "🔄 Topology update at step 1340 took 0.0000s\n",
            "Batch 1340/3750 ( 35.7%) | Loss: 0.349369 | Accuracy: 89.52% | Batch time: 0.0210s\n",
            "Step 1350 | Loss: 0.023928 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 1360 | Loss: 0.037942 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0021s, O: 0.0006s\n",
            "🔄 Topology update at step 1360 took 0.0001s\n",
            "Batch 1360/3750 ( 36.3%) | Loss: 0.346585 | Accuracy: 89.59% | Batch time: 0.0218s\n",
            "Step 1370 | Loss: 0.320220 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0040s, O: 0.0006s\n",
            "Step 1380 | Loss: 0.220818 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 1380 took 0.0000s\n",
            "Batch 1380/3750 ( 36.8%) | Loss: 0.343740 | Accuracy: 89.67% | Batch time: 0.0203s\n",
            "Step 1390 | Loss: 0.025994 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0023s, O: 0.0007s\n",
            "Step 1400 | Loss: 0.111411 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 1400 took 0.0001s\n",
            "🧹 Memory cleanup at step 1400 took 0.1378s\n",
            "Batch 1400/3750 ( 37.3%) | Loss: 0.341265 | Accuracy: 89.75% | Batch time: 0.0247s\n",
            "Step 1410 | Loss: 0.025347 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "Step 1420 | Loss: 0.020448 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0015s, O: 0.0004s\n",
            "🔄 Topology update at step 1420 took 0.0000s\n",
            "Batch 1420/3750 ( 37.9%) | Loss: 0.338747 | Accuracy: 89.83% | Batch time: 0.0192s\n",
            "Step 1430 | Loss: 0.088625 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0025s, O: 0.0006s\n",
            "Step 1440 | Loss: 0.061141 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0064s, O: 0.0005s\n",
            "🔄 Topology update at step 1440 took 0.0000s\n",
            "Batch 1440/3750 ( 38.4%) | Loss: 0.336149 | Accuracy: 89.92% | Batch time: 0.0194s\n",
            "Step 1450 | Loss: 0.026402 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 1460 | Loss: 0.013952 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0029s, O: 0.0028s\n",
            "🔄 Topology update at step 1460 took 0.0000s\n",
            "Batch 1460/3750 ( 38.9%) | Loss: 0.332998 | Accuracy: 89.99% | Batch time: 0.0213s\n",
            "Step 1470 | Loss: 0.166769 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0023s, O: 0.0006s\n",
            "Step 1480 | Loss: 0.030815 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0061s, O: 0.0006s\n",
            "🔄 Topology update at step 1480 took 0.0000s\n",
            "Batch 1480/3750 ( 39.5%) | Loss: 0.329964 | Accuracy: 90.08% | Batch time: 0.0205s\n",
            "Step 1490 | Loss: 0.135413 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 1500 | Loss: 0.042776 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0031s, O: 0.0017s\n",
            "🔄 Topology update at step 1500 took 0.0000s\n",
            "🧹 Memory cleanup at step 1500 took 0.1544s\n",
            "Batch 1500/3750 ( 40.0%) | Loss: 0.327237 | Accuracy: 90.17% | Batch time: 0.0217s\n",
            "Step 1510 | Loss: 0.019144 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0006s\n",
            "Step 1520 | Loss: 0.052747 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1520 took 0.0000s\n",
            "Batch 1520/3750 ( 40.5%) | Loss: 0.324366 | Accuracy: 90.27% | Batch time: 0.0335s\n",
            "Step 1530 | Loss: 0.154576 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0024s, O: 0.0008s\n",
            "Step 1540 | Loss: 0.176369 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0025s, O: 0.0022s\n",
            "🔄 Topology update at step 1540 took 0.0000s\n",
            "Batch 1540/3750 ( 41.1%) | Loss: 0.323356 | Accuracy: 90.30% | Batch time: 0.0198s\n",
            "Step 1550 | Loss: 0.040356 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0006s\n",
            "Step 1560 | Loss: 0.018053 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0027s, O: 0.0016s\n",
            "🔄 Topology update at step 1560 took 0.0000s\n",
            "Batch 1560/3750 ( 41.6%) | Loss: 0.321562 | Accuracy: 90.35% | Batch time: 0.0201s\n",
            "Step 1570 | Loss: 0.118286 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0041s, O: 0.0008s\n",
            "Step 1580 | Loss: 0.327722 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 1580 took 0.0001s\n",
            "Batch 1580/3750 ( 42.1%) | Loss: 0.319271 | Accuracy: 90.41% | Batch time: 0.0232s\n",
            "Step 1590 | Loss: 0.098253 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0025s, O: 0.0011s\n",
            "Step 1600 | Loss: 0.472157 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0027s, O: 0.0006s\n",
            "🔄 Topology update at step 1600 took 0.0000s\n",
            "🧹 Memory cleanup at step 1600 took 0.1433s\n",
            "Batch 1600/3750 ( 42.7%) | Loss: 0.317606 | Accuracy: 90.46% | Batch time: 0.0225s\n",
            "Step 1610 | Loss: 0.132258 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0016s\n",
            "Step 1620 | Loss: 0.171464 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0025s, O: 0.0016s\n",
            "🔄 Topology update at step 1620 took 0.0001s\n",
            "Batch 1620/3750 ( 43.2%) | Loss: 0.315697 | Accuracy: 90.52% | Batch time: 0.0200s\n",
            "Step 1630 | Loss: 0.100050 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0029s, O: 0.0018s\n",
            "Step 1640 | Loss: 0.712242 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0047s, O: 0.0007s\n",
            "🔄 Topology update at step 1640 took 0.0000s\n",
            "Batch 1640/3750 ( 43.7%) | Loss: 0.313667 | Accuracy: 90.58% | Batch time: 0.0223s\n",
            "Step 1650 | Loss: 0.054896 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 1660 | Loss: 0.242572 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0011s\n",
            "🔄 Topology update at step 1660 took 0.0000s\n",
            "Batch 1660/3750 ( 44.3%) | Loss: 0.311906 | Accuracy: 90.62% | Batch time: 0.0191s\n",
            "Step 1670 | Loss: 0.222244 | GPU: 24.4MB / 98.0MB | F: 0.0052s, B: 0.0025s, O: 0.0006s\n",
            "Step 1680 | Loss: 0.037404 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1680 took 0.0001s\n",
            "Batch 1680/3750 ( 44.8%) | Loss: 0.310179 | Accuracy: 90.69% | Batch time: 0.0185s\n",
            "Step 1690 | Loss: 0.158775 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0016s\n",
            "Step 1700 | Loss: 0.179322 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0040s, O: 0.0007s\n",
            "🔄 Topology update at step 1700 took 0.0000s\n",
            "🧹 Memory cleanup at step 1700 took 0.1319s\n",
            "Batch 1700/3750 ( 45.3%) | Loss: 0.307566 | Accuracy: 90.78% | Batch time: 0.0227s\n",
            "Step 1710 | Loss: 0.150561 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0025s, O: 0.0007s\n",
            "Step 1720 | Loss: 0.053080 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 1720 took 0.0001s\n",
            "Batch 1720/3750 ( 45.9%) | Loss: 0.304940 | Accuracy: 90.86% | Batch time: 0.0223s\n",
            "Step 1730 | Loss: 0.169140 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0052s, O: 0.0007s\n",
            "Step 1740 | Loss: 0.180640 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1740 took 0.0001s\n",
            "Batch 1740/3750 ( 46.4%) | Loss: 0.302979 | Accuracy: 90.91% | Batch time: 0.0217s\n",
            "Step 1750 | Loss: 0.195294 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0008s\n",
            "Step 1760 | Loss: 0.120645 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0053s, O: 0.0006s\n",
            "🔄 Topology update at step 1760 took 0.0001s\n",
            "Batch 1760/3750 ( 46.9%) | Loss: 0.301658 | Accuracy: 90.96% | Batch time: 0.0232s\n",
            "Step 1770 | Loss: 0.071411 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0022s, O: 0.0007s\n",
            "Step 1780 | Loss: 0.158413 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0023s, O: 0.0008s\n",
            "🔄 Topology update at step 1780 took 0.0001s\n",
            "Batch 1780/3750 ( 47.5%) | Loss: 0.300031 | Accuracy: 91.01% | Batch time: 0.0284s\n",
            "Step 1790 | Loss: 0.179645 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0018s, O: 0.0006s\n",
            "Step 1800 | Loss: 0.065851 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0019s, O: 0.0005s\n",
            "🔄 Topology update at step 1800 took 0.0000s\n",
            "🧹 Memory cleanup at step 1800 took 0.2054s\n",
            "Batch 1800/3750 ( 48.0%) | Loss: 0.297836 | Accuracy: 91.08% | Batch time: 0.0267s\n",
            "Step 1810 | Loss: 0.571986 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0017s, O: 0.0005s\n",
            "Step 1820 | Loss: 0.059931 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0020s, O: 0.0006s\n",
            "🔄 Topology update at step 1820 took 0.0001s\n",
            "Batch 1820/3750 ( 48.5%) | Loss: 0.296293 | Accuracy: 91.13% | Batch time: 0.0262s\n",
            "Step 1830 | Loss: 0.031807 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0018s, O: 0.0007s\n",
            "Step 1840 | Loss: 0.148911 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0017s, O: 0.0005s\n",
            "🔄 Topology update at step 1840 took 0.0000s\n",
            "Batch 1840/3750 ( 49.1%) | Loss: 0.293977 | Accuracy: 91.21% | Batch time: 0.0218s\n",
            "Step 1850 | Loss: 0.013390 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0044s, O: 0.0009s\n",
            "Step 1860 | Loss: 0.077848 | GPU: 24.4MB / 98.0MB | F: 0.0059s, B: 0.0020s, O: 0.0007s\n",
            "🔄 Topology update at step 1860 took 0.0000s\n",
            "Batch 1860/3750 ( 49.6%) | Loss: 0.292770 | Accuracy: 91.25% | Batch time: 0.0212s\n",
            "Step 1870 | Loss: 0.123827 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0072s, O: 0.0006s\n",
            "Step 1880 | Loss: 0.174228 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 1880 took 0.0000s\n",
            "Batch 1880/3750 ( 50.1%) | Loss: 0.290791 | Accuracy: 91.30% | Batch time: 0.0220s\n",
            "Step 1890 | Loss: 0.190322 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0020s, O: 0.0006s\n",
            "Step 1900 | Loss: 0.033027 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0042s, O: 0.0012s\n",
            "🔄 Topology update at step 1900 took 0.0001s\n",
            "🧹 Memory cleanup at step 1900 took 0.2071s\n",
            "Batch 1900/3750 ( 50.7%) | Loss: 0.288679 | Accuracy: 91.36% | Batch time: 0.0214s\n",
            "Step 1910 | Loss: 0.108428 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step 1920 | Loss: 0.021682 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0006s\n",
            "🔄 Topology update at step 1920 took 0.0000s\n",
            "Batch 1920/3750 ( 51.2%) | Loss: 0.286602 | Accuracy: 91.42% | Batch time: 0.0195s\n",
            "Step 1930 | Loss: 0.055019 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0006s\n",
            "Step 1940 | Loss: 0.056176 | GPU: 24.4MB / 98.0MB | F: 0.0063s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 1940 took 0.0000s\n",
            "Batch 1940/3750 ( 51.7%) | Loss: 0.284662 | Accuracy: 91.49% | Batch time: 0.0199s\n",
            "Step 1950 | Loss: 0.049380 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0023s, O: 0.0007s\n",
            "Step 1960 | Loss: 0.356363 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 1960 took 0.0001s\n",
            "Batch 1960/3750 ( 52.3%) | Loss: 0.283149 | Accuracy: 91.54% | Batch time: 0.0249s\n",
            "Step 1970 | Loss: 0.170698 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0024s, O: 0.0007s\n",
            "Step 1980 | Loss: 0.049893 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1980 took 0.0000s\n",
            "Batch 1980/3750 ( 52.8%) | Loss: 0.281663 | Accuracy: 91.59% | Batch time: 0.0210s\n",
            "Step 1990 | Loss: 0.006519 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0023s, O: 0.0008s\n",
            "Step 2000 | Loss: 0.064488 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 2000 took 0.0000s\n",
            "🧹 Memory cleanup at step 2000 took 0.1399s\n",
            "Batch 2000/3750 ( 53.3%) | Loss: 0.280390 | Accuracy: 91.63% | Batch time: 0.0227s\n",
            "Step 2010 | Loss: 0.408765 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0026s, O: 0.0007s\n",
            "Step 2020 | Loss: 0.009562 | GPU: 24.4MB / 98.0MB | F: 0.0036s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 2020 took 0.0000s\n",
            "Batch 2020/3750 ( 53.9%) | Loss: 0.278841 | Accuracy: 91.67% | Batch time: 0.0201s\n",
            "Step 2030 | Loss: 0.340038 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0028s, O: 0.0015s\n",
            "Step 2040 | Loss: 0.156572 | GPU: 24.4MB / 98.0MB | F: 0.0033s, B: 0.0030s, O: 0.0008s\n",
            "🔄 Topology update at step 2040 took 0.0001s\n",
            "Batch 2040/3750 ( 54.4%) | Loss: 0.277095 | Accuracy: 91.73% | Batch time: 0.0218s\n",
            "Step 2050 | Loss: 0.247434 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 2060 | Loss: 0.202240 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2060 took 0.0000s\n",
            "Batch 2060/3750 ( 54.9%) | Loss: 0.275759 | Accuracy: 91.76% | Batch time: 0.0202s\n",
            "Step 2070 | Loss: 0.006633 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "Step 2080 | Loss: 0.134313 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0029s, O: 0.0006s\n",
            "🔄 Topology update at step 2080 took 0.0001s\n",
            "Batch 2080/3750 ( 55.5%) | Loss: 0.274085 | Accuracy: 91.81% | Batch time: 0.0251s\n",
            "Step 2090 | Loss: 0.048758 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0042s, O: 0.0015s\n",
            "Step 2100 | Loss: 0.084012 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 2100 took 0.0000s\n",
            "🧹 Memory cleanup at step 2100 took 0.1492s\n",
            "Batch 2100/3750 ( 56.0%) | Loss: 0.272882 | Accuracy: 91.84% | Batch time: 0.0207s\n",
            "Step 2110 | Loss: 0.147927 | GPU: 24.4MB / 98.0MB | F: 0.0092s, B: 0.0022s, O: 0.0006s\n",
            "Step 2120 | Loss: 0.078705 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0033s, O: 0.0004s\n",
            "🔄 Topology update at step 2120 took 0.0000s\n",
            "Batch 2120/3750 ( 56.5%) | Loss: 0.272162 | Accuracy: 91.87% | Batch time: 0.0194s\n",
            "Step 2130 | Loss: 0.035430 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 2140 | Loss: 0.009812 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2140 took 0.0005s\n",
            "Batch 2140/3750 ( 57.1%) | Loss: 0.270802 | Accuracy: 91.91% | Batch time: 0.0264s\n",
            "Step 2150 | Loss: 0.012707 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0038s, O: 0.0015s\n",
            "Step 2160 | Loss: 0.030950 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0018s\n",
            "🔄 Topology update at step 2160 took 0.0001s\n",
            "Batch 2160/3750 ( 57.6%) | Loss: 0.269951 | Accuracy: 91.93% | Batch time: 0.0222s\n",
            "Step 2170 | Loss: 0.048501 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0007s\n",
            "Step 2180 | Loss: 0.251669 | GPU: 24.4MB / 98.0MB | F: 0.0043s, B: 0.0027s, O: 0.0012s\n",
            "🔄 Topology update at step 2180 took 0.0000s\n",
            "Batch 2180/3750 ( 58.1%) | Loss: 0.268427 | Accuracy: 91.97% | Batch time: 0.0211s\n",
            "Step 2190 | Loss: 0.016868 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0032s, O: 0.0022s\n",
            "Step 2200 | Loss: 0.278522 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 2200 took 0.0000s\n",
            "🧹 Memory cleanup at step 2200 took 0.1503s\n",
            "Batch 2200/3750 ( 58.7%) | Loss: 0.267051 | Accuracy: 92.01% | Batch time: 0.0258s\n",
            "Step 2210 | Loss: 0.225537 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0008s\n",
            "Step 2220 | Loss: 0.382060 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0022s, O: 0.0005s\n",
            "🔄 Topology update at step 2220 took 0.0000s\n",
            "Batch 2220/3750 ( 59.2%) | Loss: 0.266213 | Accuracy: 92.03% | Batch time: 0.0189s\n",
            "Step 2230 | Loss: 0.100610 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0020s, O: 0.0005s\n",
            "Step 2240 | Loss: 0.496652 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 2240 took 0.0000s\n",
            "Batch 2240/3750 ( 59.7%) | Loss: 0.264969 | Accuracy: 92.07% | Batch time: 0.0211s\n",
            "Step 2250 | Loss: 0.107472 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0009s\n",
            "Step 2260 | Loss: 0.099805 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0031s, O: 0.0015s\n",
            "🔄 Topology update at step 2260 took 0.0000s\n",
            "Batch 2260/3750 ( 60.3%) | Loss: 0.263425 | Accuracy: 92.12% | Batch time: 0.0228s\n",
            "Step 2270 | Loss: 0.050936 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0034s, O: 0.0008s\n",
            "Step 2280 | Loss: 0.012548 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0027s, O: 0.0006s\n",
            "🔄 Topology update at step 2280 took 0.0001s\n",
            "Batch 2280/3750 ( 60.8%) | Loss: 0.262114 | Accuracy: 92.16% | Batch time: 0.0195s\n",
            "Step 2290 | Loss: 0.057586 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0064s, O: 0.0008s\n",
            "Step 2300 | Loss: 0.098139 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0013s\n",
            "🔄 Topology update at step 2300 took 0.0000s\n",
            "🧹 Memory cleanup at step 2300 took 0.1551s\n",
            "Batch 2300/3750 ( 61.3%) | Loss: 0.260692 | Accuracy: 92.21% | Batch time: 0.0199s\n",
            "Step 2310 | Loss: 0.131147 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step 2320 | Loss: 0.292223 | GPU: 24.4MB / 98.0MB | F: 0.0045s, B: 0.0024s, O: 0.0011s\n",
            "🔄 Topology update at step 2320 took 0.0000s\n",
            "Batch 2320/3750 ( 61.9%) | Loss: 0.259482 | Accuracy: 92.25% | Batch time: 0.0222s\n",
            "Step 2330 | Loss: 0.026614 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0032s, O: 0.0007s\n",
            "Step 2340 | Loss: 0.025698 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0005s\n",
            "🔄 Topology update at step 2340 took 0.0000s\n",
            "Batch 2340/3750 ( 62.4%) | Loss: 0.258379 | Accuracy: 92.29% | Batch time: 0.0205s\n",
            "Step 2350 | Loss: 0.056401 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 2360 | Loss: 0.311438 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0010s\n",
            "🔄 Topology update at step 2360 took 0.0000s\n",
            "Batch 2360/3750 ( 62.9%) | Loss: 0.257440 | Accuracy: 92.33% | Batch time: 0.0197s\n",
            "Step 2370 | Loss: 0.081353 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0006s\n",
            "Step 2380 | Loss: 0.290641 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0042s, O: 0.0007s\n",
            "🔄 Topology update at step 2380 took 0.0000s\n",
            "Batch 2380/3750 ( 63.5%) | Loss: 0.256507 | Accuracy: 92.35% | Batch time: 0.0200s\n",
            "Step 2390 | Loss: 0.072715 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0035s, O: 0.0007s\n",
            "Step 2400 | Loss: 0.066105 | GPU: 24.4MB / 98.0MB | F: 0.0060s, B: 0.0034s, O: 0.0006s\n",
            "🔄 Topology update at step 2400 took 0.0000s\n",
            "🧹 Memory cleanup at step 2400 took 0.1465s\n",
            "Batch 2400/3750 ( 64.0%) | Loss: 0.255137 | Accuracy: 92.40% | Batch time: 0.0226s\n",
            "Step 2410 | Loss: 0.021907 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0023s, O: 0.0007s\n",
            "Step 2420 | Loss: 0.011103 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0044s, O: 0.0008s\n",
            "🔄 Topology update at step 2420 took 0.0000s\n",
            "Batch 2420/3750 ( 64.5%) | Loss: 0.253869 | Accuracy: 92.43% | Batch time: 0.0238s\n",
            "Step 2430 | Loss: 0.188860 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0025s, O: 0.0007s\n",
            "Step 2440 | Loss: 0.037168 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 2440 took 0.0000s\n",
            "Batch 2440/3750 ( 65.1%) | Loss: 0.252774 | Accuracy: 92.46% | Batch time: 0.0219s\n",
            "Step 2450 | Loss: 0.067742 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 2460 | Loss: 0.019664 | GPU: 24.4MB / 98.0MB | F: 0.0050s, B: 0.0057s, O: 0.0008s\n",
            "🔄 Topology update at step 2460 took 0.0000s\n",
            "Batch 2460/3750 ( 65.6%) | Loss: 0.251341 | Accuracy: 92.50% | Batch time: 0.0288s\n",
            "Step 2470 | Loss: 0.012936 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step 2480 | Loss: 0.169971 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2480 took 0.0000s\n",
            "Batch 2480/3750 ( 66.1%) | Loss: 0.250158 | Accuracy: 92.53% | Batch time: 0.0212s\n",
            "Step 2490 | Loss: 0.010139 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0025s, O: 0.0007s\n",
            "Step 2500 | Loss: 0.224278 | GPU: 24.4MB / 98.0MB | F: 0.0041s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 2500 took 0.0000s\n",
            "🧹 Memory cleanup at step 2500 took 0.1502s\n",
            "Batch 2500/3750 ( 66.7%) | Loss: 0.249408 | Accuracy: 92.55% | Batch time: 0.0220s\n",
            "Step 2510 | Loss: 0.006037 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0023s, O: 0.0007s\n",
            "Step 2520 | Loss: 0.204669 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0075s, O: 0.0006s\n",
            "🔄 Topology update at step 2520 took 0.0000s\n",
            "Batch 2520/3750 ( 67.2%) | Loss: 0.248369 | Accuracy: 92.58% | Batch time: 0.0195s\n",
            "Step 2530 | Loss: 0.168693 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0007s\n",
            "Step 2540 | Loss: 0.293732 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 2540 took 0.0001s\n",
            "Batch 2540/3750 ( 67.7%) | Loss: 0.247938 | Accuracy: 92.60% | Batch time: 0.0204s\n",
            "Step 2550 | Loss: 0.228634 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0029s, O: 0.0005s\n",
            "Step 2560 | Loss: 0.032296 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 2560 took 0.0000s\n",
            "Batch 2560/3750 ( 68.3%) | Loss: 0.247029 | Accuracy: 92.62% | Batch time: 0.0229s\n",
            "Step 2570 | Loss: 0.142526 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 2580 | Loss: 0.052658 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2580 took 0.0000s\n",
            "Batch 2580/3750 ( 68.8%) | Loss: 0.245732 | Accuracy: 92.66% | Batch time: 0.0198s\n",
            "Step 2590 | Loss: 0.067740 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0040s, O: 0.0006s\n",
            "Step 2600 | Loss: 0.492597 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 2600 took 0.0000s\n",
            "🧹 Memory cleanup at step 2600 took 0.1516s\n",
            "Batch 2600/3750 ( 69.3%) | Loss: 0.244946 | Accuracy: 92.70% | Batch time: 0.0230s\n",
            "Step 2610 | Loss: 0.031065 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0005s\n",
            "Step 2620 | Loss: 0.021437 | GPU: 24.4MB / 98.0MB | F: 0.0060s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 2620 took 0.0000s\n",
            "Batch 2620/3750 ( 69.9%) | Loss: 0.243701 | Accuracy: 92.74% | Batch time: 0.0194s\n",
            "Step 2630 | Loss: 0.050005 | GPU: 24.4MB / 98.0MB | F: 0.0033s, B: 0.0049s, O: 0.0016s\n",
            "Step 2640 | Loss: 0.011726 | GPU: 24.4MB / 98.0MB | F: 0.0040s, B: 0.0030s, O: 0.0007s\n",
            "🔄 Topology update at step 2640 took 0.0001s\n",
            "Batch 2640/3750 ( 70.4%) | Loss: 0.242777 | Accuracy: 92.77% | Batch time: 0.0197s\n",
            "Step 2650 | Loss: 0.011486 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "Step 2660 | Loss: 0.029963 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0047s, O: 0.0005s\n",
            "🔄 Topology update at step 2660 took 0.0000s\n",
            "Batch 2660/3750 ( 70.9%) | Loss: 0.241552 | Accuracy: 92.80% | Batch time: 0.0210s\n",
            "Step 2670 | Loss: 0.033327 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0011s\n",
            "Step 2680 | Loss: 0.198322 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0021s, O: 0.0006s\n",
            "🔄 Topology update at step 2680 took 0.0000s\n",
            "Batch 2680/3750 ( 71.5%) | Loss: 0.240665 | Accuracy: 92.82% | Batch time: 0.0245s\n",
            "Step 2690 | Loss: 0.049832 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 2700 | Loss: 0.049647 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0030s, O: 0.0008s\n",
            "🔄 Topology update at step 2700 took 0.0000s\n",
            "🧹 Memory cleanup at step 2700 took 0.1444s\n",
            "Batch 2700/3750 ( 72.0%) | Loss: 0.239608 | Accuracy: 92.86% | Batch time: 0.0240s\n",
            "Step 2710 | Loss: 0.049512 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0004s\n",
            "Step 2720 | Loss: 0.362757 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2720 took 0.0000s\n",
            "Batch 2720/3750 ( 72.5%) | Loss: 0.238356 | Accuracy: 92.90% | Batch time: 0.0198s\n",
            "Step 2730 | Loss: 0.258555 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0037s, O: 0.0007s\n",
            "Step 2740 | Loss: 0.005174 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0070s, O: 0.0026s\n",
            "🔄 Topology update at step 2740 took 0.0000s\n",
            "Batch 2740/3750 ( 73.1%) | Loss: 0.237316 | Accuracy: 92.93% | Batch time: 0.0284s\n",
            "Step 2750 | Loss: 0.075036 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0040s, O: 0.0005s\n",
            "Step 2760 | Loss: 0.008295 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0017s, O: 0.0006s\n",
            "🔄 Topology update at step 2760 took 0.0000s\n",
            "Batch 2760/3750 ( 73.6%) | Loss: 0.236523 | Accuracy: 92.96% | Batch time: 0.0269s\n",
            "Step 2770 | Loss: 0.072177 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0026s, O: 0.0007s\n",
            "Step 2780 | Loss: 0.081152 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0017s, O: 0.0005s\n",
            "🔄 Topology update at step 2780 took 0.0001s\n",
            "Batch 2780/3750 ( 74.1%) | Loss: 0.235722 | Accuracy: 92.98% | Batch time: 0.0242s\n",
            "Step 2790 | Loss: 0.467480 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0017s, O: 0.0005s\n",
            "Step 2800 | Loss: 0.045508 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0018s, O: 0.0008s\n",
            "🔄 Topology update at step 2800 took 0.0000s\n",
            "🧹 Memory cleanup at step 2800 took 0.1829s\n",
            "Batch 2800/3750 ( 74.7%) | Loss: 0.234884 | Accuracy: 93.01% | Batch time: 0.0218s\n",
            "Step 2810 | Loss: 0.075139 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0025s, O: 0.0006s\n",
            "Step 2820 | Loss: 0.062510 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0018s, O: 0.0009s\n",
            "🔄 Topology update at step 2820 took 0.0001s\n",
            "Batch 2820/3750 ( 75.2%) | Loss: 0.234183 | Accuracy: 93.03% | Batch time: 0.0263s\n",
            "Step 2830 | Loss: 0.073791 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0016s, O: 0.0005s\n",
            "Step 2840 | Loss: 0.057664 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0018s, O: 0.0006s\n",
            "🔄 Topology update at step 2840 took 0.0000s\n",
            "Batch 2840/3750 ( 75.7%) | Loss: 0.233043 | Accuracy: 93.06% | Batch time: 0.0208s\n",
            "Step 2850 | Loss: 0.013151 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0023s, O: 0.0027s\n",
            "Step 2860 | Loss: 0.274752 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0041s, O: 0.0006s\n",
            "🔄 Topology update at step 2860 took 0.0000s\n",
            "Batch 2860/3750 ( 76.3%) | Loss: 0.232376 | Accuracy: 93.09% | Batch time: 0.0222s\n",
            "Step 2870 | Loss: 0.121746 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0030s, O: 0.0007s\n",
            "Step 2880 | Loss: 0.145928 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0030s, O: 0.0006s\n",
            "🔄 Topology update at step 2880 took 0.0000s\n",
            "Batch 2880/3750 ( 76.8%) | Loss: 0.231792 | Accuracy: 93.11% | Batch time: 0.0227s\n",
            "Step 2890 | Loss: 0.566051 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0026s, O: 0.0011s\n",
            "Step 2900 | Loss: 0.095206 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 2900 took 0.0000s\n",
            "🧹 Memory cleanup at step 2900 took 0.1872s\n",
            "Batch 2900/3750 ( 77.3%) | Loss: 0.231451 | Accuracy: 93.12% | Batch time: 0.0238s\n",
            "Step 2910 | Loss: 0.038328 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0054s, O: 0.0009s\n",
            "Step 2920 | Loss: 0.034950 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2920 took 0.0000s\n",
            "Batch 2920/3750 ( 77.9%) | Loss: 0.230575 | Accuracy: 93.14% | Batch time: 0.0253s\n",
            "Step 2930 | Loss: 0.051262 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0034s, O: 0.0008s\n",
            "Step 2940 | Loss: 0.179377 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2940 took 0.0000s\n",
            "Batch 2940/3750 ( 78.4%) | Loss: 0.229658 | Accuracy: 93.17% | Batch time: 0.0224s\n",
            "Step 2950 | Loss: 0.022487 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0039s, O: 0.0007s\n",
            "Step 2960 | Loss: 0.180956 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0015s\n",
            "🔄 Topology update at step 2960 took 0.0000s\n",
            "Batch 2960/3750 ( 78.9%) | Loss: 0.229077 | Accuracy: 93.19% | Batch time: 0.0217s\n",
            "Step 2970 | Loss: 0.008116 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0019s, O: 0.0007s\n",
            "Step 2980 | Loss: 0.017501 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0039s, O: 0.0007s\n",
            "🔄 Topology update at step 2980 took 0.0000s\n",
            "Batch 2980/3750 ( 79.5%) | Loss: 0.227944 | Accuracy: 93.23% | Batch time: 0.0206s\n",
            "Step 2990 | Loss: 0.240356 | GPU: 24.4MB / 98.0MB | F: 0.0035s, B: 0.0028s, O: 0.0011s\n",
            "Step 3000 | Loss: 0.004789 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3000 took 0.0001s\n",
            "🧹 Memory cleanup at step 3000 took 0.1494s\n",
            "Batch 3000/3750 ( 80.0%) | Loss: 0.227054 | Accuracy: 93.25% | Batch time: 0.0223s\n",
            "Step 3010 | Loss: 0.020736 | GPU: 24.4MB / 98.0MB | F: 0.0033s, B: 0.0027s, O: 0.0067s\n",
            "Step 3020 | Loss: 0.014400 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3020 took 0.0000s\n",
            "Batch 3020/3750 ( 80.5%) | Loss: 0.225964 | Accuracy: 93.29% | Batch time: 0.0199s\n",
            "Step 3030 | Loss: 0.046505 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 3040 | Loss: 0.077006 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 3040 took 0.0001s\n",
            "Batch 3040/3750 ( 81.1%) | Loss: 0.225057 | Accuracy: 93.32% | Batch time: 0.0266s\n",
            "Step 3050 | Loss: 0.009553 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 3060 | Loss: 0.016587 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0031s, O: 0.0012s\n",
            "🔄 Topology update at step 3060 took 0.0000s\n",
            "Batch 3060/3750 ( 81.6%) | Loss: 0.224104 | Accuracy: 93.34% | Batch time: 0.0211s\n",
            "Step 3070 | Loss: 0.017111 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0014s\n",
            "Step 3080 | Loss: 0.010312 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0042s, O: 0.0007s\n",
            "🔄 Topology update at step 3080 took 0.0000s\n",
            "Batch 3080/3750 ( 82.1%) | Loss: 0.223147 | Accuracy: 93.37% | Batch time: 0.0206s\n",
            "Step 3090 | Loss: 0.045054 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0032s, O: 0.0004s\n",
            "Step 3100 | Loss: 0.041660 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3100 took 0.0000s\n",
            "🧹 Memory cleanup at step 3100 took 0.1601s\n",
            "Batch 3100/3750 ( 82.7%) | Loss: 0.223129 | Accuracy: 93.38% | Batch time: 0.0231s\n",
            "Step 3110 | Loss: 0.082560 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0009s\n",
            "Step 3120 | Loss: 0.273445 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0054s, O: 0.0007s\n",
            "🔄 Topology update at step 3120 took 0.0000s\n",
            "Batch 3120/3750 ( 83.2%) | Loss: 0.222435 | Accuracy: 93.40% | Batch time: 0.0197s\n",
            "Step 3130 | Loss: 0.036195 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "Step 3140 | Loss: 0.383212 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0038s, O: 0.0005s\n",
            "🔄 Topology update at step 3140 took 0.0000s\n",
            "Batch 3140/3750 ( 83.7%) | Loss: 0.221775 | Accuracy: 93.41% | Batch time: 0.0205s\n",
            "Step 3150 | Loss: 0.185529 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0011s\n",
            "Step 3160 | Loss: 0.035846 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0031s, O: 0.0037s\n",
            "🔄 Topology update at step 3160 took 0.0000s\n",
            "Batch 3160/3750 ( 84.3%) | Loss: 0.221022 | Accuracy: 93.43% | Batch time: 0.0210s\n",
            "Step 3170 | Loss: 0.198956 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0012s\n",
            "Step 3180 | Loss: 0.031233 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0059s, O: 0.0006s\n",
            "🔄 Topology update at step 3180 took 0.0000s\n",
            "Batch 3180/3750 ( 84.8%) | Loss: 0.220213 | Accuracy: 93.46% | Batch time: 0.0195s\n",
            "Step 3190 | Loss: 0.291005 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0026s, O: 0.0007s\n",
            "Step 3200 | Loss: 0.029443 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0040s, O: 0.0007s\n",
            "🔄 Topology update at step 3200 took 0.0000s\n",
            "🧹 Memory cleanup at step 3200 took 0.1496s\n",
            "Batch 3200/3750 ( 85.3%) | Loss: 0.219541 | Accuracy: 93.48% | Batch time: 0.0224s\n",
            "Step 3210 | Loss: 0.061563 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0025s, O: 0.0006s\n",
            "Step 3220 | Loss: 0.082055 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 3220 took 0.0001s\n",
            "Batch 3220/3750 ( 85.9%) | Loss: 0.218907 | Accuracy: 93.49% | Batch time: 0.0191s\n",
            "Step 3230 | Loss: 0.125705 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 3240 | Loss: 0.019867 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 3240 took 0.0000s\n",
            "Batch 3240/3750 ( 86.4%) | Loss: 0.218316 | Accuracy: 93.50% | Batch time: 0.0207s\n",
            "Step 3250 | Loss: 0.014406 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 3260 | Loss: 0.195113 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0085s, O: 0.0011s\n",
            "🔄 Topology update at step 3260 took 0.0000s\n",
            "Batch 3260/3750 ( 86.9%) | Loss: 0.217673 | Accuracy: 93.52% | Batch time: 0.0203s\n",
            "Step 3270 | Loss: 0.021013 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0025s, O: 0.0007s\n",
            "Step 3280 | Loss: 0.101636 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0037s, O: 0.0007s\n",
            "🔄 Topology update at step 3280 took 0.0000s\n",
            "Batch 3280/3750 ( 87.5%) | Loss: 0.216826 | Accuracy: 93.55% | Batch time: 0.0199s\n",
            "Step 3290 | Loss: 0.337181 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 3300 | Loss: 0.274239 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0026s, O: 0.0013s\n",
            "🔄 Topology update at step 3300 took 0.0000s\n",
            "🧹 Memory cleanup at step 3300 took 0.1523s\n",
            "Batch 3300/3750 ( 88.0%) | Loss: 0.216432 | Accuracy: 93.56% | Batch time: 0.0229s\n",
            "Step 3310 | Loss: 0.064574 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0040s, O: 0.0007s\n",
            "Step 3320 | Loss: 0.164906 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0032s, O: 0.0007s\n",
            "🔄 Topology update at step 3320 took 0.0000s\n",
            "Batch 3320/3750 ( 88.5%) | Loss: 0.215902 | Accuracy: 93.57% | Batch time: 0.0196s\n",
            "Step 3330 | Loss: 0.026508 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0029s, O: 0.0006s\n",
            "Step 3340 | Loss: 0.312684 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0036s, O: 0.0007s\n",
            "🔄 Topology update at step 3340 took 0.0001s\n",
            "Batch 3340/3750 ( 89.1%) | Loss: 0.215258 | Accuracy: 93.59% | Batch time: 0.0257s\n",
            "Step 3350 | Loss: 0.031632 | GPU: 24.4MB / 98.0MB | F: 0.0036s, B: 0.0029s, O: 0.0004s\n",
            "Step 3360 | Loss: 0.031640 | GPU: 24.4MB / 98.0MB | F: 0.0049s, B: 0.0028s, O: 0.0005s\n",
            "🔄 Topology update at step 3360 took 0.0000s\n",
            "Batch 3360/3750 ( 89.6%) | Loss: 0.214845 | Accuracy: 93.61% | Batch time: 0.0272s\n",
            "Step 3370 | Loss: 0.046227 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0032s, O: 0.0007s\n",
            "Step 3380 | Loss: 0.540740 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3380 took 0.0000s\n",
            "Batch 3380/3750 ( 90.1%) | Loss: 0.214341 | Accuracy: 93.63% | Batch time: 0.0220s\n",
            "Step 3390 | Loss: 0.395450 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0026s, O: 0.0007s\n",
            "Step 3400 | Loss: 0.038402 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 3400 took 0.0000s\n",
            "🧹 Memory cleanup at step 3400 took 0.1548s\n",
            "Batch 3400/3750 ( 90.7%) | Loss: 0.213834 | Accuracy: 93.64% | Batch time: 0.0234s\n",
            "Step 3410 | Loss: 0.454824 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0025s, O: 0.0007s\n",
            "Step 3420 | Loss: 0.194544 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0069s, O: 0.0014s\n",
            "🔄 Topology update at step 3420 took 0.0000s\n",
            "Batch 3420/3750 ( 91.2%) | Loss: 0.213438 | Accuracy: 93.66% | Batch time: 0.0199s\n",
            "Step 3430 | Loss: 0.018101 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0042s, O: 0.0014s\n",
            "Step 3440 | Loss: 0.018689 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 3440 took 0.0000s\n",
            "Batch 3440/3750 ( 91.7%) | Loss: 0.213047 | Accuracy: 93.67% | Batch time: 0.0201s\n",
            "Step 3450 | Loss: 0.042397 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step 3460 | Loss: 0.087014 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 3460 took 0.0001s\n",
            "Batch 3460/3750 ( 92.3%) | Loss: 0.212322 | Accuracy: 93.69% | Batch time: 0.0223s\n",
            "Step 3470 | Loss: 0.052215 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0042s, O: 0.0009s\n",
            "Step 3480 | Loss: 0.077419 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0042s, O: 0.0006s\n",
            "🔄 Topology update at step 3480 took 0.0001s\n",
            "Batch 3480/3750 ( 92.8%) | Loss: 0.211504 | Accuracy: 93.71% | Batch time: 0.0215s\n",
            "Step 3490 | Loss: 0.021705 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0012s\n",
            "Step 3500 | Loss: 0.009139 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0036s, O: 0.0008s\n",
            "🔄 Topology update at step 3500 took 0.0000s\n",
            "🧹 Memory cleanup at step 3500 took 0.1580s\n",
            "Batch 3500/3750 ( 93.3%) | Loss: 0.210898 | Accuracy: 93.73% | Batch time: 0.0224s\n",
            "Step 3510 | Loss: 0.036350 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0028s, O: 0.0007s\n",
            "Step 3520 | Loss: 0.091966 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0040s, O: 0.0009s\n",
            "🔄 Topology update at step 3520 took 0.0000s\n",
            "Batch 3520/3750 ( 93.9%) | Loss: 0.210372 | Accuracy: 93.75% | Batch time: 0.0241s\n",
            "Step 3530 | Loss: 0.117529 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0036s, O: 0.0007s\n",
            "Step 3540 | Loss: 0.106548 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 3540 took 0.0001s\n",
            "Batch 3540/3750 ( 94.4%) | Loss: 0.209812 | Accuracy: 93.76% | Batch time: 0.0221s\n",
            "Step 3550 | Loss: 0.022134 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0028s, O: 0.0008s\n",
            "Step 3560 | Loss: 0.154383 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 3560 took 0.0000s\n",
            "Batch 3560/3750 ( 94.9%) | Loss: 0.209203 | Accuracy: 93.78% | Batch time: 0.0214s\n",
            "Step 3570 | Loss: 0.007475 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0029s, O: 0.0018s\n",
            "Step 3580 | Loss: 0.009401 | GPU: 24.4MB / 98.0MB | F: 0.0048s, B: 0.0048s, O: 0.0005s\n",
            "🔄 Topology update at step 3580 took 0.0001s\n",
            "Batch 3580/3750 ( 95.5%) | Loss: 0.208518 | Accuracy: 93.80% | Batch time: 0.0208s\n",
            "Step 3590 | Loss: 0.141190 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0031s, O: 0.0008s\n",
            "Step 3600 | Loss: 0.007798 | GPU: 24.4MB / 98.0MB | F: 0.0072s, B: 0.0031s, O: 0.0005s\n",
            "🔄 Topology update at step 3600 took 0.0000s\n",
            "🧹 Memory cleanup at step 3600 took 0.1545s\n",
            "Batch 3600/3750 ( 96.0%) | Loss: 0.207903 | Accuracy: 93.82% | Batch time: 0.0221s\n",
            "Step 3610 | Loss: 0.084267 | GPU: 24.4MB / 98.0MB | F: 0.0037s, B: 0.0025s, O: 0.0009s\n",
            "Step 3620 | Loss: 0.016936 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0044s, O: 0.0008s\n",
            "🔄 Topology update at step 3620 took 0.0000s\n",
            "Batch 3620/3750 ( 96.5%) | Loss: 0.207678 | Accuracy: 93.83% | Batch time: 0.0206s\n",
            "Step 3630 | Loss: 0.006126 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Step 3640 | Loss: 0.012704 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0046s, O: 0.0005s\n",
            "🔄 Topology update at step 3640 took 0.0000s\n",
            "Batch 3640/3750 ( 97.1%) | Loss: 0.206890 | Accuracy: 93.86% | Batch time: 0.0206s\n",
            "Step 3650 | Loss: 0.032777 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 3660 | Loss: 0.164319 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0055s, O: 0.0010s\n",
            "🔄 Topology update at step 3660 took 0.0001s\n",
            "Batch 3660/3750 ( 97.6%) | Loss: 0.206296 | Accuracy: 93.88% | Batch time: 0.0218s\n",
            "Step 3670 | Loss: 0.181409 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0008s\n",
            "Step 3680 | Loss: 0.042668 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0044s, O: 0.0006s\n",
            "🔄 Topology update at step 3680 took 0.0000s\n",
            "Batch 3680/3750 ( 98.1%) | Loss: 0.206213 | Accuracy: 93.88% | Batch time: 0.0189s\n",
            "Step 3690 | Loss: 0.291392 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 3700 | Loss: 0.049317 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0032s, O: 0.0007s\n",
            "🔄 Topology update at step 3700 took 0.0000s\n",
            "🧹 Memory cleanup at step 3700 took 0.1542s\n",
            "Batch 3700/3750 ( 98.7%) | Loss: 0.205740 | Accuracy: 93.89% | Batch time: 0.0195s\n",
            "Step 3710 | Loss: 0.033935 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 3720 | Loss: 0.008306 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0030s, O: 0.0006s\n",
            "🔄 Topology update at step 3720 took 0.0000s\n",
            "Batch 3720/3750 ( 99.2%) | Loss: 0.205409 | Accuracy: 93.90% | Batch time: 0.0197s\n",
            "Step 3730 | Loss: 0.384936 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0049s, O: 0.0006s\n",
            "Step 3740 | Loss: 0.012686 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0101s, O: 0.0007s\n",
            "🔄 Topology update at step 3740 took 0.0000s\n",
            "Batch 3740/3750 ( 99.7%) | Loss: 0.205207 | Accuracy: 93.91% | Batch time: 0.0259s\n",
            "Step 3750 | Loss: 0.018402 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0017s, O: 0.0005s\n",
            "\n",
            "-------------------- EPOCH 1 SUMMARY --------------------\n",
            "Loss: 0.204900 | Accuracy: 93.92%\n",
            "Time: 47.28s total, 0.0114s per batch\n",
            "🔄 Final Memory - RAM: 1369.9MB, GPU: 24.4MB allocated, 98.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=24.4, peak=24.4\n",
            "===============================\n",
            "\n",
            "⏱️ TALT model training took 47.2829 seconds\n",
            "\n",
            "Cleaning up memory after training...\n",
            "⏱️ Memory cleanup took 0.1894 seconds\n",
            "🔄 After training Memory - RAM: 1369.9MB, GPU: 24.3MB allocated, 44.0MB reserved\n",
            "\n",
            "------------------------- Standard Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 0.059080 | Accuracy: 97.67% | Batch time: 0.0013s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 0.069255 | Accuracy: 97.46% | Batch time: 0.0009s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 0.079899 | Accuracy: 97.31% | Batch time: 0.0045s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 0.075226 | Accuracy: 97.45% | Batch time: 0.0009s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 0.076127 | Accuracy: 97.49% | Batch time: 0.0013s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 0.072746 | Accuracy: 97.67% | Batch time: 0.0013s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 0.065056 | Accuracy: 97.92% | Batch time: 0.0013s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 0.063046 | Accuracy: 97.97% | Batch time: 0.0016s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 0.061145 | Accuracy: 98.10% | Batch time: 0.0016s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 0.056018 | Accuracy: 98.29% | Batch time: 0.0013s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 0.053300 | Accuracy: 98.37% | Batch time: 0.0013s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 0.050606 | Accuracy: 98.43% | Batch time: 0.0012s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.052945 | Accuracy: 98.33%\n",
            "Time: 3.83s total, 0.0014s per batch\n",
            "⏱️ Standard model evaluation took 3.8336 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 0.045882 | Accuracy: 98.77% | Batch time: 0.0014s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 0.068461 | Accuracy: 97.77% | Batch time: 0.0013s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 0.075333 | Accuracy: 97.39% | Batch time: 0.0016s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 0.072343 | Accuracy: 97.64% | Batch time: 0.0013s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 0.072062 | Accuracy: 97.73% | Batch time: 0.0012s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 0.072025 | Accuracy: 97.67% | Batch time: 0.0013s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 0.065801 | Accuracy: 97.88% | Batch time: 0.0012s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 0.062373 | Accuracy: 98.00% | Batch time: 0.0013s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 0.058948 | Accuracy: 98.14% | Batch time: 0.0013s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 0.054435 | Accuracy: 98.32% | Batch time: 0.0012s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 0.051463 | Accuracy: 98.39% | Batch time: 0.0012s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 0.048628 | Accuracy: 98.46% | Batch time: 0.0016s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.050220 | Accuracy: 98.42%\n",
            "Time: 3.10s total, 0.0014s per batch\n",
            "⏱️ TALT model evaluation took 3.0978 seconds\n",
            "\n",
            "------------------------- EPOCH 1 SUMMARY -------------------------\n",
            "Time: 81.32s\n",
            "Standard Model:\n",
            "  - Train Loss: 0.405545, Accuracy: 87.14%\n",
            "  - Test Loss:  0.052945, Accuracy: 98.33%\n",
            "Improved TALT Model:\n",
            "  - Train Loss: 0.204900, Accuracy: 93.92%\n",
            "  - Test Loss:  0.050220, Accuracy: 98.42%\n",
            "\n",
            "📈 TALT outperforms standard by 0.09% on test accuracy\n",
            "\n",
            "Cleaning up memory after epoch...\n",
            "⏱️ Memory cleanup took 0.1591 seconds\n",
            "🔄 After epoch Memory - RAM: 1369.9MB, GPU: 24.3MB allocated, 44.0MB reserved\n",
            "\n",
            "------------------------- Standard Model: Epoch 2/3 -------------------------\n",
            "\n",
            "==================== STANDARD OPTIMIZER - EPOCH 2 ====================\n",
            "Device: cuda, Batches: 3750, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 1369.9MB, GPU: 24.3MB allocated, 44.0MB reserved\n",
            "Batch    0/3750 (  0.0%) | Loss: 0.440794 | Accuracy: 81.25% | GPU: 24.4MB | Batch time: 0.0100s\n",
            "Batch   20/3750 (  0.5%) | Loss: 0.171965 | Accuracy: 94.05% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch   40/3750 (  1.1%) | Loss: 0.148983 | Accuracy: 95.12% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch   60/3750 (  1.6%) | Loss: 0.140018 | Accuracy: 95.29% | GPU: 24.4MB | Batch time: 0.0116s\n",
            "Batch   80/3750 (  2.1%) | Loss: 0.141728 | Accuracy: 95.14% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch  100/3750 (  2.7%) | Loss: 0.133207 | Accuracy: 95.42% | GPU: 24.4MB | Batch time: 0.0103s\n",
            "Batch  120/3750 (  3.2%) | Loss: 0.122951 | Accuracy: 95.82% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch  140/3750 (  3.7%) | Loss: 0.122643 | Accuracy: 95.88% | GPU: 24.4MB | Batch time: 0.0086s\n",
            "Batch  160/3750 (  4.3%) | Loss: 0.126668 | Accuracy: 95.85% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch  180/3750 (  4.8%) | Loss: 0.126571 | Accuracy: 95.89% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch  200/3750 (  5.3%) | Loss: 0.123026 | Accuracy: 96.05% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch  220/3750 (  5.9%) | Loss: 0.126258 | Accuracy: 95.98% | GPU: 24.4MB | Batch time: 0.0070s\n",
            "Batch  240/3750 (  6.4%) | Loss: 0.125369 | Accuracy: 96.01% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch  260/3750 (  6.9%) | Loss: 0.126786 | Accuracy: 96.00% | GPU: 24.4MB | Batch time: 0.0057s\n",
            "Batch  280/3750 (  7.5%) | Loss: 0.130888 | Accuracy: 95.95% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch  300/3750 (  8.0%) | Loss: 0.128210 | Accuracy: 95.99% | GPU: 24.4MB | Batch time: 0.0045s\n",
            "Batch  320/3750 (  8.5%) | Loss: 0.128805 | Accuracy: 95.99% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch  340/3750 (  9.1%) | Loss: 0.129736 | Accuracy: 96.04% | GPU: 24.4MB | Batch time: 0.0094s\n",
            "Batch  360/3750 (  9.6%) | Loss: 0.130150 | Accuracy: 96.00% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch  380/3750 ( 10.1%) | Loss: 0.131757 | Accuracy: 96.00% | GPU: 24.4MB | Batch time: 0.0051s\n",
            "Batch  400/3750 ( 10.7%) | Loss: 0.130602 | Accuracy: 96.04% | GPU: 24.4MB | Batch time: 0.0061s\n",
            "Batch  420/3750 ( 11.2%) | Loss: 0.130817 | Accuracy: 96.02% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch  440/3750 ( 11.7%) | Loss: 0.131933 | Accuracy: 96.03% | GPU: 24.4MB | Batch time: 0.0057s\n",
            "Batch  460/3750 ( 12.3%) | Loss: 0.132557 | Accuracy: 96.00% | GPU: 24.4MB | Batch time: 0.0078s\n",
            "Batch  480/3750 ( 12.8%) | Loss: 0.134377 | Accuracy: 96.00% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch  500/3750 ( 13.3%) | Loss: 0.137098 | Accuracy: 95.93% | GPU: 24.4MB | Batch time: 0.0063s\n",
            "Batch  520/3750 ( 13.9%) | Loss: 0.138184 | Accuracy: 95.87% | GPU: 24.4MB | Batch time: 0.0055s\n",
            "Batch  540/3750 ( 14.4%) | Loss: 0.137736 | Accuracy: 95.90% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch  560/3750 ( 14.9%) | Loss: 0.138734 | Accuracy: 95.86% | GPU: 24.4MB | Batch time: 0.0028s\n",
            "Batch  580/3750 ( 15.5%) | Loss: 0.138194 | Accuracy: 95.86% | GPU: 24.4MB | Batch time: 0.0034s\n",
            "Batch  600/3750 ( 16.0%) | Loss: 0.139210 | Accuracy: 95.82% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch  620/3750 ( 16.5%) | Loss: 0.138536 | Accuracy: 95.82% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch  640/3750 ( 17.1%) | Loss: 0.137509 | Accuracy: 95.89% | GPU: 24.4MB | Batch time: 0.0054s\n",
            "Batch  660/3750 ( 17.6%) | Loss: 0.136633 | Accuracy: 95.89% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch  680/3750 ( 18.1%) | Loss: 0.135426 | Accuracy: 95.91% | GPU: 24.4MB | Batch time: 0.0074s\n",
            "Batch  700/3750 ( 18.7%) | Loss: 0.135390 | Accuracy: 95.93% | GPU: 24.4MB | Batch time: 0.0051s\n",
            "Batch  720/3750 ( 19.2%) | Loss: 0.134857 | Accuracy: 95.92% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch  740/3750 ( 19.7%) | Loss: 0.135884 | Accuracy: 95.88% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch  760/3750 ( 20.3%) | Loss: 0.137370 | Accuracy: 95.84% | GPU: 24.4MB | Batch time: 0.0057s\n",
            "Batch  780/3750 ( 20.8%) | Loss: 0.137425 | Accuracy: 95.83% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch  800/3750 ( 21.3%) | Loss: 0.137102 | Accuracy: 95.86% | GPU: 24.4MB | Batch time: 0.0052s\n",
            "Batch  820/3750 ( 21.9%) | Loss: 0.136581 | Accuracy: 95.85% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch  840/3750 ( 22.4%) | Loss: 0.135789 | Accuracy: 95.86% | GPU: 24.4MB | Batch time: 0.0028s\n",
            "Batch  860/3750 ( 22.9%) | Loss: 0.134513 | Accuracy: 95.88% | GPU: 24.4MB | Batch time: 0.0029s\n",
            "Batch  880/3750 ( 23.5%) | Loss: 0.135142 | Accuracy: 95.91% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch  900/3750 ( 24.0%) | Loss: 0.135923 | Accuracy: 95.88% | GPU: 24.4MB | Batch time: 0.0028s\n",
            "Batch  920/3750 ( 24.5%) | Loss: 0.136189 | Accuracy: 95.87% | GPU: 24.4MB | Batch time: 0.0028s\n",
            "Batch  940/3750 ( 25.1%) | Loss: 0.136026 | Accuracy: 95.87% | GPU: 24.4MB | Batch time: 0.0069s\n",
            "Batch  960/3750 ( 25.6%) | Loss: 0.134512 | Accuracy: 95.92% | GPU: 24.4MB | Batch time: 0.0066s\n",
            "Batch  980/3750 ( 26.1%) | Loss: 0.133778 | Accuracy: 95.94% | GPU: 24.4MB | Batch time: 0.0072s\n",
            "Batch 1000/3750 ( 26.7%) | Loss: 0.134326 | Accuracy: 95.92% | GPU: 24.4MB | Batch time: 0.0075s\n",
            "Batch 1020/3750 ( 27.2%) | Loss: 0.133533 | Accuracy: 95.94% | GPU: 24.4MB | Batch time: 0.0033s\n",
            "Batch 1040/3750 ( 27.7%) | Loss: 0.132718 | Accuracy: 95.97% | GPU: 24.4MB | Batch time: 0.0044s\n",
            "Batch 1060/3750 ( 28.3%) | Loss: 0.133662 | Accuracy: 95.92% | GPU: 24.4MB | Batch time: 0.0059s\n",
            "Batch 1080/3750 ( 28.8%) | Loss: 0.134470 | Accuracy: 95.92% | GPU: 24.4MB | Batch time: 0.0055s\n",
            "Batch 1100/3750 ( 29.3%) | Loss: 0.135177 | Accuracy: 95.92% | GPU: 24.4MB | Batch time: 0.0042s\n",
            "Batch 1120/3750 ( 29.9%) | Loss: 0.134622 | Accuracy: 95.92% | GPU: 24.4MB | Batch time: 0.0057s\n",
            "Batch 1140/3750 ( 30.4%) | Loss: 0.134946 | Accuracy: 95.92% | GPU: 24.4MB | Batch time: 0.0081s\n",
            "Batch 1160/3750 ( 30.9%) | Loss: 0.134446 | Accuracy: 95.93% | GPU: 24.4MB | Batch time: 0.0054s\n",
            "Batch 1180/3750 ( 31.5%) | Loss: 0.134436 | Accuracy: 95.93% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch 1200/3750 ( 32.0%) | Loss: 0.134317 | Accuracy: 95.94% | GPU: 24.4MB | Batch time: 0.0115s\n",
            "Batch 1220/3750 ( 32.5%) | Loss: 0.134313 | Accuracy: 95.94% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 1240/3750 ( 33.1%) | Loss: 0.133769 | Accuracy: 95.97% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 1260/3750 ( 33.6%) | Loss: 0.133228 | Accuracy: 95.99% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 1280/3750 ( 34.1%) | Loss: 0.133408 | Accuracy: 95.99% | GPU: 24.4MB | Batch time: 0.0053s\n",
            "Batch 1300/3750 ( 34.7%) | Loss: 0.132690 | Accuracy: 96.01% | GPU: 24.4MB | Batch time: 0.0050s\n",
            "Batch 1320/3750 ( 35.2%) | Loss: 0.133126 | Accuracy: 96.02% | GPU: 24.4MB | Batch time: 0.0045s\n",
            "Batch 1340/3750 ( 35.7%) | Loss: 0.132464 | Accuracy: 96.04% | GPU: 24.4MB | Batch time: 0.0061s\n",
            "Batch 1360/3750 ( 36.3%) | Loss: 0.132532 | Accuracy: 96.05% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch 1380/3750 ( 36.8%) | Loss: 0.132017 | Accuracy: 96.07% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch 1400/3750 ( 37.3%) | Loss: 0.131944 | Accuracy: 96.07% | GPU: 24.4MB | Batch time: 0.0081s\n",
            "Batch 1420/3750 ( 37.9%) | Loss: 0.132379 | Accuracy: 96.05% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 1440/3750 ( 38.4%) | Loss: 0.131816 | Accuracy: 96.06% | GPU: 24.4MB | Batch time: 0.0056s\n",
            "Batch 1460/3750 ( 38.9%) | Loss: 0.132262 | Accuracy: 96.05% | GPU: 24.4MB | Batch time: 0.0135s\n",
            "Batch 1480/3750 ( 39.5%) | Loss: 0.132237 | Accuracy: 96.05% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 1500/3750 ( 40.0%) | Loss: 0.131737 | Accuracy: 96.06% | GPU: 24.4MB | Batch time: 0.0060s\n",
            "Batch 1520/3750 ( 40.5%) | Loss: 0.133055 | Accuracy: 96.03% | GPU: 24.4MB | Batch time: 0.0064s\n",
            "Batch 1540/3750 ( 41.1%) | Loss: 0.132283 | Accuracy: 96.07% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 1560/3750 ( 41.6%) | Loss: 0.132366 | Accuracy: 96.06% | GPU: 24.4MB | Batch time: 0.0067s\n",
            "Batch 1580/3750 ( 42.1%) | Loss: 0.132850 | Accuracy: 96.06% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 1600/3750 ( 42.7%) | Loss: 0.132629 | Accuracy: 96.07% | GPU: 24.4MB | Batch time: 0.0054s\n",
            "Batch 1620/3750 ( 43.2%) | Loss: 0.132529 | Accuracy: 96.08% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 1640/3750 ( 43.7%) | Loss: 0.132190 | Accuracy: 96.10% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 1660/3750 ( 44.3%) | Loss: 0.131770 | Accuracy: 96.11% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch 1680/3750 ( 44.8%) | Loss: 0.131309 | Accuracy: 96.11% | GPU: 24.4MB | Batch time: 0.0057s\n",
            "Batch 1700/3750 ( 45.3%) | Loss: 0.131379 | Accuracy: 96.11% | GPU: 24.4MB | Batch time: 0.0051s\n",
            "Batch 1720/3750 ( 45.9%) | Loss: 0.131433 | Accuracy: 96.10% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch 1740/3750 ( 46.4%) | Loss: 0.130925 | Accuracy: 96.12% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 1760/3750 ( 46.9%) | Loss: 0.130368 | Accuracy: 96.14% | GPU: 24.4MB | Batch time: 0.0050s\n",
            "Batch 1780/3750 ( 47.5%) | Loss: 0.130074 | Accuracy: 96.16% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 1800/3750 ( 48.0%) | Loss: 0.130396 | Accuracy: 96.15% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 1820/3750 ( 48.5%) | Loss: 0.130508 | Accuracy: 96.15% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 1840/3750 ( 49.1%) | Loss: 0.130123 | Accuracy: 96.17% | GPU: 24.4MB | Batch time: 0.0043s\n",
            "Batch 1860/3750 ( 49.6%) | Loss: 0.130115 | Accuracy: 96.17% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 1880/3750 ( 50.1%) | Loss: 0.129992 | Accuracy: 96.17% | GPU: 24.4MB | Batch time: 0.0100s\n",
            "Batch 1900/3750 ( 50.7%) | Loss: 0.129710 | Accuracy: 96.18% | GPU: 24.4MB | Batch time: 0.0059s\n",
            "Batch 1920/3750 ( 51.2%) | Loss: 0.129958 | Accuracy: 96.17% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 1940/3750 ( 51.7%) | Loss: 0.130450 | Accuracy: 96.16% | GPU: 24.4MB | Batch time: 0.0053s\n",
            "Batch 1960/3750 ( 52.3%) | Loss: 0.130231 | Accuracy: 96.16% | GPU: 24.4MB | Batch time: 0.0043s\n",
            "Batch 1980/3750 ( 52.8%) | Loss: 0.129993 | Accuracy: 96.17% | GPU: 24.4MB | Batch time: 0.0046s\n",
            "Batch 2000/3750 ( 53.3%) | Loss: 0.130292 | Accuracy: 96.16% | GPU: 24.4MB | Batch time: 0.0046s\n",
            "Batch 2020/3750 ( 53.9%) | Loss: 0.129870 | Accuracy: 96.17% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 2040/3750 ( 54.4%) | Loss: 0.129579 | Accuracy: 96.17% | GPU: 24.4MB | Batch time: 0.0059s\n",
            "Batch 2060/3750 ( 54.9%) | Loss: 0.129271 | Accuracy: 96.18% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 2080/3750 ( 55.5%) | Loss: 0.128965 | Accuracy: 96.18% | GPU: 24.4MB | Batch time: 0.0050s\n",
            "Batch 2100/3750 ( 56.0%) | Loss: 0.128728 | Accuracy: 96.20% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 2120/3750 ( 56.5%) | Loss: 0.128248 | Accuracy: 96.20% | GPU: 24.4MB | Batch time: 0.0041s\n",
            "Batch 2140/3750 ( 57.1%) | Loss: 0.127640 | Accuracy: 96.22% | GPU: 24.4MB | Batch time: 0.0034s\n",
            "Batch 2160/3750 ( 57.6%) | Loss: 0.127352 | Accuracy: 96.23% | GPU: 24.4MB | Batch time: 0.0050s\n",
            "Batch 2180/3750 ( 58.1%) | Loss: 0.126957 | Accuracy: 96.24% | GPU: 24.4MB | Batch time: 0.0084s\n",
            "Batch 2200/3750 ( 58.7%) | Loss: 0.127395 | Accuracy: 96.23% | GPU: 24.4MB | Batch time: 0.0076s\n",
            "Batch 2220/3750 ( 59.2%) | Loss: 0.126854 | Accuracy: 96.25% | GPU: 24.4MB | Batch time: 0.0057s\n",
            "Batch 2240/3750 ( 59.7%) | Loss: 0.127047 | Accuracy: 96.26% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 2260/3750 ( 60.3%) | Loss: 0.126642 | Accuracy: 96.27% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 2280/3750 ( 60.8%) | Loss: 0.126518 | Accuracy: 96.27% | GPU: 24.4MB | Batch time: 0.0043s\n",
            "Batch 2300/3750 ( 61.3%) | Loss: 0.126364 | Accuracy: 96.28% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch 2320/3750 ( 61.9%) | Loss: 0.125692 | Accuracy: 96.30% | GPU: 24.4MB | Batch time: 0.0052s\n",
            "Batch 2340/3750 ( 62.4%) | Loss: 0.125415 | Accuracy: 96.32% | GPU: 24.4MB | Batch time: 0.0064s\n",
            "Batch 2360/3750 ( 62.9%) | Loss: 0.125023 | Accuracy: 96.32% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch 2380/3750 ( 63.5%) | Loss: 0.125097 | Accuracy: 96.31% | GPU: 24.4MB | Batch time: 0.0086s\n",
            "Batch 2400/3750 ( 64.0%) | Loss: 0.124784 | Accuracy: 96.32% | GPU: 24.4MB | Batch time: 0.0065s\n",
            "Batch 2420/3750 ( 64.5%) | Loss: 0.124347 | Accuracy: 96.33% | GPU: 24.4MB | Batch time: 0.0063s\n",
            "Batch 2440/3750 ( 65.1%) | Loss: 0.124444 | Accuracy: 96.32% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 2460/3750 ( 65.6%) | Loss: 0.124362 | Accuracy: 96.32% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch 2480/3750 ( 66.1%) | Loss: 0.124503 | Accuracy: 96.32% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 2500/3750 ( 66.7%) | Loss: 0.124010 | Accuracy: 96.34% | GPU: 24.4MB | Batch time: 0.0053s\n",
            "Batch 2520/3750 ( 67.2%) | Loss: 0.124260 | Accuracy: 96.34% | GPU: 24.4MB | Batch time: 0.0046s\n",
            "Batch 2540/3750 ( 67.7%) | Loss: 0.124287 | Accuracy: 96.34% | GPU: 24.4MB | Batch time: 0.0043s\n",
            "Batch 2560/3750 ( 68.3%) | Loss: 0.124840 | Accuracy: 96.33% | GPU: 24.4MB | Batch time: 0.0052s\n",
            "Batch 2580/3750 ( 68.8%) | Loss: 0.125082 | Accuracy: 96.33% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 2600/3750 ( 69.3%) | Loss: 0.124702 | Accuracy: 96.34% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch 2620/3750 ( 69.9%) | Loss: 0.124507 | Accuracy: 96.35% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 2640/3750 ( 70.4%) | Loss: 0.124222 | Accuracy: 96.36% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 2660/3750 ( 70.9%) | Loss: 0.123624 | Accuracy: 96.37% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 2680/3750 ( 71.5%) | Loss: 0.123007 | Accuracy: 96.39% | GPU: 24.4MB | Batch time: 0.0142s\n",
            "Batch 2700/3750 ( 72.0%) | Loss: 0.122821 | Accuracy: 96.39% | GPU: 24.4MB | Batch time: 0.0067s\n",
            "Batch 2720/3750 ( 72.5%) | Loss: 0.122803 | Accuracy: 96.39% | GPU: 24.4MB | Batch time: 0.0026s\n",
            "Batch 2740/3750 ( 73.1%) | Loss: 0.122294 | Accuracy: 96.40% | GPU: 24.4MB | Batch time: 0.0027s\n",
            "Batch 2760/3750 ( 73.6%) | Loss: 0.122196 | Accuracy: 96.41% | GPU: 24.4MB | Batch time: 0.0027s\n",
            "Batch 2780/3750 ( 74.1%) | Loss: 0.122060 | Accuracy: 96.41% | GPU: 24.4MB | Batch time: 0.0025s\n",
            "Batch 2800/3750 ( 74.7%) | Loss: 0.122103 | Accuracy: 96.42% | GPU: 24.4MB | Batch time: 0.0027s\n",
            "Batch 2820/3750 ( 75.2%) | Loss: 0.122299 | Accuracy: 96.42% | GPU: 24.4MB | Batch time: 0.0031s\n",
            "Batch 2840/3750 ( 75.7%) | Loss: 0.122547 | Accuracy: 96.41% | GPU: 24.4MB | Batch time: 0.0068s\n",
            "Batch 2860/3750 ( 76.3%) | Loss: 0.122301 | Accuracy: 96.43% | GPU: 24.4MB | Batch time: 0.0050s\n",
            "Batch 2880/3750 ( 76.8%) | Loss: 0.121856 | Accuracy: 96.44% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 2900/3750 ( 77.3%) | Loss: 0.121495 | Accuracy: 96.45% | GPU: 24.4MB | Batch time: 0.0158s\n",
            "Batch 2920/3750 ( 77.9%) | Loss: 0.121600 | Accuracy: 96.45% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch 2940/3750 ( 78.4%) | Loss: 0.121775 | Accuracy: 96.44% | GPU: 24.4MB | Batch time: 0.0068s\n",
            "Batch 2960/3750 ( 78.9%) | Loss: 0.121828 | Accuracy: 96.44% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch 2980/3750 ( 79.5%) | Loss: 0.121939 | Accuracy: 96.45% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 3000/3750 ( 80.0%) | Loss: 0.121605 | Accuracy: 96.46% | GPU: 24.4MB | Batch time: 0.0072s\n",
            "Batch 3020/3750 ( 80.5%) | Loss: 0.121392 | Accuracy: 96.46% | GPU: 24.4MB | Batch time: 0.0116s\n",
            "Batch 3040/3750 ( 81.1%) | Loss: 0.121368 | Accuracy: 96.47% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 3060/3750 ( 81.6%) | Loss: 0.121475 | Accuracy: 96.47% | GPU: 24.4MB | Batch time: 0.0053s\n",
            "Batch 3080/3750 ( 82.1%) | Loss: 0.121630 | Accuracy: 96.46% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 3100/3750 ( 82.7%) | Loss: 0.121499 | Accuracy: 96.47% | GPU: 24.4MB | Batch time: 0.0046s\n",
            "Batch 3120/3750 ( 83.2%) | Loss: 0.121593 | Accuracy: 96.47% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 3140/3750 ( 83.7%) | Loss: 0.121427 | Accuracy: 96.47% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 3160/3750 ( 84.3%) | Loss: 0.121452 | Accuracy: 96.48% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 3180/3750 ( 84.8%) | Loss: 0.121296 | Accuracy: 96.48% | GPU: 24.4MB | Batch time: 0.0062s\n",
            "Batch 3200/3750 ( 85.3%) | Loss: 0.121061 | Accuracy: 96.49% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 3220/3750 ( 85.9%) | Loss: 0.121026 | Accuracy: 96.49% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 3240/3750 ( 86.4%) | Loss: 0.120995 | Accuracy: 96.49% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch 3260/3750 ( 86.9%) | Loss: 0.121226 | Accuracy: 96.48% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 3280/3750 ( 87.5%) | Loss: 0.120926 | Accuracy: 96.49% | GPU: 24.4MB | Batch time: 0.0061s\n",
            "Batch 3300/3750 ( 88.0%) | Loss: 0.120816 | Accuracy: 96.49% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch 3320/3750 ( 88.5%) | Loss: 0.120636 | Accuracy: 96.50% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 3340/3750 ( 89.1%) | Loss: 0.120285 | Accuracy: 96.51% | GPU: 24.4MB | Batch time: 0.0041s\n",
            "Batch 3360/3750 ( 89.6%) | Loss: 0.119971 | Accuracy: 96.51% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 3380/3750 ( 90.1%) | Loss: 0.119919 | Accuracy: 96.51% | GPU: 24.4MB | Batch time: 0.0056s\n",
            "Batch 3400/3750 ( 90.7%) | Loss: 0.119602 | Accuracy: 96.52% | GPU: 24.4MB | Batch time: 0.0065s\n",
            "Batch 3420/3750 ( 91.2%) | Loss: 0.119576 | Accuracy: 96.52% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch 3440/3750 ( 91.7%) | Loss: 0.119601 | Accuracy: 96.53% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch 3460/3750 ( 92.3%) | Loss: 0.119214 | Accuracy: 96.53% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch 3480/3750 ( 92.8%) | Loss: 0.119278 | Accuracy: 96.53% | GPU: 24.4MB | Batch time: 0.0075s\n",
            "Batch 3500/3750 ( 93.3%) | Loss: 0.118758 | Accuracy: 96.54% | GPU: 24.4MB | Batch time: 0.0068s\n",
            "Batch 3520/3750 ( 93.9%) | Loss: 0.118706 | Accuracy: 96.55% | GPU: 24.4MB | Batch time: 0.0093s\n",
            "Batch 3540/3750 ( 94.4%) | Loss: 0.118334 | Accuracy: 96.56% | GPU: 24.4MB | Batch time: 0.0051s\n",
            "Batch 3560/3750 ( 94.9%) | Loss: 0.118258 | Accuracy: 96.56% | GPU: 24.4MB | Batch time: 0.0063s\n",
            "Batch 3580/3750 ( 95.5%) | Loss: 0.118074 | Accuracy: 96.57% | GPU: 24.4MB | Batch time: 0.0067s\n",
            "Batch 3600/3750 ( 96.0%) | Loss: 0.117989 | Accuracy: 96.57% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 3620/3750 ( 96.5%) | Loss: 0.117682 | Accuracy: 96.58% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 3640/3750 ( 97.1%) | Loss: 0.117663 | Accuracy: 96.59% | GPU: 24.4MB | Batch time: 0.0044s\n",
            "Batch 3660/3750 ( 97.6%) | Loss: 0.117474 | Accuracy: 96.59% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch 3680/3750 ( 98.1%) | Loss: 0.117245 | Accuracy: 96.60% | GPU: 24.4MB | Batch time: 0.0064s\n",
            "Batch 3700/3750 ( 98.7%) | Loss: 0.117228 | Accuracy: 96.59% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch 3720/3750 ( 99.2%) | Loss: 0.117034 | Accuracy: 96.60% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 3740/3750 ( 99.7%) | Loss: 0.116800 | Accuracy: 96.60% | GPU: 24.4MB | Batch time: 0.0051s\n",
            "Batch 3749/3750 (100.0%) | Loss: 0.116598 | Accuracy: 96.60% | GPU: 24.4MB | Batch time: 0.0024s\n",
            "\n",
            "-------------------- STANDARD OPTIMIZER - SUMMARY --------------------\n",
            "Loss: 0.116598 | Accuracy: 96.60%\n",
            "Time: 26.35s total, 0.0053s per batch\n",
            "  - Forward: 0.0018s, Backward: 0.0021s, Optimizer: 0.0005s\n",
            "🔄 Final Memory - RAM: 1369.9MB, GPU: 24.4MB allocated, 46.0MB reserved\n",
            "⏱️ Standard model training took 26.3569 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Epoch 2/3 -------------------------\n",
            "\n",
            "==================== EPOCH 2 TRAINING ====================\n",
            "Device: cuda, Batches: 3750, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 1369.9MB, GPU: 24.3MB allocated, 46.0MB reserved\n",
            "Batch    0/3750 (  0.0%) | Loss: 0.085355 | Accuracy: 93.75% | Batch time: 0.0305s\n",
            "Step 3760 | Loss: 0.018365 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0035s, O: 0.0008s\n",
            "🔄 Topology update at step 3760 took 0.0001s\n",
            "Step 3770 | Loss: 0.041776 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0030s, O: 0.0007s\n",
            "Batch   20/3750 (  0.5%) | Loss: 0.078779 | Accuracy: 97.32% | Batch time: 0.0221s\n",
            "Step 3780 | Loss: 0.046367 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 3780 took 0.0001s\n",
            "Step 3790 | Loss: 0.060596 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0037s, O: 0.0009s\n",
            "Batch   40/3750 (  1.1%) | Loss: 0.090811 | Accuracy: 97.10% | Batch time: 0.0199s\n",
            "Step 3800 | Loss: 0.332043 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 3800 took 0.0000s\n",
            "🧹 Memory cleanup at step 3800 took 0.2373s\n",
            "Step 3810 | Loss: 0.036285 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "Batch   60/3750 (  1.6%) | Loss: 0.091206 | Accuracy: 97.03% | Batch time: 0.0216s\n",
            "Step 3820 | Loss: 0.047594 | GPU: 24.4MB / 98.0MB | F: 0.0045s, B: 0.0066s, O: 0.0006s\n",
            "🔄 Topology update at step 3820 took 0.0000s\n",
            "Step 3830 | Loss: 0.079668 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "Batch   80/3750 (  2.1%) | Loss: 0.098876 | Accuracy: 96.76% | Batch time: 0.0238s\n",
            "Step 3840 | Loss: 0.017811 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 3840 took 0.0000s\n",
            "Step 3850 | Loss: 0.210129 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0053s, O: 0.0006s\n",
            "Batch  100/3750 (  2.7%) | Loss: 0.102767 | Accuracy: 96.66% | Batch time: 0.0201s\n",
            "Step 3860 | Loss: 0.176343 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0040s, O: 0.0008s\n",
            "🔄 Topology update at step 3860 took 0.0000s\n",
            "Step 3870 | Loss: 0.059101 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0031s, O: 0.0008s\n",
            "Batch  120/3750 (  3.2%) | Loss: 0.105669 | Accuracy: 96.69% | Batch time: 0.0208s\n",
            "Step 3880 | Loss: 0.032511 | GPU: 24.4MB / 98.0MB | F: 0.0056s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 3880 took 0.0000s\n",
            "Step 3890 | Loss: 0.042443 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Batch  140/3750 (  3.7%) | Loss: 0.103354 | Accuracy: 96.72% | Batch time: 0.0225s\n",
            "Step 3900 | Loss: 0.199657 | GPU: 24.4MB / 98.0MB | F: 0.0046s, B: 0.0031s, O: 0.0007s\n",
            "🔄 Topology update at step 3900 took 0.0001s\n",
            "🧹 Memory cleanup at step 3900 took 0.1535s\n",
            "Step 3910 | Loss: 0.011279 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Batch  160/3750 (  4.3%) | Loss: 0.102910 | Accuracy: 96.82% | Batch time: 0.0205s\n",
            "Step 3920 | Loss: 0.141934 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 3920 took 0.0000s\n",
            "Step 3930 | Loss: 0.036199 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0040s, O: 0.0007s\n",
            "Batch  180/3750 (  4.8%) | Loss: 0.098510 | Accuracy: 96.96% | Batch time: 0.0241s\n",
            "Step 3940 | Loss: 0.014386 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0041s, O: 0.0007s\n",
            "🔄 Topology update at step 3940 took 0.0001s\n",
            "Step 3950 | Loss: 0.052762 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0005s\n",
            "Batch  200/3750 (  5.3%) | Loss: 0.096313 | Accuracy: 97.05% | Batch time: 0.0200s\n",
            "Step 3960 | Loss: 0.026370 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0034s, O: 0.0007s\n",
            "🔄 Topology update at step 3960 took 0.0000s\n",
            "Step 3970 | Loss: 0.437050 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0028s, O: 0.0007s\n",
            "Batch  220/3750 (  5.9%) | Loss: 0.093792 | Accuracy: 97.23% | Batch time: 0.0254s\n",
            "Step 3980 | Loss: 0.031134 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 3980 took 0.0000s\n",
            "Step 3990 | Loss: 0.018334 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Batch  240/3750 (  6.4%) | Loss: 0.095059 | Accuracy: 97.15% | Batch time: 0.0208s\n",
            "Step 4000 | Loss: 0.120226 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0052s, O: 0.0005s\n",
            "🔄 Topology update at step 4000 took 0.0000s\n",
            "🧹 Memory cleanup at step 4000 took 0.1491s\n",
            "Step 4010 | Loss: 0.062753 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0055s, O: 0.0006s\n",
            "Batch  260/3750 (  6.9%) | Loss: 0.091286 | Accuracy: 97.27% | Batch time: 0.0202s\n",
            "Step 4020 | Loss: 0.028104 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0034s, O: 0.0007s\n",
            "🔄 Topology update at step 4020 took 0.0001s\n",
            "Step 4030 | Loss: 0.148290 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0031s, O: 0.0006s\n",
            "Batch  280/3750 (  7.5%) | Loss: 0.088844 | Accuracy: 97.33% | Batch time: 0.0199s\n",
            "Step 4040 | Loss: 0.046339 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0037s, O: 0.0006s\n",
            "🔄 Topology update at step 4040 took 0.0000s\n",
            "Step 4050 | Loss: 0.427358 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0026s, O: 0.0011s\n",
            "Batch  300/3750 (  8.0%) | Loss: 0.089253 | Accuracy: 97.28% | Batch time: 0.0193s\n",
            "Step 4060 | Loss: 0.602620 | GPU: 24.4MB / 98.0MB | F: 0.0043s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 4060 took 0.0001s\n",
            "Step 4070 | Loss: 0.096653 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0072s, O: 0.0006s\n",
            "Batch  320/3750 (  8.5%) | Loss: 0.090845 | Accuracy: 97.22% | Batch time: 0.0215s\n",
            "Step 4080 | Loss: 0.051136 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 4080 took 0.0001s\n",
            "Step 4090 | Loss: 0.068311 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0050s, O: 0.0007s\n",
            "Batch  340/3750 (  9.1%) | Loss: 0.090334 | Accuracy: 97.23% | Batch time: 0.0220s\n",
            "Step 4100 | Loss: 0.238593 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0043s, O: 0.0007s\n",
            "🔄 Topology update at step 4100 took 0.0000s\n",
            "🧹 Memory cleanup at step 4100 took 0.2151s\n",
            "Step 4110 | Loss: 0.030331 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0037s, O: 0.0005s\n",
            "Batch  360/3750 (  9.6%) | Loss: 0.092364 | Accuracy: 97.11% | Batch time: 0.0193s\n",
            "Step 4120 | Loss: 0.042069 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0018s, O: 0.0016s\n",
            "🔄 Topology update at step 4120 took 0.0000s\n",
            "Step 4130 | Loss: 0.542411 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0019s, O: 0.0006s\n",
            "Batch  380/3750 ( 10.1%) | Loss: 0.093870 | Accuracy: 97.08% | Batch time: 0.0227s\n",
            "Step 4140 | Loss: 0.154111 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0038s, O: 0.0005s\n",
            "🔄 Topology update at step 4140 took 0.0000s\n",
            "Step 4150 | Loss: 0.097002 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0030s, O: 0.0006s\n",
            "Batch  400/3750 ( 10.7%) | Loss: 0.092653 | Accuracy: 97.13% | Batch time: 0.0243s\n",
            "Step 4160 | Loss: 0.130886 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 4160 took 0.0000s\n",
            "Step 4170 | Loss: 0.009308 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0043s, O: 0.0007s\n",
            "Batch  420/3750 ( 11.2%) | Loss: 0.092620 | Accuracy: 97.15% | Batch time: 0.0212s\n",
            "Step 4180 | Loss: 0.020632 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0088s, O: 0.0006s\n",
            "🔄 Topology update at step 4180 took 0.0001s\n",
            "Step 4190 | Loss: 0.078648 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0080s, O: 0.0005s\n",
            "Batch  440/3750 ( 11.7%) | Loss: 0.094423 | Accuracy: 97.14% | Batch time: 0.0247s\n",
            "Step 4200 | Loss: 0.100711 | GPU: 24.4MB / 98.0MB | F: 0.0066s, B: 0.0055s, O: 0.0007s\n",
            "🔄 Topology update at step 4200 took 0.0000s\n",
            "🧹 Memory cleanup at step 4200 took 0.1995s\n",
            "Step 4210 | Loss: 0.032837 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0050s, O: 0.0008s\n",
            "Batch  460/3750 ( 12.3%) | Loss: 0.094040 | Accuracy: 97.14% | Batch time: 0.0337s\n",
            "Step 4220 | Loss: 0.005982 | GPU: 24.4MB / 98.0MB | F: 0.0038s, B: 0.0050s, O: 0.0006s\n",
            "🔄 Topology update at step 4220 took 0.0000s\n",
            "Step 4230 | Loss: 0.079610 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0048s, O: 0.0007s\n",
            "Batch  480/3750 ( 12.8%) | Loss: 0.092894 | Accuracy: 97.14% | Batch time: 0.0382s\n",
            "Step 4240 | Loss: 0.062113 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0023s, O: 0.0015s\n",
            "🔄 Topology update at step 4240 took 0.0001s\n",
            "Step 4250 | Loss: 0.024644 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0019s, O: 0.0013s\n",
            "Batch  500/3750 ( 13.3%) | Loss: 0.092910 | Accuracy: 97.16% | Batch time: 0.0194s\n",
            "Step 4260 | Loss: 0.099343 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0040s, O: 0.0008s\n",
            "🔄 Topology update at step 4260 took 0.0001s\n",
            "Step 4270 | Loss: 0.007795 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0024s, O: 0.0007s\n",
            "Batch  520/3750 ( 13.9%) | Loss: 0.091121 | Accuracy: 97.22% | Batch time: 0.0204s\n",
            "Step 4280 | Loss: 0.032521 | GPU: 24.4MB / 98.0MB | F: 0.0038s, B: 0.0027s, O: 0.0013s\n",
            "🔄 Topology update at step 4280 took 0.0000s\n",
            "Step 4290 | Loss: 0.018189 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0033s, O: 0.0006s\n",
            "Batch  540/3750 ( 14.4%) | Loss: 0.091100 | Accuracy: 97.22% | Batch time: 0.0227s\n",
            "Step 4300 | Loss: 0.477502 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0021s\n",
            "🔄 Topology update at step 4300 took 0.0000s\n",
            "🧹 Memory cleanup at step 4300 took 0.1995s\n",
            "Step 4310 | Loss: 0.031501 | GPU: 24.4MB / 98.0MB | F: 0.0040s, B: 0.0028s, O: 0.0009s\n",
            "Batch  560/3750 ( 14.9%) | Loss: 0.091112 | Accuracy: 97.21% | Batch time: 0.0192s\n",
            "Step 4320 | Loss: 0.047286 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 4320 took 0.0000s\n",
            "Step 4330 | Loss: 0.263582 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0034s, O: 0.0007s\n",
            "Batch  580/3750 ( 15.5%) | Loss: 0.090286 | Accuracy: 97.24% | Batch time: 0.0197s\n",
            "Step 4340 | Loss: 0.035975 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 4340 took 0.0000s\n",
            "Step 4350 | Loss: 0.424199 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0024s, O: 0.0007s\n",
            "Batch  600/3750 ( 16.0%) | Loss: 0.089641 | Accuracy: 97.29% | Batch time: 0.0207s\n",
            "Step 4360 | Loss: 0.106901 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 4360 took 0.0001s\n",
            "Step 4370 | Loss: 0.040137 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0028s, O: 0.0005s\n",
            "Batch  620/3750 ( 16.5%) | Loss: 0.090187 | Accuracy: 97.27% | Batch time: 0.0206s\n",
            "Step 4380 | Loss: 0.006961 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 4380 took 0.0000s\n",
            "Step 4390 | Loss: 0.059083 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0031s, O: 0.0005s\n",
            "Batch  640/3750 ( 17.1%) | Loss: 0.089056 | Accuracy: 97.32% | Batch time: 0.0199s\n",
            "Step 4400 | Loss: 0.207793 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0023s, O: 0.0008s\n",
            "🔄 Topology update at step 4400 took 0.0001s\n",
            "🧹 Memory cleanup at step 4400 took 0.1657s\n",
            "Step 4410 | Loss: 0.002801 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0029s, O: 0.0015s\n",
            "Batch  660/3750 ( 17.6%) | Loss: 0.089967 | Accuracy: 97.29% | Batch time: 0.0203s\n",
            "Step 4420 | Loss: 0.229564 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0030s, O: 0.0006s\n",
            "🔄 Topology update at step 4420 took 0.0000s\n",
            "Step 4430 | Loss: 0.147313 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Batch  680/3750 ( 18.1%) | Loss: 0.090885 | Accuracy: 97.24% | Batch time: 0.0211s\n",
            "Step 4440 | Loss: 0.068985 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 4440 took 0.0000s\n",
            "Step 4450 | Loss: 0.022863 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0035s, O: 0.0018s\n",
            "Batch  700/3750 ( 18.7%) | Loss: 0.092195 | Accuracy: 97.22% | Batch time: 0.0200s\n",
            "Step 4460 | Loss: 0.023678 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0038s, O: 0.0014s\n",
            "🔄 Topology update at step 4460 took 0.0001s\n",
            "Step 4470 | Loss: 0.013881 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0024s, O: 0.0017s\n",
            "Batch  720/3750 ( 19.2%) | Loss: 0.091591 | Accuracy: 97.21% | Batch time: 0.0208s\n",
            "Step 4480 | Loss: 0.003588 | GPU: 24.4MB / 98.0MB | F: 0.0043s, B: 0.0043s, O: 0.0005s\n",
            "🔄 Topology update at step 4480 took 0.0001s\n",
            "Step 4490 | Loss: 0.059640 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0048s, O: 0.0010s\n",
            "Batch  740/3750 ( 19.7%) | Loss: 0.090466 | Accuracy: 97.24% | Batch time: 0.0193s\n",
            "Step 4500 | Loss: 0.106367 | GPU: 24.4MB / 98.0MB | F: 0.0052s, B: 0.0031s, O: 0.0005s\n",
            "🔄 Topology update at step 4500 took 0.0000s\n",
            "🧹 Memory cleanup at step 4500 took 0.1606s\n",
            "Step 4510 | Loss: 0.063942 | GPU: 24.4MB / 98.0MB | F: 0.0036s, B: 0.0028s, O: 0.0008s\n",
            "Batch  760/3750 ( 20.3%) | Loss: 0.090965 | Accuracy: 97.24% | Batch time: 0.0206s\n",
            "Step 4520 | Loss: 0.125606 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 4520 took 0.0000s\n",
            "Step 4530 | Loss: 0.003539 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Batch  780/3750 ( 20.8%) | Loss: 0.090169 | Accuracy: 97.27% | Batch time: 0.0201s\n",
            "Step 4540 | Loss: 0.026325 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0029s, O: 0.0020s\n",
            "🔄 Topology update at step 4540 took 0.0001s\n",
            "Step 4550 | Loss: 0.256847 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "Batch  800/3750 ( 21.3%) | Loss: 0.090355 | Accuracy: 97.25% | Batch time: 0.0225s\n",
            "Step 4560 | Loss: 0.012072 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 4560 took 0.0001s\n",
            "Step 4570 | Loss: 0.002512 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0036s, O: 0.0008s\n",
            "Batch  820/3750 ( 21.9%) | Loss: 0.089818 | Accuracy: 97.26% | Batch time: 0.0193s\n",
            "Step 4580 | Loss: 0.176671 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 4580 took 0.0000s\n",
            "Step 4590 | Loss: 0.027307 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Batch  840/3750 ( 22.4%) | Loss: 0.090338 | Accuracy: 97.24% | Batch time: 0.0192s\n",
            "Step 4600 | Loss: 0.015417 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0075s, O: 0.0008s\n",
            "🔄 Topology update at step 4600 took 0.0000s\n",
            "🧹 Memory cleanup at step 4600 took 0.1501s\n",
            "Step 4610 | Loss: 0.038501 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0006s\n",
            "Batch  860/3750 ( 22.9%) | Loss: 0.090077 | Accuracy: 97.26% | Batch time: 0.0211s\n",
            "Step 4620 | Loss: 0.014580 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0043s, O: 0.0010s\n",
            "🔄 Topology update at step 4620 took 0.0000s\n",
            "Step 4630 | Loss: 0.076264 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0045s, O: 0.0010s\n",
            "Batch  880/3750 ( 23.5%) | Loss: 0.091484 | Accuracy: 97.23% | Batch time: 0.0216s\n",
            "Step 4640 | Loss: 0.080046 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 4640 took 0.0000s\n",
            "Step 4650 | Loss: 0.006095 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0034s, O: 0.0007s\n",
            "Batch  900/3750 ( 24.0%) | Loss: 0.091025 | Accuracy: 97.23% | Batch time: 0.0208s\n",
            "Step 4660 | Loss: 0.014451 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0028s, O: 0.0007s\n",
            "🔄 Topology update at step 4660 took 0.0001s\n",
            "Step 4670 | Loss: 0.028556 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0034s, O: 0.0007s\n",
            "Batch  920/3750 ( 24.5%) | Loss: 0.091105 | Accuracy: 97.24% | Batch time: 0.0225s\n",
            "Step 4680 | Loss: 0.024217 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0034s, O: 0.0005s\n",
            "🔄 Topology update at step 4680 took 0.0000s\n",
            "Step 4690 | Loss: 0.017442 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Batch  940/3750 ( 25.1%) | Loss: 0.090457 | Accuracy: 97.26% | Batch time: 0.0213s\n",
            "Step 4700 | Loss: 0.094553 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0032s, O: 0.0011s\n",
            "🔄 Topology update at step 4700 took 0.0000s\n",
            "🧹 Memory cleanup at step 4700 took 0.1515s\n",
            "Step 4710 | Loss: 0.041672 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0036s, O: 0.0016s\n",
            "Batch  960/3750 ( 25.6%) | Loss: 0.090192 | Accuracy: 97.26% | Batch time: 0.0217s\n",
            "Step 4720 | Loss: 0.016846 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0034s, O: 0.0008s\n",
            "🔄 Topology update at step 4720 took 0.0000s\n",
            "Step 4730 | Loss: 0.098006 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0046s, O: 0.0008s\n",
            "Batch  980/3750 ( 26.1%) | Loss: 0.091326 | Accuracy: 97.22% | Batch time: 0.0276s\n",
            "Step 4740 | Loss: 0.002657 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0030s, O: 0.0008s\n",
            "🔄 Topology update at step 4740 took 0.0000s\n",
            "Step 4750 | Loss: 0.471160 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0034s, O: 0.0007s\n",
            "Batch 1000/3750 ( 26.7%) | Loss: 0.091522 | Accuracy: 97.23% | Batch time: 0.0198s\n",
            "Step 4760 | Loss: 0.030079 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0075s, O: 0.0012s\n",
            "🔄 Topology update at step 4760 took 0.0000s\n",
            "Step 4770 | Loss: 0.006857 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1020/3750 ( 27.2%) | Loss: 0.091488 | Accuracy: 97.24% | Batch time: 0.0207s\n",
            "Step 4780 | Loss: 0.069948 | GPU: 24.4MB / 98.0MB | F: 0.0076s, B: 0.0040s, O: 0.0005s\n",
            "🔄 Topology update at step 4780 took 0.0000s\n",
            "Step 4790 | Loss: 0.167124 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "Batch 1040/3750 ( 27.7%) | Loss: 0.092303 | Accuracy: 97.22% | Batch time: 0.0208s\n",
            "Step 4800 | Loss: 0.049815 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0028s, O: 0.0009s\n",
            "🔄 Topology update at step 4800 took 0.0000s\n",
            "🧹 Memory cleanup at step 4800 took 0.1627s\n",
            "Step 4810 | Loss: 0.038580 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "Batch 1060/3750 ( 28.3%) | Loss: 0.092268 | Accuracy: 97.23% | Batch time: 0.0246s\n",
            "Step 4820 | Loss: 0.021822 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 4820 took 0.0001s\n",
            "Step 4830 | Loss: 0.015523 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0011s\n",
            "Batch 1080/3750 ( 28.8%) | Loss: 0.091808 | Accuracy: 97.24% | Batch time: 0.0233s\n",
            "Step 4840 | Loss: 0.037521 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 4840 took 0.0000s\n",
            "Step 4850 | Loss: 0.072311 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0027s, O: 0.0008s\n",
            "Batch 1100/3750 ( 29.3%) | Loss: 0.092559 | Accuracy: 97.22% | Batch time: 0.0228s\n",
            "Step 4860 | Loss: 0.086118 | GPU: 24.4MB / 98.0MB | F: 0.0036s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 4860 took 0.0000s\n",
            "Step 4870 | Loss: 0.120432 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0026s, O: 0.0008s\n",
            "Batch 1120/3750 ( 29.9%) | Loss: 0.092511 | Accuracy: 97.21% | Batch time: 0.0212s\n",
            "Step 4880 | Loss: 0.006422 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0028s, O: 0.0016s\n",
            "🔄 Topology update at step 4880 took 0.0000s\n",
            "Step 4890 | Loss: 0.057104 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "Batch 1140/3750 ( 30.4%) | Loss: 0.091689 | Accuracy: 97.24% | Batch time: 0.0210s\n",
            "Step 4900 | Loss: 0.071739 | GPU: 24.4MB / 98.0MB | F: 0.0045s, B: 0.0029s, O: 0.0010s\n",
            "🔄 Topology update at step 4900 took 0.0001s\n",
            "🧹 Memory cleanup at step 4900 took 0.1759s\n",
            "Step 4910 | Loss: 0.016307 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0030s, O: 0.0009s\n",
            "Batch 1160/3750 ( 30.9%) | Loss: 0.091548 | Accuracy: 97.24% | Batch time: 0.0211s\n",
            "Step 4920 | Loss: 0.012985 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0028s, O: 0.0009s\n",
            "🔄 Topology update at step 4920 took 0.0001s\n",
            "Step 4930 | Loss: 0.099369 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "Batch 1180/3750 ( 31.5%) | Loss: 0.092339 | Accuracy: 97.24% | Batch time: 0.0246s\n",
            "Step 4940 | Loss: 0.216077 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0029s, O: 0.0018s\n",
            "🔄 Topology update at step 4940 took 0.0001s\n",
            "Step 4950 | Loss: 0.170154 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "Batch 1200/3750 ( 32.0%) | Loss: 0.092130 | Accuracy: 97.24% | Batch time: 0.0223s\n",
            "Step 4960 | Loss: 0.074385 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 4960 took 0.0001s\n",
            "Step 4970 | Loss: 0.026331 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0015s\n",
            "Batch 1220/3750 ( 32.5%) | Loss: 0.091661 | Accuracy: 97.26% | Batch time: 0.0204s\n",
            "Step 4980 | Loss: 0.085106 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 4980 took 0.0000s\n",
            "Step 4990 | Loss: 0.207256 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1240/3750 ( 33.1%) | Loss: 0.091689 | Accuracy: 97.25% | Batch time: 0.0214s\n",
            "Step 5000 | Loss: 0.033893 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 5000 took 0.0001s\n",
            "🧹 Memory cleanup at step 5000 took 0.1682s\n",
            "Step 5010 | Loss: 0.253362 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0030s, O: 0.0012s\n",
            "Batch 1260/3750 ( 33.6%) | Loss: 0.091589 | Accuracy: 97.25% | Batch time: 0.0201s\n",
            "Step 5020 | Loss: 0.003648 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 5020 took 0.0001s\n",
            "Step 5030 | Loss: 0.195443 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1280/3750 ( 34.1%) | Loss: 0.090865 | Accuracy: 97.27% | Batch time: 0.0220s\n",
            "Step 5040 | Loss: 0.029960 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 5040 took 0.0001s\n",
            "Step 5050 | Loss: 0.019728 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0027s, O: 0.0008s\n",
            "Batch 1300/3750 ( 34.7%) | Loss: 0.090342 | Accuracy: 97.28% | Batch time: 0.0211s\n",
            "Step 5060 | Loss: 0.011332 | GPU: 24.4MB / 98.0MB | F: 0.0084s, B: 0.0036s, O: 0.0006s\n",
            "🔄 Topology update at step 5060 took 0.0000s\n",
            "Step 5070 | Loss: 0.056161 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0058s, O: 0.0009s\n",
            "Batch 1320/3750 ( 35.2%) | Loss: 0.090501 | Accuracy: 97.27% | Batch time: 0.0297s\n",
            "Step 5080 | Loss: 0.049793 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0021s, O: 0.0011s\n",
            "🔄 Topology update at step 5080 took 0.0000s\n",
            "Step 5090 | Loss: 0.010179 | GPU: 24.4MB / 98.0MB | F: 0.0057s, B: 0.0025s, O: 0.0008s\n",
            "Batch 1340/3750 ( 35.7%) | Loss: 0.090417 | Accuracy: 97.27% | Batch time: 0.0214s\n",
            "Step 5100 | Loss: 0.215184 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0017s, O: 0.0005s\n",
            "🔄 Topology update at step 5100 took 0.0000s\n",
            "🧹 Memory cleanup at step 5100 took 0.1981s\n",
            "Step 5110 | Loss: 0.150723 | GPU: 24.4MB / 98.0MB | F: 0.0062s, B: 0.0031s, O: 0.0007s\n",
            "Batch 1360/3750 ( 36.3%) | Loss: 0.091061 | Accuracy: 97.26% | Batch time: 0.0264s\n",
            "Step 5120 | Loss: 0.004991 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0020s, O: 0.0006s\n",
            "🔄 Topology update at step 5120 took 0.0000s\n",
            "Step 5130 | Loss: 0.013197 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0029s, O: 0.0005s\n",
            "Batch 1380/3750 ( 36.8%) | Loss: 0.090462 | Accuracy: 97.28% | Batch time: 0.0198s\n",
            "Step 5140 | Loss: 0.099751 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0021s, O: 0.0006s\n",
            "🔄 Topology update at step 5140 took 0.0000s\n",
            "Step 5150 | Loss: 0.005269 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "Batch 1400/3750 ( 37.3%) | Loss: 0.090043 | Accuracy: 97.30% | Batch time: 0.0229s\n",
            "Step 5160 | Loss: 0.203088 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0063s, O: 0.0008s\n",
            "🔄 Topology update at step 5160 took 0.0000s\n",
            "Step 5170 | Loss: 0.024644 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "Batch 1420/3750 ( 37.9%) | Loss: 0.089567 | Accuracy: 97.32% | Batch time: 0.0315s\n",
            "Step 5180 | Loss: 0.006870 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0067s, O: 0.0013s\n",
            "🔄 Topology update at step 5180 took 0.0000s\n",
            "Step 5190 | Loss: 0.340222 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0051s, O: 0.0024s\n",
            "Batch 1440/3750 ( 38.4%) | Loss: 0.089272 | Accuracy: 97.33% | Batch time: 0.0274s\n",
            "Step 5200 | Loss: 0.207418 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0031s, O: 0.0008s\n",
            "🔄 Topology update at step 5200 took 0.0001s\n",
            "🧹 Memory cleanup at step 5200 took 0.2125s\n",
            "Step 5210 | Loss: 0.648883 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0028s, O: 0.0008s\n",
            "Batch 1460/3750 ( 38.9%) | Loss: 0.090169 | Accuracy: 97.31% | Batch time: 0.0222s\n",
            "Step 5220 | Loss: 0.028521 | GPU: 24.4MB / 98.0MB | F: 0.0033s, B: 0.0028s, O: 0.0010s\n",
            "🔄 Topology update at step 5220 took 0.0000s\n",
            "Step 5230 | Loss: 0.163987 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0021s, O: 0.0007s\n",
            "Batch 1480/3750 ( 39.5%) | Loss: 0.090276 | Accuracy: 97.31% | Batch time: 0.0227s\n",
            "Step 5240 | Loss: 0.026912 | GPU: 24.4MB / 98.0MB | F: 0.0063s, B: 0.0023s, O: 0.0009s\n",
            "🔄 Topology update at step 5240 took 0.0001s\n",
            "Step 5250 | Loss: 0.064918 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0043s, O: 0.0008s\n",
            "Batch 1500/3750 ( 40.0%) | Loss: 0.090240 | Accuracy: 97.31% | Batch time: 0.0243s\n",
            "Step 5260 | Loss: 0.023951 | GPU: 24.4MB / 98.0MB | F: 0.0054s, B: 0.0030s, O: 0.0008s\n",
            "🔄 Topology update at step 5260 took 0.0001s\n",
            "Step 5270 | Loss: 0.021072 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0028s, O: 0.0008s\n",
            "Batch 1520/3750 ( 40.5%) | Loss: 0.089804 | Accuracy: 97.33% | Batch time: 0.0208s\n",
            "Step 5280 | Loss: 0.031486 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 5280 took 0.0000s\n",
            "Step 5290 | Loss: 0.095986 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0043s, O: 0.0009s\n",
            "Batch 1540/3750 ( 41.1%) | Loss: 0.089442 | Accuracy: 97.34% | Batch time: 0.0205s\n",
            "Step 5300 | Loss: 0.416875 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0024s, O: 0.0009s\n",
            "🔄 Topology update at step 5300 took 0.0000s\n",
            "🧹 Memory cleanup at step 5300 took 0.1693s\n",
            "Step 5310 | Loss: 0.025382 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1560/3750 ( 41.6%) | Loss: 0.089551 | Accuracy: 97.34% | Batch time: 0.0212s\n",
            "Step 5320 | Loss: 0.062255 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0074s, O: 0.0008s\n",
            "🔄 Topology update at step 5320 took 0.0000s\n",
            "Step 5330 | Loss: 0.147850 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1580/3750 ( 42.1%) | Loss: 0.089795 | Accuracy: 97.34% | Batch time: 0.0221s\n",
            "Step 5340 | Loss: 0.002448 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0015s\n",
            "🔄 Topology update at step 5340 took 0.0001s\n",
            "Step 5350 | Loss: 0.074844 | GPU: 24.4MB / 98.0MB | F: 0.0038s, B: 0.0026s, O: 0.0012s\n",
            "Batch 1600/3750 ( 42.7%) | Loss: 0.089900 | Accuracy: 97.33% | Batch time: 0.0209s\n",
            "Step 5360 | Loss: 0.015345 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 5360 took 0.0000s\n",
            "Step 5370 | Loss: 0.003126 | GPU: 24.4MB / 98.0MB | F: 0.0042s, B: 0.0032s, O: 0.0009s\n",
            "Batch 1620/3750 ( 43.2%) | Loss: 0.089948 | Accuracy: 97.34% | Batch time: 0.0219s\n",
            "Step 5380 | Loss: 0.010216 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 5380 took 0.0001s\n",
            "Step 5390 | Loss: 0.099796 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "Batch 1640/3750 ( 43.7%) | Loss: 0.089559 | Accuracy: 97.36% | Batch time: 0.0213s\n",
            "Step 5400 | Loss: 0.145870 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0034s, O: 0.0008s\n",
            "🔄 Topology update at step 5400 took 0.0001s\n",
            "🧹 Memory cleanup at step 5400 took 0.1767s\n",
            "Step 5410 | Loss: 0.060938 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "Batch 1660/3750 ( 44.3%) | Loss: 0.089253 | Accuracy: 97.36% | Batch time: 0.0223s\n",
            "Step 5420 | Loss: 0.020926 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 5420 took 0.0000s\n",
            "Step 5430 | Loss: 0.016994 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "Batch 1680/3750 ( 44.8%) | Loss: 0.088964 | Accuracy: 97.37% | Batch time: 0.0200s\n",
            "Step 5440 | Loss: 0.057528 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0029s, O: 0.0016s\n",
            "🔄 Topology update at step 5440 took 0.0001s\n",
            "Step 5450 | Loss: 0.041564 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0024s, O: 0.0008s\n",
            "Batch 1700/3750 ( 45.3%) | Loss: 0.088326 | Accuracy: 97.39% | Batch time: 0.0196s\n",
            "Step 5460 | Loss: 0.084751 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 5460 took 0.0001s\n",
            "Step 5470 | Loss: 0.016758 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0033s, O: 0.0011s\n",
            "Batch 1720/3750 ( 45.9%) | Loss: 0.088123 | Accuracy: 97.40% | Batch time: 0.0215s\n",
            "Step 5480 | Loss: 0.003059 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 5480 took 0.0001s\n",
            "Step 5490 | Loss: 0.013621 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0061s\n",
            "Batch 1740/3750 ( 46.4%) | Loss: 0.088022 | Accuracy: 97.40% | Batch time: 0.0300s\n",
            "Step 5500 | Loss: 0.023737 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 5500 took 0.0000s\n",
            "🧹 Memory cleanup at step 5500 took 0.1698s\n",
            "Step 5510 | Loss: 0.031749 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0031s, O: 0.0004s\n",
            "Batch 1760/3750 ( 46.9%) | Loss: 0.087652 | Accuracy: 97.41% | Batch time: 0.0199s\n",
            "Step 5520 | Loss: 0.012429 | GPU: 24.4MB / 98.0MB | F: 0.0035s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 5520 took 0.0000s\n",
            "Step 5530 | Loss: 0.178766 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1780/3750 ( 47.5%) | Loss: 0.088108 | Accuracy: 97.40% | Batch time: 0.0271s\n",
            "Step 5540 | Loss: 0.036939 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0035s, O: 0.0010s\n",
            "🔄 Topology update at step 5540 took 0.0000s\n",
            "Step 5550 | Loss: 0.115683 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1800/3750 ( 48.0%) | Loss: 0.088193 | Accuracy: 97.40% | Batch time: 0.0210s\n",
            "Step 5560 | Loss: 0.023575 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 5560 took 0.0001s\n",
            "Step 5570 | Loss: 0.161386 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0028s\n",
            "Batch 1820/3750 ( 48.5%) | Loss: 0.088294 | Accuracy: 97.38% | Batch time: 0.0218s\n",
            "Step 5580 | Loss: 0.117295 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 5580 took 0.0000s\n",
            "Step 5590 | Loss: 0.006604 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1840/3750 ( 49.1%) | Loss: 0.088084 | Accuracy: 97.39% | Batch time: 0.0202s\n",
            "Step 5600 | Loss: 0.015008 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 5600 took 0.0000s\n",
            "🧹 Memory cleanup at step 5600 took 0.1720s\n",
            "Step 5610 | Loss: 0.330225 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1860/3750 ( 49.6%) | Loss: 0.087847 | Accuracy: 97.40% | Batch time: 0.0214s\n",
            "Step 5620 | Loss: 0.057567 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0019s, O: 0.0007s\n",
            "🔄 Topology update at step 5620 took 0.0000s\n",
            "Step 5630 | Loss: 0.005290 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0030s, O: 0.0009s\n",
            "Batch 1880/3750 ( 50.1%) | Loss: 0.087506 | Accuracy: 97.41% | Batch time: 0.0233s\n",
            "Step 5640 | Loss: 0.023154 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0023s, O: 0.0005s\n",
            "🔄 Topology update at step 5640 took 0.0000s\n",
            "Step 5650 | Loss: 0.142596 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0021s, O: 0.0007s\n",
            "Batch 1900/3750 ( 50.7%) | Loss: 0.087335 | Accuracy: 97.41% | Batch time: 0.0211s\n",
            "Step 5660 | Loss: 0.001422 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0039s, O: 0.0009s\n",
            "🔄 Topology update at step 5660 took 0.0000s\n",
            "Step 5670 | Loss: 0.001247 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1920/3750 ( 51.2%) | Loss: 0.086963 | Accuracy: 97.40% | Batch time: 0.0206s\n",
            "Step 5680 | Loss: 0.025461 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0049s, O: 0.0007s\n",
            "🔄 Topology update at step 5680 took 0.0001s\n",
            "Step 5690 | Loss: 0.002432 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1940/3750 ( 51.7%) | Loss: 0.086792 | Accuracy: 97.40% | Batch time: 0.0205s\n",
            "Step 5700 | Loss: 0.002628 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0050s, O: 0.0005s\n",
            "🔄 Topology update at step 5700 took 0.0000s\n",
            "🧹 Memory cleanup at step 5700 took 0.1583s\n",
            "Step 5710 | Loss: 0.006736 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0029s, O: 0.0017s\n",
            "Batch 1960/3750 ( 52.3%) | Loss: 0.086296 | Accuracy: 97.41% | Batch time: 0.0225s\n",
            "Step 5720 | Loss: 0.003803 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 5720 took 0.0000s\n",
            "Step 5730 | Loss: 0.032580 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0026s, O: 0.0006s\n",
            "Batch 1980/3750 ( 52.8%) | Loss: 0.086175 | Accuracy: 97.42% | Batch time: 0.0215s\n",
            "Step 5740 | Loss: 0.322029 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 5740 took 0.0000s\n",
            "Step 5750 | Loss: 0.163489 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0010s\n",
            "Batch 2000/3750 ( 53.3%) | Loss: 0.085993 | Accuracy: 97.42% | Batch time: 0.0207s\n",
            "Step 5760 | Loss: 0.037731 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 5760 took 0.0000s\n",
            "Step 5770 | Loss: 0.012195 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0047s, O: 0.0009s\n",
            "Batch 2020/3750 ( 53.9%) | Loss: 0.085601 | Accuracy: 97.43% | Batch time: 0.0220s\n",
            "Step 5780 | Loss: 0.177077 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 5780 took 0.0000s\n",
            "Step 5790 | Loss: 0.010094 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "Batch 2040/3750 ( 54.4%) | Loss: 0.086290 | Accuracy: 97.40% | Batch time: 0.0237s\n",
            "Step 5800 | Loss: 0.009237 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 5800 took 0.0001s\n",
            "🧹 Memory cleanup at step 5800 took 0.1749s\n",
            "Step 5810 | Loss: 0.038187 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0029s, O: 0.0010s\n",
            "Batch 2060/3750 ( 54.9%) | Loss: 0.085912 | Accuracy: 97.41% | Batch time: 0.0217s\n",
            "Step 5820 | Loss: 0.400782 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0039s, O: 0.0007s\n",
            "🔄 Topology update at step 5820 took 0.0000s\n",
            "Step 5830 | Loss: 0.021677 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0011s\n",
            "Batch 2080/3750 ( 55.5%) | Loss: 0.085899 | Accuracy: 97.41% | Batch time: 0.0204s\n",
            "Step 5840 | Loss: 0.682271 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0034s, O: 0.0008s\n",
            "🔄 Topology update at step 5840 took 0.0001s\n",
            "Step 5850 | Loss: 0.064516 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0041s, O: 0.0007s\n",
            "Batch 2100/3750 ( 56.0%) | Loss: 0.085867 | Accuracy: 97.42% | Batch time: 0.0229s\n",
            "Step 5860 | Loss: 0.567169 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0040s, O: 0.0015s\n",
            "🔄 Topology update at step 5860 took 0.0000s\n",
            "Step 5870 | Loss: 0.031538 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0013s\n",
            "Batch 2120/3750 ( 56.5%) | Loss: 0.085971 | Accuracy: 97.42% | Batch time: 0.0264s\n",
            "Step 5880 | Loss: 0.428456 | GPU: 24.4MB / 98.0MB | F: 0.0058s, B: 0.0025s, O: 0.0005s\n",
            "🔄 Topology update at step 5880 took 0.0000s\n",
            "Step 5890 | Loss: 0.006767 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Batch 2140/3750 ( 57.1%) | Loss: 0.086149 | Accuracy: 97.43% | Batch time: 0.0254s\n",
            "Step 5900 | Loss: 0.020549 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0030s, O: 0.0007s\n",
            "🔄 Topology update at step 5900 took 0.0001s\n",
            "🧹 Memory cleanup at step 5900 took 0.1688s\n",
            "Step 5910 | Loss: 0.003610 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0015s\n",
            "Batch 2160/3750 ( 57.6%) | Loss: 0.085846 | Accuracy: 97.43% | Batch time: 0.0193s\n",
            "Step 5920 | Loss: 0.086774 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 5920 took 0.0000s\n",
            "Step 5930 | Loss: 0.013660 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0026s, O: 0.0007s\n",
            "Batch 2180/3750 ( 58.1%) | Loss: 0.085412 | Accuracy: 97.44% | Batch time: 0.0215s\n",
            "Step 5940 | Loss: 0.076795 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 5940 took 0.0000s\n",
            "Step 5950 | Loss: 0.004521 | GPU: 24.4MB / 98.0MB | F: 0.0046s, B: 0.0030s, O: 0.0010s\n",
            "Batch 2200/3750 ( 58.7%) | Loss: 0.085011 | Accuracy: 97.45% | Batch time: 0.0206s\n",
            "Step 5960 | Loss: 0.043253 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 5960 took 0.0000s\n",
            "Step 5970 | Loss: 0.023194 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0027s, O: 0.0008s\n",
            "Batch 2220/3750 ( 59.2%) | Loss: 0.085006 | Accuracy: 97.45% | Batch time: 0.0236s\n",
            "Step 5980 | Loss: 0.001133 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0049s, O: 0.0008s\n",
            "🔄 Topology update at step 5980 took 0.0000s\n",
            "Step 5990 | Loss: 0.058530 | GPU: 24.4MB / 98.0MB | F: 0.0046s, B: 0.0033s, O: 0.0026s\n",
            "Batch 2240/3750 ( 59.7%) | Loss: 0.085038 | Accuracy: 97.44% | Batch time: 0.0255s\n",
            "Step 6000 | Loss: 0.322342 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0058s, O: 0.0007s\n",
            "🔄 Topology update at step 6000 took 0.0001s\n",
            "🧹 Memory cleanup at step 6000 took 0.2147s\n",
            "Step 6010 | Loss: 0.011245 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0020s, O: 0.0006s\n",
            "Batch 2260/3750 ( 60.3%) | Loss: 0.085424 | Accuracy: 97.44% | Batch time: 0.0208s\n",
            "Step 6020 | Loss: 0.005470 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0020s, O: 0.0006s\n",
            "🔄 Topology update at step 6020 took 0.0000s\n",
            "Step 6030 | Loss: 0.006671 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0023s, O: 0.0007s\n",
            "Batch 2280/3750 ( 60.8%) | Loss: 0.085046 | Accuracy: 97.45% | Batch time: 0.0310s\n",
            "Step 6040 | Loss: 0.081295 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0018s, O: 0.0006s\n",
            "🔄 Topology update at step 6040 took 0.0000s\n",
            "Step 6050 | Loss: 0.006153 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0025s, O: 0.0008s\n",
            "Batch 2300/3750 ( 61.3%) | Loss: 0.084924 | Accuracy: 97.45% | Batch time: 0.0204s\n",
            "Step 6060 | Loss: 0.093144 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0055s, O: 0.0008s\n",
            "🔄 Topology update at step 6060 took 0.0000s\n",
            "Step 6070 | Loss: 0.102817 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0044s, O: 0.0007s\n",
            "Batch 2320/3750 ( 61.9%) | Loss: 0.085531 | Accuracy: 97.44% | Batch time: 0.0253s\n",
            "Step 6080 | Loss: 0.011885 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0048s, O: 0.0020s\n",
            "🔄 Topology update at step 6080 took 0.0000s\n",
            "Step 6090 | Loss: 0.084341 | GPU: 24.4MB / 98.0MB | F: 0.0035s, B: 0.0020s, O: 0.0008s\n",
            "Batch 2340/3750 ( 62.4%) | Loss: 0.085353 | Accuracy: 97.44% | Batch time: 0.0194s\n",
            "Step 6100 | Loss: 0.024592 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0067s, O: 0.0008s\n",
            "🔄 Topology update at step 6100 took 0.0000s\n",
            "🧹 Memory cleanup at step 6100 took 0.2255s\n",
            "Step 6110 | Loss: 0.148419 | GPU: 24.4MB / 98.0MB | F: 0.0073s, B: 0.0088s, O: 0.0010s\n",
            "Batch 2360/3750 ( 62.9%) | Loss: 0.085162 | Accuracy: 97.44% | Batch time: 0.0236s\n",
            "Step 6120 | Loss: 0.058635 | GPU: 24.4MB / 98.0MB | F: 0.0040s, B: 0.0022s, O: 0.0008s\n",
            "🔄 Topology update at step 6120 took 0.0001s\n",
            "Step 6130 | Loss: 0.134064 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0018s, O: 0.0008s\n",
            "Batch 2380/3750 ( 63.5%) | Loss: 0.085422 | Accuracy: 97.43% | Batch time: 0.0227s\n",
            "Step 6140 | Loss: 0.105610 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0034s, O: 0.0006s\n",
            "🔄 Topology update at step 6140 took 0.0000s\n",
            "Step 6150 | Loss: 0.030745 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0008s\n",
            "Batch 2400/3750 ( 64.0%) | Loss: 0.085380 | Accuracy: 97.43% | Batch time: 0.0205s\n",
            "Step 6160 | Loss: 0.006027 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0023s, O: 0.0017s\n",
            "🔄 Topology update at step 6160 took 0.0000s\n",
            "Step 6170 | Loss: 0.097899 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0029s, O: 0.0023s\n",
            "Batch 2420/3750 ( 64.5%) | Loss: 0.085169 | Accuracy: 97.43% | Batch time: 0.0212s\n",
            "Step 6180 | Loss: 0.164889 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 6180 took 0.0001s\n",
            "Step 6190 | Loss: 0.012468 | GPU: 24.4MB / 98.0MB | F: 0.0033s, B: 0.0027s, O: 0.0007s\n",
            "Batch 2440/3750 ( 65.1%) | Loss: 0.085345 | Accuracy: 97.42% | Batch time: 0.0200s\n",
            "Step 6200 | Loss: 0.194762 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0047s, O: 0.0016s\n",
            "🔄 Topology update at step 6200 took 0.0000s\n",
            "🧹 Memory cleanup at step 6200 took 0.1546s\n",
            "Step 6210 | Loss: 0.041846 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0033s, O: 0.0010s\n",
            "Batch 2460/3750 ( 65.6%) | Loss: 0.085155 | Accuracy: 97.43% | Batch time: 0.0213s\n",
            "Step 6220 | Loss: 0.488748 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 6220 took 0.0001s\n",
            "Step 6230 | Loss: 0.305028 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Batch 2480/3750 ( 66.1%) | Loss: 0.085390 | Accuracy: 97.43% | Batch time: 0.0191s\n",
            "Step 6240 | Loss: 0.048885 | GPU: 24.4MB / 98.0MB | F: 0.0042s, B: 0.0036s, O: 0.0006s\n",
            "🔄 Topology update at step 6240 took 0.0000s\n",
            "Step 6250 | Loss: 0.059247 | GPU: 24.4MB / 98.0MB | F: 0.0033s, B: 0.0027s, O: 0.0013s\n",
            "Batch 2500/3750 ( 66.7%) | Loss: 0.085494 | Accuracy: 97.43% | Batch time: 0.0204s\n",
            "Step 6260 | Loss: 0.252924 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 6260 took 0.0000s\n",
            "Step 6270 | Loss: 0.001696 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0021s, O: 0.0007s\n",
            "Batch 2520/3750 ( 67.2%) | Loss: 0.085395 | Accuracy: 97.43% | Batch time: 0.0207s\n",
            "Step 6280 | Loss: 0.011177 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 6280 took 0.0000s\n",
            "Step 6290 | Loss: 0.071148 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0029s, O: 0.0009s\n",
            "Batch 2540/3750 ( 67.7%) | Loss: 0.085282 | Accuracy: 97.44% | Batch time: 0.0218s\n",
            "Step 6300 | Loss: 0.023534 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 6300 took 0.0000s\n",
            "🧹 Memory cleanup at step 6300 took 0.1702s\n",
            "Step 6310 | Loss: 0.023489 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0030s, O: 0.0011s\n",
            "Batch 2560/3750 ( 68.3%) | Loss: 0.084983 | Accuracy: 97.45% | Batch time: 0.0227s\n",
            "Step 6320 | Loss: 0.066665 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 6320 took 0.0000s\n",
            "Step 6330 | Loss: 0.444937 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0035s, O: 0.0005s\n",
            "Batch 2580/3750 ( 68.8%) | Loss: 0.085015 | Accuracy: 97.45% | Batch time: 0.0196s\n",
            "Step 6340 | Loss: 0.013960 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 6340 took 0.0001s\n",
            "Step 6350 | Loss: 0.060435 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "Batch 2600/3750 ( 69.3%) | Loss: 0.084699 | Accuracy: 97.46% | Batch time: 0.0209s\n",
            "Step 6360 | Loss: 0.047198 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0024s, O: 0.0008s\n",
            "🔄 Topology update at step 6360 took 0.0001s\n",
            "Step 6370 | Loss: 0.067328 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0035s, O: 0.0008s\n",
            "Batch 2620/3750 ( 69.9%) | Loss: 0.084621 | Accuracy: 97.46% | Batch time: 0.0225s\n",
            "Step 6380 | Loss: 0.124450 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 6380 took 0.0001s\n",
            "Step 6390 | Loss: 0.162571 | GPU: 24.4MB / 98.0MB | F: 0.0049s, B: 0.0028s, O: 0.0009s\n",
            "Batch 2640/3750 ( 70.4%) | Loss: 0.084353 | Accuracy: 97.47% | Batch time: 0.0216s\n",
            "Step 6400 | Loss: 0.009761 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0037s, O: 0.0011s\n",
            "🔄 Topology update at step 6400 took 0.0000s\n",
            "🧹 Memory cleanup at step 6400 took 0.1744s\n",
            "Step 6410 | Loss: 0.161303 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0027s, O: 0.0009s\n",
            "Batch 2660/3750 ( 70.9%) | Loss: 0.084523 | Accuracy: 97.47% | Batch time: 0.0208s\n",
            "Step 6420 | Loss: 0.001853 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 6420 took 0.0000s\n",
            "Step 6430 | Loss: 0.099741 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0033s, O: 0.0007s\n",
            "Batch 2680/3750 ( 71.5%) | Loss: 0.084615 | Accuracy: 97.46% | Batch time: 0.0223s\n",
            "Step 6440 | Loss: 0.247994 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0033s, O: 0.0017s\n",
            "🔄 Topology update at step 6440 took 0.0000s\n",
            "Step 6450 | Loss: 0.134286 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0027s, O: 0.0008s\n",
            "Batch 2700/3750 ( 72.0%) | Loss: 0.084371 | Accuracy: 97.47% | Batch time: 0.0211s\n",
            "Step 6460 | Loss: 0.016045 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0039s, O: 0.0017s\n",
            "🔄 Topology update at step 6460 took 0.0001s\n",
            "Step 6470 | Loss: 0.100550 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0034s, O: 0.0005s\n",
            "Batch 2720/3750 ( 72.5%) | Loss: 0.084315 | Accuracy: 97.47% | Batch time: 0.0195s\n",
            "Step 6480 | Loss: 0.433788 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0034s, O: 0.0009s\n",
            "🔄 Topology update at step 6480 took 0.0001s\n",
            "Step 6490 | Loss: 0.021895 | GPU: 24.4MB / 98.0MB | F: 0.0088s, B: 0.0023s, O: 0.0013s\n",
            "Batch 2740/3750 ( 73.1%) | Loss: 0.084199 | Accuracy: 97.48% | Batch time: 0.0272s\n",
            "Step 6500 | Loss: 0.007085 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0033s, O: 0.0011s\n",
            "🔄 Topology update at step 6500 took 0.0000s\n",
            "🧹 Memory cleanup at step 6500 took 0.1706s\n",
            "Step 6510 | Loss: 0.146490 | GPU: 24.4MB / 98.0MB | F: 0.0035s, B: 0.0029s, O: 0.0011s\n",
            "Batch 2760/3750 ( 73.6%) | Loss: 0.084227 | Accuracy: 97.47% | Batch time: 0.0204s\n",
            "Step 6520 | Loss: 0.012233 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0046s, O: 0.0017s\n",
            "🔄 Topology update at step 6520 took 0.0000s\n",
            "Step 6530 | Loss: 0.005636 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0030s, O: 0.0009s\n",
            "Batch 2780/3750 ( 74.1%) | Loss: 0.084300 | Accuracy: 97.46% | Batch time: 0.0220s\n",
            "Step 6540 | Loss: 0.021813 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0043s, O: 0.0008s\n",
            "🔄 Topology update at step 6540 took 0.0001s\n",
            "Step 6550 | Loss: 0.009815 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0031s, O: 0.0008s\n",
            "Batch 2800/3750 ( 74.7%) | Loss: 0.084116 | Accuracy: 97.47% | Batch time: 0.0216s\n",
            "Step 6560 | Loss: 0.306829 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 6560 took 0.0000s\n",
            "Step 6570 | Loss: 0.006316 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0043s, O: 0.0008s\n",
            "Batch 2820/3750 ( 75.2%) | Loss: 0.084130 | Accuracy: 97.47% | Batch time: 0.0234s\n",
            "Step 6580 | Loss: 0.010394 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0041s, O: 0.0005s\n",
            "🔄 Topology update at step 6580 took 0.0000s\n",
            "Step 6590 | Loss: 0.025143 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0028s, O: 0.0008s\n",
            "Batch 2840/3750 ( 75.7%) | Loss: 0.083971 | Accuracy: 97.47% | Batch time: 0.0210s\n",
            "Step 6600 | Loss: 0.007758 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 6600 took 0.0000s\n",
            "🧹 Memory cleanup at step 6600 took 0.1661s\n",
            "Step 6610 | Loss: 0.106336 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0044s, O: 0.0008s\n",
            "Batch 2860/3750 ( 76.3%) | Loss: 0.084060 | Accuracy: 97.47% | Batch time: 0.0209s\n",
            "Step 6620 | Loss: 0.013086 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 6620 took 0.0000s\n",
            "Step 6630 | Loss: 0.278100 | GPU: 24.4MB / 98.0MB | F: 0.0042s, B: 0.0050s, O: 0.0008s\n",
            "Batch 2880/3750 ( 76.8%) | Loss: 0.083828 | Accuracy: 97.48% | Batch time: 0.0212s\n",
            "Step 6640 | Loss: 0.018227 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0057s, O: 0.0007s\n",
            "🔄 Topology update at step 6640 took 0.0001s\n",
            "Step 6650 | Loss: 0.002385 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0007s\n",
            "Batch 2900/3750 ( 77.3%) | Loss: 0.083597 | Accuracy: 97.49% | Batch time: 0.0202s\n",
            "Step 6660 | Loss: 0.300932 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0031s, O: 0.0018s\n",
            "🔄 Topology update at step 6660 took 0.0000s\n",
            "Step 6670 | Loss: 0.035266 | GPU: 24.4MB / 98.0MB | F: 0.0043s, B: 0.0026s, O: 0.0014s\n",
            "Batch 2920/3750 ( 77.9%) | Loss: 0.083820 | Accuracy: 97.47% | Batch time: 0.0196s\n",
            "Step 6680 | Loss: 0.040200 | GPU: 24.4MB / 98.0MB | F: 0.0047s, B: 0.0029s, O: 0.0009s\n",
            "🔄 Topology update at step 6680 took 0.0000s\n",
            "Step 6690 | Loss: 0.004614 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0010s\n",
            "Batch 2940/3750 ( 78.4%) | Loss: 0.083803 | Accuracy: 97.48% | Batch time: 0.0222s\n",
            "Step 6700 | Loss: 0.078595 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 6700 took 0.0001s\n",
            "🧹 Memory cleanup at step 6700 took 0.1667s\n",
            "Step 6710 | Loss: 0.049830 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0035s, O: 0.0014s\n",
            "Batch 2960/3750 ( 78.9%) | Loss: 0.083789 | Accuracy: 97.48% | Batch time: 0.0188s\n",
            "Step 6720 | Loss: 0.055867 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0057s, O: 0.0022s\n",
            "🔄 Topology update at step 6720 took 0.0000s\n",
            "Step 6730 | Loss: 0.047078 | GPU: 24.4MB / 98.0MB | F: 0.0033s, B: 0.0032s, O: 0.0009s\n",
            "Batch 2980/3750 ( 79.5%) | Loss: 0.083781 | Accuracy: 97.48% | Batch time: 0.0210s\n",
            "Step 6740 | Loss: 0.010959 | GPU: 24.4MB / 98.0MB | F: 0.0051s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 6740 took 0.0000s\n",
            "Step 6750 | Loss: 0.034679 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0024s, O: 0.0007s\n",
            "Batch 3000/3750 ( 80.0%) | Loss: 0.083616 | Accuracy: 97.49% | Batch time: 0.0199s\n",
            "Step 6760 | Loss: 0.415193 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0047s, O: 0.0006s\n",
            "🔄 Topology update at step 6760 took 0.0000s\n",
            "Step 6770 | Loss: 0.013024 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0028s, O: 0.0008s\n",
            "Batch 3020/3750 ( 80.5%) | Loss: 0.083619 | Accuracy: 97.49% | Batch time: 0.0210s\n",
            "Step 6780 | Loss: 0.021324 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 6780 took 0.0001s\n",
            "Step 6790 | Loss: 0.026555 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0013s\n",
            "Batch 3040/3750 ( 81.1%) | Loss: 0.083662 | Accuracy: 97.49% | Batch time: 0.0215s\n",
            "Step 6800 | Loss: 0.017882 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0048s, O: 0.0022s\n",
            "🔄 Topology update at step 6800 took 0.0000s\n",
            "🧹 Memory cleanup at step 6800 took 0.1718s\n",
            "Step 6810 | Loss: 0.081750 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0027s, O: 0.0007s\n",
            "Batch 3060/3750 ( 81.6%) | Loss: 0.083784 | Accuracy: 97.49% | Batch time: 0.0202s\n",
            "Step 6820 | Loss: 0.025170 | GPU: 24.4MB / 98.0MB | F: 0.0033s, B: 0.0028s, O: 0.0009s\n",
            "🔄 Topology update at step 6820 took 0.0000s\n",
            "Step 6830 | Loss: 0.026418 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0047s, O: 0.0016s\n",
            "Batch 3080/3750 ( 82.1%) | Loss: 0.083839 | Accuracy: 97.49% | Batch time: 0.0212s\n",
            "Step 6840 | Loss: 0.285200 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0029s, O: 0.0011s\n",
            "🔄 Topology update at step 6840 took 0.0001s\n",
            "Step 6850 | Loss: 0.122346 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0013s\n",
            "Batch 3100/3750 ( 82.7%) | Loss: 0.083893 | Accuracy: 97.49% | Batch time: 0.0218s\n",
            "Step 6860 | Loss: 0.009927 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 6860 took 0.0000s\n",
            "Step 6870 | Loss: 0.152687 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0008s\n",
            "Batch 3120/3750 ( 83.2%) | Loss: 0.083874 | Accuracy: 97.49% | Batch time: 0.0259s\n",
            "Step 6880 | Loss: 0.017743 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 6880 took 0.0000s\n",
            "Step 6890 | Loss: 0.129679 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0026s, O: 0.0007s\n",
            "Batch 3140/3750 ( 83.7%) | Loss: 0.084052 | Accuracy: 97.48% | Batch time: 0.0210s\n",
            "Step 6900 | Loss: 0.257245 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 6900 took 0.0000s\n",
            "🧹 Memory cleanup at step 6900 took 0.2126s\n",
            "Step 6910 | Loss: 0.327085 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0011s\n",
            "Batch 3160/3750 ( 84.3%) | Loss: 0.084059 | Accuracy: 97.48% | Batch time: 0.0197s\n",
            "Step 6920 | Loss: 0.018986 | GPU: 24.4MB / 98.0MB | F: 0.0044s, B: 0.0029s, O: 0.0018s\n",
            "🔄 Topology update at step 6920 took 0.0000s\n",
            "Step 6930 | Loss: 0.071018 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0019s, O: 0.0005s\n",
            "Batch 3180/3750 ( 84.8%) | Loss: 0.083759 | Accuracy: 97.49% | Batch time: 0.0189s\n",
            "Step 6940 | Loss: 0.036691 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0066s, O: 0.0007s\n",
            "🔄 Topology update at step 6940 took 0.0000s\n",
            "Step 6950 | Loss: 0.477018 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0021s, O: 0.0007s\n",
            "Batch 3200/3750 ( 85.3%) | Loss: 0.084031 | Accuracy: 97.49% | Batch time: 0.0313s\n",
            "Step 6960 | Loss: 0.164784 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0017s, O: 0.0006s\n",
            "🔄 Topology update at step 6960 took 0.0001s\n",
            "Step 6970 | Loss: 0.011128 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0021s, O: 0.0007s\n",
            "Batch 3220/3750 ( 85.9%) | Loss: 0.084086 | Accuracy: 97.48% | Batch time: 0.0229s\n",
            "Step 6980 | Loss: 0.020688 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0019s, O: 0.0006s\n",
            "🔄 Topology update at step 6980 took 0.0000s\n",
            "Step 6990 | Loss: 0.009467 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0039s, O: 0.0026s\n",
            "Batch 3240/3750 ( 86.4%) | Loss: 0.084095 | Accuracy: 97.48% | Batch time: 0.0268s\n",
            "Step 7000 | Loss: 0.017755 | GPU: 24.4MB / 98.0MB | F: 0.0041s, B: 0.0021s, O: 0.0006s\n",
            "🔄 Topology update at step 7000 took 0.0000s\n",
            "🧹 Memory cleanup at step 7000 took 0.2175s\n",
            "Step 7010 | Loss: 0.018210 | GPU: 24.4MB / 98.0MB | F: 0.0046s, B: 0.0055s, O: 0.0009s\n",
            "Batch 3260/3750 ( 86.9%) | Loss: 0.083761 | Accuracy: 97.50% | Batch time: 0.0325s\n",
            "Step 7020 | Loss: 0.007779 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 7020 took 0.0000s\n",
            "Step 7030 | Loss: 0.000278 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0064s, O: 0.0009s\n",
            "Batch 3280/3750 ( 87.5%) | Loss: 0.083813 | Accuracy: 97.50% | Batch time: 0.0256s\n",
            "Step 7040 | Loss: 0.533044 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0092s, O: 0.0007s\n",
            "🔄 Topology update at step 7040 took 0.0001s\n",
            "Step 7050 | Loss: 0.370379 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0024s, O: 0.0007s\n",
            "Batch 3300/3750 ( 88.0%) | Loss: 0.084210 | Accuracy: 97.49% | Batch time: 0.0205s\n",
            "Step 7060 | Loss: 0.204094 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0052s, O: 0.0005s\n",
            "🔄 Topology update at step 7060 took 0.0000s\n",
            "Step 7070 | Loss: 0.066523 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0032s, O: 0.0009s\n",
            "Batch 3320/3750 ( 88.5%) | Loss: 0.084041 | Accuracy: 97.49% | Batch time: 0.0225s\n",
            "Step 7080 | Loss: 0.189005 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 7080 took 0.0000s\n",
            "Step 7090 | Loss: 0.174637 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0029s, O: 0.0009s\n",
            "Batch 3340/3750 ( 89.1%) | Loss: 0.084462 | Accuracy: 97.49% | Batch time: 0.0225s\n",
            "Step 7100 | Loss: 0.037036 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0034s, O: 0.0009s\n",
            "🔄 Topology update at step 7100 took 0.0000s\n",
            "🧹 Memory cleanup at step 7100 took 0.1579s\n",
            "Step 7110 | Loss: 0.004579 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "Batch 3360/3750 ( 89.6%) | Loss: 0.084437 | Accuracy: 97.49% | Batch time: 0.0217s\n",
            "Step 7120 | Loss: 0.100474 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 7120 took 0.0001s\n",
            "Step 7130 | Loss: 0.184191 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0039s, O: 0.0009s\n",
            "Batch 3380/3750 ( 90.1%) | Loss: 0.084483 | Accuracy: 97.48% | Batch time: 0.0212s\n",
            "Step 7140 | Loss: 0.113885 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0026s, O: 0.0066s\n",
            "🔄 Topology update at step 7140 took 0.0000s\n",
            "Step 7150 | Loss: 0.005298 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0028s, O: 0.0008s\n",
            "Batch 3400/3750 ( 90.7%) | Loss: 0.084322 | Accuracy: 97.49% | Batch time: 0.0216s\n",
            "Step 7160 | Loss: 0.007249 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 7160 took 0.0000s\n",
            "Step 7170 | Loss: 0.043782 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0025s, O: 0.0007s\n",
            "Batch 3420/3750 ( 91.2%) | Loss: 0.084133 | Accuracy: 97.49% | Batch time: 0.0202s\n",
            "Step 7180 | Loss: 0.179441 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0031s, O: 0.0014s\n",
            "🔄 Topology update at step 7180 took 0.0000s\n",
            "Step 7190 | Loss: 0.008329 | GPU: 24.4MB / 98.0MB | F: 0.0036s, B: 0.0027s, O: 0.0009s\n",
            "Batch 3440/3750 ( 91.7%) | Loss: 0.084073 | Accuracy: 97.49% | Batch time: 0.0202s\n",
            "Step 7200 | Loss: 0.184903 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0033s, O: 0.0046s\n",
            "🔄 Topology update at step 7200 took 0.0000s\n",
            "🧹 Memory cleanup at step 7200 took 0.1675s\n",
            "Step 7210 | Loss: 0.098472 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "Batch 3460/3750 ( 92.3%) | Loss: 0.083900 | Accuracy: 97.50% | Batch time: 0.0217s\n",
            "Step 7220 | Loss: 0.147510 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 7220 took 0.0001s\n",
            "Step 7230 | Loss: 0.088277 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0006s\n",
            "Batch 3480/3750 ( 92.8%) | Loss: 0.083767 | Accuracy: 97.50% | Batch time: 0.0207s\n",
            "Step 7240 | Loss: 0.019084 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0030s, O: 0.0006s\n",
            "🔄 Topology update at step 7240 took 0.0000s\n",
            "Step 7250 | Loss: 0.007079 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0039s, O: 0.0008s\n",
            "Batch 3500/3750 ( 93.3%) | Loss: 0.083713 | Accuracy: 97.50% | Batch time: 0.0220s\n",
            "Step 7260 | Loss: 0.017781 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0028s, O: 0.0005s\n",
            "🔄 Topology update at step 7260 took 0.0000s\n",
            "Step 7270 | Loss: 0.001976 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "Batch 3520/3750 ( 93.9%) | Loss: 0.083474 | Accuracy: 97.50% | Batch time: 0.0222s\n",
            "Step 7280 | Loss: 0.015213 | GPU: 24.4MB / 98.0MB | F: 0.0084s, B: 0.0042s, O: 0.0006s\n",
            "🔄 Topology update at step 7280 took 0.0001s\n",
            "Step 7290 | Loss: 0.041319 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0026s, O: 0.0007s\n",
            "Batch 3540/3750 ( 94.4%) | Loss: 0.083371 | Accuracy: 97.50% | Batch time: 0.0196s\n",
            "Step 7300 | Loss: 0.038460 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 7300 took 0.0000s\n",
            "🧹 Memory cleanup at step 7300 took 0.1610s\n",
            "Step 7310 | Loss: 0.003304 | GPU: 24.4MB / 98.0MB | F: 0.0039s, B: 0.0030s, O: 0.0014s\n",
            "Batch 3560/3750 ( 94.9%) | Loss: 0.083415 | Accuracy: 97.50% | Batch time: 0.0214s\n",
            "Step 7320 | Loss: 0.157316 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0036s, O: 0.0008s\n",
            "🔄 Topology update at step 7320 took 0.0000s\n",
            "Step 7330 | Loss: 0.052555 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0029s, O: 0.0008s\n",
            "Batch 3580/3750 ( 95.5%) | Loss: 0.083308 | Accuracy: 97.51% | Batch time: 0.0230s\n",
            "Step 7340 | Loss: 0.165702 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 7340 took 0.0001s\n",
            "Step 7350 | Loss: 0.004066 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0033s, O: 0.0007s\n",
            "Batch 3600/3750 ( 96.0%) | Loss: 0.083102 | Accuracy: 97.51% | Batch time: 0.0204s\n",
            "Step 7360 | Loss: 0.008625 | GPU: 24.4MB / 98.0MB | F: 0.0040s, B: 0.0031s, O: 0.0005s\n",
            "🔄 Topology update at step 7360 took 0.0000s\n",
            "Step 7370 | Loss: 0.028573 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0020s, O: 0.0005s\n",
            "Batch 3620/3750 ( 96.5%) | Loss: 0.082883 | Accuracy: 97.52% | Batch time: 0.0184s\n",
            "Step 7380 | Loss: 0.129600 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0033s, O: 0.0018s\n",
            "🔄 Topology update at step 7380 took 0.0000s\n",
            "Step 7390 | Loss: 0.371060 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0035s, O: 0.0007s\n",
            "Batch 3640/3750 ( 97.1%) | Loss: 0.082875 | Accuracy: 97.52% | Batch time: 0.0236s\n",
            "Step 7400 | Loss: 0.094224 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0051s, O: 0.0005s\n",
            "🔄 Topology update at step 7400 took 0.0000s\n",
            "🧹 Memory cleanup at step 7400 took 0.1667s\n",
            "Step 7410 | Loss: 0.010982 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "Batch 3660/3750 ( 97.6%) | Loss: 0.082877 | Accuracy: 97.52% | Batch time: 0.0210s\n",
            "Step 7420 | Loss: 0.012741 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 7420 took 0.0000s\n",
            "Step 7430 | Loss: 0.008714 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0012s\n",
            "Batch 3680/3750 ( 98.1%) | Loss: 0.082772 | Accuracy: 97.52% | Batch time: 0.0197s\n",
            "Step 7440 | Loss: 0.002451 | GPU: 24.4MB / 98.0MB | F: 0.0047s, B: 0.0039s, O: 0.0007s\n",
            "🔄 Topology update at step 7440 took 0.0000s\n",
            "Step 7450 | Loss: 0.179095 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0044s, O: 0.0015s\n",
            "Batch 3700/3750 ( 98.7%) | Loss: 0.082670 | Accuracy: 97.52% | Batch time: 0.0195s\n",
            "Step 7460 | Loss: 0.052927 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0039s, O: 0.0007s\n",
            "🔄 Topology update at step 7460 took 0.0001s\n",
            "Step 7470 | Loss: 0.071316 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0038s, O: 0.0010s\n",
            "Batch 3720/3750 ( 99.2%) | Loss: 0.082569 | Accuracy: 97.52% | Batch time: 0.0197s\n",
            "Step 7480 | Loss: 0.001003 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 7480 took 0.0000s\n",
            "Step 7490 | Loss: 0.070718 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0024s, O: 0.0007s\n",
            "Batch 3740/3750 ( 99.7%) | Loss: 0.082367 | Accuracy: 97.52% | Batch time: 0.0216s\n",
            "Step 7500 | Loss: 0.014614 | GPU: 24.4MB / 98.0MB | F: 0.0010s, B: 0.0014s, O: 0.0005s\n",
            "🔄 Topology update at step 7500 took 0.0000s\n",
            "🧹 Memory cleanup at step 7500 took 0.1380s\n",
            "\n",
            "-------------------- EPOCH 2 SUMMARY --------------------\n",
            "Loss: 0.082295 | Accuracy: 97.53%\n",
            "Time: 50.89s total, 0.0122s per batch\n",
            "🔄 Final Memory - RAM: 1370.0MB, GPU: 24.4MB allocated, 44.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=24.4, peak=24.4\n",
            "===============================\n",
            "\n",
            "⏱️ TALT model training took 50.8897 seconds\n",
            "\n",
            "Cleaning up memory after training...\n",
            "⏱️ Memory cleanup took 0.1476 seconds\n",
            "🔄 After training Memory - RAM: 1370.0MB, GPU: 24.3MB allocated, 44.0MB reserved\n",
            "\n",
            "------------------------- Standard Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 0.031487 | Accuracy: 98.77% | Batch time: 0.0013s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 0.045853 | Accuracy: 98.51% | Batch time: 0.0014s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 0.057086 | Accuracy: 98.26% | Batch time: 0.0012s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 0.055669 | Accuracy: 98.26% | Batch time: 0.0014s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 0.056541 | Accuracy: 98.26% | Batch time: 0.0013s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 0.054781 | Accuracy: 98.26% | Batch time: 0.0013s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 0.048506 | Accuracy: 98.45% | Batch time: 0.0012s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 0.047061 | Accuracy: 98.49% | Batch time: 0.0014s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 0.045995 | Accuracy: 98.54% | Batch time: 0.0014s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 0.041580 | Accuracy: 98.69% | Batch time: 0.0013s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 0.039412 | Accuracy: 98.75% | Batch time: 0.0014s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 0.037274 | Accuracy: 98.81% | Batch time: 0.0013s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.039218 | Accuracy: 98.74%\n",
            "Time: 3.12s total, 0.0014s per batch\n",
            "⏱️ Standard model evaluation took 3.1194 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 0.032917 | Accuracy: 98.77% | Batch time: 0.0022s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 0.053581 | Accuracy: 98.02% | Batch time: 0.0013s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 0.058084 | Accuracy: 98.01% | Batch time: 0.0058s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 0.058219 | Accuracy: 98.01% | Batch time: 0.0076s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 0.059361 | Accuracy: 97.98% | Batch time: 0.0009s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 0.059211 | Accuracy: 97.92% | Batch time: 0.0009s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 0.053487 | Accuracy: 98.11% | Batch time: 0.0010s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 0.049680 | Accuracy: 98.29% | Batch time: 0.0010s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 0.047394 | Accuracy: 98.38% | Batch time: 0.0012s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 0.043485 | Accuracy: 98.52% | Batch time: 0.0012s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 0.040631 | Accuracy: 98.60% | Batch time: 0.0052s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 0.038922 | Accuracy: 98.66% | Batch time: 0.0014s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.040553 | Accuracy: 98.61%\n",
            "Time: 3.92s total, 0.0014s per batch\n",
            "⏱️ TALT model evaluation took 3.9246 seconds\n",
            "\n",
            "------------------------- EPOCH 2 SUMMARY -------------------------\n",
            "Time: 84.44s\n",
            "Standard Model:\n",
            "  - Train Loss: 0.116598, Accuracy: 96.60%\n",
            "  - Test Loss:  0.039218, Accuracy: 98.74%\n",
            "Improved TALT Model:\n",
            "  - Train Loss: 0.082295, Accuracy: 97.53%\n",
            "  - Test Loss:  0.040553, Accuracy: 98.61%\n",
            "\n",
            "Cleaning up memory after epoch...\n",
            "⏱️ Memory cleanup took 0.1491 seconds\n",
            "🔄 After epoch Memory - RAM: 1370.0MB, GPU: 24.3MB allocated, 44.0MB reserved\n",
            "\n",
            "------------------------- Standard Model: Epoch 3/3 -------------------------\n",
            "\n",
            "==================== STANDARD OPTIMIZER - EPOCH 3 ====================\n",
            "Device: cuda, Batches: 3750, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 1370.0MB, GPU: 24.3MB allocated, 44.0MB reserved\n",
            "Batch    0/3750 (  0.0%) | Loss: 0.115167 | Accuracy: 93.75% | GPU: 24.4MB | Batch time: 0.0108s\n",
            "Batch   20/3750 (  0.5%) | Loss: 0.091887 | Accuracy: 97.32% | GPU: 24.4MB | Batch time: 0.0081s\n",
            "Batch   40/3750 (  1.1%) | Loss: 0.078941 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0111s\n",
            "Batch   60/3750 (  1.6%) | Loss: 0.087106 | Accuracy: 97.34% | GPU: 24.4MB | Batch time: 0.0079s\n",
            "Batch   80/3750 (  2.1%) | Loss: 0.088458 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch  100/3750 (  2.7%) | Loss: 0.084093 | Accuracy: 97.65% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch  120/3750 (  3.2%) | Loss: 0.079376 | Accuracy: 97.83% | GPU: 24.4MB | Batch time: 0.0050s\n",
            "Batch  140/3750 (  3.7%) | Loss: 0.086523 | Accuracy: 97.78% | GPU: 24.4MB | Batch time: 0.0042s\n",
            "Batch  160/3750 (  4.3%) | Loss: 0.088291 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0067s\n",
            "Batch  180/3750 (  4.8%) | Loss: 0.091006 | Accuracy: 97.44% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch  200/3750 (  5.3%) | Loss: 0.093026 | Accuracy: 97.39% | GPU: 24.4MB | Batch time: 0.0052s\n",
            "Batch  220/3750 (  5.9%) | Loss: 0.093147 | Accuracy: 97.37% | GPU: 24.4MB | Batch time: 0.0070s\n",
            "Batch  240/3750 (  6.4%) | Loss: 0.093410 | Accuracy: 97.33% | GPU: 24.4MB | Batch time: 0.0064s\n",
            "Batch  260/3750 (  6.9%) | Loss: 0.089962 | Accuracy: 97.44% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch  280/3750 (  7.5%) | Loss: 0.089330 | Accuracy: 97.40% | GPU: 24.4MB | Batch time: 0.0064s\n",
            "Batch  300/3750 (  8.0%) | Loss: 0.091685 | Accuracy: 97.36% | GPU: 24.4MB | Batch time: 0.0057s\n",
            "Batch  320/3750 (  8.5%) | Loss: 0.090177 | Accuracy: 97.41% | GPU: 24.4MB | Batch time: 0.0050s\n",
            "Batch  340/3750 (  9.1%) | Loss: 0.094054 | Accuracy: 97.38% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch  360/3750 (  9.6%) | Loss: 0.095833 | Accuracy: 97.35% | GPU: 24.4MB | Batch time: 0.0045s\n",
            "Batch  380/3750 ( 10.1%) | Loss: 0.094227 | Accuracy: 97.39% | GPU: 24.4MB | Batch time: 0.0046s\n",
            "Batch  400/3750 ( 10.7%) | Loss: 0.096758 | Accuracy: 97.35% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch  420/3750 ( 11.2%) | Loss: 0.095499 | Accuracy: 97.37% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch  440/3750 ( 11.7%) | Loss: 0.094922 | Accuracy: 97.39% | GPU: 24.4MB | Batch time: 0.0062s\n",
            "Batch  460/3750 ( 12.3%) | Loss: 0.094071 | Accuracy: 97.41% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch  480/3750 ( 12.8%) | Loss: 0.091031 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch  500/3750 ( 13.3%) | Loss: 0.089924 | Accuracy: 97.55% | GPU: 24.4MB | Batch time: 0.0103s\n",
            "Batch  520/3750 ( 13.9%) | Loss: 0.090400 | Accuracy: 97.55% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch  540/3750 ( 14.4%) | Loss: 0.091599 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch  560/3750 ( 14.9%) | Loss: 0.091821 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch  580/3750 ( 15.5%) | Loss: 0.089926 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0063s\n",
            "Batch  600/3750 ( 16.0%) | Loss: 0.089785 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0056s\n",
            "Batch  620/3750 ( 16.5%) | Loss: 0.090014 | Accuracy: 97.54% | GPU: 24.4MB | Batch time: 0.0041s\n",
            "Batch  640/3750 ( 17.1%) | Loss: 0.090125 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0051s\n",
            "Batch  660/3750 ( 17.6%) | Loss: 0.090401 | Accuracy: 97.55% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch  680/3750 ( 18.1%) | Loss: 0.089293 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0057s\n",
            "Batch  700/3750 ( 18.7%) | Loss: 0.089804 | Accuracy: 97.54% | GPU: 24.4MB | Batch time: 0.0057s\n",
            "Batch  720/3750 ( 19.2%) | Loss: 0.089573 | Accuracy: 97.54% | GPU: 24.4MB | Batch time: 0.0068s\n",
            "Batch  740/3750 ( 19.7%) | Loss: 0.089559 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch  760/3750 ( 20.3%) | Loss: 0.090520 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0051s\n",
            "Batch  780/3750 ( 20.8%) | Loss: 0.091435 | Accuracy: 97.45% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch  800/3750 ( 21.3%) | Loss: 0.091783 | Accuracy: 97.45% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch  820/3750 ( 21.9%) | Loss: 0.090763 | Accuracy: 97.46% | GPU: 24.4MB | Batch time: 0.0034s\n",
            "Batch  840/3750 ( 22.4%) | Loss: 0.089771 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0044s\n",
            "Batch  860/3750 ( 22.9%) | Loss: 0.088660 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0060s\n",
            "Batch  880/3750 ( 23.5%) | Loss: 0.088487 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0060s\n",
            "Batch  900/3750 ( 24.0%) | Loss: 0.088845 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0052s\n",
            "Batch  920/3750 ( 24.5%) | Loss: 0.089443 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0101s\n",
            "Batch  940/3750 ( 25.1%) | Loss: 0.089543 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0044s\n",
            "Batch  960/3750 ( 25.6%) | Loss: 0.089388 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch  980/3750 ( 26.1%) | Loss: 0.089261 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch 1000/3750 ( 26.7%) | Loss: 0.088431 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0053s\n",
            "Batch 1020/3750 ( 27.2%) | Loss: 0.088542 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch 1040/3750 ( 27.7%) | Loss: 0.089367 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0054s\n",
            "Batch 1060/3750 ( 28.3%) | Loss: 0.088832 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch 1080/3750 ( 28.8%) | Loss: 0.088013 | Accuracy: 97.55% | GPU: 24.4MB | Batch time: 0.0042s\n",
            "Batch 1100/3750 ( 29.3%) | Loss: 0.087967 | Accuracy: 97.55% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch 1120/3750 ( 29.9%) | Loss: 0.088720 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 1140/3750 ( 30.4%) | Loss: 0.088952 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 1160/3750 ( 30.9%) | Loss: 0.088217 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 1180/3750 ( 31.5%) | Loss: 0.087920 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0060s\n",
            "Batch 1200/3750 ( 32.0%) | Loss: 0.088644 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0045s\n",
            "Batch 1220/3750 ( 32.5%) | Loss: 0.088328 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch 1240/3750 ( 33.1%) | Loss: 0.088358 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 1260/3750 ( 33.6%) | Loss: 0.088050 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0051s\n",
            "Batch 1280/3750 ( 34.1%) | Loss: 0.087992 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0054s\n",
            "Batch 1300/3750 ( 34.7%) | Loss: 0.087671 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0042s\n",
            "Batch 1320/3750 ( 35.2%) | Loss: 0.087175 | Accuracy: 97.54% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch 1340/3750 ( 35.7%) | Loss: 0.086756 | Accuracy: 97.54% | GPU: 24.4MB | Batch time: 0.0104s\n",
            "Batch 1360/3750 ( 36.3%) | Loss: 0.086126 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0043s\n",
            "Batch 1380/3750 ( 36.8%) | Loss: 0.086717 | Accuracy: 97.55% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch 1400/3750 ( 37.3%) | Loss: 0.087052 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 1420/3750 ( 37.9%) | Loss: 0.087903 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0045s\n",
            "Batch 1440/3750 ( 38.4%) | Loss: 0.087950 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0059s\n",
            "Batch 1460/3750 ( 38.9%) | Loss: 0.087963 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0033s\n",
            "Batch 1480/3750 ( 39.5%) | Loss: 0.087774 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0059s\n",
            "Batch 1500/3750 ( 40.0%) | Loss: 0.088408 | Accuracy: 97.49% | GPU: 24.4MB | Batch time: 0.0069s\n",
            "Batch 1520/3750 ( 40.5%) | Loss: 0.088294 | Accuracy: 97.49% | GPU: 24.4MB | Batch time: 0.0033s\n",
            "Batch 1540/3750 ( 41.1%) | Loss: 0.088645 | Accuracy: 97.47% | GPU: 24.4MB | Batch time: 0.0053s\n",
            "Batch 1560/3750 ( 41.6%) | Loss: 0.088270 | Accuracy: 97.47% | GPU: 24.4MB | Batch time: 0.0063s\n",
            "Batch 1580/3750 ( 42.1%) | Loss: 0.088193 | Accuracy: 97.48% | GPU: 24.4MB | Batch time: 0.0077s\n",
            "Batch 1600/3750 ( 42.7%) | Loss: 0.088632 | Accuracy: 97.48% | GPU: 24.4MB | Batch time: 0.0062s\n",
            "Batch 1620/3750 ( 43.2%) | Loss: 0.088085 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0109s\n",
            "Batch 1640/3750 ( 43.7%) | Loss: 0.087985 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0026s\n",
            "Batch 1660/3750 ( 44.3%) | Loss: 0.088453 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0126s\n",
            "Batch 1680/3750 ( 44.8%) | Loss: 0.088236 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0033s\n",
            "Batch 1700/3750 ( 45.3%) | Loss: 0.087830 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0034s\n",
            "Batch 1720/3750 ( 45.9%) | Loss: 0.087275 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0030s\n",
            "Batch 1740/3750 ( 46.4%) | Loss: 0.086837 | Accuracy: 97.54% | GPU: 24.4MB | Batch time: 0.0056s\n",
            "Batch 1760/3750 ( 46.9%) | Loss: 0.086536 | Accuracy: 97.54% | GPU: 24.4MB | Batch time: 0.0027s\n",
            "Batch 1780/3750 ( 47.5%) | Loss: 0.086857 | Accuracy: 97.54% | GPU: 24.4MB | Batch time: 0.0057s\n",
            "Batch 1800/3750 ( 48.0%) | Loss: 0.087025 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0080s\n",
            "Batch 1820/3750 ( 48.5%) | Loss: 0.087093 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0056s\n",
            "Batch 1840/3750 ( 49.1%) | Loss: 0.087224 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0046s\n",
            "Batch 1860/3750 ( 49.6%) | Loss: 0.087800 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0078s\n",
            "Batch 1880/3750 ( 50.1%) | Loss: 0.087834 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0081s\n",
            "Batch 1900/3750 ( 50.7%) | Loss: 0.087432 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch 1920/3750 ( 51.2%) | Loss: 0.088023 | Accuracy: 97.49% | GPU: 24.4MB | Batch time: 0.0070s\n",
            "Batch 1940/3750 ( 51.7%) | Loss: 0.087922 | Accuracy: 97.49% | GPU: 24.4MB | Batch time: 0.0044s\n",
            "Batch 1960/3750 ( 52.3%) | Loss: 0.087758 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0063s\n",
            "Batch 1980/3750 ( 52.8%) | Loss: 0.087906 | Accuracy: 97.49% | GPU: 24.4MB | Batch time: 0.0046s\n",
            "Batch 2000/3750 ( 53.3%) | Loss: 0.087543 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch 2020/3750 ( 53.9%) | Loss: 0.087602 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0034s\n",
            "Batch 2040/3750 ( 54.4%) | Loss: 0.087222 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0045s\n",
            "Batch 2060/3750 ( 54.9%) | Loss: 0.086881 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0094s\n",
            "Batch 2080/3750 ( 55.5%) | Loss: 0.087583 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 2100/3750 ( 56.0%) | Loss: 0.087800 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0063s\n",
            "Batch 2120/3750 ( 56.5%) | Loss: 0.087673 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 2140/3750 ( 57.1%) | Loss: 0.087618 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 2160/3750 ( 57.6%) | Loss: 0.087419 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch 2180/3750 ( 58.1%) | Loss: 0.087324 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0115s\n",
            "Batch 2200/3750 ( 58.7%) | Loss: 0.087537 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0046s\n",
            "Batch 2220/3750 ( 59.2%) | Loss: 0.087582 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 2240/3750 ( 59.7%) | Loss: 0.087426 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0047s\n",
            "Batch 2260/3750 ( 60.3%) | Loss: 0.087425 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0079s\n",
            "Batch 2280/3750 ( 60.8%) | Loss: 0.087543 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0052s\n",
            "Batch 2300/3750 ( 61.3%) | Loss: 0.087324 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0063s\n",
            "Batch 2320/3750 ( 61.9%) | Loss: 0.087407 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 2340/3750 ( 62.4%) | Loss: 0.087203 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0051s\n",
            "Batch 2360/3750 ( 62.9%) | Loss: 0.087098 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0039s\n",
            "Batch 2380/3750 ( 63.5%) | Loss: 0.087158 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0066s\n",
            "Batch 2400/3750 ( 64.0%) | Loss: 0.087071 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0053s\n",
            "Batch 2420/3750 ( 64.5%) | Loss: 0.087359 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 2440/3750 ( 65.1%) | Loss: 0.087777 | Accuracy: 97.50% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 2460/3750 ( 65.6%) | Loss: 0.087262 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0055s\n",
            "Batch 2480/3750 ( 66.1%) | Loss: 0.086942 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0082s\n",
            "Batch 2500/3750 ( 66.7%) | Loss: 0.087189 | Accuracy: 97.52% | GPU: 24.4MB | Batch time: 0.0051s\n",
            "Batch 2520/3750 ( 67.2%) | Loss: 0.087311 | Accuracy: 97.51% | GPU: 24.4MB | Batch time: 0.0066s\n",
            "Batch 2540/3750 ( 67.7%) | Loss: 0.086934 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0056s\n",
            "Batch 2560/3750 ( 68.3%) | Loss: 0.086648 | Accuracy: 97.54% | GPU: 24.4MB | Batch time: 0.0066s\n",
            "Batch 2580/3750 ( 68.8%) | Loss: 0.086968 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0056s\n",
            "Batch 2600/3750 ( 69.3%) | Loss: 0.087443 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch 2620/3750 ( 69.9%) | Loss: 0.087358 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0052s\n",
            "Batch 2640/3750 ( 70.4%) | Loss: 0.087382 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0045s\n",
            "Batch 2660/3750 ( 70.9%) | Loss: 0.087288 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 2680/3750 ( 71.5%) | Loss: 0.087282 | Accuracy: 97.53% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 2700/3750 ( 72.0%) | Loss: 0.087131 | Accuracy: 97.54% | GPU: 24.4MB | Batch time: 0.0053s\n",
            "Batch 2720/3750 ( 72.5%) | Loss: 0.086986 | Accuracy: 97.55% | GPU: 24.4MB | Batch time: 0.0040s\n",
            "Batch 2740/3750 ( 73.1%) | Loss: 0.086597 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0034s\n",
            "Batch 2760/3750 ( 73.6%) | Loss: 0.086435 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 2780/3750 ( 74.1%) | Loss: 0.086547 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 2800/3750 ( 74.7%) | Loss: 0.086595 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0051s\n",
            "Batch 2820/3750 ( 75.2%) | Loss: 0.086648 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0060s\n",
            "Batch 2840/3750 ( 75.7%) | Loss: 0.086531 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 2860/3750 ( 76.3%) | Loss: 0.086542 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0046s\n",
            "Batch 2880/3750 ( 76.8%) | Loss: 0.086279 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 2900/3750 ( 77.3%) | Loss: 0.086207 | Accuracy: 97.58% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 2920/3750 ( 77.9%) | Loss: 0.086375 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0090s\n",
            "Batch 2940/3750 ( 78.4%) | Loss: 0.086806 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 2960/3750 ( 78.9%) | Loss: 0.086750 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0044s\n",
            "Batch 2980/3750 ( 79.5%) | Loss: 0.086640 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0048s\n",
            "Batch 3000/3750 ( 80.0%) | Loss: 0.086570 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0054s\n",
            "Batch 3020/3750 ( 80.5%) | Loss: 0.086280 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0038s\n",
            "Batch 3040/3750 ( 81.1%) | Loss: 0.086285 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0050s\n",
            "Batch 3060/3750 ( 81.6%) | Loss: 0.086010 | Accuracy: 97.58% | GPU: 24.4MB | Batch time: 0.0062s\n",
            "Batch 3080/3750 ( 82.1%) | Loss: 0.085550 | Accuracy: 97.59% | GPU: 24.4MB | Batch time: 0.0033s\n",
            "Batch 3100/3750 ( 82.7%) | Loss: 0.085292 | Accuracy: 97.59% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch 3120/3750 ( 83.2%) | Loss: 0.085151 | Accuracy: 97.59% | GPU: 24.4MB | Batch time: 0.0041s\n",
            "Batch 3140/3750 ( 83.7%) | Loss: 0.085091 | Accuracy: 97.59% | GPU: 24.4MB | Batch time: 0.0041s\n",
            "Batch 3160/3750 ( 84.3%) | Loss: 0.085201 | Accuracy: 97.59% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 3180/3750 ( 84.8%) | Loss: 0.085226 | Accuracy: 97.59% | GPU: 24.4MB | Batch time: 0.0058s\n",
            "Batch 3200/3750 ( 85.3%) | Loss: 0.085490 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch 3220/3750 ( 85.9%) | Loss: 0.085839 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0050s\n",
            "Batch 3240/3750 ( 86.4%) | Loss: 0.085835 | Accuracy: 97.55% | GPU: 24.4MB | Batch time: 0.0099s\n",
            "Batch 3260/3750 ( 86.9%) | Loss: 0.085617 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0061s\n",
            "Batch 3280/3750 ( 87.5%) | Loss: 0.085614 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch 3300/3750 ( 88.0%) | Loss: 0.085547 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch 3320/3750 ( 88.5%) | Loss: 0.085241 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0044s\n",
            "Batch 3340/3750 ( 89.1%) | Loss: 0.085780 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0080s\n",
            "Batch 3360/3750 ( 89.6%) | Loss: 0.085534 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0079s\n",
            "Batch 3380/3750 ( 90.1%) | Loss: 0.085521 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0055s\n",
            "Batch 3400/3750 ( 90.7%) | Loss: 0.085773 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0049s\n",
            "Batch 3420/3750 ( 91.2%) | Loss: 0.085585 | Accuracy: 97.58% | GPU: 24.4MB | Batch time: 0.0070s\n",
            "Batch 3440/3750 ( 91.7%) | Loss: 0.085525 | Accuracy: 97.58% | GPU: 24.4MB | Batch time: 0.0050s\n",
            "Batch 3460/3750 ( 92.3%) | Loss: 0.085300 | Accuracy: 97.58% | GPU: 24.4MB | Batch time: 0.0052s\n",
            "Batch 3480/3750 ( 92.8%) | Loss: 0.085399 | Accuracy: 97.58% | GPU: 24.4MB | Batch time: 0.0059s\n",
            "Batch 3500/3750 ( 93.3%) | Loss: 0.085335 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0042s\n",
            "Batch 3520/3750 ( 93.9%) | Loss: 0.085166 | Accuracy: 97.58% | GPU: 24.4MB | Batch time: 0.0029s\n",
            "Batch 3540/3750 ( 94.4%) | Loss: 0.085019 | Accuracy: 97.58% | GPU: 24.4MB | Batch time: 0.0032s\n",
            "Batch 3560/3750 ( 94.9%) | Loss: 0.085115 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0031s\n",
            "Batch 3580/3750 ( 95.5%) | Loss: 0.085074 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 3600/3750 ( 96.0%) | Loss: 0.085066 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0084s\n",
            "Batch 3620/3750 ( 96.5%) | Loss: 0.085257 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0028s\n",
            "Batch 3640/3750 ( 97.1%) | Loss: 0.085186 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0085s\n",
            "Batch 3660/3750 ( 97.6%) | Loss: 0.085328 | Accuracy: 97.57% | GPU: 24.4MB | Batch time: 0.0070s\n",
            "Batch 3680/3750 ( 98.1%) | Loss: 0.085362 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0050s\n",
            "Batch 3700/3750 ( 98.7%) | Loss: 0.085454 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0037s\n",
            "Batch 3720/3750 ( 99.2%) | Loss: 0.085511 | Accuracy: 97.55% | GPU: 24.4MB | Batch time: 0.0035s\n",
            "Batch 3740/3750 ( 99.7%) | Loss: 0.085230 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0036s\n",
            "Batch 3749/3750 (100.0%) | Loss: 0.085183 | Accuracy: 97.56% | GPU: 24.4MB | Batch time: 0.0022s\n",
            "\n",
            "-------------------- STANDARD OPTIMIZER - SUMMARY --------------------\n",
            "Loss: 0.085183 | Accuracy: 97.56%\n",
            "Time: 25.75s total, 0.0052s per batch\n",
            "  - Forward: 0.0018s, Backward: 0.0021s, Optimizer: 0.0005s\n",
            "🔄 Final Memory - RAM: 1370.0MB, GPU: 24.4MB allocated, 46.0MB reserved\n",
            "⏱️ Standard model training took 25.7532 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Epoch 3/3 -------------------------\n",
            "\n",
            "==================== EPOCH 3 TRAINING ====================\n",
            "Device: cuda, Batches: 3750, Batch size: 16\n",
            "🔄 Initial Memory - RAM: 1370.0MB, GPU: 24.3MB allocated, 46.0MB reserved\n",
            "Batch    0/3750 (  0.0%) | Loss: 0.022014 | Accuracy: 100.00% | Batch time: 0.0288s\n",
            "Step 7510 | Loss: 0.004202 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0051s, O: 0.0007s\n",
            "Step 7520 | Loss: 0.167041 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 7520 took 0.0001s\n",
            "Batch   20/3750 (  0.5%) | Loss: 0.080953 | Accuracy: 97.92% | Batch time: 0.0206s\n",
            "Step 7530 | Loss: 0.309801 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 7540 | Loss: 0.001785 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 7540 took 0.0000s\n",
            "Batch   40/3750 (  1.1%) | Loss: 0.091496 | Accuracy: 97.26% | Batch time: 0.0212s\n",
            "Step 7550 | Loss: 0.011527 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0008s\n",
            "Step 7560 | Loss: 0.011383 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 7560 took 0.0000s\n",
            "Batch   60/3750 (  1.6%) | Loss: 0.072426 | Accuracy: 97.95% | Batch time: 0.0199s\n",
            "Step 7570 | Loss: 0.097609 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0010s\n",
            "Step 7580 | Loss: 0.205480 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0009s\n",
            "🔄 Topology update at step 7580 took 0.0000s\n",
            "Batch   80/3750 (  2.1%) | Loss: 0.082614 | Accuracy: 97.53% | Batch time: 0.0185s\n",
            "Step 7590 | Loss: 0.039820 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 7600 | Loss: 0.015648 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 7600 took 0.0000s\n",
            "🧹 Memory cleanup at step 7600 took 0.2049s\n",
            "Batch  100/3750 (  2.7%) | Loss: 0.072658 | Accuracy: 97.83% | Batch time: 0.0252s\n",
            "Step 7610 | Loss: 0.165928 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0035s, O: 0.0006s\n",
            "Step 7620 | Loss: 0.011843 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0004s\n",
            "🔄 Topology update at step 7620 took 0.0000s\n",
            "Batch  120/3750 (  3.2%) | Loss: 0.075036 | Accuracy: 97.68% | Batch time: 0.0189s\n",
            "Step 7630 | Loss: 0.012784 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0021s\n",
            "Step 7640 | Loss: 0.018813 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 7640 took 0.0000s\n",
            "Batch  140/3750 (  3.7%) | Loss: 0.071295 | Accuracy: 97.78% | Batch time: 0.0201s\n",
            "Step 7650 | Loss: 0.089280 | GPU: 24.4MB / 98.0MB | F: 0.0036s, B: 0.0033s, O: 0.0004s\n",
            "Step 7660 | Loss: 0.224997 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0027s, O: 0.0011s\n",
            "🔄 Topology update at step 7660 took 0.0000s\n",
            "Batch  160/3750 (  4.3%) | Loss: 0.067104 | Accuracy: 97.86% | Batch time: 0.0184s\n",
            "Step 7670 | Loss: 0.027016 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "Step 7680 | Loss: 0.349775 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0030s, O: 0.0006s\n",
            "🔄 Topology update at step 7680 took 0.0000s\n",
            "Batch  180/3750 (  4.8%) | Loss: 0.065017 | Accuracy: 98.00% | Batch time: 0.0195s\n",
            "Step 7690 | Loss: 0.038123 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0029s, O: 0.0008s\n",
            "Step 7700 | Loss: 0.033603 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 7700 took 0.0000s\n",
            "🧹 Memory cleanup at step 7700 took 0.1427s\n",
            "Batch  200/3750 (  5.3%) | Loss: 0.065131 | Accuracy: 98.01% | Batch time: 0.0211s\n",
            "Step 7710 | Loss: 0.015099 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "Step 7720 | Loss: 0.026021 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0042s, O: 0.0013s\n",
            "🔄 Topology update at step 7720 took 0.0000s\n",
            "Batch  220/3750 (  5.9%) | Loss: 0.063894 | Accuracy: 97.99% | Batch time: 0.0188s\n",
            "Step 7730 | Loss: 0.097832 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0034s, O: 0.0006s\n",
            "Step 7740 | Loss: 0.024009 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 7740 took 0.0000s\n",
            "Batch  240/3750 (  6.4%) | Loss: 0.063748 | Accuracy: 98.08% | Batch time: 0.0195s\n",
            "Step 7750 | Loss: 0.554575 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0034s, O: 0.0007s\n",
            "Step 7760 | Loss: 0.022943 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0022s, O: 0.0009s\n",
            "🔄 Topology update at step 7760 took 0.0000s\n",
            "Batch  260/3750 (  6.9%) | Loss: 0.067060 | Accuracy: 97.96% | Batch time: 0.0206s\n",
            "Step 7770 | Loss: 0.024339 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0028s, O: 0.0015s\n",
            "Step 7780 | Loss: 0.124407 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 7780 took 0.0000s\n",
            "Batch  280/3750 (  7.5%) | Loss: 0.067089 | Accuracy: 97.91% | Batch time: 0.0199s\n",
            "Step 7790 | Loss: 0.002457 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "Step 7800 | Loss: 0.001054 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0064s, O: 0.0006s\n",
            "🔄 Topology update at step 7800 took 0.0000s\n",
            "🧹 Memory cleanup at step 7800 took 0.1343s\n",
            "Batch  300/3750 (  8.0%) | Loss: 0.065529 | Accuracy: 97.99% | Batch time: 0.0195s\n",
            "Step 7810 | Loss: 0.004518 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 7820 | Loss: 0.057349 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0029s, O: 0.0026s\n",
            "🔄 Topology update at step 7820 took 0.0000s\n",
            "Batch  320/3750 (  8.5%) | Loss: 0.063645 | Accuracy: 98.05% | Batch time: 0.0214s\n",
            "Step 7830 | Loss: 0.090345 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0018s\n",
            "Step 7840 | Loss: 0.013450 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0029s, O: 0.0007s\n",
            "🔄 Topology update at step 7840 took 0.0001s\n",
            "Batch  340/3750 (  9.1%) | Loss: 0.063232 | Accuracy: 98.09% | Batch time: 0.0232s\n",
            "Step 7850 | Loss: 0.085515 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0027s, O: 0.0006s\n",
            "Step 7860 | Loss: 0.098098 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0031s, O: 0.0019s\n",
            "🔄 Topology update at step 7860 took 0.0000s\n",
            "Batch  360/3750 (  9.6%) | Loss: 0.062260 | Accuracy: 98.13% | Batch time: 0.0192s\n",
            "Step 7870 | Loss: 0.041596 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0032s, O: 0.0007s\n",
            "Step 7880 | Loss: 0.069410 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 7880 took 0.0001s\n",
            "Batch  380/3750 ( 10.1%) | Loss: 0.061864 | Accuracy: 98.15% | Batch time: 0.0220s\n",
            "Step 7890 | Loss: 0.046333 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 7900 | Loss: 0.044796 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 7900 took 0.0000s\n",
            "🧹 Memory cleanup at step 7900 took 0.1386s\n",
            "Batch  400/3750 ( 10.7%) | Loss: 0.061957 | Accuracy: 98.13% | Batch time: 0.0210s\n",
            "Step 7910 | Loss: 0.052385 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Step 7920 | Loss: 0.063549 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0042s, O: 0.0009s\n",
            "🔄 Topology update at step 7920 took 0.0000s\n",
            "Batch  420/3750 ( 11.2%) | Loss: 0.063275 | Accuracy: 98.10% | Batch time: 0.0283s\n",
            "Step 7930 | Loss: 0.005632 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0035s, O: 0.0007s\n",
            "Step 7940 | Loss: 0.032211 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0027s, O: 0.0013s\n",
            "🔄 Topology update at step 7940 took 0.0000s\n",
            "Batch  440/3750 ( 11.7%) | Loss: 0.063537 | Accuracy: 98.06% | Batch time: 0.0197s\n",
            "Step 7950 | Loss: 0.063574 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0038s, O: 0.0006s\n",
            "Step 7960 | Loss: 0.010176 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0045s, O: 0.0004s\n",
            "🔄 Topology update at step 7960 took 0.0000s\n",
            "Batch  460/3750 ( 12.3%) | Loss: 0.065657 | Accuracy: 98.01% | Batch time: 0.0190s\n",
            "Step 7970 | Loss: 0.014568 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 7980 | Loss: 0.226287 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0021s, O: 0.0006s\n",
            "🔄 Topology update at step 7980 took 0.0000s\n",
            "Batch  480/3750 ( 12.8%) | Loss: 0.065892 | Accuracy: 98.04% | Batch time: 0.0232s\n",
            "Step 7990 | Loss: 0.018004 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 8000 | Loss: 0.031720 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0061s, O: 0.0007s\n",
            "🔄 Topology update at step 8000 took 0.0001s\n",
            "🧹 Memory cleanup at step 8000 took 0.1355s\n",
            "Batch  500/3750 ( 13.3%) | Loss: 0.065766 | Accuracy: 98.00% | Batch time: 0.0210s\n",
            "Step 8010 | Loss: 0.257784 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "Step 8020 | Loss: 0.007477 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 8020 took 0.0000s\n",
            "Batch  520/3750 ( 13.9%) | Loss: 0.066501 | Accuracy: 98.00% | Batch time: 0.0220s\n",
            "Step 8030 | Loss: 0.005819 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0024s, O: 0.0007s\n",
            "Step 8040 | Loss: 0.000633 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 8040 took 0.0000s\n",
            "Batch  540/3750 ( 14.4%) | Loss: 0.066809 | Accuracy: 97.97% | Batch time: 0.0204s\n",
            "Step 8050 | Loss: 0.010014 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0023s, O: 0.0012s\n",
            "Step 8060 | Loss: 0.016227 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 8060 took 0.0001s\n",
            "Batch  560/3750 ( 14.9%) | Loss: 0.066400 | Accuracy: 97.98% | Batch time: 0.0207s\n",
            "Step 8070 | Loss: 0.051777 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0024s, O: 0.0006s\n",
            "Step 8080 | Loss: 0.007693 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 8080 took 0.0000s\n",
            "Batch  580/3750 ( 15.5%) | Loss: 0.066570 | Accuracy: 97.99% | Batch time: 0.0211s\n",
            "Step 8090 | Loss: 0.112401 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Step 8100 | Loss: 0.028400 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0028s, O: 0.0010s\n",
            "🔄 Topology update at step 8100 took 0.0000s\n",
            "🧹 Memory cleanup at step 8100 took 0.1319s\n",
            "Batch  600/3750 ( 16.0%) | Loss: 0.066982 | Accuracy: 97.97% | Batch time: 0.0236s\n",
            "Step 8110 | Loss: 0.117407 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0029s, O: 0.0006s\n",
            "Step 8120 | Loss: 0.010266 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 8120 took 0.0000s\n",
            "Batch  620/3750 ( 16.5%) | Loss: 0.067231 | Accuracy: 97.97% | Batch time: 0.0217s\n",
            "Step 8130 | Loss: 0.059302 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0014s\n",
            "Step 8140 | Loss: 0.011372 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0013s\n",
            "🔄 Topology update at step 8140 took 0.0000s\n",
            "Batch  640/3750 ( 17.1%) | Loss: 0.068238 | Accuracy: 97.97% | Batch time: 0.0197s\n",
            "Step 8150 | Loss: 0.003020 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 8160 | Loss: 0.351321 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0037s, O: 0.0008s\n",
            "🔄 Topology update at step 8160 took 0.0000s\n",
            "Batch  660/3750 ( 17.6%) | Loss: 0.069485 | Accuracy: 97.95% | Batch time: 0.0231s\n",
            "Step 8170 | Loss: 0.001827 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0011s\n",
            "Step 8180 | Loss: 0.057484 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0041s, O: 0.0014s\n",
            "🔄 Topology update at step 8180 took 0.0001s\n",
            "Batch  680/3750 ( 18.1%) | Loss: 0.069175 | Accuracy: 97.94% | Batch time: 0.0187s\n",
            "Step 8190 | Loss: 0.159505 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0028s, O: 0.0007s\n",
            "Step 8200 | Loss: 0.018474 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0041s, O: 0.0007s\n",
            "🔄 Topology update at step 8200 took 0.0000s\n",
            "🧹 Memory cleanup at step 8200 took 0.1297s\n",
            "Batch  700/3750 ( 18.7%) | Loss: 0.068363 | Accuracy: 97.98% | Batch time: 0.0206s\n",
            "Step 8210 | Loss: 0.034434 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "Step 8220 | Loss: 0.002684 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 8220 took 0.0000s\n",
            "Batch  720/3750 ( 19.2%) | Loss: 0.068400 | Accuracy: 97.97% | Batch time: 0.0206s\n",
            "Step 8230 | Loss: 0.065313 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0059s, O: 0.0006s\n",
            "Step 8240 | Loss: 0.105992 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 8240 took 0.0001s\n",
            "Batch  740/3750 ( 19.7%) | Loss: 0.067594 | Accuracy: 98.00% | Batch time: 0.0216s\n",
            "Step 8250 | Loss: 0.032196 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0033s, O: 0.0007s\n",
            "Step 8260 | Loss: 0.032922 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 8260 took 0.0000s\n",
            "Batch  760/3750 ( 20.3%) | Loss: 0.066826 | Accuracy: 98.03% | Batch time: 0.0191s\n",
            "Step 8270 | Loss: 0.028416 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 8280 | Loss: 0.012795 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0035s, O: 0.0012s\n",
            "🔄 Topology update at step 8280 took 0.0000s\n",
            "Batch  780/3750 ( 20.8%) | Loss: 0.067345 | Accuracy: 98.03% | Batch time: 0.0260s\n",
            "Step 8290 | Loss: 0.142863 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0009s\n",
            "Step 8300 | Loss: 0.171446 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0008s\n",
            "🔄 Topology update at step 8300 took 0.0000s\n",
            "🧹 Memory cleanup at step 8300 took 0.1301s\n",
            "Batch  800/3750 ( 21.3%) | Loss: 0.066839 | Accuracy: 98.03% | Batch time: 0.0253s\n",
            "Step 8310 | Loss: 0.019667 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0034s, O: 0.0007s\n",
            "Step 8320 | Loss: 0.095439 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0016s, O: 0.0006s\n",
            "🔄 Topology update at step 8320 took 0.0000s\n",
            "Batch  820/3750 ( 21.9%) | Loss: 0.066412 | Accuracy: 98.04% | Batch time: 0.0259s\n",
            "Step 8330 | Loss: 0.009903 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0093s, O: 0.0005s\n",
            "Step 8340 | Loss: 0.129401 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0066s, O: 0.0005s\n",
            "🔄 Topology update at step 8340 took 0.0000s\n",
            "Batch  840/3750 ( 22.4%) | Loss: 0.066735 | Accuracy: 98.02% | Batch time: 0.0181s\n",
            "Step 8350 | Loss: 0.281951 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0017s, O: 0.0005s\n",
            "Step 8360 | Loss: 0.019930 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0016s, O: 0.0005s\n",
            "🔄 Topology update at step 8360 took 0.0001s\n",
            "Batch  860/3750 ( 22.9%) | Loss: 0.067928 | Accuracy: 98.00% | Batch time: 0.0176s\n",
            "Step 8370 | Loss: 0.018205 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0017s, O: 0.0005s\n",
            "Step 8380 | Loss: 0.019220 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0016s, O: 0.0005s\n",
            "🔄 Topology update at step 8380 took 0.0000s\n",
            "Batch  880/3750 ( 23.5%) | Loss: 0.067729 | Accuracy: 98.03% | Batch time: 0.0189s\n",
            "Step 8390 | Loss: 0.098680 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0016s, O: 0.0005s\n",
            "Step 8400 | Loss: 0.024151 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0016s, O: 0.0005s\n",
            "🔄 Topology update at step 8400 took 0.0000s\n",
            "🧹 Memory cleanup at step 8400 took 0.1807s\n",
            "Batch  900/3750 ( 24.0%) | Loss: 0.067343 | Accuracy: 98.04% | Batch time: 0.0247s\n",
            "Step 8410 | Loss: 0.144051 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0040s, O: 0.0006s\n",
            "Step 8420 | Loss: 0.010849 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0020s, O: 0.0006s\n",
            "🔄 Topology update at step 8420 took 0.0000s\n",
            "Batch  920/3750 ( 24.5%) | Loss: 0.067066 | Accuracy: 98.03% | Batch time: 0.0200s\n",
            "Step 8430 | Loss: 0.125624 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0016s, O: 0.0005s\n",
            "Step 8440 | Loss: 0.065210 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 8440 took 0.0000s\n",
            "Batch  940/3750 ( 25.1%) | Loss: 0.066652 | Accuracy: 98.03% | Batch time: 0.0270s\n",
            "Step 8450 | Loss: 0.100595 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0032s, O: 0.0006s\n",
            "Step 8460 | Loss: 0.021371 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0024s, O: 0.0009s\n",
            "🔄 Topology update at step 8460 took 0.0001s\n",
            "Batch  960/3750 ( 25.6%) | Loss: 0.066736 | Accuracy: 98.04% | Batch time: 0.0306s\n",
            "Step 8470 | Loss: 0.091231 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0036s, O: 0.0016s\n",
            "Step 8480 | Loss: 0.004647 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0016s, O: 0.0005s\n",
            "🔄 Topology update at step 8480 took 0.0000s\n",
            "Batch  980/3750 ( 26.1%) | Loss: 0.066743 | Accuracy: 98.03% | Batch time: 0.0185s\n",
            "Step 8490 | Loss: 0.344892 | GPU: 24.4MB / 98.0MB | F: 0.0045s, B: 0.0036s, O: 0.0021s\n",
            "Step 8500 | Loss: 0.046404 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 8500 took 0.0000s\n",
            "🧹 Memory cleanup at step 8500 took 0.1382s\n",
            "Batch 1000/3750 ( 26.7%) | Loss: 0.066539 | Accuracy: 98.03% | Batch time: 0.0211s\n",
            "Step 8510 | Loss: 0.027891 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0026s, O: 0.0012s\n",
            "Step 8520 | Loss: 0.328209 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 8520 took 0.0000s\n",
            "Batch 1020/3750 ( 27.2%) | Loss: 0.067536 | Accuracy: 98.02% | Batch time: 0.0225s\n",
            "Step 8530 | Loss: 0.003578 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Step 8540 | Loss: 0.071274 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0020s, O: 0.0006s\n",
            "🔄 Topology update at step 8540 took 0.0000s\n",
            "Batch 1040/3750 ( 27.7%) | Loss: 0.067032 | Accuracy: 98.04% | Batch time: 0.0205s\n",
            "Step 8550 | Loss: 0.012027 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 8560 | Loss: 0.026649 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 8560 took 0.0000s\n",
            "Batch 1060/3750 ( 28.3%) | Loss: 0.067477 | Accuracy: 98.02% | Batch time: 0.0193s\n",
            "Step 8570 | Loss: 0.106193 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step 8580 | Loss: 0.001166 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 8580 took 0.0001s\n",
            "Batch 1080/3750 ( 28.8%) | Loss: 0.067804 | Accuracy: 98.01% | Batch time: 0.0223s\n",
            "Step 8590 | Loss: 0.014159 | GPU: 24.4MB / 98.0MB | F: 0.0047s, B: 0.0028s, O: 0.0025s\n",
            "Step 8600 | Loss: 0.003088 | GPU: 24.4MB / 98.0MB | F: 0.0021s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 8600 took 0.0001s\n",
            "🧹 Memory cleanup at step 8600 took 0.1396s\n",
            "Batch 1100/3750 ( 29.3%) | Loss: 0.067559 | Accuracy: 98.01% | Batch time: 0.0231s\n",
            "Step 8610 | Loss: 0.086397 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0026s, O: 0.0007s\n",
            "Step 8620 | Loss: 0.028237 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 8620 took 0.0001s\n",
            "Batch 1120/3750 ( 29.9%) | Loss: 0.068018 | Accuracy: 97.99% | Batch time: 0.0260s\n",
            "Step 8630 | Loss: 0.143640 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0030s, O: 0.0012s\n",
            "Step 8640 | Loss: 0.007800 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0151s, O: 0.0007s\n",
            "🔄 Topology update at step 8640 took 0.0000s\n",
            "Batch 1140/3750 ( 30.4%) | Loss: 0.067962 | Accuracy: 98.00% | Batch time: 0.0277s\n",
            "Step 8650 | Loss: 0.001998 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0024s, O: 0.0006s\n",
            "Step 8660 | Loss: 0.054506 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0012s\n",
            "🔄 Topology update at step 8660 took 0.0001s\n",
            "Batch 1160/3750 ( 30.9%) | Loss: 0.067319 | Accuracy: 98.02% | Batch time: 0.0203s\n",
            "Step 8670 | Loss: 0.306476 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0114s, O: 0.0006s\n",
            "Step 8680 | Loss: 0.021557 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 8680 took 0.0000s\n",
            "Batch 1180/3750 ( 31.5%) | Loss: 0.067566 | Accuracy: 98.00% | Batch time: 0.0210s\n",
            "Step 8690 | Loss: 0.014344 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0008s\n",
            "Step 8700 | Loss: 0.106586 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0008s\n",
            "🔄 Topology update at step 8700 took 0.0000s\n",
            "🧹 Memory cleanup at step 8700 took 0.1355s\n",
            "Batch 1200/3750 ( 32.0%) | Loss: 0.067382 | Accuracy: 98.00% | Batch time: 0.0259s\n",
            "Step 8710 | Loss: 0.059855 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0007s\n",
            "Step 8720 | Loss: 0.229175 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0045s, O: 0.0017s\n",
            "🔄 Topology update at step 8720 took 0.0001s\n",
            "Batch 1220/3750 ( 32.5%) | Loss: 0.067909 | Accuracy: 97.97% | Batch time: 0.0216s\n",
            "Step 8730 | Loss: 0.023797 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0037s, O: 0.0010s\n",
            "Step 8740 | Loss: 0.012324 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0029s, O: 0.0010s\n",
            "🔄 Topology update at step 8740 took 0.0000s\n",
            "Batch 1240/3750 ( 33.1%) | Loss: 0.067360 | Accuracy: 97.99% | Batch time: 0.0202s\n",
            "Step 8750 | Loss: 0.211578 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 8760 | Loss: 0.004968 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0024s, O: 0.0008s\n",
            "🔄 Topology update at step 8760 took 0.0000s\n",
            "Batch 1260/3750 ( 33.6%) | Loss: 0.067478 | Accuracy: 97.98% | Batch time: 0.0217s\n",
            "Step 8770 | Loss: 0.010570 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0026s, O: 0.0007s\n",
            "Step 8780 | Loss: 0.033763 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0016s, O: 0.0007s\n",
            "🔄 Topology update at step 8780 took 0.0000s\n",
            "Batch 1280/3750 ( 34.1%) | Loss: 0.067313 | Accuracy: 98.00% | Batch time: 0.0219s\n",
            "Step 8790 | Loss: 0.083927 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 8800 | Loss: 0.008203 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 8800 took 0.0001s\n",
            "🧹 Memory cleanup at step 8800 took 0.1459s\n",
            "Batch 1300/3750 ( 34.7%) | Loss: 0.067205 | Accuracy: 98.01% | Batch time: 0.0241s\n",
            "Step 8810 | Loss: 0.060223 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0026s, O: 0.0007s\n",
            "Step 8820 | Loss: 0.003136 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 8820 took 0.0001s\n",
            "Batch 1320/3750 ( 35.2%) | Loss: 0.067082 | Accuracy: 98.01% | Batch time: 0.0226s\n",
            "Step 8830 | Loss: 0.128397 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "Step 8840 | Loss: 0.003015 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 8840 took 0.0000s\n",
            "Batch 1340/3750 ( 35.7%) | Loss: 0.066763 | Accuracy: 98.02% | Batch time: 0.0561s\n",
            "Step 8850 | Loss: 0.080749 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0014s\n",
            "Step 8860 | Loss: 0.190271 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0048s, O: 0.0015s\n",
            "🔄 Topology update at step 8860 took 0.0000s\n",
            "Batch 1360/3750 ( 36.3%) | Loss: 0.066866 | Accuracy: 98.00% | Batch time: 0.0294s\n",
            "Step 8870 | Loss: 0.175641 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 8880 | Loss: 0.074372 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0022s, O: 0.0005s\n",
            "🔄 Topology update at step 8880 took 0.0000s\n",
            "Batch 1380/3750 ( 36.8%) | Loss: 0.067046 | Accuracy: 97.99% | Batch time: 0.0228s\n",
            "Step 8890 | Loss: 0.079621 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0024s, O: 0.0007s\n",
            "Step 8900 | Loss: 0.028101 | GPU: 24.4MB / 98.0MB | F: 0.0056s, B: 0.0032s, O: 0.0013s\n",
            "🔄 Topology update at step 8900 took 0.0000s\n",
            "🧹 Memory cleanup at step 8900 took 0.1363s\n",
            "Batch 1400/3750 ( 37.3%) | Loss: 0.066701 | Accuracy: 98.00% | Batch time: 0.0208s\n",
            "Step 8910 | Loss: 0.008073 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0030s, O: 0.0011s\n",
            "Step 8920 | Loss: 0.017917 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0035s, O: 0.0007s\n",
            "🔄 Topology update at step 8920 took 0.0000s\n",
            "Batch 1420/3750 ( 37.9%) | Loss: 0.066422 | Accuracy: 98.00% | Batch time: 0.0225s\n",
            "Step 8930 | Loss: 0.200646 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0025s, O: 0.0007s\n",
            "Step 8940 | Loss: 0.047358 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 8940 took 0.0000s\n",
            "Batch 1440/3750 ( 38.4%) | Loss: 0.066835 | Accuracy: 97.99% | Batch time: 0.0197s\n",
            "Step 8950 | Loss: 0.028871 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0047s, O: 0.0012s\n",
            "Step 8960 | Loss: 0.005664 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0036s, O: 0.0007s\n",
            "🔄 Topology update at step 8960 took 0.0001s\n",
            "Batch 1460/3750 ( 38.9%) | Loss: 0.066504 | Accuracy: 97.99% | Batch time: 0.0195s\n",
            "Step 8970 | Loss: 0.380658 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0025s, O: 0.0007s\n",
            "Step 8980 | Loss: 0.007084 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0008s\n",
            "🔄 Topology update at step 8980 took 0.0000s\n",
            "Batch 1480/3750 ( 39.5%) | Loss: 0.066463 | Accuracy: 97.98% | Batch time: 0.0185s\n",
            "Step 8990 | Loss: 0.000416 | GPU: 24.4MB / 98.0MB | F: 0.0035s, B: 0.0024s, O: 0.0007s\n",
            "Step 9000 | Loss: 0.266472 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0052s, O: 0.0004s\n",
            "🔄 Topology update at step 9000 took 0.0000s\n",
            "🧹 Memory cleanup at step 9000 took 0.1321s\n",
            "Batch 1500/3750 ( 40.0%) | Loss: 0.066936 | Accuracy: 97.96% | Batch time: 0.0214s\n",
            "Step 9010 | Loss: 0.031074 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 9020 | Loss: 0.008508 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0062s, O: 0.0006s\n",
            "🔄 Topology update at step 9020 took 0.0000s\n",
            "Batch 1520/3750 ( 40.5%) | Loss: 0.066789 | Accuracy: 97.96% | Batch time: 0.0213s\n",
            "Step 9030 | Loss: 0.352219 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 9040 | Loss: 0.002316 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0011s\n",
            "🔄 Topology update at step 9040 took 0.0000s\n",
            "Batch 1540/3750 ( 41.1%) | Loss: 0.066935 | Accuracy: 97.95% | Batch time: 0.0245s\n",
            "Step 9050 | Loss: 0.010163 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0029s, O: 0.0010s\n",
            "Step 9060 | Loss: 0.078312 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 9060 took 0.0000s\n",
            "Batch 1560/3750 ( 41.6%) | Loss: 0.066587 | Accuracy: 97.97% | Batch time: 0.0232s\n",
            "Step 9070 | Loss: 0.150836 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 9080 | Loss: 0.005810 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0011s\n",
            "🔄 Topology update at step 9080 took 0.0000s\n",
            "Batch 1580/3750 ( 42.1%) | Loss: 0.066621 | Accuracy: 97.98% | Batch time: 0.0187s\n",
            "Step 9090 | Loss: 0.033471 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "Step 9100 | Loss: 0.110918 | GPU: 24.4MB / 98.0MB | F: 0.0036s, B: 0.0027s, O: 0.0010s\n",
            "🔄 Topology update at step 9100 took 0.0000s\n",
            "🧹 Memory cleanup at step 9100 took 0.1315s\n",
            "Batch 1600/3750 ( 42.7%) | Loss: 0.066340 | Accuracy: 97.99% | Batch time: 0.0231s\n",
            "Step 9110 | Loss: 0.038509 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 9120 | Loss: 0.027569 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0037s, O: 0.0019s\n",
            "🔄 Topology update at step 9120 took 0.0000s\n",
            "Batch 1620/3750 ( 43.2%) | Loss: 0.066336 | Accuracy: 97.98% | Batch time: 0.0241s\n",
            "Step 9130 | Loss: 0.050232 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "Step 9140 | Loss: 0.002306 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0025s, O: 0.0015s\n",
            "🔄 Topology update at step 9140 took 0.0000s\n",
            "Batch 1640/3750 ( 43.7%) | Loss: 0.066377 | Accuracy: 97.99% | Batch time: 0.0190s\n",
            "Step 9150 | Loss: 0.002701 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0042s, O: 0.0007s\n",
            "Step 9160 | Loss: 0.012468 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 9160 took 0.0000s\n",
            "Batch 1660/3750 ( 44.3%) | Loss: 0.065909 | Accuracy: 98.01% | Batch time: 0.0211s\n",
            "Step 9170 | Loss: 0.035734 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 9180 | Loss: 0.030476 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 9180 took 0.0000s\n",
            "Batch 1680/3750 ( 44.8%) | Loss: 0.065488 | Accuracy: 98.03% | Batch time: 0.0195s\n",
            "Step 9190 | Loss: 0.005286 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0035s, O: 0.0008s\n",
            "Step 9200 | Loss: 0.008835 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0050s, O: 0.0011s\n",
            "🔄 Topology update at step 9200 took 0.0000s\n",
            "🧹 Memory cleanup at step 9200 took 0.1335s\n",
            "Batch 1700/3750 ( 45.3%) | Loss: 0.065383 | Accuracy: 98.03% | Batch time: 0.0241s\n",
            "Step 9210 | Loss: 0.010827 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "Step 9220 | Loss: 0.145151 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0029s, O: 0.0010s\n",
            "🔄 Topology update at step 9220 took 0.0000s\n",
            "Batch 1720/3750 ( 45.9%) | Loss: 0.065211 | Accuracy: 98.03% | Batch time: 0.0235s\n",
            "Step 9230 | Loss: 0.573076 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 9240 | Loss: 0.079059 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 9240 took 0.0000s\n",
            "Batch 1740/3750 ( 46.4%) | Loss: 0.065430 | Accuracy: 98.03% | Batch time: 0.0209s\n",
            "Step 9250 | Loss: 0.031370 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 9260 | Loss: 0.006124 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 9260 took 0.0000s\n",
            "Batch 1760/3750 ( 46.9%) | Loss: 0.065349 | Accuracy: 98.02% | Batch time: 0.0193s\n",
            "Step 9270 | Loss: 0.260737 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0029s, O: 0.0017s\n",
            "Step 9280 | Loss: 0.082773 | GPU: 24.4MB / 98.0MB | F: 0.0039s, B: 0.0027s, O: 0.0013s\n",
            "🔄 Topology update at step 9280 took 0.0001s\n",
            "Batch 1780/3750 ( 47.5%) | Loss: 0.065868 | Accuracy: 98.01% | Batch time: 0.0188s\n",
            "Step 9290 | Loss: 0.055217 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "Step 9300 | Loss: 0.005681 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 9300 took 0.0000s\n",
            "🧹 Memory cleanup at step 9300 took 0.1358s\n",
            "Batch 1800/3750 ( 48.0%) | Loss: 0.065599 | Accuracy: 98.02% | Batch time: 0.0233s\n",
            "Step 9310 | Loss: 0.005421 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0045s, O: 0.0038s\n",
            "Step 9320 | Loss: 0.011742 | GPU: 24.4MB / 98.0MB | F: 0.0023s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 9320 took 0.0001s\n",
            "Batch 1820/3750 ( 48.5%) | Loss: 0.065367 | Accuracy: 98.03% | Batch time: 0.0289s\n",
            "Step 9330 | Loss: 0.003277 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0030s, O: 0.0006s\n",
            "Step 9340 | Loss: 0.066156 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0018s, O: 0.0006s\n",
            "🔄 Topology update at step 9340 took 0.0000s\n",
            "Batch 1840/3750 ( 49.1%) | Loss: 0.065639 | Accuracy: 98.02% | Batch time: 0.0244s\n",
            "Step 9350 | Loss: 0.022552 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0023s, O: 0.0011s\n",
            "Step 9360 | Loss: 0.088524 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0017s, O: 0.0005s\n",
            "🔄 Topology update at step 9360 took 0.0000s\n",
            "Batch 1860/3750 ( 49.6%) | Loss: 0.065797 | Accuracy: 98.01% | Batch time: 0.0174s\n",
            "Step 9370 | Loss: 0.016076 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0016s, O: 0.0005s\n",
            "Step 9380 | Loss: 0.030764 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0023s, O: 0.0005s\n",
            "🔄 Topology update at step 9380 took 0.0000s\n",
            "Batch 1880/3750 ( 50.1%) | Loss: 0.066041 | Accuracy: 98.01% | Batch time: 0.0219s\n",
            "Step 9390 | Loss: 0.008737 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0062s, O: 0.0006s\n",
            "Step 9400 | Loss: 0.037714 | GPU: 24.4MB / 98.0MB | F: 0.0011s, B: 0.0016s, O: 0.0005s\n",
            "🔄 Topology update at step 9400 took 0.0000s\n",
            "🧹 Memory cleanup at step 9400 took 0.1804s\n",
            "Batch 1900/3750 ( 50.7%) | Loss: 0.065806 | Accuracy: 98.02% | Batch time: 0.0218s\n",
            "Step 9410 | Loss: 0.171843 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0025s, O: 0.0006s\n",
            "Step 9420 | Loss: 0.032948 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0021s, O: 0.0006s\n",
            "🔄 Topology update at step 9420 took 0.0001s\n",
            "Batch 1920/3750 ( 51.2%) | Loss: 0.065745 | Accuracy: 98.02% | Batch time: 0.0247s\n",
            "Step 9430 | Loss: 0.027249 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0006s\n",
            "Step 9440 | Loss: 0.006937 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0031s, O: 0.0038s\n",
            "🔄 Topology update at step 9440 took 0.0000s\n",
            "Batch 1940/3750 ( 51.7%) | Loss: 0.065640 | Accuracy: 98.02% | Batch time: 0.0260s\n",
            "Step 9450 | Loss: 0.019826 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0062s, O: 0.0006s\n",
            "Step 9460 | Loss: 0.103707 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 9460 took 0.0000s\n",
            "Batch 1960/3750 ( 52.3%) | Loss: 0.065566 | Accuracy: 98.02% | Batch time: 0.0258s\n",
            "Step 9470 | Loss: 0.034087 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0047s, O: 0.0012s\n",
            "Step 9480 | Loss: 0.002318 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0020s, O: 0.0006s\n",
            "🔄 Topology update at step 9480 took 0.0000s\n",
            "Batch 1980/3750 ( 52.8%) | Loss: 0.065894 | Accuracy: 98.02% | Batch time: 0.0222s\n",
            "Step 9490 | Loss: 0.003684 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0036s, O: 0.0006s\n",
            "Step 9500 | Loss: 0.023892 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 9500 took 0.0001s\n",
            "🧹 Memory cleanup at step 9500 took 0.1381s\n",
            "Batch 2000/3750 ( 53.3%) | Loss: 0.065965 | Accuracy: 98.01% | Batch time: 0.0218s\n",
            "Step 9510 | Loss: 0.050060 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "Step 9520 | Loss: 0.020431 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 9520 took 0.0001s\n",
            "Batch 2020/3750 ( 53.9%) | Loss: 0.066656 | Accuracy: 97.99% | Batch time: 0.0209s\n",
            "Step 9530 | Loss: 0.023548 | GPU: 24.4MB / 98.0MB | F: 0.0056s, B: 0.0118s, O: 0.0007s\n",
            "Step 9540 | Loss: 0.027344 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0038s, O: 0.0007s\n",
            "🔄 Topology update at step 9540 took 0.0000s\n",
            "Batch 2040/3750 ( 54.4%) | Loss: 0.066656 | Accuracy: 97.99% | Batch time: 0.0191s\n",
            "Step 9550 | Loss: 0.230695 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 9560 | Loss: 0.090707 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 9560 took 0.0004s\n",
            "Batch 2060/3750 ( 54.9%) | Loss: 0.066584 | Accuracy: 98.00% | Batch time: 0.0236s\n",
            "Step 9570 | Loss: 0.007505 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0028s, O: 0.0008s\n",
            "Step 9580 | Loss: 0.044783 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 9580 took 0.0000s\n",
            "Batch 2080/3750 ( 55.5%) | Loss: 0.066313 | Accuracy: 98.01% | Batch time: 0.0196s\n",
            "Step 9590 | Loss: 0.001546 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0024s, O: 0.0007s\n",
            "Step 9600 | Loss: 0.015786 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0025s, O: 0.0014s\n",
            "🔄 Topology update at step 9600 took 0.0000s\n",
            "🧹 Memory cleanup at step 9600 took 0.1335s\n",
            "Batch 2100/3750 ( 56.0%) | Loss: 0.066019 | Accuracy: 98.02% | Batch time: 0.0202s\n",
            "Step 9610 | Loss: 0.031969 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 9620 | Loss: 0.015108 | GPU: 24.4MB / 98.0MB | F: 0.0052s, B: 0.0016s, O: 0.0004s\n",
            "🔄 Topology update at step 9620 took 0.0000s\n",
            "Batch 2120/3750 ( 56.5%) | Loss: 0.066184 | Accuracy: 98.01% | Batch time: 0.0185s\n",
            "Step 9630 | Loss: 0.126320 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 9640 | Loss: 0.060255 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 9640 took 0.0001s\n",
            "Batch 2140/3750 ( 57.1%) | Loss: 0.066226 | Accuracy: 98.01% | Batch time: 0.0228s\n",
            "Step 9650 | Loss: 0.005298 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0024s, O: 0.0006s\n",
            "Step 9660 | Loss: 0.167230 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 9660 took 0.0000s\n",
            "Batch 2160/3750 ( 57.6%) | Loss: 0.066457 | Accuracy: 98.00% | Batch time: 0.0198s\n",
            "Step 9670 | Loss: 0.011769 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Step 9680 | Loss: 0.017857 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 9680 took 0.0000s\n",
            "Batch 2180/3750 ( 58.1%) | Loss: 0.066130 | Accuracy: 98.01% | Batch time: 0.0187s\n",
            "Step 9690 | Loss: 0.049476 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0027s, O: 0.0009s\n",
            "Step 9700 | Loss: 0.063606 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 9700 took 0.0000s\n",
            "🧹 Memory cleanup at step 9700 took 0.1389s\n",
            "Batch 2200/3750 ( 58.7%) | Loss: 0.066177 | Accuracy: 98.01% | Batch time: 0.0220s\n",
            "Step 9710 | Loss: 0.139955 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0027s, O: 0.0006s\n",
            "Step 9720 | Loss: 0.046596 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 9720 took 0.0000s\n",
            "Batch 2220/3750 ( 59.2%) | Loss: 0.066177 | Accuracy: 98.00% | Batch time: 0.0201s\n",
            "Step 9730 | Loss: 0.002327 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0030s, O: 0.0019s\n",
            "Step 9740 | Loss: 0.036792 | GPU: 24.4MB / 98.0MB | F: 0.0077s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 9740 took 0.0000s\n",
            "Batch 2240/3750 ( 59.7%) | Loss: 0.066129 | Accuracy: 98.00% | Batch time: 0.0185s\n",
            "Step 9750 | Loss: 0.006182 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0009s\n",
            "Step 9760 | Loss: 0.360431 | GPU: 24.4MB / 98.0MB | F: 0.0013s, B: 0.0018s, O: 0.0009s\n",
            "🔄 Topology update at step 9760 took 0.0000s\n",
            "Batch 2260/3750 ( 60.3%) | Loss: 0.065994 | Accuracy: 98.01% | Batch time: 0.0184s\n",
            "Step 9770 | Loss: 0.007059 | GPU: 24.4MB / 98.0MB | F: 0.0038s, B: 0.0026s, O: 0.0007s\n",
            "Step 9780 | Loss: 0.017015 | GPU: 24.4MB / 98.0MB | F: 0.0044s, B: 0.0017s, O: 0.0008s\n",
            "🔄 Topology update at step 9780 took 0.0000s\n",
            "Batch 2280/3750 ( 60.8%) | Loss: 0.065752 | Accuracy: 98.02% | Batch time: 0.0227s\n",
            "Step 9790 | Loss: 0.050994 | GPU: 24.4MB / 98.0MB | F: 0.0031s, B: 0.0022s, O: 0.0006s\n",
            "Step 9800 | Loss: 0.014109 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0042s, O: 0.0014s\n",
            "🔄 Topology update at step 9800 took 0.0000s\n",
            "🧹 Memory cleanup at step 9800 took 0.1472s\n",
            "Batch 2300/3750 ( 61.3%) | Loss: 0.065791 | Accuracy: 98.01% | Batch time: 0.0222s\n",
            "Step 9810 | Loss: 0.023684 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 9820 | Loss: 0.006253 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0022s\n",
            "🔄 Topology update at step 9820 took 0.0000s\n",
            "Batch 2320/3750 ( 61.9%) | Loss: 0.065698 | Accuracy: 98.02% | Batch time: 0.0180s\n",
            "Step 9830 | Loss: 0.074123 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 9840 | Loss: 0.001586 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0046s, O: 0.0005s\n",
            "🔄 Topology update at step 9840 took 0.0000s\n",
            "Batch 2340/3750 ( 62.4%) | Loss: 0.065823 | Accuracy: 98.01% | Batch time: 0.0252s\n",
            "Step 9850 | Loss: 0.024839 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0037s, O: 0.0007s\n",
            "Step 9860 | Loss: 0.008116 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 9860 took 0.0000s\n",
            "Batch 2360/3750 ( 62.9%) | Loss: 0.066394 | Accuracy: 97.99% | Batch time: 0.0206s\n",
            "Step 9870 | Loss: 0.096165 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0011s\n",
            "Step 9880 | Loss: 0.143659 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 9880 took 0.0001s\n",
            "Batch 2380/3750 ( 63.5%) | Loss: 0.066419 | Accuracy: 97.99% | Batch time: 0.0191s\n",
            "Step 9890 | Loss: 0.004789 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0037s, O: 0.0006s\n",
            "Step 9900 | Loss: 0.365256 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0011s\n",
            "🔄 Topology update at step 9900 took 0.0000s\n",
            "🧹 Memory cleanup at step 9900 took 0.1320s\n",
            "Batch 2400/3750 ( 64.0%) | Loss: 0.066662 | Accuracy: 97.99% | Batch time: 0.0210s\n",
            "Step 9910 | Loss: 0.095697 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 9920 | Loss: 0.019983 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 9920 took 0.0001s\n",
            "Batch 2420/3750 ( 64.5%) | Loss: 0.066433 | Accuracy: 98.00% | Batch time: 0.0213s\n",
            "Step 9930 | Loss: 0.001943 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0022s, O: 0.0006s\n",
            "Step 9940 | Loss: 0.079426 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 9940 took 0.0000s\n",
            "Batch 2440/3750 ( 65.1%) | Loss: 0.066514 | Accuracy: 98.00% | Batch time: 0.0186s\n",
            "Step 9950 | Loss: 0.215222 | GPU: 24.4MB / 98.0MB | F: 0.0032s, B: 0.0023s, O: 0.0009s\n",
            "Step 9960 | Loss: 0.039071 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0022s, O: 0.0008s\n",
            "🔄 Topology update at step 9960 took 0.0001s\n",
            "Batch 2460/3750 ( 65.6%) | Loss: 0.066793 | Accuracy: 97.98% | Batch time: 0.0203s\n",
            "Step 9970 | Loss: 0.003740 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "Step 9980 | Loss: 0.002245 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 9980 took 0.0000s\n",
            "Batch 2480/3750 ( 66.1%) | Loss: 0.066632 | Accuracy: 97.99% | Batch time: 0.0213s\n",
            "Step 9990 | Loss: 0.007868 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0025s, O: 0.0006s\n",
            "Step 10000 | Loss: 0.067799 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0034s, O: 0.0008s\n",
            "🔄 Topology update at step 10000 took 0.0000s\n",
            "🧹 Memory cleanup at step 10000 took 0.1341s\n",
            "Batch 2500/3750 ( 66.7%) | Loss: 0.066823 | Accuracy: 98.00% | Batch time: 0.0189s\n",
            "Step 10010 | Loss: 0.002788 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0024s, O: 0.0006s\n",
            "Step 10020 | Loss: 0.021514 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0035s, O: 0.0007s\n",
            "🔄 Topology update at step 10020 took 0.0000s\n",
            "Batch 2520/3750 ( 67.2%) | Loss: 0.066552 | Accuracy: 98.00% | Batch time: 0.0212s\n",
            "Step 10030 | Loss: 0.054075 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0036s, O: 0.0006s\n",
            "Step 10040 | Loss: 0.084954 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 10040 took 0.0000s\n",
            "Batch 2540/3750 ( 67.7%) | Loss: 0.066464 | Accuracy: 98.01% | Batch time: 0.0196s\n",
            "Step 10050 | Loss: 0.091272 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0007s\n",
            "Step 10060 | Loss: 0.007808 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 10060 took 0.0000s\n",
            "Batch 2560/3750 ( 68.3%) | Loss: 0.066776 | Accuracy: 98.00% | Batch time: 0.0207s\n",
            "Step 10070 | Loss: 0.021861 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "Step 10080 | Loss: 0.000523 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0082s, O: 0.0006s\n",
            "🔄 Topology update at step 10080 took 0.0001s\n",
            "Batch 2580/3750 ( 68.8%) | Loss: 0.066748 | Accuracy: 97.99% | Batch time: 0.0213s\n",
            "Step 10090 | Loss: 0.038286 | GPU: 24.4MB / 98.0MB | F: 0.0061s, B: 0.0043s, O: 0.0008s\n",
            "Step 10100 | Loss: 0.002706 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0026s, O: 0.0011s\n",
            "🔄 Topology update at step 10100 took 0.0000s\n",
            "🧹 Memory cleanup at step 10100 took 0.1362s\n",
            "Batch 2600/3750 ( 69.3%) | Loss: 0.066477 | Accuracy: 98.00% | Batch time: 0.0208s\n",
            "Step 10110 | Loss: 0.123339 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0015s\n",
            "Step 10120 | Loss: 0.021434 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 10120 took 0.0000s\n",
            "Batch 2620/3750 ( 69.9%) | Loss: 0.066337 | Accuracy: 98.00% | Batch time: 0.0226s\n",
            "Step 10130 | Loss: 0.135049 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 10140 | Loss: 0.012266 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 10140 took 0.0000s\n",
            "Batch 2640/3750 ( 70.4%) | Loss: 0.066331 | Accuracy: 98.00% | Batch time: 0.0204s\n",
            "Step 10150 | Loss: 0.037340 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "Step 10160 | Loss: 0.001309 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0038s, O: 0.0015s\n",
            "🔄 Topology update at step 10160 took 0.0000s\n",
            "Batch 2660/3750 ( 70.9%) | Loss: 0.066222 | Accuracy: 98.00% | Batch time: 0.0187s\n",
            "Step 10170 | Loss: 0.017110 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0043s, O: 0.0004s\n",
            "Step 10180 | Loss: 0.013358 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0035s, O: 0.0007s\n",
            "🔄 Topology update at step 10180 took 0.0000s\n",
            "Batch 2680/3750 ( 71.5%) | Loss: 0.066142 | Accuracy: 98.01% | Batch time: 0.0181s\n",
            "Step 10190 | Loss: 0.023787 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "Step 10200 | Loss: 0.026175 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 10200 took 0.0001s\n",
            "🧹 Memory cleanup at step 10200 took 0.1363s\n",
            "Batch 2700/3750 ( 72.0%) | Loss: 0.066434 | Accuracy: 98.01% | Batch time: 0.0246s\n",
            "Step 10210 | Loss: 0.016870 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0023s, O: 0.0007s\n",
            "Step 10220 | Loss: 0.004242 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 10220 took 0.0000s\n",
            "Batch 2720/3750 ( 72.5%) | Loss: 0.066436 | Accuracy: 98.01% | Batch time: 0.0203s\n",
            "Step 10230 | Loss: 0.001608 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0006s\n",
            "Step 10240 | Loss: 0.240996 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 10240 took 0.0001s\n",
            "Batch 2740/3750 ( 73.1%) | Loss: 0.066565 | Accuracy: 98.01% | Batch time: 0.0200s\n",
            "Step 10250 | Loss: 0.046494 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Step 10260 | Loss: 0.028321 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 10260 took 0.0000s\n",
            "Batch 2760/3750 ( 73.6%) | Loss: 0.066476 | Accuracy: 98.01% | Batch time: 0.0208s\n",
            "Step 10270 | Loss: 0.070414 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0077s, O: 0.0007s\n",
            "Step 10280 | Loss: 0.128700 | GPU: 24.4MB / 98.0MB | F: 0.0035s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 10280 took 0.0001s\n",
            "Batch 2780/3750 ( 74.1%) | Loss: 0.066325 | Accuracy: 98.02% | Batch time: 0.0198s\n",
            "Step 10290 | Loss: 0.088911 | GPU: 24.4MB / 98.0MB | F: 0.0029s, B: 0.0025s, O: 0.0007s\n",
            "Step 10300 | Loss: 0.000556 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0031s, O: 0.0015s\n",
            "🔄 Topology update at step 10300 took 0.0000s\n",
            "🧹 Memory cleanup at step 10300 took 0.1368s\n",
            "Batch 2800/3750 ( 74.7%) | Loss: 0.066180 | Accuracy: 98.02% | Batch time: 0.0209s\n",
            "Step 10310 | Loss: 0.002614 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0038s, O: 0.0015s\n",
            "Step 10320 | Loss: 0.004453 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0048s, O: 0.0009s\n",
            "🔄 Topology update at step 10320 took 0.0000s\n",
            "Batch 2820/3750 ( 75.2%) | Loss: 0.066003 | Accuracy: 98.02% | Batch time: 0.0194s\n",
            "Step 10330 | Loss: 0.005505 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0007s\n",
            "Step 10340 | Loss: 0.053796 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 10340 took 0.0000s\n",
            "Batch 2840/3750 ( 75.7%) | Loss: 0.065885 | Accuracy: 98.02% | Batch time: 0.0222s\n",
            "Step 10350 | Loss: 0.002316 | GPU: 24.4MB / 98.0MB | F: 0.0015s, B: 0.0030s, O: 0.0013s\n",
            "Step 10360 | Loss: 0.152336 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0021s, O: 0.0006s\n",
            "🔄 Topology update at step 10360 took 0.0000s\n",
            "Batch 2860/3750 ( 76.3%) | Loss: 0.065692 | Accuracy: 98.03% | Batch time: 0.0223s\n",
            "Step 10370 | Loss: 0.001734 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0043s, O: 0.0005s\n",
            "Step 10380 | Loss: 0.011005 | GPU: 24.4MB / 98.0MB | F: 0.0038s, B: 0.0070s, O: 0.0006s\n",
            "🔄 Topology update at step 10380 took 0.0000s\n",
            "Batch 2880/3750 ( 76.8%) | Loss: 0.065903 | Accuracy: 98.02% | Batch time: 0.0249s\n",
            "Step 10390 | Loss: 0.014529 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0018s, O: 0.0074s\n",
            "Step 10400 | Loss: 0.003573 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0017s, O: 0.0005s\n",
            "🔄 Topology update at step 10400 took 0.0000s\n",
            "🧹 Memory cleanup at step 10400 took 0.1619s\n",
            "Batch 2900/3750 ( 77.3%) | Loss: 0.065706 | Accuracy: 98.02% | Batch time: 0.0199s\n",
            "Step 10410 | Loss: 0.007357 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0020s, O: 0.0005s\n",
            "Step 10420 | Loss: 0.384125 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0025s, O: 0.0005s\n",
            "🔄 Topology update at step 10420 took 0.0000s\n",
            "Batch 2920/3750 ( 77.9%) | Loss: 0.065916 | Accuracy: 98.02% | Batch time: 0.0414s\n",
            "Step 10430 | Loss: 0.043885 | GPU: 24.4MB / 98.0MB | F: 0.0011s, B: 0.0016s, O: 0.0005s\n",
            "Step 10440 | Loss: 0.000534 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0016s, O: 0.0006s\n",
            "🔄 Topology update at step 10440 took 0.0000s\n",
            "Batch 2940/3750 ( 78.4%) | Loss: 0.065972 | Accuracy: 98.02% | Batch time: 0.0229s\n",
            "Step 10450 | Loss: 0.063223 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0028s, O: 0.0020s\n",
            "Step 10460 | Loss: 0.003281 | GPU: 24.4MB / 98.0MB | F: 0.0052s, B: 0.0044s, O: 0.0017s\n",
            "🔄 Topology update at step 10460 took 0.0000s\n",
            "Batch 2960/3750 ( 78.9%) | Loss: 0.065893 | Accuracy: 98.03% | Batch time: 0.0255s\n",
            "Step 10470 | Loss: 0.005968 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0033s, O: 0.0005s\n",
            "Step 10480 | Loss: 0.094361 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0030s, O: 0.0043s\n",
            "🔄 Topology update at step 10480 took 0.0001s\n",
            "Batch 2980/3750 ( 79.5%) | Loss: 0.065847 | Accuracy: 98.02% | Batch time: 0.0268s\n",
            "Step 10490 | Loss: 0.017143 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0037s, O: 0.0007s\n",
            "Step 10500 | Loss: 0.015946 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0048s, O: 0.0007s\n",
            "🔄 Topology update at step 10500 took 0.0000s\n",
            "🧹 Memory cleanup at step 10500 took 0.1799s\n",
            "Batch 3000/3750 ( 80.0%) | Loss: 0.065773 | Accuracy: 98.03% | Batch time: 0.0227s\n",
            "Step 10510 | Loss: 0.093487 | GPU: 24.4MB / 98.0MB | F: 0.0012s, B: 0.0084s, O: 0.0005s\n",
            "Step 10520 | Loss: 0.058568 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 10520 took 0.0000s\n",
            "Batch 3020/3750 ( 80.5%) | Loss: 0.065721 | Accuracy: 98.03% | Batch time: 0.0186s\n",
            "Step 10530 | Loss: 0.022017 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0025s, O: 0.0006s\n",
            "Step 10540 | Loss: 0.085411 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0006s\n",
            "🔄 Topology update at step 10540 took 0.0000s\n",
            "Batch 3040/3750 ( 81.1%) | Loss: 0.065632 | Accuracy: 98.03% | Batch time: 0.0256s\n",
            "Step 10550 | Loss: 0.091616 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 10560 | Loss: 0.042443 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0026s, O: 0.0014s\n",
            "🔄 Topology update at step 10560 took 0.0000s\n",
            "Batch 3060/3750 ( 81.6%) | Loss: 0.065567 | Accuracy: 98.03% | Batch time: 0.0188s\n",
            "Step 10570 | Loss: 0.126052 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "Step 10580 | Loss: 0.000450 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0057s, O: 0.0007s\n",
            "🔄 Topology update at step 10580 took 0.0000s\n",
            "Batch 3080/3750 ( 82.1%) | Loss: 0.065654 | Accuracy: 98.03% | Batch time: 0.0272s\n",
            "Step 10590 | Loss: 0.026538 | GPU: 24.4MB / 98.0MB | F: 0.0085s, B: 0.0020s, O: 0.0014s\n",
            "Step 10600 | Loss: 0.013362 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 10600 took 0.0001s\n",
            "🧹 Memory cleanup at step 10600 took 0.1299s\n",
            "Batch 3100/3750 ( 82.7%) | Loss: 0.065555 | Accuracy: 98.03% | Batch time: 0.0250s\n",
            "Step 10610 | Loss: 0.101389 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0022s, O: 0.0006s\n",
            "Step 10620 | Loss: 0.026110 | GPU: 24.4MB / 98.0MB | F: 0.0030s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 10620 took 0.0000s\n",
            "Batch 3120/3750 ( 83.2%) | Loss: 0.065629 | Accuracy: 98.03% | Batch time: 0.0228s\n",
            "Step 10630 | Loss: 0.004572 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0023s, O: 0.0007s\n",
            "Step 10640 | Loss: 0.006657 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 10640 took 0.0000s\n",
            "Batch 3140/3750 ( 83.7%) | Loss: 0.065481 | Accuracy: 98.03% | Batch time: 0.0213s\n",
            "Step 10650 | Loss: 0.001295 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 10660 | Loss: 0.052673 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 10660 took 0.0000s\n",
            "Batch 3160/3750 ( 84.3%) | Loss: 0.065514 | Accuracy: 98.03% | Batch time: 0.0213s\n",
            "Step 10670 | Loss: 0.048068 | GPU: 24.4MB / 98.0MB | F: 0.0014s, B: 0.0162s, O: 0.0006s\n",
            "Step 10680 | Loss: 0.004880 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0043s, O: 0.0008s\n",
            "🔄 Topology update at step 10680 took 0.0000s\n",
            "Batch 3180/3750 ( 84.8%) | Loss: 0.065464 | Accuracy: 98.03% | Batch time: 0.0186s\n",
            "Step 10690 | Loss: 0.035302 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "Step 10700 | Loss: 0.155277 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 10700 took 0.0000s\n",
            "🧹 Memory cleanup at step 10700 took 0.1342s\n",
            "Batch 3200/3750 ( 85.3%) | Loss: 0.065267 | Accuracy: 98.03% | Batch time: 0.0209s\n",
            "Step 10710 | Loss: 0.012199 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0013s\n",
            "Step 10720 | Loss: 0.664121 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 10720 took 0.0000s\n",
            "Batch 3220/3750 ( 85.9%) | Loss: 0.065729 | Accuracy: 98.02% | Batch time: 0.0190s\n",
            "Step 10730 | Loss: 0.003988 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0045s, O: 0.0006s\n",
            "Step 10740 | Loss: 0.085612 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 10740 took 0.0000s\n",
            "Batch 3240/3750 ( 86.4%) | Loss: 0.065487 | Accuracy: 98.03% | Batch time: 0.0197s\n",
            "Step 10750 | Loss: 0.030312 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0030s, O: 0.0006s\n",
            "Step 10760 | Loss: 0.028377 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0011s\n",
            "🔄 Topology update at step 10760 took 0.0000s\n",
            "Batch 3260/3750 ( 86.9%) | Loss: 0.065275 | Accuracy: 98.03% | Batch time: 0.0300s\n",
            "Step 10770 | Loss: 0.037079 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 10780 | Loss: 0.055055 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 10780 took 0.0000s\n",
            "Batch 3280/3750 ( 87.5%) | Loss: 0.065055 | Accuracy: 98.04% | Batch time: 0.0210s\n",
            "Step 10790 | Loss: 0.002652 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0043s, O: 0.0009s\n",
            "Step 10800 | Loss: 0.118368 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0020s, O: 0.0007s\n",
            "🔄 Topology update at step 10800 took 0.0000s\n",
            "🧹 Memory cleanup at step 10800 took 0.1333s\n",
            "Batch 3300/3750 ( 88.0%) | Loss: 0.065079 | Accuracy: 98.04% | Batch time: 0.0224s\n",
            "Step 10810 | Loss: 0.040678 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0025s, O: 0.0007s\n",
            "Step 10820 | Loss: 0.323395 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 10820 took 0.0000s\n",
            "Batch 3320/3750 ( 88.5%) | Loss: 0.065308 | Accuracy: 98.03% | Batch time: 0.0244s\n",
            "Step 10830 | Loss: 0.041257 | GPU: 24.4MB / 98.0MB | F: 0.0026s, B: 0.0024s, O: 0.0007s\n",
            "Step 10840 | Loss: 0.011442 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 10840 took 0.0000s\n",
            "Batch 3340/3750 ( 89.1%) | Loss: 0.065200 | Accuracy: 98.04% | Batch time: 0.0188s\n",
            "Step 10850 | Loss: 0.032752 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0026s, O: 0.0006s\n",
            "Step 10860 | Loss: 0.030112 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0031s, O: 0.0004s\n",
            "🔄 Topology update at step 10860 took 0.0000s\n",
            "Batch 3360/3750 ( 89.6%) | Loss: 0.065275 | Accuracy: 98.04% | Batch time: 0.0184s\n",
            "Step 10870 | Loss: 0.019482 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0050s, O: 0.0006s\n",
            "Step 10880 | Loss: 0.022291 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0023s, O: 0.0011s\n",
            "🔄 Topology update at step 10880 took 0.0000s\n",
            "Batch 3380/3750 ( 90.1%) | Loss: 0.065179 | Accuracy: 98.04% | Batch time: 0.0187s\n",
            "Step 10890 | Loss: 0.061945 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 10900 | Loss: 0.071718 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 10900 took 0.0000s\n",
            "🧹 Memory cleanup at step 10900 took 0.1397s\n",
            "Batch 3400/3750 ( 90.7%) | Loss: 0.064910 | Accuracy: 98.05% | Batch time: 0.0227s\n",
            "Step 10910 | Loss: 0.013967 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0025s, O: 0.0006s\n",
            "Step 10920 | Loss: 0.006757 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 10920 took 0.0000s\n",
            "Batch 3420/3750 ( 91.2%) | Loss: 0.064968 | Accuracy: 98.05% | Batch time: 0.0190s\n",
            "Step 10930 | Loss: 0.004533 | GPU: 24.4MB / 98.0MB | F: 0.0039s, B: 0.0024s, O: 0.0007s\n",
            "Step 10940 | Loss: 0.108183 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0060s, O: 0.0008s\n",
            "🔄 Topology update at step 10940 took 0.0000s\n",
            "Batch 3440/3750 ( 91.7%) | Loss: 0.065158 | Accuracy: 98.05% | Batch time: 0.0301s\n",
            "Step 10950 | Loss: 0.112759 | GPU: 24.4MB / 98.0MB | F: 0.0034s, B: 0.0030s, O: 0.0009s\n",
            "Step 10960 | Loss: 0.104332 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0019s, O: 0.0006s\n",
            "🔄 Topology update at step 10960 took 0.0000s\n",
            "Batch 3460/3750 ( 92.3%) | Loss: 0.065059 | Accuracy: 98.05% | Batch time: 0.0240s\n",
            "Step 10970 | Loss: 0.057222 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "Step 10980 | Loss: 0.012288 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 10980 took 0.0000s\n",
            "Batch 3480/3750 ( 92.8%) | Loss: 0.064878 | Accuracy: 98.06% | Batch time: 0.0216s\n",
            "Step 10990 | Loss: 0.246746 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0025s, O: 0.0008s\n",
            "Step 11000 | Loss: 0.065101 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 11000 took 0.0000s\n",
            "🧹 Memory cleanup at step 11000 took 0.1345s\n",
            "Batch 3500/3750 ( 93.3%) | Loss: 0.064752 | Accuracy: 98.06% | Batch time: 0.0221s\n",
            "Step 11010 | Loss: 0.044667 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 11020 | Loss: 0.012295 | GPU: 24.4MB / 98.0MB | F: 0.0024s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 11020 took 0.0000s\n",
            "Batch 3520/3750 ( 93.9%) | Loss: 0.064622 | Accuracy: 98.06% | Batch time: 0.0214s\n",
            "Step 11030 | Loss: 0.008757 | GPU: 24.4MB / 98.0MB | F: 0.0025s, B: 0.0023s, O: 0.0007s\n",
            "Step 11040 | Loss: 0.591599 | GPU: 24.4MB / 98.0MB | F: 0.0022s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 11040 took 0.0001s\n",
            "Batch 3540/3750 ( 94.4%) | Loss: 0.064843 | Accuracy: 98.06% | Batch time: 0.0195s\n",
            "Step 11050 | Loss: 0.003798 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 11060 | Loss: 0.007845 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 11060 took 0.0001s\n",
            "Batch 3560/3750 ( 94.9%) | Loss: 0.064953 | Accuracy: 98.05% | Batch time: 0.0198s\n",
            "Step 11070 | Loss: 0.007240 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0043s, O: 0.0007s\n",
            "Step 11080 | Loss: 0.019035 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 11080 took 0.0001s\n",
            "Batch 3580/3750 ( 95.5%) | Loss: 0.064821 | Accuracy: 98.06% | Batch time: 0.0210s\n",
            "Step 11090 | Loss: 0.003962 | GPU: 24.4MB / 98.0MB | F: 0.0027s, B: 0.0027s, O: 0.0007s\n",
            "Step 11100 | Loss: 0.117551 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0085s, O: 0.0007s\n",
            "🔄 Topology update at step 11100 took 0.0000s\n",
            "🧹 Memory cleanup at step 11100 took 0.1303s\n",
            "Batch 3600/3750 ( 96.0%) | Loss: 0.065101 | Accuracy: 98.05% | Batch time: 0.0211s\n",
            "Step 11110 | Loss: 0.030658 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0036s, O: 0.0009s\n",
            "Step 11120 | Loss: 0.100142 | GPU: 24.4MB / 98.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 11120 took 0.0000s\n",
            "Batch 3620/3750 ( 96.5%) | Loss: 0.064968 | Accuracy: 98.06% | Batch time: 0.0328s\n",
            "Step 11130 | Loss: 0.017670 | GPU: 24.4MB / 98.0MB | F: 0.0016s, B: 0.0024s, O: 0.0013s\n",
            "Step 11140 | Loss: 0.018418 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 11140 took 0.0000s\n",
            "Batch 3640/3750 ( 97.1%) | Loss: 0.064962 | Accuracy: 98.06% | Batch time: 0.0212s\n",
            "Step 11150 | Loss: 0.002307 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0027s, O: 0.0008s\n",
            "Step 11160 | Loss: 0.015176 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0042s, O: 0.0016s\n",
            "🔄 Topology update at step 11160 took 0.0000s\n",
            "Batch 3660/3750 ( 97.6%) | Loss: 0.064791 | Accuracy: 98.06% | Batch time: 0.0192s\n",
            "Step 11170 | Loss: 0.069409 | GPU: 24.4MB / 98.0MB | F: 0.0059s, B: 0.0064s, O: 0.0008s\n",
            "Step 11180 | Loss: 0.026355 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 11180 took 0.0001s\n",
            "Batch 3680/3750 ( 98.1%) | Loss: 0.064927 | Accuracy: 98.06% | Batch time: 0.0191s\n",
            "Step 11190 | Loss: 0.114129 | GPU: 24.4MB / 98.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 11200 | Loss: 0.005265 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0022s, O: 0.0008s\n",
            "🔄 Topology update at step 11200 took 0.0000s\n",
            "🧹 Memory cleanup at step 11200 took 0.1300s\n",
            "Batch 3700/3750 ( 98.7%) | Loss: 0.065343 | Accuracy: 98.05% | Batch time: 0.0210s\n",
            "Step 11210 | Loss: 0.015575 | GPU: 24.4MB / 98.0MB | F: 0.0028s, B: 0.0025s, O: 0.0007s\n",
            "Step 11220 | Loss: 0.027325 | GPU: 24.4MB / 98.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 11220 took 0.0001s\n",
            "Batch 3720/3750 ( 99.2%) | Loss: 0.065310 | Accuracy: 98.05% | Batch time: 0.0210s\n",
            "Step 11230 | Loss: 0.006969 | GPU: 24.4MB / 98.0MB | F: 0.0035s, B: 0.0065s, O: 0.0005s\n",
            "Step 11240 | Loss: 0.039831 | GPU: 24.4MB / 98.0MB | F: 0.0019s, B: 0.0041s, O: 0.0007s\n",
            "🔄 Topology update at step 11240 took 0.0001s\n",
            "Batch 3740/3750 ( 99.7%) | Loss: 0.065242 | Accuracy: 98.05% | Batch time: 0.0220s\n",
            "Step 11250 | Loss: 0.072750 | GPU: 24.4MB / 98.0MB | F: 0.0010s, B: 0.0015s, O: 0.0005s\n",
            "\n",
            "-------------------- EPOCH 3 SUMMARY --------------------\n",
            "Loss: 0.065166 | Accuracy: 98.06%\n",
            "Time: 45.73s total, 0.0109s per batch\n",
            "🔄 Final Memory - RAM: 1370.1MB, GPU: 24.4MB allocated, 98.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=24.4, peak=24.4\n",
            "===============================\n",
            "\n",
            "⏱️ TALT model training took 45.7348 seconds\n",
            "\n",
            "Cleaning up memory after training...\n",
            "⏱️ Memory cleanup took 0.1327 seconds\n",
            "🔄 After training Memory - RAM: 1370.1MB, GPU: 24.3MB allocated, 44.0MB reserved\n",
            "\n",
            "------------------------- Standard Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 0.031084 | Accuracy: 98.77% | Batch time: 0.0012s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 0.039954 | Accuracy: 98.45% | Batch time: 0.0013s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 0.045003 | Accuracy: 98.30% | Batch time: 0.0013s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 0.046777 | Accuracy: 98.38% | Batch time: 0.0013s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 0.046784 | Accuracy: 98.48% | Batch time: 0.0012s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 0.045493 | Accuracy: 98.46% | Batch time: 0.0016s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 0.040431 | Accuracy: 98.63% | Batch time: 0.0010s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 0.038501 | Accuracy: 98.64% | Batch time: 0.0010s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 0.036685 | Accuracy: 98.71% | Batch time: 0.0009s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 0.033258 | Accuracy: 98.83% | Batch time: 0.0009s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 0.031073 | Accuracy: 98.89% | Batch time: 0.0012s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 0.028841 | Accuracy: 98.96% | Batch time: 0.0024s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.030343 | Accuracy: 98.90%\n",
            "Time: 3.86s total, 0.0013s per batch\n",
            "⏱️ Standard model evaluation took 3.8562 seconds\n",
            "\n",
            "------------------------- Improved TALT Model: Evaluation -------------------------\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 625, Batch size: 16\n",
            "Batch   50/ 625 (  8.0%) | Loss: 0.041894 | Accuracy: 98.53% | Batch time: 0.0013s\n",
            "Batch  100/ 625 ( 16.0%) | Loss: 0.056266 | Accuracy: 97.90% | Batch time: 0.0020s\n",
            "Batch  150/ 625 ( 24.0%) | Loss: 0.056896 | Accuracy: 97.93% | Batch time: 0.0013s\n",
            "Batch  200/ 625 ( 32.0%) | Loss: 0.058412 | Accuracy: 97.92% | Batch time: 0.0013s\n",
            "Batch  250/ 625 ( 40.0%) | Loss: 0.057403 | Accuracy: 97.91% | Batch time: 0.0013s\n",
            "Batch  300/ 625 ( 48.0%) | Loss: 0.058066 | Accuracy: 97.94% | Batch time: 0.0013s\n",
            "Batch  350/ 625 ( 56.0%) | Loss: 0.051955 | Accuracy: 98.17% | Batch time: 0.0013s\n",
            "Batch  400/ 625 ( 64.0%) | Loss: 0.048414 | Accuracy: 98.30% | Batch time: 0.0013s\n",
            "Batch  450/ 625 ( 72.0%) | Loss: 0.045756 | Accuracy: 98.42% | Batch time: 0.0030s\n",
            "Batch  500/ 625 ( 80.0%) | Loss: 0.041655 | Accuracy: 98.58% | Batch time: 0.0013s\n",
            "Batch  550/ 625 ( 88.0%) | Loss: 0.038914 | Accuracy: 98.67% | Batch time: 0.0012s\n",
            "Batch  600/ 625 ( 96.0%) | Loss: 0.036941 | Accuracy: 98.73% | Batch time: 0.0013s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.038534 | Accuracy: 98.69%\n",
            "Time: 3.16s total, 0.0014s per batch\n",
            "⏱️ TALT model evaluation took 3.1635 seconds\n",
            "\n",
            "------------------------- EPOCH 3 SUMMARY -------------------------\n",
            "Time: 78.64s\n",
            "Standard Model:\n",
            "  - Train Loss: 0.085183, Accuracy: 97.56%\n",
            "  - Test Loss:  0.030343, Accuracy: 98.90%\n",
            "Improved TALT Model:\n",
            "  - Train Loss: 0.065166, Accuracy: 98.06%\n",
            "  - Test Loss:  0.038534, Accuracy: 98.69%\n",
            "\n",
            "Cleaning up memory after epoch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error during training: num must be an integer with 1 <= num <= 4, not 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Memory cleanup took 0.1424 seconds\n",
            "🔄 After epoch Memory - RAM: 1370.1MB, GPU: 24.3MB allocated, 44.0MB reserved\n",
            "\n",
            "============================== TRAINING COMPLETED ==============================\n",
            "Total training time: 245.65s\n",
            "Final results on MNIST:\n",
            "Standard Model: 98.90% test accuracy\n",
            "Improved TALT: 98.69% test accuracy\n",
            "❌ Standard model outperformed Improved TALT by 0.21%\n",
            "\n",
            "Saving visualizations to disk...\n",
            "⏱️ Saving comparative results plot took 0.0012 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from torch.amp import autocast, GradScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import Dict, List, Tuple, Optional, Union, Callable, Any\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import gc\n",
        "import json\n",
        "import time\n",
        "import psutil\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Import the implemented classes and functions\n",
        "# [Note: In a real implementation, these would be imported from their respective modules]\n",
        "\n",
        "# Initialize the Advanced Visualizer\n",
        "if __name__ == \"__main__\":\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Check for CUDA availability\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logger.info(f\"Using device: {device}\")\n",
        "\n",
        "    # Set torch memory management options\n",
        "    if torch.cuda.is_available():\n",
        "        # Clear cache\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Limit memory usage\n",
        "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128,garbage_collection_threshold:0.6'\n",
        "\n",
        "        try:\n",
        "            # Limit GPU memory fraction\n",
        "            torch.cuda.set_per_process_memory_fraction(0.5)\n",
        "        except Exception:\n",
        "            logger.info(\"Per-process memory fraction setting not available\")\n",
        "\n",
        "    # Create output directories\n",
        "    results_dir = \"./results\"\n",
        "    plots_dir = \"./plots\"\n",
        "\n",
        "    if not os.path.exists(results_dir):\n",
        "        os.makedirs(results_dir)\n",
        "        print(f\"Created results directory: {results_dir}\")\n",
        "\n",
        "    if not os.path.exists(plots_dir):\n",
        "        os.makedirs(plots_dir)\n",
        "        print(f\"Created plots directory: {plots_dir}\")\n",
        "\n",
        "    try:\n",
        "        # Train and evaluate with multiple optimizers on MNIST\n",
        "        logger.info(\"Starting MNIST training with multiple optimizers\")\n",
        "        train_with_multiple_optimizers(\n",
        "            \"MNIST\",\n",
        "            epochs=3,\n",
        "            batch_size=32,\n",
        "            device=device,\n",
        "            save_dir=f\"{results_dir}/mnist\",\n",
        "            plots_dir=f\"{plots_dir}/mnist\"\n",
        "        )\n",
        "\n",
        "        # Clear memory\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        logger.info(\"Memory cleared successfully after MNIST\")\n",
        "\n",
        "        # Train and evaluate with multiple optimizers on CIFAR10\n",
        "        logger.info(\"Starting CIFAR10 training with multiple optimizers\")\n",
        "        train_with_multiple_optimizers(\n",
        "            \"CIFAR10\",\n",
        "            epochs=3,\n",
        "            batch_size=32,\n",
        "            device=device,\n",
        "            save_dir=f\"{results_dir}/cifar10\",\n",
        "            plots_dir=f\"{plots_dir}/cifar10\"\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during training: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        # Clean up on error\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(\"\\nTraining and visualization complete!\")\n",
        "    print(f\"Results saved in {results_dir}\")\n",
        "    print(f\"Plots saved in {plots_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiKRY36k91KQ",
        "outputId": "b5181c91-4351-4de4-dd35-40e670651092"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created results directory: ./results\n",
            "\n",
            "============================== OPTIMIZER COMPARISON ON MNIST ==============================\n",
            "Configuration: epochs=3, batch_size=32, device=cuda\n",
            "Created results directory: ./results/mnist\n",
            "\n",
            "Loading datasets...\n",
            "Train set: 60000 samples, 1875 batches\n",
            "Test set: 10000 samples, 313 batches\n",
            "\n",
            "Initializing models and optimizers...\n",
            "Model parameters: 421,834\n",
            "\n",
            "======================================================================\n",
            "STARTING TRAINING FOR 3 EPOCHS WITH 4 OPTIMIZERS\n",
            "======================================================================\n",
            "\n",
            "============================== EPOCH 1/3 ==============================\n",
            "\n",
            "------------------------- SGD Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 1\n",
            "Batches: 1875, Batch size: 32\n",
            "Batch   50/1875 (  2.7%) | Loss: 1.287296 | Acc: 54.84% | Batch time: 0.0041s\n",
            "Batch  100/1875 (  5.3%) | Loss: 0.942046 | Acc: 67.64% | Batch time: 0.0038s\n",
            "Batch  150/1875 (  8.0%) | Loss: 0.796036 | Acc: 72.85% | Batch time: 0.0042s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.731767 | Acc: 75.36% | Batch time: 0.0040s\n",
            "Batch  250/1875 ( 13.3%) | Loss: 0.663495 | Acc: 77.80% | Batch time: 0.0044s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.616174 | Acc: 79.60% | Batch time: 0.0045s\n",
            "Batch  350/1875 ( 18.7%) | Loss: 0.578274 | Acc: 80.96% | Batch time: 0.0045s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.541434 | Acc: 82.25% | Batch time: 0.0036s\n",
            "Batch  450/1875 ( 24.0%) | Loss: 0.518114 | Acc: 83.05% | Batch time: 0.0037s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.497167 | Acc: 83.80% | Batch time: 0.0073s\n",
            "Batch  550/1875 ( 29.3%) | Loss: 0.475062 | Acc: 84.51% | Batch time: 0.0044s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.461509 | Acc: 85.00% | Batch time: 0.0045s\n",
            "Batch  650/1875 ( 34.7%) | Loss: 0.444068 | Acc: 85.57% | Batch time: 0.0047s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.426994 | Acc: 86.09% | Batch time: 0.0039s\n",
            "Batch  750/1875 ( 40.0%) | Loss: 0.415614 | Acc: 86.47% | Batch time: 0.0041s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.403157 | Acc: 86.86% | Batch time: 0.0039s\n",
            "Batch  850/1875 ( 45.3%) | Loss: 0.391110 | Acc: 87.32% | Batch time: 0.0039s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.378812 | Acc: 87.74% | Batch time: 0.0114s\n",
            "Batch  950/1875 ( 50.7%) | Loss: 0.369248 | Acc: 88.08% | Batch time: 0.0042s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.360364 | Acc: 88.37% | Batch time: 0.0048s\n",
            "Batch 1050/1875 ( 56.0%) | Loss: 0.354257 | Acc: 88.60% | Batch time: 0.0041s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.347020 | Acc: 88.87% | Batch time: 0.0051s\n",
            "Batch 1150/1875 ( 61.3%) | Loss: 0.339747 | Acc: 89.13% | Batch time: 0.0041s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.333662 | Acc: 89.35% | Batch time: 0.0042s\n",
            "Batch 1250/1875 ( 66.7%) | Loss: 0.326384 | Acc: 89.58% | Batch time: 0.0045s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.320879 | Acc: 89.77% | Batch time: 0.0046s\n",
            "Batch 1350/1875 ( 72.0%) | Loss: 0.314585 | Acc: 89.96% | Batch time: 0.0128s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.309189 | Acc: 90.16% | Batch time: 0.0042s\n",
            "Batch 1450/1875 ( 77.3%) | Loss: 0.302928 | Acc: 90.36% | Batch time: 0.0047s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.299101 | Acc: 90.53% | Batch time: 0.0051s\n",
            "Batch 1550/1875 ( 82.7%) | Loss: 0.294782 | Acc: 90.68% | Batch time: 0.0050s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.290513 | Acc: 90.84% | Batch time: 0.0049s\n",
            "Batch 1650/1875 ( 88.0%) | Loss: 0.286929 | Acc: 90.98% | Batch time: 0.0041s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.283109 | Acc: 91.12% | Batch time: 0.0037s\n",
            "Batch 1750/1875 ( 93.3%) | Loss: 0.278731 | Acc: 91.27% | Batch time: 0.0142s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.275180 | Acc: 91.38% | Batch time: 0.0038s\n",
            "Batch 1850/1875 ( 98.7%) | Loss: 0.271043 | Acc: 91.51% | Batch time: 0.0041s\n",
            "\n",
            "Standard optimizer - Epoch 1 summary:\n",
            "Loss: 0.270452 | Accuracy: 91.55%\n",
            "⏱️ SGD training took 20.0770 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.086320 | Accuracy: 96.94% | Batch time: 0.0012s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.102257 | Accuracy: 96.44% | Batch time: 0.0021s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.098421 | Accuracy: 96.61% | Batch time: 0.0014s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.086342 | Accuracy: 96.98% | Batch time: 0.0013s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.078592 | Accuracy: 97.31% | Batch time: 0.0014s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.071661 | Accuracy: 97.56% | Batch time: 0.0014s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.073308 | Accuracy: 97.51%\n",
            "Time: 2.55s total, 0.0018s per batch\n",
            "⏱️ SGD evaluation took 2.5505 seconds\n",
            "SGD - Epoch 1:\n",
            "  Train Loss: 0.270452, Train Acc: 91.55%\n",
            "  Test Loss:  0.073308, Test Acc:  97.51%\n",
            "\n",
            "------------------------- Adam Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 1\n",
            "Batches: 1875, Batch size: 32\n",
            "Batch   50/1875 (  2.7%) | Loss: 1.239021 | Acc: 61.27% | Batch time: 0.0045s\n",
            "Batch  100/1875 (  5.3%) | Loss: 0.870993 | Acc: 73.11% | Batch time: 0.0052s\n",
            "Batch  150/1875 (  8.0%) | Loss: 0.724762 | Acc: 77.71% | Batch time: 0.0049s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.619418 | Acc: 80.95% | Batch time: 0.0042s\n",
            "Batch  250/1875 ( 13.3%) | Loss: 0.547083 | Acc: 83.11% | Batch time: 0.0054s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.497334 | Acc: 84.74% | Batch time: 0.0046s\n",
            "Batch  350/1875 ( 18.7%) | Loss: 0.466019 | Acc: 85.79% | Batch time: 0.0052s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.438955 | Acc: 86.70% | Batch time: 0.0057s\n",
            "Batch  450/1875 ( 24.0%) | Loss: 0.412979 | Acc: 87.47% | Batch time: 0.0049s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.391296 | Acc: 88.16% | Batch time: 0.0046s\n",
            "Batch  550/1875 ( 29.3%) | Loss: 0.374918 | Acc: 88.63% | Batch time: 0.0046s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.357812 | Acc: 89.11% | Batch time: 0.0053s\n",
            "Batch  650/1875 ( 34.7%) | Loss: 0.342344 | Acc: 89.52% | Batch time: 0.0140s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.332083 | Acc: 89.86% | Batch time: 0.0039s\n",
            "Batch  750/1875 ( 40.0%) | Loss: 0.321538 | Acc: 90.18% | Batch time: 0.0040s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.310917 | Acc: 90.50% | Batch time: 0.0045s\n",
            "Batch  850/1875 ( 45.3%) | Loss: 0.302357 | Acc: 90.76% | Batch time: 0.0049s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.294647 | Acc: 91.02% | Batch time: 0.0044s\n",
            "Batch  950/1875 ( 50.7%) | Loss: 0.288635 | Acc: 91.22% | Batch time: 0.0058s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.282199 | Acc: 91.42% | Batch time: 0.0043s\n",
            "Batch 1050/1875 ( 56.0%) | Loss: 0.278986 | Acc: 91.53% | Batch time: 0.0066s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.272026 | Acc: 91.74% | Batch time: 0.0046s\n",
            "Batch 1150/1875 ( 61.3%) | Loss: 0.266634 | Acc: 91.90% | Batch time: 0.0044s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.262945 | Acc: 91.99% | Batch time: 0.0049s\n",
            "Batch 1250/1875 ( 66.7%) | Loss: 0.258497 | Acc: 92.14% | Batch time: 0.0044s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.253221 | Acc: 92.28% | Batch time: 0.0042s\n",
            "Batch 1350/1875 ( 72.0%) | Loss: 0.248914 | Acc: 92.43% | Batch time: 0.0053s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.244948 | Acc: 92.53% | Batch time: 0.0049s\n",
            "Batch 1450/1875 ( 77.3%) | Loss: 0.241163 | Acc: 92.66% | Batch time: 0.0042s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.238528 | Acc: 92.76% | Batch time: 0.0044s\n",
            "Batch 1550/1875 ( 82.7%) | Loss: 0.235327 | Acc: 92.84% | Batch time: 0.0045s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.231908 | Acc: 92.94% | Batch time: 0.0057s\n",
            "Batch 1650/1875 ( 88.0%) | Loss: 0.229030 | Acc: 93.05% | Batch time: 0.0058s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.225140 | Acc: 93.17% | Batch time: 0.0059s\n",
            "Batch 1750/1875 ( 93.3%) | Loss: 0.222561 | Acc: 93.25% | Batch time: 0.0060s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.220030 | Acc: 93.34% | Batch time: 0.0042s\n",
            "Batch 1850/1875 ( 98.7%) | Loss: 0.217804 | Acc: 93.41% | Batch time: 0.0090s\n",
            "\n",
            "Standard optimizer - Epoch 1 summary:\n",
            "Loss: 0.216583 | Accuracy: 93.45%\n",
            "⏱️ Adam training took 19.4387 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.061296 | Accuracy: 97.98% | Batch time: 0.0010s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.064721 | Accuracy: 97.93% | Batch time: 0.0010s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.068000 | Accuracy: 97.74% | Batch time: 0.0014s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.056200 | Accuracy: 98.13% | Batch time: 0.0014s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.049747 | Accuracy: 98.36% | Batch time: 0.0014s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.045089 | Accuracy: 98.55% | Batch time: 0.0019s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.046453 | Accuracy: 98.50%\n",
            "Time: 3.24s total, 0.0015s per batch\n",
            "⏱️ Adam evaluation took 3.2417 seconds\n",
            "Adam - Epoch 1:\n",
            "  Train Loss: 0.216583, Train Acc: 93.45%\n",
            "  Test Loss:  0.046453, Test Acc:  98.50%\n",
            "\n",
            "------------------------- AdamW Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 1\n",
            "Batches: 1875, Batch size: 32\n",
            "Batch   50/1875 (  2.7%) | Loss: 1.366095 | Acc: 55.21% | Batch time: 0.0042s\n",
            "Batch  100/1875 (  5.3%) | Loss: 0.975531 | Acc: 68.56% | Batch time: 0.0056s\n",
            "Batch  150/1875 (  8.0%) | Loss: 0.789191 | Acc: 75.00% | Batch time: 0.0058s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.683463 | Acc: 78.78% | Batch time: 0.0044s\n",
            "Batch  250/1875 ( 13.3%) | Loss: 0.610888 | Acc: 81.39% | Batch time: 0.0051s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.561400 | Acc: 82.93% | Batch time: 0.0043s\n",
            "Batch  350/1875 ( 18.7%) | Loss: 0.524392 | Acc: 84.10% | Batch time: 0.0041s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.488953 | Acc: 85.19% | Batch time: 0.0040s\n",
            "Batch  450/1875 ( 24.0%) | Loss: 0.461097 | Acc: 86.15% | Batch time: 0.0069s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.434361 | Acc: 86.99% | Batch time: 0.0054s\n",
            "Batch  550/1875 ( 29.3%) | Loss: 0.415529 | Acc: 87.51% | Batch time: 0.0057s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.396942 | Acc: 87.98% | Batch time: 0.0047s\n",
            "Batch  650/1875 ( 34.7%) | Loss: 0.383724 | Acc: 88.41% | Batch time: 0.0048s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.371110 | Acc: 88.76% | Batch time: 0.0043s\n",
            "Batch  750/1875 ( 40.0%) | Loss: 0.360600 | Acc: 89.02% | Batch time: 0.0042s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.352682 | Acc: 89.29% | Batch time: 0.0043s\n",
            "Batch  850/1875 ( 45.3%) | Loss: 0.342434 | Acc: 89.58% | Batch time: 0.0047s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.331949 | Acc: 89.87% | Batch time: 0.0050s\n",
            "Batch  950/1875 ( 50.7%) | Loss: 0.325895 | Acc: 90.08% | Batch time: 0.0059s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.319173 | Acc: 90.31% | Batch time: 0.0035s\n",
            "Batch 1050/1875 ( 56.0%) | Loss: 0.312338 | Acc: 90.51% | Batch time: 0.0033s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.305908 | Acc: 90.71% | Batch time: 0.0039s\n",
            "Batch 1150/1875 ( 61.3%) | Loss: 0.301683 | Acc: 90.83% | Batch time: 0.0078s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.295829 | Acc: 90.98% | Batch time: 0.0044s\n",
            "Batch 1250/1875 ( 66.7%) | Loss: 0.290523 | Acc: 91.14% | Batch time: 0.0042s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.285798 | Acc: 91.29% | Batch time: 0.0041s\n",
            "Batch 1350/1875 ( 72.0%) | Loss: 0.280410 | Acc: 91.46% | Batch time: 0.0048s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.275786 | Acc: 91.58% | Batch time: 0.0041s\n",
            "Batch 1450/1875 ( 77.3%) | Loss: 0.271051 | Acc: 91.72% | Batch time: 0.0043s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.268113 | Acc: 91.83% | Batch time: 0.0040s\n",
            "Batch 1550/1875 ( 82.7%) | Loss: 0.264977 | Acc: 91.92% | Batch time: 0.0042s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.262022 | Acc: 92.02% | Batch time: 0.0043s\n",
            "Batch 1650/1875 ( 88.0%) | Loss: 0.259289 | Acc: 92.10% | Batch time: 0.0072s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.256099 | Acc: 92.20% | Batch time: 0.0041s\n",
            "Batch 1750/1875 ( 93.3%) | Loss: 0.252615 | Acc: 92.30% | Batch time: 0.0042s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.249150 | Acc: 92.40% | Batch time: 0.0041s\n",
            "Batch 1850/1875 ( 98.7%) | Loss: 0.246159 | Acc: 92.49% | Batch time: 0.0057s\n",
            "\n",
            "Standard optimizer - Epoch 1 summary:\n",
            "Loss: 0.244712 | Accuracy: 92.53%\n",
            "⏱️ AdamW training took 18.4181 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.066607 | Accuracy: 97.92% | Batch time: 0.0108s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.075108 | Accuracy: 97.65% | Batch time: 0.0014s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.077564 | Accuracy: 97.43% | Batch time: 0.0014s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.065349 | Accuracy: 97.82% | Batch time: 0.0013s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.058090 | Accuracy: 98.11% | Batch time: 0.0015s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.052376 | Accuracy: 98.31% | Batch time: 0.0013s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.056028 | Accuracy: 98.20%\n",
            "Time: 2.55s total, 0.0016s per batch\n",
            "⏱️ AdamW evaluation took 2.5512 seconds\n",
            "AdamW - Epoch 1:\n",
            "  Train Loss: 0.244712, Train Acc: 92.53%\n",
            "  Test Loss:  0.056028, Test Acc:  98.20%\n",
            "\n",
            "------------------------- ImprovedTALT Optimizer -------------------------\n",
            "\n",
            "==================== EPOCH 1 TRAINING ====================\n",
            "Device: cuda, Batches: 1875, Batch size: 32\n",
            "🔄 Initial Memory - RAM: 1404.6MB, GPU: 35.6MB allocated, 62.0MB reserved\n",
            "Step    1 | Loss: 2.390320 | GPU: 37.3MB / 118.0MB | F: 0.0177s, B: 0.0139s, O: 0.0012s\n",
            "Batch    0/1875 (  0.0%) | Loss: 2.390320 | Accuracy: 12.50% | Batch time: 0.0529s\n",
            "Step   10 | Loss: 2.093445 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0027s, O: 0.0007s\n",
            "Step   20 | Loss: 1.725311 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 20 took 0.0004s\n",
            "Batch   20/1875 (  1.1%) | Loss: 1.960960 | Accuracy: 35.86% | Batch time: 0.0227s\n",
            "Step   30 | Loss: 1.401161 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0022s, O: 0.0006s\n",
            "Step   40 | Loss: 1.284138 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0033s, O: 0.0009s\n",
            "🔄 Topology update at step 40 took 0.0000s\n",
            "Batch   40/1875 (  2.1%) | Loss: 1.695630 | Accuracy: 47.10% | Batch time: 0.0295s\n",
            "Step   50 | Loss: 0.923790 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0064s, O: 0.0007s\n",
            "Step   60 | Loss: 1.137318 | GPU: 37.3MB / 118.0MB | F: 0.0038s, B: 0.0035s, O: 0.0007s\n",
            "🔄 Topology update at step 60 took 0.0027s\n",
            "Batch   60/1875 (  3.2%) | Loss: 1.487508 | Accuracy: 54.76% | Batch time: 0.0370s\n",
            "Step   70 | Loss: 1.069258 | GPU: 37.3MB / 118.0MB | F: 0.0061s, B: 0.0016s, O: 0.0007s\n",
            "Step   80 | Loss: 0.835727 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0066s, O: 0.0006s\n",
            "🔄 Topology update at step 80 took 0.0043s\n",
            "Batch   80/1875 (  4.3%) | Loss: 1.339155 | Accuracy: 59.80% | Batch time: 0.0283s\n",
            "Step   90 | Loss: 0.634875 | GPU: 37.3MB / 118.0MB | F: 0.0013s, B: 0.0017s, O: 0.0007s\n",
            "Step  100 | Loss: 0.555431 | GPU: 37.3MB / 118.0MB | F: 0.0013s, B: 0.0017s, O: 0.0006s\n",
            "🔄 Topology update at step 100 took 0.0000s\n",
            "🧹 Memory cleanup at step 100 took 0.2725s\n",
            "Batch  100/1875 (  5.3%) | Loss: 1.221743 | Accuracy: 63.40% | Batch time: 0.0278s\n",
            "Step  110 | Loss: 0.705247 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0044s, O: 0.0006s\n",
            "Step  120 | Loss: 0.646976 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0017s, O: 0.0006s\n",
            "🔄 Topology update at step 120 took 0.0001s\n",
            "Batch  120/1875 (  6.4%) | Loss: 1.125622 | Accuracy: 66.53% | Batch time: 0.0442s\n",
            "Step  130 | Loss: 0.384682 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0023s, O: 0.0014s\n",
            "Step  140 | Loss: 0.623495 | GPU: 37.3MB / 118.0MB | F: 0.0027s, B: 0.0020s, O: 0.0006s\n",
            "🔄 Topology update at step 140 took 0.0001s\n",
            "Batch  140/1875 (  7.5%) | Loss: 1.048752 | Accuracy: 68.82% | Batch time: 0.0325s\n",
            "Step  150 | Loss: 0.571105 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0036s, O: 0.0007s\n",
            "Step  160 | Loss: 0.510856 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0027s, O: 0.0006s\n",
            "🔄 Topology update at step 160 took 0.0000s\n",
            "Batch  160/1875 (  8.5%) | Loss: 0.979228 | Accuracy: 71.02% | Batch time: 0.0255s\n",
            "Step  170 | Loss: 0.421766 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0084s, O: 0.0007s\n",
            "Step  180 | Loss: 0.270201 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 180 took 0.0000s\n",
            "Batch  180/1875 (  9.6%) | Loss: 0.918951 | Accuracy: 72.98% | Batch time: 0.0256s\n",
            "Step  190 | Loss: 0.351916 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0069s, O: 0.0007s\n",
            "Step  200 | Loss: 0.311139 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 200 took 0.0000s\n",
            "🧹 Memory cleanup at step 200 took 0.1408s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.867672 | Accuracy: 74.44% | Batch time: 0.0218s\n",
            "Step  210 | Loss: 0.393463 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0011s\n",
            "Step  220 | Loss: 0.229220 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 220 took 0.0001s\n",
            "Batch  220/1875 ( 11.7%) | Loss: 0.826235 | Accuracy: 75.61% | Batch time: 0.0233s\n",
            "Step  230 | Loss: 0.217902 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0026s, O: 0.0015s\n",
            "Step  240 | Loss: 0.240657 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0034s, O: 0.0013s\n",
            "🔄 Topology update at step 240 took 0.0001s\n",
            "Batch  240/1875 ( 12.8%) | Loss: 0.783913 | Accuracy: 76.96% | Batch time: 0.0476s\n",
            "Step  250 | Loss: 0.222493 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0026s, O: 0.0006s\n",
            "Step  260 | Loss: 0.374128 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 260 took 0.0001s\n",
            "Batch  260/1875 ( 13.9%) | Loss: 0.749215 | Accuracy: 78.04% | Batch time: 0.0233s\n",
            "Step  270 | Loss: 0.283725 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "Step  280 | Loss: 0.287159 | GPU: 37.3MB / 118.0MB | F: 0.0029s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 280 took 0.0000s\n",
            "Batch  280/1875 ( 14.9%) | Loss: 0.721091 | Accuracy: 78.83% | Batch time: 0.0207s\n",
            "Step  290 | Loss: 0.337012 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step  300 | Loss: 0.232196 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0039s, O: 0.0007s\n",
            "🔄 Topology update at step 300 took 0.0001s\n",
            "🧹 Memory cleanup at step 300 took 0.1422s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.695502 | Accuracy: 79.60% | Batch time: 0.0252s\n",
            "Step  310 | Loss: 0.395740 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "Step  320 | Loss: 0.424804 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0028s, O: 0.0007s\n",
            "🔄 Topology update at step 320 took 0.0054s\n",
            "Batch  320/1875 ( 17.1%) | Loss: 0.673661 | Accuracy: 80.36% | Batch time: 0.0238s\n",
            "Step  330 | Loss: 0.452046 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step  340 | Loss: 0.354135 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0010s\n",
            "🔄 Topology update at step 340 took 0.0000s\n",
            "Batch  340/1875 ( 18.1%) | Loss: 0.652749 | Accuracy: 81.03% | Batch time: 0.0201s\n",
            "Step  350 | Loss: 0.274143 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step  360 | Loss: 0.390628 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 360 took 0.0001s\n",
            "Batch  360/1875 ( 19.2%) | Loss: 0.635676 | Accuracy: 81.53% | Batch time: 0.0323s\n",
            "Step  370 | Loss: 0.264210 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0029s, O: 0.0007s\n",
            "Step  380 | Loss: 0.092299 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0026s, O: 0.0013s\n",
            "🔄 Topology update at step 380 took 0.0000s\n",
            "Batch  380/1875 ( 20.3%) | Loss: 0.617732 | Accuracy: 82.09% | Batch time: 0.0263s\n",
            "Step  390 | Loss: 0.205271 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step  400 | Loss: 0.379096 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 400 took 0.0000s\n",
            "🧹 Memory cleanup at step 400 took 0.1472s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.601046 | Accuracy: 82.57% | Batch time: 0.0223s\n",
            "Step  410 | Loss: 0.167190 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0091s, O: 0.0008s\n",
            "Step  420 | Loss: 0.405225 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 420 took 0.0000s\n",
            "Batch  420/1875 ( 22.4%) | Loss: 0.584445 | Accuracy: 83.07% | Batch time: 0.0236s\n",
            "Step  430 | Loss: 0.284696 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0089s, O: 0.0018s\n",
            "Step  440 | Loss: 0.612175 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 440 took 0.0001s\n",
            "Batch  440/1875 ( 23.5%) | Loss: 0.571676 | Accuracy: 83.43% | Batch time: 0.0218s\n",
            "Step  450 | Loss: 0.201415 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0053s, O: 0.0007s\n",
            "Step  460 | Loss: 0.177410 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 460 took 0.0000s\n",
            "Batch  460/1875 ( 24.5%) | Loss: 0.557325 | Accuracy: 83.85% | Batch time: 0.0291s\n",
            "Step  470 | Loss: 0.116987 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0157s, O: 0.0044s\n",
            "Step  480 | Loss: 0.278351 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 480 took 0.0000s\n",
            "Batch  480/1875 ( 25.6%) | Loss: 0.545895 | Accuracy: 84.19% | Batch time: 0.0342s\n",
            "Step  490 | Loss: 0.330602 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0008s\n",
            "Step  500 | Loss: 0.380497 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0095s, O: 0.0008s\n",
            "🔄 Topology update at step 500 took 0.0000s\n",
            "🧹 Memory cleanup at step 500 took 0.1512s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.533481 | Accuracy: 84.59% | Batch time: 0.0221s\n",
            "Step  510 | Loss: 0.171764 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step  520 | Loss: 0.153067 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 520 took 0.0001s\n",
            "Batch  520/1875 ( 27.7%) | Loss: 0.523603 | Accuracy: 84.91% | Batch time: 0.0213s\n",
            "Step  530 | Loss: 0.084547 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step  540 | Loss: 0.306823 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 540 took 0.0000s\n",
            "Batch  540/1875 ( 28.8%) | Loss: 0.512189 | Accuracy: 85.26% | Batch time: 0.0372s\n",
            "Step  550 | Loss: 0.119383 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0041s, O: 0.0006s\n",
            "Step  560 | Loss: 0.253604 | GPU: 37.3MB / 118.0MB | F: 0.0039s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 560 took 0.0000s\n",
            "Batch  560/1875 ( 29.9%) | Loss: 0.503497 | Accuracy: 85.52% | Batch time: 0.0232s\n",
            "Step  570 | Loss: 0.201113 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step  580 | Loss: 0.229052 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 580 took 0.0000s\n",
            "Batch  580/1875 ( 30.9%) | Loss: 0.493436 | Accuracy: 85.82% | Batch time: 0.0207s\n",
            "Step  590 | Loss: 0.041484 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step  600 | Loss: 0.290130 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0013s\n",
            "🔄 Topology update at step 600 took 0.0000s\n",
            "🧹 Memory cleanup at step 600 took 0.1506s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.484042 | Accuracy: 86.09% | Batch time: 0.0220s\n",
            "Step  610 | Loss: 0.202031 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0063s, O: 0.0021s\n",
            "Step  620 | Loss: 0.410424 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 620 took 0.0001s\n",
            "Batch  620/1875 ( 33.1%) | Loss: 0.475777 | Accuracy: 86.33% | Batch time: 0.0287s\n",
            "Step  630 | Loss: 0.455501 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0023s, O: 0.0006s\n",
            "Step  640 | Loss: 0.192908 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 640 took 0.0000s\n",
            "Batch  640/1875 ( 34.1%) | Loss: 0.467432 | Accuracy: 86.56% | Batch time: 0.0272s\n",
            "Step  650 | Loss: 0.105988 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step  660 | Loss: 0.081934 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0027s, O: 0.0021s\n",
            "🔄 Topology update at step 660 took 0.0000s\n",
            "Batch  660/1875 ( 35.2%) | Loss: 0.458734 | Accuracy: 86.82% | Batch time: 0.0244s\n",
            "Step  670 | Loss: 0.095150 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0023s, O: 0.0007s\n",
            "Step  680 | Loss: 0.222446 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 680 took 0.0001s\n",
            "Batch  680/1875 ( 36.3%) | Loss: 0.451447 | Accuracy: 87.00% | Batch time: 0.0225s\n",
            "Step  690 | Loss: 0.097881 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0008s\n",
            "Step  700 | Loss: 0.193963 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0037s, O: 0.0006s\n",
            "🔄 Topology update at step 700 took 0.0000s\n",
            "🧹 Memory cleanup at step 700 took 0.1489s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.444830 | Accuracy: 87.18% | Batch time: 0.0222s\n",
            "Step  710 | Loss: 0.067623 | GPU: 37.3MB / 118.0MB | F: 0.0035s, B: 0.0023s, O: 0.0006s\n",
            "Step  720 | Loss: 0.101200 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 720 took 0.0000s\n",
            "Batch  720/1875 ( 38.4%) | Loss: 0.437679 | Accuracy: 87.41% | Batch time: 0.0204s\n",
            "Step  730 | Loss: 0.441169 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0070s, O: 0.0005s\n",
            "Step  740 | Loss: 0.147892 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 740 took 0.0000s\n",
            "Batch  740/1875 ( 39.5%) | Loss: 0.431311 | Accuracy: 87.60% | Batch time: 0.0234s\n",
            "Step  750 | Loss: 0.403856 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0028s, O: 0.0006s\n",
            "Step  760 | Loss: 0.440175 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 760 took 0.0000s\n",
            "Batch  760/1875 ( 40.5%) | Loss: 0.426707 | Accuracy: 87.73% | Batch time: 0.0305s\n",
            "Step  770 | Loss: 0.254068 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Step  780 | Loss: 0.297669 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 780 took 0.0000s\n",
            "Batch  780/1875 ( 41.6%) | Loss: 0.420369 | Accuracy: 87.92% | Batch time: 0.0267s\n",
            "Step  790 | Loss: 0.200819 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "Step  800 | Loss: 0.303607 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0044s, O: 0.0007s\n",
            "🔄 Topology update at step 800 took 0.0000s\n",
            "🧹 Memory cleanup at step 800 took 0.1472s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.414234 | Accuracy: 88.08% | Batch time: 0.0228s\n",
            "Step  810 | Loss: 0.140243 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step  820 | Loss: 0.266368 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0005s\n",
            "🔄 Topology update at step 820 took 0.0000s\n",
            "Batch  820/1875 ( 43.7%) | Loss: 0.409202 | Accuracy: 88.22% | Batch time: 0.0213s\n",
            "Step  830 | Loss: 0.347678 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0008s\n",
            "Step  840 | Loss: 0.202731 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 840 took 0.0000s\n",
            "Batch  840/1875 ( 44.8%) | Loss: 0.403495 | Accuracy: 88.41% | Batch time: 0.0239s\n",
            "Step  850 | Loss: 0.333185 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0022s, O: 0.0006s\n",
            "Step  860 | Loss: 0.222287 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0042s, O: 0.0006s\n",
            "🔄 Topology update at step 860 took 0.0001s\n",
            "Batch  860/1875 ( 45.9%) | Loss: 0.398024 | Accuracy: 88.58% | Batch time: 0.0272s\n",
            "Step  870 | Loss: 0.489997 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0027s, O: 0.0007s\n",
            "Step  880 | Loss: 0.095088 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0054s, O: 0.0039s\n",
            "🔄 Topology update at step 880 took 0.0001s\n",
            "Batch  880/1875 ( 46.9%) | Loss: 0.393212 | Accuracy: 88.72% | Batch time: 0.0216s\n",
            "Step  890 | Loss: 0.232578 | GPU: 37.3MB / 118.0MB | F: 0.0026s, B: 0.0028s, O: 0.0018s\n",
            "Step  900 | Loss: 0.057409 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0109s, O: 0.0007s\n",
            "🔄 Topology update at step 900 took 0.0000s\n",
            "🧹 Memory cleanup at step 900 took 0.2060s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.389024 | Accuracy: 88.85% | Batch time: 0.0318s\n",
            "Step  910 | Loss: 0.302885 | GPU: 37.3MB / 118.0MB | F: 0.0038s, B: 0.0037s, O: 0.0006s\n",
            "Step  920 | Loss: 0.335915 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0067s, O: 0.0007s\n",
            "🔄 Topology update at step 920 took 0.0001s\n",
            "Batch  920/1875 ( 49.1%) | Loss: 0.384671 | Accuracy: 88.98% | Batch time: 0.0268s\n",
            "Step  930 | Loss: 0.102742 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0064s, O: 0.0006s\n",
            "Step  940 | Loss: 0.475743 | GPU: 37.3MB / 118.0MB | F: 0.0077s, B: 0.0016s, O: 0.0007s\n",
            "🔄 Topology update at step 940 took 0.0000s\n",
            "Batch  940/1875 ( 50.1%) | Loss: 0.380319 | Accuracy: 89.12% | Batch time: 0.0341s\n",
            "Step  950 | Loss: 0.092042 | GPU: 37.3MB / 118.0MB | F: 0.0013s, B: 0.0067s, O: 0.0006s\n",
            "Step  960 | Loss: 0.112164 | GPU: 37.3MB / 118.0MB | F: 0.0013s, B: 0.0090s, O: 0.0006s\n",
            "🔄 Topology update at step 960 took 0.0000s\n",
            "Batch  960/1875 ( 51.2%) | Loss: 0.375319 | Accuracy: 89.27% | Batch time: 0.0297s\n",
            "Step  970 | Loss: 0.086111 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "Step  980 | Loss: 0.119664 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0034s, O: 0.0006s\n",
            "🔄 Topology update at step 980 took 0.0000s\n",
            "Batch  980/1875 ( 52.3%) | Loss: 0.371041 | Accuracy: 89.38% | Batch time: 0.0357s\n",
            "Step  990 | Loss: 0.128658 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0089s, O: 0.0006s\n",
            "Step 1000 | Loss: 0.389222 | GPU: 37.3MB / 118.0MB | F: 0.0056s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 1000 took 0.0009s\n",
            "🧹 Memory cleanup at step 1000 took 0.1902s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.367233 | Accuracy: 89.51% | Batch time: 0.0250s\n",
            "Step 1010 | Loss: 0.157009 | GPU: 37.3MB / 118.0MB | F: 0.0088s, B: 0.0086s, O: 0.0007s\n",
            "Step 1020 | Loss: 0.171978 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1020 took 0.0000s\n",
            "Batch 1020/1875 ( 54.4%) | Loss: 0.364253 | Accuracy: 89.58% | Batch time: 0.0228s\n",
            "Step 1030 | Loss: 0.134817 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0023s, O: 0.0007s\n",
            "Step 1040 | Loss: 0.094317 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 1040 took 0.0000s\n",
            "Batch 1040/1875 ( 55.5%) | Loss: 0.360404 | Accuracy: 89.69% | Batch time: 0.0227s\n",
            "Step 1050 | Loss: 0.063391 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0024s, O: 0.0007s\n",
            "Step 1060 | Loss: 0.265331 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1060 took 0.0000s\n",
            "Batch 1060/1875 ( 56.5%) | Loss: 0.356365 | Accuracy: 89.81% | Batch time: 0.0204s\n",
            "Step 1070 | Loss: 0.124137 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "Step 1080 | Loss: 0.386656 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1080 took 0.0001s\n",
            "Batch 1080/1875 ( 57.6%) | Loss: 0.353078 | Accuracy: 89.91% | Batch time: 0.0218s\n",
            "Step 1090 | Loss: 0.086951 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0146s, O: 0.0009s\n",
            "Step 1100 | Loss: 0.139141 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 1100 took 0.0000s\n",
            "🧹 Memory cleanup at step 1100 took 0.1481s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.349721 | Accuracy: 90.01% | Batch time: 0.0237s\n",
            "Step 1110 | Loss: 0.402547 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0027s, O: 0.0007s\n",
            "Step 1120 | Loss: 0.079967 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1120 took 0.0001s\n",
            "Batch 1120/1875 ( 59.7%) | Loss: 0.346385 | Accuracy: 90.09% | Batch time: 0.0241s\n",
            "Step 1130 | Loss: 0.307692 | GPU: 37.3MB / 118.0MB | F: 0.0027s, B: 0.0027s, O: 0.0006s\n",
            "Step 1140 | Loss: 0.153804 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1140 took 0.0001s\n",
            "Batch 1140/1875 ( 60.8%) | Loss: 0.343587 | Accuracy: 90.16% | Batch time: 0.0277s\n",
            "Step 1150 | Loss: 0.475389 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Step 1160 | Loss: 0.142718 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0030s, O: 0.0014s\n",
            "🔄 Topology update at step 1160 took 0.0001s\n",
            "Batch 1160/1875 ( 61.9%) | Loss: 0.340651 | Accuracy: 90.25% | Batch time: 0.0381s\n",
            "Step 1170 | Loss: 0.091939 | GPU: 37.3MB / 118.0MB | F: 0.0032s, B: 0.0029s, O: 0.0008s\n",
            "Step 1180 | Loss: 0.124951 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 1180 took 0.0001s\n",
            "Batch 1180/1875 ( 62.9%) | Loss: 0.337574 | Accuracy: 90.35% | Batch time: 0.0214s\n",
            "Step 1190 | Loss: 0.112818 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0044s, O: 0.0008s\n",
            "Step 1200 | Loss: 0.114751 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0044s, O: 0.0015s\n",
            "🔄 Topology update at step 1200 took 0.0000s\n",
            "🧹 Memory cleanup at step 1200 took 0.1409s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.334534 | Accuracy: 90.43% | Batch time: 0.0223s\n",
            "Step 1210 | Loss: 0.149310 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0027s, O: 0.0007s\n",
            "Step 1220 | Loss: 0.254209 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0026s, O: 0.0013s\n",
            "🔄 Topology update at step 1220 took 0.0000s\n",
            "Batch 1220/1875 ( 65.1%) | Loss: 0.331035 | Accuracy: 90.53% | Batch time: 0.0215s\n",
            "Step 1230 | Loss: 0.300634 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0089s, O: 0.0006s\n",
            "Step 1240 | Loss: 0.032349 | GPU: 37.3MB / 118.0MB | F: 0.0028s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 1240 took 0.0000s\n",
            "Batch 1240/1875 ( 66.1%) | Loss: 0.327896 | Accuracy: 90.62% | Batch time: 0.0220s\n",
            "Step 1250 | Loss: 0.109177 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0043s, O: 0.0007s\n",
            "Step 1260 | Loss: 0.062187 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 1260 took 0.0000s\n",
            "Batch 1260/1875 ( 67.2%) | Loss: 0.324754 | Accuracy: 90.72% | Batch time: 0.0222s\n",
            "Step 1270 | Loss: 0.140525 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 1280 | Loss: 0.201710 | GPU: 37.3MB / 118.0MB | F: 0.0032s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1280 took 0.0001s\n",
            "Batch 1280/1875 ( 68.3%) | Loss: 0.322101 | Accuracy: 90.80% | Batch time: 0.0244s\n",
            "Step 1290 | Loss: 0.059296 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0072s, O: 0.0007s\n",
            "Step 1300 | Loss: 0.083719 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1300 took 0.0000s\n",
            "🧹 Memory cleanup at step 1300 took 0.1342s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.318959 | Accuracy: 90.89% | Batch time: 0.0243s\n",
            "Step 1310 | Loss: 0.201356 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "Step 1320 | Loss: 0.048350 | GPU: 37.3MB / 118.0MB | F: 0.0037s, B: 0.0023s, O: 0.0010s\n",
            "🔄 Topology update at step 1320 took 0.0000s\n",
            "Batch 1320/1875 ( 70.4%) | Loss: 0.316076 | Accuracy: 90.97% | Batch time: 0.0200s\n",
            "Step 1330 | Loss: 0.175724 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 1340 | Loss: 0.091630 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1340 took 0.0001s\n",
            "Batch 1340/1875 ( 71.5%) | Loss: 0.313205 | Accuracy: 91.05% | Batch time: 0.0307s\n",
            "Step 1350 | Loss: 0.213452 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0023s, O: 0.0006s\n",
            "Step 1360 | Loss: 0.371498 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0023s, O: 0.0015s\n",
            "🔄 Topology update at step 1360 took 0.0001s\n",
            "Batch 1360/1875 ( 72.5%) | Loss: 0.310917 | Accuracy: 91.11% | Batch time: 0.0300s\n",
            "Step 1370 | Loss: 0.094062 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "Step 1380 | Loss: 0.159562 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 1380 took 0.0000s\n",
            "Batch 1380/1875 ( 73.6%) | Loss: 0.308266 | Accuracy: 91.18% | Batch time: 0.0211s\n",
            "Step 1390 | Loss: 0.024597 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0035s, O: 0.0007s\n",
            "Step 1400 | Loss: 0.330345 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1400 took 0.0000s\n",
            "🧹 Memory cleanup at step 1400 took 0.1392s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.305755 | Accuracy: 91.24% | Batch time: 0.0221s\n",
            "Step 1410 | Loss: 0.067712 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "Step 1420 | Loss: 0.128454 | GPU: 37.3MB / 118.0MB | F: 0.0043s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1420 took 0.0000s\n",
            "Batch 1420/1875 ( 75.7%) | Loss: 0.303368 | Accuracy: 91.32% | Batch time: 0.0237s\n",
            "Step 1430 | Loss: 0.061823 | GPU: 37.3MB / 118.0MB | F: 0.0115s, B: 0.0024s, O: 0.0016s\n",
            "Step 1440 | Loss: 0.141253 | GPU: 37.3MB / 118.0MB | F: 0.0028s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 1440 took 0.0000s\n",
            "Batch 1440/1875 ( 76.8%) | Loss: 0.301502 | Accuracy: 91.36% | Batch time: 0.0211s\n",
            "Step 1450 | Loss: 0.089259 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0025s, O: 0.0006s\n",
            "Step 1460 | Loss: 0.173815 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 1460 took 0.0001s\n",
            "Batch 1460/1875 ( 77.9%) | Loss: 0.299294 | Accuracy: 91.44% | Batch time: 0.0210s\n",
            "Step 1470 | Loss: 0.032931 | GPU: 37.3MB / 118.0MB | F: 0.0033s, B: 0.0022s, O: 0.0007s\n",
            "Step 1480 | Loss: 0.112967 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1480 took 0.0000s\n",
            "Batch 1480/1875 ( 78.9%) | Loss: 0.296987 | Accuracy: 91.50% | Batch time: 0.0322s\n",
            "Step 1490 | Loss: 0.107045 | GPU: 37.3MB / 118.0MB | F: 0.0027s, B: 0.0025s, O: 0.0007s\n",
            "Step 1500 | Loss: 0.037314 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1500 took 0.0000s\n",
            "🧹 Memory cleanup at step 1500 took 0.1371s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.294873 | Accuracy: 91.56% | Batch time: 0.0224s\n",
            "Step 1510 | Loss: 0.177816 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0042s, O: 0.0006s\n",
            "Step 1520 | Loss: 0.339668 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 1520 took 0.0000s\n",
            "Batch 1520/1875 ( 81.1%) | Loss: 0.292675 | Accuracy: 91.63% | Batch time: 0.0333s\n",
            "Step 1530 | Loss: 0.177015 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 1540 | Loss: 0.080086 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0040s, O: 0.0015s\n",
            "🔄 Topology update at step 1540 took 0.0000s\n",
            "Batch 1540/1875 ( 82.1%) | Loss: 0.290716 | Accuracy: 91.68% | Batch time: 0.0205s\n",
            "Step 1550 | Loss: 0.205342 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0026s, O: 0.0007s\n",
            "Step 1560 | Loss: 0.094377 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0088s, O: 0.0006s\n",
            "🔄 Topology update at step 1560 took 0.0000s\n",
            "Batch 1560/1875 ( 83.2%) | Loss: 0.288445 | Accuracy: 91.74% | Batch time: 0.0300s\n",
            "Step 1570 | Loss: 0.121655 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 1580 | Loss: 0.291051 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0030s, O: 0.0012s\n",
            "🔄 Topology update at step 1580 took 0.0000s\n",
            "Batch 1580/1875 ( 84.3%) | Loss: 0.286393 | Accuracy: 91.80% | Batch time: 0.0222s\n",
            "Step 1590 | Loss: 0.132170 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0055s, O: 0.0007s\n",
            "Step 1600 | Loss: 0.063300 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0055s, O: 0.0007s\n",
            "🔄 Topology update at step 1600 took 0.0000s\n",
            "🧹 Memory cleanup at step 1600 took 0.1437s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.284056 | Accuracy: 91.86% | Batch time: 0.0218s\n",
            "Step 1610 | Loss: 0.107017 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 1620 | Loss: 0.160792 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 1620 took 0.0000s\n",
            "Batch 1620/1875 ( 86.4%) | Loss: 0.282073 | Accuracy: 91.91% | Batch time: 0.0233s\n",
            "Step 1630 | Loss: 0.091267 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 1640 | Loss: 0.036053 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 1640 took 0.0000s\n",
            "Batch 1640/1875 ( 87.5%) | Loss: 0.279931 | Accuracy: 91.98% | Batch time: 0.0204s\n",
            "Step 1650 | Loss: 0.398380 | GPU: 37.3MB / 118.0MB | F: 0.0094s, B: 0.0027s, O: 0.0012s\n",
            "Step 1660 | Loss: 0.062113 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0052s, O: 0.0007s\n",
            "🔄 Topology update at step 1660 took 0.0001s\n",
            "Batch 1660/1875 ( 88.5%) | Loss: 0.277566 | Accuracy: 92.05% | Batch time: 0.0232s\n",
            "Step 1670 | Loss: 0.167981 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0030s, O: 0.0017s\n",
            "Step 1680 | Loss: 0.090188 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0029s, O: 0.0012s\n",
            "🔄 Topology update at step 1680 took 0.0000s\n",
            "Batch 1680/1875 ( 89.6%) | Loss: 0.275483 | Accuracy: 92.11% | Batch time: 0.0225s\n",
            "Step 1690 | Loss: 0.302519 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0024s, O: 0.0014s\n",
            "Step 1700 | Loss: 0.188278 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1700 took 0.0000s\n",
            "🧹 Memory cleanup at step 1700 took 0.1399s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.273782 | Accuracy: 92.16% | Batch time: 0.0218s\n",
            "Step 1710 | Loss: 0.046827 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0006s\n",
            "Step 1720 | Loss: 0.043203 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 1720 took 0.0001s\n",
            "Batch 1720/1875 ( 91.7%) | Loss: 0.271926 | Accuracy: 92.22% | Batch time: 0.0252s\n",
            "Step 1730 | Loss: 0.080912 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 1740 | Loss: 0.065894 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0034s, O: 0.0007s\n",
            "🔄 Topology update at step 1740 took 0.0000s\n",
            "Batch 1740/1875 ( 92.8%) | Loss: 0.269909 | Accuracy: 92.27% | Batch time: 0.0213s\n",
            "Step 1750 | Loss: 0.302937 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0100s, O: 0.0007s\n",
            "Step 1760 | Loss: 0.032009 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0071s\n",
            "🔄 Topology update at step 1760 took 0.0000s\n",
            "Batch 1760/1875 ( 93.9%) | Loss: 0.268015 | Accuracy: 92.33% | Batch time: 0.0398s\n",
            "Step 1770 | Loss: 0.077510 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0048s, O: 0.0006s\n",
            "Step 1780 | Loss: 0.126153 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0112s, O: 0.0009s\n",
            "🔄 Topology update at step 1780 took 0.0000s\n",
            "Batch 1780/1875 ( 94.9%) | Loss: 0.266018 | Accuracy: 92.38% | Batch time: 0.0286s\n",
            "Step 1790 | Loss: 0.193146 | GPU: 37.3MB / 118.0MB | F: 0.0013s, B: 0.0055s, O: 0.0006s\n",
            "Step 1800 | Loss: 0.033901 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0068s, O: 0.0007s\n",
            "🔄 Topology update at step 1800 took 0.0000s\n",
            "🧹 Memory cleanup at step 1800 took 0.1702s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.264291 | Accuracy: 92.42% | Batch time: 0.0292s\n",
            "Step 1810 | Loss: 0.126179 | GPU: 37.3MB / 118.0MB | F: 0.0011s, B: 0.0021s, O: 0.0007s\n",
            "Step 1820 | Loss: 0.143490 | GPU: 37.3MB / 118.0MB | F: 0.0013s, B: 0.0047s, O: 0.0007s\n",
            "🔄 Topology update at step 1820 took 0.0000s\n",
            "Batch 1820/1875 ( 97.1%) | Loss: 0.262540 | Accuracy: 92.47% | Batch time: 0.0274s\n",
            "Step 1830 | Loss: 0.035997 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0018s, O: 0.0006s\n",
            "Step 1840 | Loss: 0.094705 | GPU: 37.3MB / 118.0MB | F: 0.0014s, B: 0.0067s, O: 0.0006s\n",
            "🔄 Topology update at step 1840 took 0.0000s\n",
            "Batch 1840/1875 ( 98.1%) | Loss: 0.260987 | Accuracy: 92.51% | Batch time: 0.0374s\n",
            "Step 1850 | Loss: 0.032665 | GPU: 37.3MB / 118.0MB | F: 0.0039s, B: 0.0135s, O: 0.0007s\n",
            "Step 1860 | Loss: 0.154602 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0049s, O: 0.0006s\n",
            "🔄 Topology update at step 1860 took 0.0008s\n",
            "Batch 1860/1875 ( 99.2%) | Loss: 0.259786 | Accuracy: 92.54% | Batch time: 0.0413s\n",
            "Step 1870 | Loss: 0.051529 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0127s, O: 0.0007s\n",
            "\n",
            "-------------------- EPOCH 1 SUMMARY --------------------\n",
            "Loss: 0.258555 | Accuracy: 92.58%\n",
            "Time: 28.61s total, 0.0130s per batch\n",
            "🔄 Final Memory - RAM: 1406.0MB, GPU: 37.3MB allocated, 118.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=37.3, peak=37.3\n",
            "===============================\n",
            "\n",
            "⏱️ ImprovedTALT training took 28.6120 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.083668 | Accuracy: 96.88% | Batch time: 0.0014s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.087498 | Accuracy: 97.09% | Batch time: 0.0014s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.089465 | Accuracy: 97.08% | Batch time: 0.0014s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.077270 | Accuracy: 97.53% | Batch time: 0.0014s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.067907 | Accuracy: 97.87% | Batch time: 0.0013s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.061042 | Accuracy: 98.10% | Batch time: 0.0014s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.062525 | Accuracy: 98.05%\n",
            "Time: 2.54s total, 0.0015s per batch\n",
            "⏱️ ImprovedTALT evaluation took 2.5404 seconds\n",
            "ImprovedTALT - Epoch 1:\n",
            "  Train Loss: 0.258555, Train Acc: 92.58%\n",
            "  Test Loss:  0.062525, Test Acc:  98.05%\n",
            "\n",
            "Epoch 1 completed in 98.10s\n",
            "Results saved to ./results/mnist/epoch_1_results.json\n",
            "\n",
            "============================== EPOCH 2/3 ==============================\n",
            "\n",
            "------------------------- SGD Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 2\n",
            "Batches: 1875, Batch size: 32\n",
            "Batch   50/1875 (  2.7%) | Loss: 0.135951 | Acc: 96.20% | Batch time: 0.0039s\n",
            "Batch  100/1875 (  5.3%) | Loss: 0.140202 | Acc: 96.19% | Batch time: 0.0038s\n",
            "Batch  150/1875 (  8.0%) | Loss: 0.132694 | Acc: 96.17% | Batch time: 0.0038s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.140624 | Acc: 95.91% | Batch time: 0.0042s\n",
            "Batch  250/1875 ( 13.3%) | Loss: 0.131608 | Acc: 96.15% | Batch time: 0.0038s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.130711 | Acc: 96.22% | Batch time: 0.0044s\n",
            "Batch  350/1875 ( 18.7%) | Loss: 0.129946 | Acc: 96.25% | Batch time: 0.0043s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.130742 | Acc: 96.17% | Batch time: 0.0038s\n",
            "Batch  450/1875 ( 24.0%) | Loss: 0.128037 | Acc: 96.28% | Batch time: 0.0038s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.128129 | Acc: 96.31% | Batch time: 0.0039s\n",
            "Batch  550/1875 ( 29.3%) | Loss: 0.127697 | Acc: 96.31% | Batch time: 0.0038s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.125957 | Acc: 96.34% | Batch time: 0.0039s\n",
            "Batch  650/1875 ( 34.7%) | Loss: 0.124425 | Acc: 96.36% | Batch time: 0.0057s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.124544 | Acc: 96.37% | Batch time: 0.0039s\n",
            "Batch  750/1875 ( 40.0%) | Loss: 0.126715 | Acc: 96.30% | Batch time: 0.0046s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.126119 | Acc: 96.31% | Batch time: 0.0040s\n",
            "Batch  850/1875 ( 45.3%) | Loss: 0.125527 | Acc: 96.31% | Batch time: 0.0038s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.125488 | Acc: 96.30% | Batch time: 0.0040s\n",
            "Batch  950/1875 ( 50.7%) | Loss: 0.125033 | Acc: 96.30% | Batch time: 0.0031s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.124455 | Acc: 96.31% | Batch time: 0.0081s\n",
            "Batch 1050/1875 ( 56.0%) | Loss: 0.125294 | Acc: 96.31% | Batch time: 0.0093s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.124369 | Acc: 96.34% | Batch time: 0.0043s\n",
            "Batch 1150/1875 ( 61.3%) | Loss: 0.123285 | Acc: 96.37% | Batch time: 0.0042s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.121840 | Acc: 96.42% | Batch time: 0.0041s\n",
            "Batch 1250/1875 ( 66.7%) | Loss: 0.121795 | Acc: 96.42% | Batch time: 0.0043s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.121002 | Acc: 96.45% | Batch time: 0.0040s\n",
            "Batch 1350/1875 ( 72.0%) | Loss: 0.119978 | Acc: 96.47% | Batch time: 0.0039s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.119810 | Acc: 96.48% | Batch time: 0.0039s\n",
            "Batch 1450/1875 ( 77.3%) | Loss: 0.118711 | Acc: 96.50% | Batch time: 0.0040s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.118942 | Acc: 96.50% | Batch time: 0.0039s\n",
            "Batch 1550/1875 ( 82.7%) | Loss: 0.117179 | Acc: 96.55% | Batch time: 0.0055s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.116528 | Acc: 96.56% | Batch time: 0.0088s\n",
            "Batch 1650/1875 ( 88.0%) | Loss: 0.115683 | Acc: 96.59% | Batch time: 0.0090s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.115143 | Acc: 96.61% | Batch time: 0.0051s\n",
            "Batch 1750/1875 ( 93.3%) | Loss: 0.115009 | Acc: 96.61% | Batch time: 0.0067s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.114642 | Acc: 96.62% | Batch time: 0.0045s\n",
            "Batch 1850/1875 ( 98.7%) | Loss: 0.115018 | Acc: 96.62% | Batch time: 0.0039s\n",
            "\n",
            "Standard optimizer - Epoch 2 summary:\n",
            "Loss: 0.114616 | Accuracy: 96.62%\n",
            "⏱️ SGD training took 18.1716 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.050325 | Accuracy: 98.10% | Batch time: 0.0013s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.057360 | Accuracy: 98.17% | Batch time: 0.0014s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.056652 | Accuracy: 98.12% | Batch time: 0.0013s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.045820 | Accuracy: 98.51% | Batch time: 0.0020s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.040170 | Accuracy: 98.69% | Batch time: 0.0014s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.035077 | Accuracy: 98.86% | Batch time: 0.0014s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.036793 | Accuracy: 98.82%\n",
            "Time: 2.69s total, 0.0015s per batch\n",
            "⏱️ SGD evaluation took 2.6939 seconds\n",
            "SGD - Epoch 2:\n",
            "  Train Loss: 0.114616, Train Acc: 96.62%\n",
            "  Test Loss:  0.036793, Test Acc:  98.82%\n",
            "\n",
            "------------------------- Adam Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 2\n",
            "Batches: 1875, Batch size: 32\n",
            "Batch   50/1875 (  2.7%) | Loss: 0.125124 | Acc: 96.26% | Batch time: 0.0043s\n",
            "Batch  100/1875 (  5.3%) | Loss: 0.122228 | Acc: 96.38% | Batch time: 0.0074s\n",
            "Batch  150/1875 (  8.0%) | Loss: 0.124967 | Acc: 96.38% | Batch time: 0.0044s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.125100 | Acc: 96.53% | Batch time: 0.0041s\n",
            "Batch  250/1875 ( 13.3%) | Loss: 0.119668 | Acc: 96.66% | Batch time: 0.0044s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.111901 | Acc: 96.78% | Batch time: 0.0085s\n",
            "Batch  350/1875 ( 18.7%) | Loss: 0.113960 | Acc: 96.71% | Batch time: 0.0044s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.111201 | Acc: 96.66% | Batch time: 0.0042s\n",
            "Batch  450/1875 ( 24.0%) | Loss: 0.109344 | Acc: 96.76% | Batch time: 0.0049s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.109300 | Acc: 96.79% | Batch time: 0.0044s\n",
            "Batch  550/1875 ( 29.3%) | Loss: 0.107065 | Acc: 96.82% | Batch time: 0.0045s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.106673 | Acc: 96.80% | Batch time: 0.0037s\n",
            "Batch  650/1875 ( 34.7%) | Loss: 0.105983 | Acc: 96.81% | Batch time: 0.0047s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.106262 | Acc: 96.85% | Batch time: 0.0054s\n",
            "Batch  750/1875 ( 40.0%) | Loss: 0.106904 | Acc: 96.82% | Batch time: 0.0048s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.107969 | Acc: 96.78% | Batch time: 0.0048s\n",
            "Batch  850/1875 ( 45.3%) | Loss: 0.107549 | Acc: 96.82% | Batch time: 0.0112s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.107089 | Acc: 96.84% | Batch time: 0.0062s\n",
            "Batch  950/1875 ( 50.7%) | Loss: 0.106763 | Acc: 96.83% | Batch time: 0.0051s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.105228 | Acc: 96.88% | Batch time: 0.0042s\n",
            "Batch 1050/1875 ( 56.0%) | Loss: 0.104313 | Acc: 96.91% | Batch time: 0.0039s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.102914 | Acc: 96.95% | Batch time: 0.0046s\n",
            "Batch 1150/1875 ( 61.3%) | Loss: 0.103554 | Acc: 96.93% | Batch time: 0.0047s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.104155 | Acc: 96.91% | Batch time: 0.0054s\n",
            "Batch 1250/1875 ( 66.7%) | Loss: 0.104235 | Acc: 96.89% | Batch time: 0.0035s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.104049 | Acc: 96.91% | Batch time: 0.0031s\n",
            "Batch 1350/1875 ( 72.0%) | Loss: 0.103592 | Acc: 96.92% | Batch time: 0.0039s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.103305 | Acc: 96.94% | Batch time: 0.0043s\n",
            "Batch 1450/1875 ( 77.3%) | Loss: 0.103680 | Acc: 96.94% | Batch time: 0.0049s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.103339 | Acc: 96.95% | Batch time: 0.0046s\n",
            "Batch 1550/1875 ( 82.7%) | Loss: 0.103032 | Acc: 96.96% | Batch time: 0.0052s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.102103 | Acc: 96.99% | Batch time: 0.0048s\n",
            "Batch 1650/1875 ( 88.0%) | Loss: 0.101396 | Acc: 97.03% | Batch time: 0.0051s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.100922 | Acc: 97.03% | Batch time: 0.0043s\n",
            "Batch 1750/1875 ( 93.3%) | Loss: 0.100371 | Acc: 97.04% | Batch time: 0.0044s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.100263 | Acc: 97.04% | Batch time: 0.0045s\n",
            "Batch 1850/1875 ( 98.7%) | Loss: 0.099998 | Acc: 97.05% | Batch time: 0.0045s\n",
            "\n",
            "Standard optimizer - Epoch 2 summary:\n",
            "Loss: 0.099733 | Accuracy: 97.06%\n",
            "⏱️ Adam training took 19.1611 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.040231 | Accuracy: 98.53% | Batch time: 0.0013s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.050991 | Accuracy: 98.48% | Batch time: 0.0013s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.054044 | Accuracy: 98.18% | Batch time: 0.0014s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.044828 | Accuracy: 98.54% | Batch time: 0.0014s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.040987 | Accuracy: 98.71% | Batch time: 0.0013s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.036303 | Accuracy: 98.84% | Batch time: 0.0012s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.039235 | Accuracy: 98.77%\n",
            "Time: 2.47s total, 0.0014s per batch\n",
            "⏱️ Adam evaluation took 2.4687 seconds\n",
            "Adam - Epoch 2:\n",
            "  Train Loss: 0.099733, Train Acc: 97.06%\n",
            "  Test Loss:  0.039235, Test Acc:  98.77%\n",
            "\n",
            "------------------------- AdamW Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 2\n",
            "Batches: 1875, Batch size: 32\n",
            "Batch   50/1875 (  2.7%) | Loss: 0.128130 | Acc: 96.26% | Batch time: 0.0044s\n",
            "Batch  100/1875 (  5.3%) | Loss: 0.126378 | Acc: 96.35% | Batch time: 0.0043s\n",
            "Batch  150/1875 (  8.0%) | Loss: 0.125474 | Acc: 96.46% | Batch time: 0.0044s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.132808 | Acc: 96.27% | Batch time: 0.0044s\n",
            "Batch  250/1875 ( 13.3%) | Loss: 0.133277 | Acc: 96.20% | Batch time: 0.0052s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.133753 | Acc: 96.19% | Batch time: 0.0044s\n",
            "Batch  350/1875 ( 18.7%) | Loss: 0.137276 | Acc: 96.14% | Batch time: 0.0033s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.138695 | Acc: 96.03% | Batch time: 0.0041s\n",
            "Batch  450/1875 ( 24.0%) | Loss: 0.135927 | Acc: 96.04% | Batch time: 0.0054s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.134827 | Acc: 96.08% | Batch time: 0.0044s\n",
            "Batch  550/1875 ( 29.3%) | Loss: 0.134248 | Acc: 96.05% | Batch time: 0.0042s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.134964 | Acc: 96.00% | Batch time: 0.0049s\n",
            "Batch  650/1875 ( 34.7%) | Loss: 0.134752 | Acc: 96.00% | Batch time: 0.0066s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.135783 | Acc: 95.97% | Batch time: 0.0042s\n",
            "Batch  750/1875 ( 40.0%) | Loss: 0.134045 | Acc: 96.01% | Batch time: 0.0043s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.132655 | Acc: 96.02% | Batch time: 0.0057s\n",
            "Batch  850/1875 ( 45.3%) | Loss: 0.131853 | Acc: 96.04% | Batch time: 0.0054s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.131629 | Acc: 96.05% | Batch time: 0.0041s\n",
            "Batch  950/1875 ( 50.7%) | Loss: 0.130956 | Acc: 96.08% | Batch time: 0.0039s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.130931 | Acc: 96.05% | Batch time: 0.0046s\n",
            "Batch 1050/1875 ( 56.0%) | Loss: 0.129688 | Acc: 96.10% | Batch time: 0.0047s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.129957 | Acc: 96.09% | Batch time: 0.0044s\n",
            "Batch 1150/1875 ( 61.3%) | Loss: 0.128912 | Acc: 96.12% | Batch time: 0.0046s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.128022 | Acc: 96.15% | Batch time: 0.0043s\n",
            "Batch 1250/1875 ( 66.7%) | Loss: 0.128420 | Acc: 96.13% | Batch time: 0.0050s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.127860 | Acc: 96.12% | Batch time: 0.0042s\n",
            "Batch 1350/1875 ( 72.0%) | Loss: 0.126974 | Acc: 96.14% | Batch time: 0.0042s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.126635 | Acc: 96.15% | Batch time: 0.0043s\n",
            "Batch 1450/1875 ( 77.3%) | Loss: 0.126367 | Acc: 96.17% | Batch time: 0.0042s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.126331 | Acc: 96.18% | Batch time: 0.0054s\n",
            "Batch 1550/1875 ( 82.7%) | Loss: 0.126238 | Acc: 96.20% | Batch time: 0.0059s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.126236 | Acc: 96.20% | Batch time: 0.0035s\n",
            "Batch 1650/1875 ( 88.0%) | Loss: 0.125652 | Acc: 96.22% | Batch time: 0.0035s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.124723 | Acc: 96.25% | Batch time: 0.0065s\n",
            "Batch 1750/1875 ( 93.3%) | Loss: 0.124342 | Acc: 96.26% | Batch time: 0.0043s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.123905 | Acc: 96.29% | Batch time: 0.0041s\n",
            "Batch 1850/1875 ( 98.7%) | Loss: 0.123321 | Acc: 96.31% | Batch time: 0.0043s\n",
            "\n",
            "Standard optimizer - Epoch 2 summary:\n",
            "Loss: 0.123378 | Accuracy: 96.30%\n",
            "⏱️ AdamW training took 19.3749 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.051734 | Accuracy: 98.47% | Batch time: 0.0013s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.058780 | Accuracy: 98.30% | Batch time: 0.0014s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.060845 | Accuracy: 98.10% | Batch time: 0.0013s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.049076 | Accuracy: 98.48% | Batch time: 0.0013s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.044093 | Accuracy: 98.66% | Batch time: 0.0015s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.039551 | Accuracy: 98.80% | Batch time: 0.0014s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.040590 | Accuracy: 98.73%\n",
            "Time: 2.48s total, 0.0014s per batch\n",
            "⏱️ AdamW evaluation took 2.4842 seconds\n",
            "AdamW - Epoch 2:\n",
            "  Train Loss: 0.123378, Train Acc: 96.30%\n",
            "  Test Loss:  0.040590, Test Acc:  98.73%\n",
            "\n",
            "------------------------- ImprovedTALT Optimizer -------------------------\n",
            "\n",
            "==================== EPOCH 2 TRAINING ====================\n",
            "Device: cuda, Batches: 1875, Batch size: 32\n",
            "🔄 Initial Memory - RAM: 1406.8MB, GPU: 37.2MB allocated, 62.0MB reserved\n",
            "Batch    0/1875 (  0.0%) | Loss: 0.055764 | Accuracy: 100.00% | Batch time: 0.0314s\n",
            "Step 1880 | Loss: 0.117050 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1880 took 0.0002s\n",
            "Step 1890 | Loss: 0.024520 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0034s, O: 0.0007s\n",
            "Batch   20/1875 (  1.1%) | Loss: 0.120707 | Accuracy: 96.73% | Batch time: 0.0325s\n",
            "Step 1900 | Loss: 0.062084 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 1900 took 0.0001s\n",
            "🧹 Memory cleanup at step 1900 took 0.2080s\n",
            "Step 1910 | Loss: 0.069232 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0148s, O: 0.0018s\n",
            "Batch   40/1875 (  2.1%) | Loss: 0.107497 | Accuracy: 97.18% | Batch time: 0.0208s\n",
            "Step 1920 | Loss: 0.282813 | GPU: 37.3MB / 68.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 1920 took 0.0000s\n",
            "Step 1930 | Loss: 0.057732 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0039s, O: 0.0007s\n",
            "Batch   60/1875 (  3.2%) | Loss: 0.106214 | Accuracy: 97.03% | Batch time: 0.0194s\n",
            "Step 1940 | Loss: 0.060063 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1940 took 0.0001s\n",
            "Step 1950 | Loss: 0.219581 | GPU: 37.3MB / 118.0MB | F: 0.0031s, B: 0.0021s, O: 0.0006s\n",
            "Batch   80/1875 (  4.3%) | Loss: 0.109411 | Accuracy: 96.95% | Batch time: 0.0198s\n",
            "Step 1960 | Loss: 0.121860 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0065s, O: 0.0008s\n",
            "🔄 Topology update at step 1960 took 0.0001s\n",
            "Step 1970 | Loss: 0.040096 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0022s, O: 0.0007s\n",
            "Batch  100/1875 (  5.3%) | Loss: 0.116104 | Accuracy: 96.72% | Batch time: 0.0226s\n",
            "Step 1980 | Loss: 0.021926 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0026s, O: 0.0009s\n",
            "🔄 Topology update at step 1980 took 0.0000s\n",
            "Step 1990 | Loss: 0.049991 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0022s, O: 0.0006s\n",
            "Batch  120/1875 (  6.4%) | Loss: 0.110378 | Accuracy: 96.82% | Batch time: 0.0391s\n",
            "Step 2000 | Loss: 0.037366 | GPU: 37.3MB / 68.0MB | F: 0.0027s, B: 0.0041s, O: 0.0007s\n",
            "🔄 Topology update at step 2000 took 0.0000s\n",
            "🧹 Memory cleanup at step 2000 took 0.1386s\n",
            "Step 2010 | Loss: 0.058905 | GPU: 37.3MB / 118.0MB | F: 0.0030s, B: 0.0025s, O: 0.0007s\n",
            "Batch  140/1875 (  7.5%) | Loss: 0.111042 | Accuracy: 96.79% | Batch time: 0.0210s\n",
            "Step 2020 | Loss: 0.151549 | GPU: 37.3MB / 68.0MB | F: 0.0030s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 2020 took 0.0000s\n",
            "Step 2030 | Loss: 0.045729 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0083s, O: 0.0007s\n",
            "Batch  160/1875 (  8.5%) | Loss: 0.109816 | Accuracy: 96.76% | Batch time: 0.0197s\n",
            "Step 2040 | Loss: 0.303686 | GPU: 37.3MB / 68.0MB | F: 0.0020s, B: 0.0111s, O: 0.0008s\n",
            "🔄 Topology update at step 2040 took 0.0001s\n",
            "Step 2050 | Loss: 0.104044 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0074s, O: 0.0007s\n",
            "Batch  180/1875 (  9.6%) | Loss: 0.110653 | Accuracy: 96.75% | Batch time: 0.0224s\n",
            "Step 2060 | Loss: 0.081158 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 2060 took 0.0000s\n",
            "Step 2070 | Loss: 0.052887 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0063s, O: 0.0006s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.108202 | Accuracy: 96.77% | Batch time: 0.0219s\n",
            "Step 2080 | Loss: 0.098958 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0063s, O: 0.0006s\n",
            "🔄 Topology update at step 2080 took 0.0000s\n",
            "Step 2090 | Loss: 0.052649 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0061s, O: 0.0015s\n",
            "Batch  220/1875 ( 11.7%) | Loss: 0.104971 | Accuracy: 96.86% | Batch time: 0.0191s\n",
            "Step 2100 | Loss: 0.049791 | GPU: 37.3MB / 68.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 2100 took 0.0000s\n",
            "🧹 Memory cleanup at step 2100 took 0.1357s\n",
            "Step 2110 | Loss: 0.108203 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0024s, O: 0.0007s\n",
            "Batch  240/1875 ( 12.8%) | Loss: 0.103227 | Accuracy: 96.90% | Batch time: 0.0287s\n",
            "Step 2120 | Loss: 0.305671 | GPU: 37.3MB / 68.0MB | F: 0.0030s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 2120 took 0.0000s\n",
            "Step 2130 | Loss: 0.107866 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "Batch  260/1875 ( 13.9%) | Loss: 0.104021 | Accuracy: 96.90% | Batch time: 0.0264s\n",
            "Step 2140 | Loss: 0.135495 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0026s, O: 0.0017s\n",
            "🔄 Topology update at step 2140 took 0.0000s\n",
            "Step 2150 | Loss: 0.030155 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Batch  280/1875 ( 14.9%) | Loss: 0.102470 | Accuracy: 96.98% | Batch time: 0.0278s\n",
            "Step 2160 | Loss: 0.222650 | GPU: 37.3MB / 68.0MB | F: 0.0027s, B: 0.0071s, O: 0.0007s\n",
            "🔄 Topology update at step 2160 took 0.0000s\n",
            "Step 2170 | Loss: 0.119717 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.103796 | Accuracy: 96.98% | Batch time: 0.0230s\n",
            "Step 2180 | Loss: 0.084978 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2180 took 0.0001s\n",
            "Step 2190 | Loss: 0.125905 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Batch  320/1875 ( 17.1%) | Loss: 0.101846 | Accuracy: 97.07% | Batch time: 0.0215s\n",
            "Step 2200 | Loss: 0.027663 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2200 took 0.0000s\n",
            "🧹 Memory cleanup at step 2200 took 0.1310s\n",
            "Step 2210 | Loss: 0.039335 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Batch  340/1875 ( 18.1%) | Loss: 0.102777 | Accuracy: 97.08% | Batch time: 0.0215s\n",
            "Step 2220 | Loss: 0.169911 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 2220 took 0.0001s\n",
            "Step 2230 | Loss: 0.043153 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Batch  360/1875 ( 19.2%) | Loss: 0.101797 | Accuracy: 97.11% | Batch time: 0.0290s\n",
            "Step 2240 | Loss: 0.074021 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2240 took 0.0001s\n",
            "Step 2250 | Loss: 0.126262 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Batch  380/1875 ( 20.3%) | Loss: 0.101232 | Accuracy: 97.14% | Batch time: 0.0263s\n",
            "Step 2260 | Loss: 0.060054 | GPU: 37.3MB / 68.0MB | F: 0.0015s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 2260 took 0.0000s\n",
            "Step 2270 | Loss: 0.212947 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.100786 | Accuracy: 97.13% | Batch time: 0.0222s\n",
            "Step 2280 | Loss: 0.022305 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2280 took 0.0001s\n",
            "Step 2290 | Loss: 0.019642 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0027s, O: 0.0007s\n",
            "Batch  420/1875 ( 22.4%) | Loss: 0.099735 | Accuracy: 97.13% | Batch time: 0.0226s\n",
            "Step 2300 | Loss: 0.033612 | GPU: 37.3MB / 68.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 2300 took 0.0000s\n",
            "🧹 Memory cleanup at step 2300 took 0.1472s\n",
            "Step 2310 | Loss: 0.070887 | GPU: 37.3MB / 118.0MB | F: 0.0042s, B: 0.0026s, O: 0.0005s\n",
            "Batch  440/1875 ( 23.5%) | Loss: 0.100236 | Accuracy: 97.12% | Batch time: 0.0262s\n",
            "Step 2320 | Loss: 0.122149 | GPU: 37.3MB / 68.0MB | F: 0.0013s, B: 0.0045s, O: 0.0008s\n",
            "🔄 Topology update at step 2320 took 0.0000s\n",
            "Step 2330 | Loss: 0.112042 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0082s, O: 0.0044s\n",
            "Batch  460/1875 ( 24.5%) | Loss: 0.101228 | Accuracy: 97.06% | Batch time: 0.0435s\n",
            "Step 2340 | Loss: 0.046787 | GPU: 37.3MB / 68.0MB | F: 0.0014s, B: 0.0097s, O: 0.0006s\n",
            "🔄 Topology update at step 2340 took 0.0001s\n",
            "Step 2350 | Loss: 0.151815 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0060s, O: 0.0006s\n",
            "Batch  480/1875 ( 25.6%) | Loss: 0.101895 | Accuracy: 97.04% | Batch time: 0.0356s\n",
            "Step 2360 | Loss: 0.090043 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 2360 took 0.0007s\n",
            "Step 2370 | Loss: 0.114280 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0034s, O: 0.0007s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.101049 | Accuracy: 97.05% | Batch time: 0.0393s\n",
            "Step 2380 | Loss: 0.062410 | GPU: 37.3MB / 68.0MB | F: 0.0016s, B: 0.0068s, O: 0.0005s\n",
            "🔄 Topology update at step 2380 took 0.0000s\n",
            "Step 2390 | Loss: 0.098500 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0032s, O: 0.0007s\n",
            "Batch  520/1875 ( 27.7%) | Loss: 0.101729 | Accuracy: 97.05% | Batch time: 0.0355s\n",
            "Step 2400 | Loss: 0.061160 | GPU: 37.3MB / 68.0MB | F: 0.0013s, B: 0.0109s, O: 0.0006s\n",
            "🔄 Topology update at step 2400 took 0.0000s\n",
            "🧹 Memory cleanup at step 2400 took 0.1773s\n",
            "Step 2410 | Loss: 0.047004 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0062s, O: 0.0035s\n",
            "Batch  540/1875 ( 28.8%) | Loss: 0.100264 | Accuracy: 97.12% | Batch time: 0.0384s\n",
            "Step 2420 | Loss: 0.283179 | GPU: 37.3MB / 68.0MB | F: 0.0027s, B: 0.0075s, O: 0.0007s\n",
            "🔄 Topology update at step 2420 took 0.0001s\n",
            "Step 2430 | Loss: 0.093662 | GPU: 37.3MB / 118.0MB | F: 0.0044s, B: 0.0074s, O: 0.0006s\n",
            "Batch  560/1875 ( 29.9%) | Loss: 0.099768 | Accuracy: 97.12% | Batch time: 0.0283s\n",
            "Step 2440 | Loss: 0.028337 | GPU: 37.3MB / 68.0MB | F: 0.0012s, B: 0.0031s, O: 0.0007s\n",
            "🔄 Topology update at step 2440 took 0.0028s\n",
            "Step 2450 | Loss: 0.218707 | GPU: 37.3MB / 118.0MB | F: 0.0028s, B: 0.0024s, O: 0.0006s\n",
            "Batch  580/1875 ( 30.9%) | Loss: 0.099345 | Accuracy: 97.12% | Batch time: 0.0203s\n",
            "Step 2460 | Loss: 0.339750 | GPU: 37.3MB / 68.0MB | F: 0.0016s, B: 0.0023s, O: 0.0021s\n",
            "🔄 Topology update at step 2460 took 0.0000s\n",
            "Step 2470 | Loss: 0.069017 | GPU: 37.3MB / 118.0MB | F: 0.0028s, B: 0.0024s, O: 0.0006s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.101137 | Accuracy: 97.11% | Batch time: 0.0231s\n",
            "Step 2480 | Loss: 0.161126 | GPU: 37.3MB / 68.0MB | F: 0.0023s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2480 took 0.0001s\n",
            "Step 2490 | Loss: 0.031886 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0091s, O: 0.0007s\n",
            "Batch  620/1875 ( 33.1%) | Loss: 0.100400 | Accuracy: 97.15% | Batch time: 0.0213s\n",
            "Step 2500 | Loss: 0.054390 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 2500 took 0.0000s\n",
            "🧹 Memory cleanup at step 2500 took 0.1351s\n",
            "Step 2510 | Loss: 0.128863 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0022s, O: 0.0007s\n",
            "Batch  640/1875 ( 34.1%) | Loss: 0.100104 | Accuracy: 97.14% | Batch time: 0.0206s\n",
            "Step 2520 | Loss: 0.120069 | GPU: 37.3MB / 68.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 2520 took 0.0000s\n",
            "Step 2530 | Loss: 0.055874 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0024s, O: 0.0007s\n",
            "Batch  660/1875 ( 35.2%) | Loss: 0.099270 | Accuracy: 97.16% | Batch time: 0.0237s\n",
            "Step 2540 | Loss: 0.309470 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 2540 took 0.0000s\n",
            "Step 2550 | Loss: 0.086743 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0068s, O: 0.0024s\n",
            "Batch  680/1875 ( 36.3%) | Loss: 0.098857 | Accuracy: 97.18% | Batch time: 0.0230s\n",
            "Step 2560 | Loss: 0.100118 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0078s, O: 0.0006s\n",
            "🔄 Topology update at step 2560 took 0.0001s\n",
            "Step 2570 | Loss: 0.116311 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.099525 | Accuracy: 97.14% | Batch time: 0.0190s\n",
            "Step 2580 | Loss: 0.036157 | GPU: 37.3MB / 68.0MB | F: 0.0015s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 2580 took 0.0000s\n",
            "Step 2590 | Loss: 0.148292 | GPU: 37.3MB / 118.0MB | F: 0.0027s, B: 0.0023s, O: 0.0006s\n",
            "Batch  720/1875 ( 38.4%) | Loss: 0.099778 | Accuracy: 97.14% | Batch time: 0.0228s\n",
            "Step 2600 | Loss: 0.011254 | GPU: 37.3MB / 68.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 2600 took 0.0000s\n",
            "🧹 Memory cleanup at step 2600 took 0.1366s\n",
            "Step 2610 | Loss: 0.402195 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Batch  740/1875 ( 39.5%) | Loss: 0.099507 | Accuracy: 97.15% | Batch time: 0.0225s\n",
            "Step 2620 | Loss: 0.120439 | GPU: 37.3MB / 68.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 2620 took 0.0000s\n",
            "Step 2630 | Loss: 0.221252 | GPU: 37.3MB / 118.0MB | F: 0.0036s, B: 0.0024s, O: 0.0006s\n",
            "Batch  760/1875 ( 40.5%) | Loss: 0.098941 | Accuracy: 97.15% | Batch time: 0.0223s\n",
            "Step 2640 | Loss: 0.146632 | GPU: 37.3MB / 68.0MB | F: 0.0073s, B: 0.0049s, O: 0.0026s\n",
            "🔄 Topology update at step 2640 took 0.0000s\n",
            "Step 2650 | Loss: 0.140865 | GPU: 37.3MB / 118.0MB | F: 0.0023s, B: 0.0026s, O: 0.0006s\n",
            "Batch  780/1875 ( 41.6%) | Loss: 0.099129 | Accuracy: 97.15% | Batch time: 0.0206s\n",
            "Step 2660 | Loss: 0.167415 | GPU: 37.3MB / 68.0MB | F: 0.0015s, B: 0.0023s, O: 0.0011s\n",
            "🔄 Topology update at step 2660 took 0.0000s\n",
            "Step 2670 | Loss: 0.071242 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0022s, O: 0.0006s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.099206 | Accuracy: 97.14% | Batch time: 0.0209s\n",
            "Step 2680 | Loss: 0.032523 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0053s, O: 0.0011s\n",
            "🔄 Topology update at step 2680 took 0.0000s\n",
            "Step 2690 | Loss: 0.071642 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0022s, O: 0.0006s\n",
            "Batch  820/1875 ( 43.7%) | Loss: 0.099386 | Accuracy: 97.13% | Batch time: 0.0220s\n",
            "Step 2700 | Loss: 0.189380 | GPU: 37.3MB / 68.0MB | F: 0.0028s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2700 took 0.0000s\n",
            "🧹 Memory cleanup at step 2700 took 0.1421s\n",
            "Step 2710 | Loss: 0.009456 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0107s, O: 0.0012s\n",
            "Batch  840/1875 ( 44.8%) | Loss: 0.099509 | Accuracy: 97.13% | Batch time: 0.0266s\n",
            "Step 2720 | Loss: 0.371296 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 2720 took 0.0000s\n",
            "Step 2730 | Loss: 0.068898 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "Batch  860/1875 ( 45.9%) | Loss: 0.100035 | Accuracy: 97.11% | Batch time: 0.0211s\n",
            "Step 2740 | Loss: 0.228948 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 2740 took 0.0001s\n",
            "Step 2750 | Loss: 0.095059 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0024s, O: 0.0007s\n",
            "Batch  880/1875 ( 46.9%) | Loss: 0.100337 | Accuracy: 97.10% | Batch time: 0.0273s\n",
            "Step 2760 | Loss: 0.113813 | GPU: 37.3MB / 68.0MB | F: 0.0016s, B: 0.0039s, O: 0.0006s\n",
            "🔄 Topology update at step 2760 took 0.0025s\n",
            "Step 2770 | Loss: 0.119896 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.100939 | Accuracy: 97.09% | Batch time: 0.0249s\n",
            "Step 2780 | Loss: 0.019557 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0043s, O: 0.0007s\n",
            "🔄 Topology update at step 2780 took 0.0001s\n",
            "Step 2790 | Loss: 0.123590 | GPU: 37.3MB / 118.0MB | F: 0.0027s, B: 0.0024s, O: 0.0007s\n",
            "Batch  920/1875 ( 49.1%) | Loss: 0.100947 | Accuracy: 97.07% | Batch time: 0.0299s\n",
            "Step 2800 | Loss: 0.025996 | GPU: 37.3MB / 68.0MB | F: 0.0024s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2800 took 0.0001s\n",
            "🧹 Memory cleanup at step 2800 took 0.1497s\n",
            "Step 2810 | Loss: 0.045947 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0028s, O: 0.0008s\n",
            "Batch  940/1875 ( 50.1%) | Loss: 0.100406 | Accuracy: 97.09% | Batch time: 0.0223s\n",
            "Step 2820 | Loss: 0.264514 | GPU: 37.3MB / 68.0MB | F: 0.0027s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 2820 took 0.0000s\n",
            "Step 2830 | Loss: 0.022222 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "Batch  960/1875 ( 51.2%) | Loss: 0.100173 | Accuracy: 97.10% | Batch time: 0.0310s\n",
            "Step 2840 | Loss: 0.012176 | GPU: 37.3MB / 68.0MB | F: 0.0016s, B: 0.0059s, O: 0.0007s\n",
            "🔄 Topology update at step 2840 took 0.0000s\n",
            "Step 2850 | Loss: 0.257754 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Batch  980/1875 ( 52.3%) | Loss: 0.100654 | Accuracy: 97.08% | Batch time: 0.0261s\n",
            "Step 2860 | Loss: 0.096436 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2860 took 0.0000s\n",
            "Step 2870 | Loss: 0.032292 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.099940 | Accuracy: 97.10% | Batch time: 0.0295s\n",
            "Step 2880 | Loss: 0.034220 | GPU: 37.3MB / 68.0MB | F: 0.0100s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2880 took 0.0001s\n",
            "Step 2890 | Loss: 0.201489 | GPU: 37.3MB / 118.0MB | F: 0.0024s, B: 0.0024s, O: 0.0006s\n",
            "Batch 1020/1875 ( 54.4%) | Loss: 0.099479 | Accuracy: 97.11% | Batch time: 0.0207s\n",
            "Step 2900 | Loss: 0.080318 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 2900 took 0.0000s\n",
            "🧹 Memory cleanup at step 2900 took 0.1364s\n",
            "Step 2910 | Loss: 0.005909 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0041s, O: 0.0007s\n",
            "Batch 1040/1875 ( 55.5%) | Loss: 0.099759 | Accuracy: 97.12% | Batch time: 0.0221s\n",
            "Step 2920 | Loss: 0.065851 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0078s, O: 0.0020s\n",
            "🔄 Topology update at step 2920 took 0.0000s\n",
            "Step 2930 | Loss: 0.085055 | GPU: 37.3MB / 118.0MB | F: 0.0057s, B: 0.0023s, O: 0.0007s\n",
            "Batch 1060/1875 ( 56.5%) | Loss: 0.099850 | Accuracy: 97.11% | Batch time: 0.0223s\n",
            "Step 2940 | Loss: 0.072256 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0027s, O: 0.0012s\n",
            "🔄 Topology update at step 2940 took 0.0000s\n",
            "Step 2950 | Loss: 0.104546 | GPU: 37.3MB / 118.0MB | F: 0.0038s, B: 0.0024s, O: 0.0006s\n",
            "Batch 1080/1875 ( 57.6%) | Loss: 0.099715 | Accuracy: 97.11% | Batch time: 0.0324s\n",
            "Step 2960 | Loss: 0.169269 | GPU: 37.3MB / 68.0MB | F: 0.0026s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 2960 took 0.0001s\n",
            "Step 2970 | Loss: 0.098876 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.099672 | Accuracy: 97.10% | Batch time: 0.0245s\n",
            "Step 2980 | Loss: 0.117349 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 2980 took 0.0001s\n",
            "Step 2990 | Loss: 0.218501 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0057s, O: 0.0017s\n",
            "Batch 1120/1875 ( 59.7%) | Loss: 0.099313 | Accuracy: 97.12% | Batch time: 0.0200s\n",
            "Step 3000 | Loss: 0.046407 | GPU: 37.3MB / 68.0MB | F: 0.0032s, B: 0.0024s, O: 0.0023s\n",
            "🔄 Topology update at step 3000 took 0.0006s\n",
            "🧹 Memory cleanup at step 3000 took 0.1413s\n",
            "Step 3010 | Loss: 0.039427 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0024s, O: 0.0008s\n",
            "Batch 1140/1875 ( 60.8%) | Loss: 0.099683 | Accuracy: 97.11% | Batch time: 0.0244s\n",
            "Step 3020 | Loss: 0.070575 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0046s, O: 0.0006s\n",
            "🔄 Topology update at step 3020 took 0.0000s\n",
            "Step 3030 | Loss: 0.014809 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0033s, O: 0.0017s\n",
            "Batch 1160/1875 ( 61.9%) | Loss: 0.099310 | Accuracy: 97.13% | Batch time: 0.0237s\n",
            "Step 3040 | Loss: 0.031622 | GPU: 37.3MB / 68.0MB | F: 0.0016s, B: 0.0034s, O: 0.0007s\n",
            "🔄 Topology update at step 3040 took 0.0001s\n",
            "Step 3050 | Loss: 0.206438 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0010s\n",
            "Batch 1180/1875 ( 62.9%) | Loss: 0.099239 | Accuracy: 97.12% | Batch time: 0.0224s\n",
            "Step 3060 | Loss: 0.084762 | GPU: 37.3MB / 68.0MB | F: 0.0031s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 3060 took 0.0001s\n",
            "Step 3070 | Loss: 0.046790 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0029s, O: 0.0008s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.099185 | Accuracy: 97.12% | Batch time: 0.0263s\n",
            "Step 3080 | Loss: 0.067564 | GPU: 37.3MB / 68.0MB | F: 0.0031s, B: 0.0026s, O: 0.0012s\n",
            "🔄 Topology update at step 3080 took 0.0000s\n",
            "Step 3090 | Loss: 0.037398 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0032s, O: 0.0007s\n",
            "Batch 1220/1875 ( 65.1%) | Loss: 0.099057 | Accuracy: 97.12% | Batch time: 0.0293s\n",
            "Step 3100 | Loss: 0.162576 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0024s, O: 0.0041s\n",
            "🔄 Topology update at step 3100 took 0.0001s\n",
            "🧹 Memory cleanup at step 3100 took 0.1567s\n",
            "Step 3110 | Loss: 0.089489 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "Batch 1240/1875 ( 66.1%) | Loss: 0.099006 | Accuracy: 97.13% | Batch time: 0.0331s\n",
            "Step 3120 | Loss: 0.085305 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 3120 took 0.0001s\n",
            "Step 3130 | Loss: 0.011682 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1260/1875 ( 67.2%) | Loss: 0.098731 | Accuracy: 97.14% | Batch time: 0.0238s\n",
            "Step 3140 | Loss: 0.018784 | GPU: 37.3MB / 68.0MB | F: 0.0033s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3140 took 0.0000s\n",
            "Step 3150 | Loss: 0.015112 | GPU: 37.3MB / 118.0MB | F: 0.0028s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1280/1875 ( 68.3%) | Loss: 0.098469 | Accuracy: 97.15% | Batch time: 0.0223s\n",
            "Step 3160 | Loss: 0.167835 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 3160 took 0.0000s\n",
            "Step 3170 | Loss: 0.035852 | GPU: 37.3MB / 118.0MB | F: 0.0038s, B: 0.0024s, O: 0.0007s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.098626 | Accuracy: 97.16% | Batch time: 0.0223s\n",
            "Step 3180 | Loss: 0.165692 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 3180 took 0.0001s\n",
            "Step 3190 | Loss: 0.039271 | GPU: 37.3MB / 118.0MB | F: 0.0037s, B: 0.0070s, O: 0.0007s\n",
            "Batch 1320/1875 ( 70.4%) | Loss: 0.098800 | Accuracy: 97.15% | Batch time: 0.0425s\n",
            "Step 3200 | Loss: 0.285078 | GPU: 37.3MB / 68.0MB | F: 0.0019s, B: 0.0036s, O: 0.0006s\n",
            "🔄 Topology update at step 3200 took 0.0001s\n",
            "🧹 Memory cleanup at step 3200 took 0.2091s\n",
            "Step 3210 | Loss: 0.161690 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0047s, O: 0.0006s\n",
            "Batch 1340/1875 ( 71.5%) | Loss: 0.099076 | Accuracy: 97.15% | Batch time: 0.0231s\n",
            "Step 3220 | Loss: 0.054502 | GPU: 37.3MB / 68.0MB | F: 0.0015s, B: 0.0018s, O: 0.0007s\n",
            "🔄 Topology update at step 3220 took 0.0001s\n",
            "Step 3230 | Loss: 0.025856 | GPU: 37.3MB / 118.0MB | F: 0.0013s, B: 0.0062s, O: 0.0006s\n",
            "Batch 1360/1875 ( 72.5%) | Loss: 0.098992 | Accuracy: 97.15% | Batch time: 0.0403s\n",
            "Step 3240 | Loss: 0.029681 | GPU: 37.3MB / 68.0MB | F: 0.0012s, B: 0.0107s, O: 0.0005s\n",
            "🔄 Topology update at step 3240 took 0.0000s\n",
            "Step 3250 | Loss: 0.032207 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0075s, O: 0.0007s\n",
            "Batch 1380/1875 ( 73.6%) | Loss: 0.098821 | Accuracy: 97.15% | Batch time: 0.0339s\n",
            "Step 3260 | Loss: 0.023026 | GPU: 37.3MB / 68.0MB | F: 0.0014s, B: 0.0051s, O: 0.0007s\n",
            "🔄 Topology update at step 3260 took 0.0000s\n",
            "Step 3270 | Loss: 0.245817 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0018s, O: 0.0007s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.098349 | Accuracy: 97.16% | Batch time: 0.0371s\n",
            "Step 3280 | Loss: 0.002823 | GPU: 37.3MB / 68.0MB | F: 0.0013s, B: 0.0090s, O: 0.0007s\n",
            "🔄 Topology update at step 3280 took 0.0021s\n",
            "Step 3290 | Loss: 0.303613 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0016s, O: 0.0007s\n",
            "Batch 1420/1875 ( 75.7%) | Loss: 0.098357 | Accuracy: 97.17% | Batch time: 0.0464s\n",
            "Step 3300 | Loss: 0.190681 | GPU: 37.3MB / 68.0MB | F: 0.0058s, B: 0.0056s, O: 0.0006s\n",
            "🔄 Topology update at step 3300 took 0.0000s\n",
            "🧹 Memory cleanup at step 3300 took 0.1872s\n",
            "Step 3310 | Loss: 0.052709 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0109s, O: 0.0005s\n",
            "Batch 1440/1875 ( 76.8%) | Loss: 0.098262 | Accuracy: 97.16% | Batch time: 0.0270s\n",
            "Step 3320 | Loss: 0.021996 | GPU: 37.3MB / 68.0MB | F: 0.0027s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 3320 took 0.0000s\n",
            "Step 3330 | Loss: 0.025566 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0079s, O: 0.0016s\n",
            "Batch 1460/1875 ( 77.9%) | Loss: 0.097926 | Accuracy: 97.18% | Batch time: 0.0277s\n",
            "Step 3340 | Loss: 0.230001 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 3340 took 0.0000s\n",
            "Step 3350 | Loss: 0.165759 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Batch 1480/1875 ( 78.9%) | Loss: 0.098060 | Accuracy: 97.18% | Batch time: 0.0302s\n",
            "Step 3360 | Loss: 0.091526 | GPU: 37.3MB / 68.0MB | F: 0.0034s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 3360 took 0.0001s\n",
            "Step 3370 | Loss: 0.084848 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0024s, O: 0.0007s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.097993 | Accuracy: 97.17% | Batch time: 0.0237s\n",
            "Step 3380 | Loss: 0.091787 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0037s, O: 0.0007s\n",
            "🔄 Topology update at step 3380 took 0.0001s\n",
            "Step 3390 | Loss: 0.082420 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0053s, O: 0.0008s\n",
            "Batch 1520/1875 ( 81.1%) | Loss: 0.097832 | Accuracy: 97.18% | Batch time: 0.0204s\n",
            "Step 3400 | Loss: 0.075372 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0026s, O: 0.0013s\n",
            "🔄 Topology update at step 3400 took 0.0001s\n",
            "🧹 Memory cleanup at step 3400 took 0.1491s\n",
            "Step 3410 | Loss: 0.215298 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0037s, O: 0.0007s\n",
            "Batch 1540/1875 ( 82.1%) | Loss: 0.097957 | Accuracy: 97.19% | Batch time: 0.0457s\n",
            "Step 3420 | Loss: 0.133190 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0024s, O: 0.0008s\n",
            "🔄 Topology update at step 3420 took 0.0001s\n",
            "Step 3430 | Loss: 0.013881 | GPU: 37.3MB / 118.0MB | F: 0.0024s, B: 0.0053s, O: 0.0007s\n",
            "Batch 1560/1875 ( 83.2%) | Loss: 0.097576 | Accuracy: 97.20% | Batch time: 0.0214s\n",
            "Step 3440 | Loss: 0.084123 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 3440 took 0.0001s\n",
            "Step 3450 | Loss: 0.212581 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0096s, O: 0.0018s\n",
            "Batch 1580/1875 ( 84.3%) | Loss: 0.097340 | Accuracy: 97.21% | Batch time: 0.0304s\n",
            "Step 3460 | Loss: 0.103801 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 3460 took 0.0000s\n",
            "Step 3470 | Loss: 0.109925 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0027s, O: 0.0014s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.097464 | Accuracy: 97.20% | Batch time: 0.0227s\n",
            "Step 3480 | Loss: 0.049225 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0025s, O: 0.0012s\n",
            "🔄 Topology update at step 3480 took 0.0000s\n",
            "Step 3490 | Loss: 0.214814 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Batch 1620/1875 ( 86.4%) | Loss: 0.097135 | Accuracy: 97.22% | Batch time: 0.0217s\n",
            "Step 3500 | Loss: 0.176632 | GPU: 37.3MB / 68.0MB | F: 0.0024s, B: 0.0032s, O: 0.0008s\n",
            "🔄 Topology update at step 3500 took 0.0001s\n",
            "🧹 Memory cleanup at step 3500 took 0.1444s\n",
            "Step 3510 | Loss: 0.036979 | GPU: 37.3MB / 118.0MB | F: 0.0030s, B: 0.0030s, O: 0.0009s\n",
            "Batch 1640/1875 ( 87.5%) | Loss: 0.097102 | Accuracy: 97.22% | Batch time: 0.0318s\n",
            "Step 3520 | Loss: 0.063357 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0042s, O: 0.0025s\n",
            "🔄 Topology update at step 3520 took 0.0001s\n",
            "Step 3530 | Loss: 0.055325 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1660/1875 ( 88.5%) | Loss: 0.096701 | Accuracy: 97.23% | Batch time: 0.0219s\n",
            "Step 3540 | Loss: 0.141974 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0084s, O: 0.0013s\n",
            "🔄 Topology update at step 3540 took 0.0000s\n",
            "Step 3550 | Loss: 0.038453 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0031s, O: 0.0096s\n",
            "Batch 1680/1875 ( 89.6%) | Loss: 0.096262 | Accuracy: 97.24% | Batch time: 0.0241s\n",
            "Step 3560 | Loss: 0.128769 | GPU: 37.3MB / 68.0MB | F: 0.0020s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3560 took 0.0001s\n",
            "Step 3570 | Loss: 0.092321 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0023s, O: 0.0007s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.096092 | Accuracy: 97.25% | Batch time: 0.0229s\n",
            "Step 3580 | Loss: 0.086710 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3580 took 0.0000s\n",
            "Step 3590 | Loss: 0.021745 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1720/1875 ( 91.7%) | Loss: 0.096370 | Accuracy: 97.24% | Batch time: 0.0229s\n",
            "Step 3600 | Loss: 0.046775 | GPU: 37.3MB / 68.0MB | F: 0.0020s, B: 0.0027s, O: 0.0010s\n",
            "🔄 Topology update at step 3600 took 0.0000s\n",
            "🧹 Memory cleanup at step 3600 took 0.1508s\n",
            "Step 3610 | Loss: 0.127455 | GPU: 37.3MB / 118.0MB | F: 0.0023s, B: 0.0028s, O: 0.0009s\n",
            "Batch 1740/1875 ( 92.8%) | Loss: 0.096711 | Accuracy: 97.24% | Batch time: 0.0261s\n",
            "Step 3620 | Loss: 0.230319 | GPU: 37.3MB / 68.0MB | F: 0.0020s, B: 0.0026s, O: 0.0011s\n",
            "🔄 Topology update at step 3620 took 0.0000s\n",
            "Step 3630 | Loss: 0.054369 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Batch 1760/1875 ( 93.9%) | Loss: 0.097409 | Accuracy: 97.21% | Batch time: 0.0228s\n",
            "Step 3640 | Loss: 0.025012 | GPU: 37.3MB / 68.0MB | F: 0.0017s, B: 0.0032s, O: 0.0035s\n",
            "🔄 Topology update at step 3640 took 0.0000s\n",
            "Step 3650 | Loss: 0.058316 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "Batch 1780/1875 ( 94.9%) | Loss: 0.097167 | Accuracy: 97.22% | Batch time: 0.0301s\n",
            "Step 3660 | Loss: 0.297305 | GPU: 37.3MB / 68.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 3660 took 0.0001s\n",
            "Step 3670 | Loss: 0.009365 | GPU: 37.3MB / 118.0MB | F: 0.0037s, B: 0.0024s, O: 0.0007s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.096996 | Accuracy: 97.23% | Batch time: 0.0258s\n",
            "Step 3680 | Loss: 0.031822 | GPU: 37.3MB / 68.0MB | F: 0.0018s, B: 0.0046s, O: 0.0007s\n",
            "🔄 Topology update at step 3680 took 0.0001s\n",
            "Step 3690 | Loss: 0.011742 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1820/1875 ( 97.1%) | Loss: 0.096942 | Accuracy: 97.23% | Batch time: 0.0323s\n",
            "Step 3700 | Loss: 0.055230 | GPU: 37.3MB / 68.0MB | F: 0.0041s, B: 0.0028s, O: 0.0009s\n",
            "🔄 Topology update at step 3700 took 0.0001s\n",
            "🧹 Memory cleanup at step 3700 took 0.1688s\n",
            "Step 3710 | Loss: 0.120368 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0028s, O: 0.0008s\n",
            "Batch 1840/1875 ( 98.1%) | Loss: 0.096655 | Accuracy: 97.24% | Batch time: 0.0300s\n",
            "Step 3720 | Loss: 0.030183 | GPU: 37.3MB / 68.0MB | F: 0.0021s, B: 0.0036s, O: 0.0018s\n",
            "🔄 Topology update at step 3720 took 0.0001s\n",
            "Step 3730 | Loss: 0.022643 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0029s, O: 0.0008s\n",
            "Batch 1860/1875 ( 99.2%) | Loss: 0.096330 | Accuracy: 97.26% | Batch time: 0.0301s\n",
            "Step 3740 | Loss: 0.052063 | GPU: 37.3MB / 68.0MB | F: 0.0049s, B: 0.0031s, O: 0.0010s\n",
            "🔄 Topology update at step 3740 took 0.0001s\n",
            "Step 3750 | Loss: 0.142630 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0021s, O: 0.0006s\n",
            "\n",
            "-------------------- EPOCH 2 SUMMARY --------------------\n",
            "Loss: 0.096292 | Accuracy: 97.26%\n",
            "Time: 27.50s total, 0.0127s per batch\n",
            "🔄 Final Memory - RAM: 1406.8MB, GPU: 37.3MB allocated, 118.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=37.3, peak=37.3\n",
            "===============================\n",
            "\n",
            "⏱️ ImprovedTALT training took 27.5043 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.061814 | Accuracy: 97.79% | Batch time: 0.0017s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.063956 | Accuracy: 97.83% | Batch time: 0.0017s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.067209 | Accuracy: 97.76% | Batch time: 0.0014s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.059214 | Accuracy: 97.98% | Batch time: 0.0013s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.052245 | Accuracy: 98.26% | Batch time: 0.0016s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.047275 | Accuracy: 98.42% | Batch time: 0.0015s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.049554 | Accuracy: 98.34%\n",
            "Time: 2.63s total, 0.0018s per batch\n",
            "⏱️ ImprovedTALT evaluation took 2.6277 seconds\n",
            "ImprovedTALT - Epoch 2:\n",
            "  Train Loss: 0.096292, Train Acc: 97.26%\n",
            "  Test Loss:  0.049554, Test Acc:  98.34%\n",
            "\n",
            "Epoch 2 completed in 95.19s\n",
            "Results saved to ./results/mnist/epoch_2_results.json\n",
            "\n",
            "============================== EPOCH 3/3 ==============================\n",
            "\n",
            "------------------------- SGD Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 3\n",
            "Batches: 1875, Batch size: 32\n",
            "Batch   50/1875 (  2.7%) | Loss: 0.111084 | Acc: 96.88% | Batch time: 0.0050s\n",
            "Batch  100/1875 (  5.3%) | Loss: 0.106555 | Acc: 97.06% | Batch time: 0.0135s\n",
            "Batch  150/1875 (  8.0%) | Loss: 0.096338 | Acc: 97.27% | Batch time: 0.0042s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.090315 | Acc: 97.34% | Batch time: 0.0081s\n",
            "Batch  250/1875 ( 13.3%) | Loss: 0.094575 | Acc: 97.24% | Batch time: 0.0066s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.096405 | Acc: 97.10% | Batch time: 0.0120s\n",
            "Batch  350/1875 ( 18.7%) | Loss: 0.093212 | Acc: 97.18% | Batch time: 0.0050s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.093159 | Acc: 97.23% | Batch time: 0.0048s\n",
            "Batch  450/1875 ( 24.0%) | Loss: 0.091018 | Acc: 97.28% | Batch time: 0.0046s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.089365 | Acc: 97.32% | Batch time: 0.0046s\n",
            "Batch  550/1875 ( 29.3%) | Loss: 0.086514 | Acc: 97.37% | Batch time: 0.0058s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.087201 | Acc: 97.36% | Batch time: 0.0048s\n",
            "Batch  650/1875 ( 34.7%) | Loss: 0.085555 | Acc: 97.44% | Batch time: 0.0039s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.084763 | Acc: 97.47% | Batch time: 0.0051s\n",
            "Batch  750/1875 ( 40.0%) | Loss: 0.084823 | Acc: 97.47% | Batch time: 0.0046s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.084140 | Acc: 97.50% | Batch time: 0.0046s\n",
            "Batch  850/1875 ( 45.3%) | Loss: 0.083551 | Acc: 97.52% | Batch time: 0.0056s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.083255 | Acc: 97.54% | Batch time: 0.0046s\n",
            "Batch  950/1875 ( 50.7%) | Loss: 0.083273 | Acc: 97.55% | Batch time: 0.0132s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.082520 | Acc: 97.55% | Batch time: 0.0050s\n",
            "Batch 1050/1875 ( 56.0%) | Loss: 0.082999 | Acc: 97.54% | Batch time: 0.0047s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.082978 | Acc: 97.53% | Batch time: 0.0052s\n",
            "Batch 1150/1875 ( 61.3%) | Loss: 0.084101 | Acc: 97.50% | Batch time: 0.0061s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.083563 | Acc: 97.52% | Batch time: 0.0041s\n",
            "Batch 1250/1875 ( 66.7%) | Loss: 0.083980 | Acc: 97.54% | Batch time: 0.0046s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.083640 | Acc: 97.55% | Batch time: 0.0061s\n",
            "Batch 1350/1875 ( 72.0%) | Loss: 0.083845 | Acc: 97.56% | Batch time: 0.0030s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.083032 | Acc: 97.59% | Batch time: 0.0101s\n",
            "Batch 1450/1875 ( 77.3%) | Loss: 0.083429 | Acc: 97.59% | Batch time: 0.0132s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.083440 | Acc: 97.60% | Batch time: 0.0047s\n",
            "Batch 1550/1875 ( 82.7%) | Loss: 0.083635 | Acc: 97.61% | Batch time: 0.0041s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.083658 | Acc: 97.63% | Batch time: 0.0045s\n",
            "Batch 1650/1875 ( 88.0%) | Loss: 0.083512 | Acc: 97.64% | Batch time: 0.0129s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.082775 | Acc: 97.65% | Batch time: 0.0044s\n",
            "Batch 1750/1875 ( 93.3%) | Loss: 0.082666 | Acc: 97.65% | Batch time: 0.0043s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.083024 | Acc: 97.65% | Batch time: 0.0041s\n",
            "Batch 1850/1875 ( 98.7%) | Loss: 0.083389 | Acc: 97.64% | Batch time: 0.0046s\n",
            "\n",
            "Standard optimizer - Epoch 3 summary:\n",
            "Loss: 0.083179 | Accuracy: 97.65%\n",
            "⏱️ SGD training took 20.3579 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.042898 | Accuracy: 98.65% | Batch time: 0.0015s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.051720 | Accuracy: 98.30% | Batch time: 0.0017s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.049691 | Accuracy: 98.30% | Batch time: 0.0018s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.041858 | Accuracy: 98.57% | Batch time: 0.0013s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.037021 | Accuracy: 98.75% | Batch time: 0.0014s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.033785 | Accuracy: 98.88% | Batch time: 0.0016s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.035265 | Accuracy: 98.84%\n",
            "Time: 2.62s total, 0.0017s per batch\n",
            "⏱️ SGD evaluation took 2.6247 seconds\n",
            "SGD - Epoch 3:\n",
            "  Train Loss: 0.083179, Train Acc: 97.65%\n",
            "  Test Loss:  0.035265, Test Acc:  98.84%\n",
            "\n",
            "------------------------- Adam Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 3\n",
            "Batches: 1875, Batch size: 32\n",
            "Batch   50/1875 (  2.7%) | Loss: 0.063907 | Acc: 97.73% | Batch time: 0.0048s\n",
            "Batch  100/1875 (  5.3%) | Loss: 0.073226 | Acc: 97.43% | Batch time: 0.0111s\n",
            "Batch  150/1875 (  8.0%) | Loss: 0.072281 | Acc: 97.58% | Batch time: 0.0048s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.073432 | Acc: 97.53% | Batch time: 0.0105s\n",
            "Batch  250/1875 ( 13.3%) | Loss: 0.074589 | Acc: 97.46% | Batch time: 0.0063s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.077777 | Acc: 97.38% | Batch time: 0.0045s\n",
            "Batch  350/1875 ( 18.7%) | Loss: 0.078197 | Acc: 97.40% | Batch time: 0.0076s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.076966 | Acc: 97.48% | Batch time: 0.0061s\n",
            "Batch  450/1875 ( 24.0%) | Loss: 0.077090 | Acc: 97.49% | Batch time: 0.0069s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.078326 | Acc: 97.51% | Batch time: 0.0068s\n",
            "Batch  550/1875 ( 29.3%) | Loss: 0.076723 | Acc: 97.54% | Batch time: 0.0069s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.077409 | Acc: 97.51% | Batch time: 0.0080s\n",
            "Batch  650/1875 ( 34.7%) | Loss: 0.076155 | Acc: 97.56% | Batch time: 0.0045s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.076750 | Acc: 97.55% | Batch time: 0.0064s\n",
            "Batch  750/1875 ( 40.0%) | Loss: 0.077591 | Acc: 97.55% | Batch time: 0.0058s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.075911 | Acc: 97.62% | Batch time: 0.0047s\n",
            "Batch  850/1875 ( 45.3%) | Loss: 0.075272 | Acc: 97.64% | Batch time: 0.0049s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.076138 | Acc: 97.62% | Batch time: 0.0068s\n",
            "Batch  950/1875 ( 50.7%) | Loss: 0.077205 | Acc: 97.61% | Batch time: 0.0061s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.076722 | Acc: 97.65% | Batch time: 0.0077s\n",
            "Batch 1050/1875 ( 56.0%) | Loss: 0.077111 | Acc: 97.64% | Batch time: 0.0080s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.077938 | Acc: 97.62% | Batch time: 0.0050s\n",
            "Batch 1150/1875 ( 61.3%) | Loss: 0.078037 | Acc: 97.64% | Batch time: 0.0059s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.078114 | Acc: 97.64% | Batch time: 0.0068s\n",
            "Batch 1250/1875 ( 66.7%) | Loss: 0.078172 | Acc: 97.62% | Batch time: 0.0090s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.078332 | Acc: 97.62% | Batch time: 0.0073s\n",
            "Batch 1350/1875 ( 72.0%) | Loss: 0.077948 | Acc: 97.63% | Batch time: 0.0047s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.077192 | Acc: 97.65% | Batch time: 0.0051s\n",
            "Batch 1450/1875 ( 77.3%) | Loss: 0.076990 | Acc: 97.66% | Batch time: 0.0046s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.077112 | Acc: 97.67% | Batch time: 0.0045s\n",
            "Batch 1550/1875 ( 82.7%) | Loss: 0.077653 | Acc: 97.66% | Batch time: 0.0042s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.077676 | Acc: 97.67% | Batch time: 0.0034s\n",
            "Batch 1650/1875 ( 88.0%) | Loss: 0.077807 | Acc: 97.66% | Batch time: 0.0057s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.077210 | Acc: 97.67% | Batch time: 0.0048s\n",
            "Batch 1750/1875 ( 93.3%) | Loss: 0.077786 | Acc: 97.65% | Batch time: 0.0048s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.077612 | Acc: 97.66% | Batch time: 0.0051s\n",
            "Batch 1850/1875 ( 98.7%) | Loss: 0.078078 | Acc: 97.65% | Batch time: 0.0049s\n",
            "\n",
            "Standard optimizer - Epoch 3 summary:\n",
            "Loss: 0.078236 | Accuracy: 97.64%\n",
            "⏱️ Adam training took 20.8701 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.029268 | Accuracy: 98.90% | Batch time: 0.0015s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.041304 | Accuracy: 98.67% | Batch time: 0.0014s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.043364 | Accuracy: 98.63% | Batch time: 0.0018s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.035522 | Accuracy: 98.91% | Batch time: 0.0016s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.031556 | Accuracy: 99.04% | Batch time: 0.0019s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.029686 | Accuracy: 99.13% | Batch time: 0.0016s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.031749 | Accuracy: 99.08%\n",
            "Time: 2.66s total, 0.0018s per batch\n",
            "⏱️ Adam evaluation took 2.6573 seconds\n",
            "Adam - Epoch 3:\n",
            "  Train Loss: 0.078236, Train Acc: 97.64%\n",
            "  Test Loss:  0.031749, Test Acc:  99.08%\n",
            "\n",
            "------------------------- AdamW Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 3\n",
            "Batches: 1875, Batch size: 32\n",
            "Batch   50/1875 (  2.7%) | Loss: 0.113554 | Acc: 97.06% | Batch time: 0.0046s\n",
            "Batch  100/1875 (  5.3%) | Loss: 0.099732 | Acc: 97.09% | Batch time: 0.0055s\n",
            "Batch  150/1875 (  8.0%) | Loss: 0.107341 | Acc: 97.04% | Batch time: 0.0049s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.099966 | Acc: 97.20% | Batch time: 0.0110s\n",
            "Batch  250/1875 ( 13.3%) | Loss: 0.105853 | Acc: 97.06% | Batch time: 0.0045s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.102444 | Acc: 97.17% | Batch time: 0.0042s\n",
            "Batch  350/1875 ( 18.7%) | Loss: 0.100276 | Acc: 97.22% | Batch time: 0.0071s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.100543 | Acc: 97.13% | Batch time: 0.0051s\n",
            "Batch  450/1875 ( 24.0%) | Loss: 0.100261 | Acc: 97.10% | Batch time: 0.0052s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.101048 | Acc: 97.08% | Batch time: 0.0055s\n",
            "Batch  550/1875 ( 29.3%) | Loss: 0.102021 | Acc: 97.03% | Batch time: 0.0135s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.102280 | Acc: 97.00% | Batch time: 0.0164s\n",
            "Batch  650/1875 ( 34.7%) | Loss: 0.100365 | Acc: 97.02% | Batch time: 0.0043s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.101830 | Acc: 96.98% | Batch time: 0.0150s\n",
            "Batch  750/1875 ( 40.0%) | Loss: 0.100929 | Acc: 97.00% | Batch time: 0.0063s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.099579 | Acc: 97.02% | Batch time: 0.0072s\n",
            "Batch  850/1875 ( 45.3%) | Loss: 0.097776 | Acc: 97.06% | Batch time: 0.0125s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.097505 | Acc: 97.07% | Batch time: 0.0076s\n",
            "Batch  950/1875 ( 50.7%) | Loss: 0.097765 | Acc: 97.05% | Batch time: 0.0050s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.097373 | Acc: 97.04% | Batch time: 0.0143s\n",
            "Batch 1050/1875 ( 56.0%) | Loss: 0.097919 | Acc: 97.03% | Batch time: 0.0049s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.098385 | Acc: 97.02% | Batch time: 0.0068s\n",
            "Batch 1150/1875 ( 61.3%) | Loss: 0.098474 | Acc: 97.01% | Batch time: 0.0069s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.098207 | Acc: 97.01% | Batch time: 0.0084s\n",
            "Batch 1250/1875 ( 66.7%) | Loss: 0.098122 | Acc: 97.00% | Batch time: 0.0054s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.096758 | Acc: 97.06% | Batch time: 0.0052s\n",
            "Batch 1350/1875 ( 72.0%) | Loss: 0.096730 | Acc: 97.07% | Batch time: 0.0059s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.096337 | Acc: 97.07% | Batch time: 0.0082s\n",
            "Batch 1450/1875 ( 77.3%) | Loss: 0.096809 | Acc: 97.08% | Batch time: 0.0043s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.096498 | Acc: 97.08% | Batch time: 0.0049s\n",
            "Batch 1550/1875 ( 82.7%) | Loss: 0.096613 | Acc: 97.07% | Batch time: 0.0053s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.095976 | Acc: 97.09% | Batch time: 0.0094s\n",
            "Batch 1650/1875 ( 88.0%) | Loss: 0.096584 | Acc: 97.07% | Batch time: 0.0059s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.096282 | Acc: 97.09% | Batch time: 0.0074s\n",
            "Batch 1750/1875 ( 93.3%) | Loss: 0.096459 | Acc: 97.09% | Batch time: 0.0078s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.096524 | Acc: 97.08% | Batch time: 0.0063s\n",
            "Batch 1850/1875 ( 98.7%) | Loss: 0.096392 | Acc: 97.08% | Batch time: 0.0068s\n",
            "\n",
            "Standard optimizer - Epoch 3 summary:\n",
            "Loss: 0.096099 | Accuracy: 97.09%\n",
            "⏱️ AdamW training took 21.1021 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.036149 | Accuracy: 98.53% | Batch time: 0.0055s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.045195 | Accuracy: 98.51% | Batch time: 0.0019s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.047298 | Accuracy: 98.55% | Batch time: 0.0019s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.038765 | Accuracy: 98.85% | Batch time: 0.0017s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.033755 | Accuracy: 98.98% | Batch time: 0.0022s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.031696 | Accuracy: 99.07% | Batch time: 0.0017s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.032350 | Accuracy: 99.03%\n",
            "Time: 2.67s total, 0.0018s per batch\n",
            "⏱️ AdamW evaluation took 2.6703 seconds\n",
            "AdamW - Epoch 3:\n",
            "  Train Loss: 0.096099, Train Acc: 97.09%\n",
            "  Test Loss:  0.032350, Test Acc:  99.03%\n",
            "\n",
            "------------------------- ImprovedTALT Optimizer -------------------------\n",
            "\n",
            "==================== EPOCH 3 TRAINING ====================\n",
            "Device: cuda, Batches: 1875, Batch size: 32\n",
            "🔄 Initial Memory - RAM: 1406.9MB, GPU: 37.2MB allocated, 64.0MB reserved\n",
            "Batch    0/1875 (  0.0%) | Loss: 0.019732 | Accuracy: 100.00% | Batch time: 0.0330s\n",
            "Step 3760 | Loss: 0.127508 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 3760 took 0.0002s\n",
            "Step 3770 | Loss: 0.017545 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0028s, O: 0.0011s\n",
            "Batch   20/1875 (  1.1%) | Loss: 0.074685 | Accuracy: 98.36% | Batch time: 0.0306s\n",
            "Step 3780 | Loss: 0.111733 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 3780 took 0.0001s\n",
            "Step 3790 | Loss: 0.058498 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Batch   40/1875 (  2.1%) | Loss: 0.072145 | Accuracy: 98.32% | Batch time: 0.0212s\n",
            "Step 3800 | Loss: 0.011236 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 3800 took 0.0001s\n",
            "🧹 Memory cleanup at step 3800 took 0.2436s\n",
            "Step 3810 | Loss: 0.110492 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "Batch   60/1875 (  3.2%) | Loss: 0.070160 | Accuracy: 98.21% | Batch time: 0.0245s\n",
            "Step 3820 | Loss: 0.041799 | GPU: 37.3MB / 118.0MB | F: 0.0024s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 3820 took 0.0000s\n",
            "Step 3830 | Loss: 0.087428 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Batch   80/1875 (  4.3%) | Loss: 0.069221 | Accuracy: 98.19% | Batch time: 0.0219s\n",
            "Step 3840 | Loss: 0.073699 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 3840 took 0.0000s\n",
            "Step 3850 | Loss: 0.059840 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0029s, O: 0.0008s\n",
            "Batch  100/1875 (  5.3%) | Loss: 0.069119 | Accuracy: 97.96% | Batch time: 0.0331s\n",
            "Step 3860 | Loss: 0.053194 | GPU: 37.3MB / 118.0MB | F: 0.0023s, B: 0.0055s, O: 0.0020s\n",
            "🔄 Topology update at step 3860 took 0.0000s\n",
            "Step 3870 | Loss: 0.229235 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0027s, O: 0.0008s\n",
            "Batch  120/1875 (  6.4%) | Loss: 0.079339 | Accuracy: 97.62% | Batch time: 0.0343s\n",
            "Step 3880 | Loss: 0.081357 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0073s, O: 0.0009s\n",
            "🔄 Topology update at step 3880 took 0.0000s\n",
            "Step 3890 | Loss: 0.195424 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0028s, O: 0.0007s\n",
            "Batch  140/1875 (  7.5%) | Loss: 0.081005 | Accuracy: 97.50% | Batch time: 0.0373s\n",
            "Step 3900 | Loss: 0.187919 | GPU: 37.3MB / 118.0MB | F: 0.0036s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 3900 took 0.0000s\n",
            "🧹 Memory cleanup at step 3900 took 0.1667s\n",
            "Step 3910 | Loss: 0.357558 | GPU: 37.3MB / 118.0MB | F: 0.0032s, B: 0.0032s, O: 0.0008s\n",
            "Batch  160/1875 (  8.5%) | Loss: 0.082671 | Accuracy: 97.48% | Batch time: 0.0259s\n",
            "Step 3920 | Loss: 0.067059 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0027s, O: 0.0021s\n",
            "🔄 Topology update at step 3920 took 0.0001s\n",
            "Step 3930 | Loss: 0.048876 | GPU: 37.3MB / 118.0MB | F: 0.0038s, B: 0.0093s, O: 0.0009s\n",
            "Batch  180/1875 (  9.6%) | Loss: 0.081489 | Accuracy: 97.53% | Batch time: 0.0248s\n",
            "Step 3940 | Loss: 0.020971 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0027s, O: 0.0005s\n",
            "🔄 Topology update at step 3940 took 0.0001s\n",
            "Step 3950 | Loss: 0.079078 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0032s, O: 0.0010s\n",
            "Batch  200/1875 ( 10.7%) | Loss: 0.079060 | Accuracy: 97.53% | Batch time: 0.0206s\n",
            "Step 3960 | Loss: 0.036125 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0030s, O: 0.0009s\n",
            "🔄 Topology update at step 3960 took 0.0001s\n",
            "Step 3970 | Loss: 0.074579 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0043s, O: 0.0008s\n",
            "Batch  220/1875 ( 11.7%) | Loss: 0.080470 | Accuracy: 97.54% | Batch time: 0.0314s\n",
            "Step 3980 | Loss: 0.012869 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 3980 took 0.0000s\n",
            "Step 3990 | Loss: 0.112727 | GPU: 37.3MB / 118.0MB | F: 0.0073s, B: 0.0025s, O: 0.0007s\n",
            "Batch  240/1875 ( 12.8%) | Loss: 0.081404 | Accuracy: 97.51% | Batch time: 0.0331s\n",
            "Step 4000 | Loss: 0.130783 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0041s, O: 0.0099s\n",
            "🔄 Topology update at step 4000 took 0.0000s\n",
            "🧹 Memory cleanup at step 4000 took 0.1786s\n",
            "Step 4010 | Loss: 0.077531 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0030s, O: 0.0022s\n",
            "Batch  260/1875 ( 13.9%) | Loss: 0.082337 | Accuracy: 97.50% | Batch time: 0.0237s\n",
            "Step 4020 | Loss: 0.255248 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0034s, O: 0.0008s\n",
            "🔄 Topology update at step 4020 took 0.0000s\n",
            "Step 4030 | Loss: 0.058557 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0028s, O: 0.0030s\n",
            "Batch  280/1875 ( 14.9%) | Loss: 0.081443 | Accuracy: 97.52% | Batch time: 0.0243s\n",
            "Step 4040 | Loss: 0.034506 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0028s, O: 0.0019s\n",
            "🔄 Topology update at step 4040 took 0.0000s\n",
            "Step 4050 | Loss: 0.010665 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0027s, O: 0.0020s\n",
            "Batch  300/1875 ( 16.0%) | Loss: 0.081590 | Accuracy: 97.53% | Batch time: 0.0350s\n",
            "Step 4060 | Loss: 0.218672 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 4060 took 0.0001s\n",
            "Step 4070 | Loss: 0.042741 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0037s, O: 0.0025s\n",
            "Batch  320/1875 ( 17.1%) | Loss: 0.082641 | Accuracy: 97.54% | Batch time: 0.0225s\n",
            "Step 4080 | Loss: 0.026272 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0034s, O: 0.0035s\n",
            "🔄 Topology update at step 4080 took 0.0001s\n",
            "Step 4090 | Loss: 0.072414 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "Batch  340/1875 ( 18.1%) | Loss: 0.082623 | Accuracy: 97.53% | Batch time: 0.0256s\n",
            "Step 4100 | Loss: 0.020368 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0028s, O: 0.0020s\n",
            "🔄 Topology update at step 4100 took 0.0001s\n",
            "🧹 Memory cleanup at step 4100 took 0.1703s\n",
            "Step 4110 | Loss: 0.011303 | GPU: 37.3MB / 118.0MB | F: 0.0023s, B: 0.0028s, O: 0.0008s\n",
            "Batch  360/1875 ( 19.2%) | Loss: 0.082332 | Accuracy: 97.57% | Batch time: 0.0262s\n",
            "Step 4120 | Loss: 0.048129 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 4120 took 0.0001s\n",
            "Step 4130 | Loss: 0.120825 | GPU: 37.3MB / 118.0MB | F: 0.0047s, B: 0.0144s, O: 0.0011s\n",
            "Batch  380/1875 ( 20.3%) | Loss: 0.081561 | Accuracy: 97.59% | Batch time: 0.0336s\n",
            "Step 4140 | Loss: 0.153280 | GPU: 37.3MB / 118.0MB | F: 0.0035s, B: 0.0028s, O: 0.0009s\n",
            "🔄 Topology update at step 4140 took 0.0001s\n",
            "Step 4150 | Loss: 0.008607 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0025s, O: 0.0011s\n",
            "Batch  400/1875 ( 21.3%) | Loss: 0.082406 | Accuracy: 97.57% | Batch time: 0.0231s\n",
            "Step 4160 | Loss: 0.021499 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0043s, O: 0.0008s\n",
            "🔄 Topology update at step 4160 took 0.0000s\n",
            "Step 4170 | Loss: 0.067456 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0029s, O: 0.0009s\n",
            "Batch  420/1875 ( 22.4%) | Loss: 0.081302 | Accuracy: 97.58% | Batch time: 0.0264s\n",
            "Step 4180 | Loss: 0.016107 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 4180 took 0.0001s\n",
            "Step 4190 | Loss: 0.018165 | GPU: 37.3MB / 118.0MB | F: 0.0032s, B: 0.0030s, O: 0.0017s\n",
            "Batch  440/1875 ( 23.5%) | Loss: 0.079825 | Accuracy: 97.60% | Batch time: 0.0220s\n",
            "Step 4200 | Loss: 0.013182 | GPU: 37.3MB / 118.0MB | F: 0.0040s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 4200 took 0.0000s\n",
            "🧹 Memory cleanup at step 4200 took 0.1801s\n",
            "Step 4210 | Loss: 0.087943 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0127s, O: 0.0009s\n",
            "Batch  460/1875 ( 24.5%) | Loss: 0.079126 | Accuracy: 97.63% | Batch time: 0.0286s\n",
            "Step 4220 | Loss: 0.007457 | GPU: 37.3MB / 118.0MB | F: 0.0074s, B: 0.0035s, O: 0.0048s\n",
            "🔄 Topology update at step 4220 took 0.0000s\n",
            "Step 4230 | Loss: 0.004989 | GPU: 37.3MB / 118.0MB | F: 0.0137s, B: 0.0029s, O: 0.0009s\n",
            "Batch  480/1875 ( 25.6%) | Loss: 0.077765 | Accuracy: 97.65% | Batch time: 0.0328s\n",
            "Step 4240 | Loss: 0.170281 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0116s, O: 0.0035s\n",
            "🔄 Topology update at step 4240 took 0.0001s\n",
            "Step 4250 | Loss: 0.010113 | GPU: 37.3MB / 118.0MB | F: 0.0121s, B: 0.0041s, O: 0.0007s\n",
            "Batch  500/1875 ( 26.7%) | Loss: 0.078426 | Accuracy: 97.65% | Batch time: 0.0226s\n",
            "Step 4260 | Loss: 0.202010 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0030s, O: 0.0008s\n",
            "🔄 Topology update at step 4260 took 0.0001s\n",
            "Step 4270 | Loss: 0.049231 | GPU: 37.3MB / 118.0MB | F: 0.0056s, B: 0.0020s, O: 0.0007s\n",
            "Batch  520/1875 ( 27.7%) | Loss: 0.078530 | Accuracy: 97.64% | Batch time: 0.0334s\n",
            "Step 4280 | Loss: 0.008337 | GPU: 37.3MB / 118.0MB | F: 0.0080s, B: 0.0020s, O: 0.0007s\n",
            "🔄 Topology update at step 4280 took 0.0001s\n",
            "Step 4290 | Loss: 0.351835 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0018s, O: 0.0007s\n",
            "Batch  540/1875 ( 28.8%) | Loss: 0.078390 | Accuracy: 97.67% | Batch time: 0.0362s\n",
            "Step 4300 | Loss: 0.079312 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0069s, O: 0.0006s\n",
            "🔄 Topology update at step 4300 took 0.0038s\n",
            "🧹 Memory cleanup at step 4300 took 0.2417s\n",
            "Step 4310 | Loss: 0.179058 | GPU: 37.3MB / 118.0MB | F: 0.0112s, B: 0.0081s, O: 0.0011s\n",
            "Batch  560/1875 ( 29.9%) | Loss: 0.078655 | Accuracy: 97.66% | Batch time: 0.0398s\n",
            "Step 4320 | Loss: 0.035667 | GPU: 37.3MB / 118.0MB | F: 0.0014s, B: 0.0087s, O: 0.0007s\n",
            "🔄 Topology update at step 4320 took 0.0047s\n",
            "Step 4330 | Loss: 0.115446 | GPU: 37.3MB / 118.0MB | F: 0.0029s, B: 0.0029s, O: 0.0009s\n",
            "Batch  580/1875 ( 30.9%) | Loss: 0.077745 | Accuracy: 97.68% | Batch time: 0.0222s\n",
            "Step 4340 | Loss: 0.139811 | GPU: 37.3MB / 118.0MB | F: 0.0024s, B: 0.0031s, O: 0.0007s\n",
            "🔄 Topology update at step 4340 took 0.0000s\n",
            "Step 4350 | Loss: 0.035929 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "Batch  600/1875 ( 32.0%) | Loss: 0.078597 | Accuracy: 97.65% | Batch time: 0.0518s\n",
            "Step 4360 | Loss: 0.058914 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0028s, O: 0.0021s\n",
            "🔄 Topology update at step 4360 took 0.0001s\n",
            "Step 4370 | Loss: 0.039479 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0049s, O: 0.0009s\n",
            "Batch  620/1875 ( 33.1%) | Loss: 0.078207 | Accuracy: 97.67% | Batch time: 0.0293s\n",
            "Step 4380 | Loss: 0.082200 | GPU: 37.3MB / 118.0MB | F: 0.0023s, B: 0.0028s, O: 0.0009s\n",
            "🔄 Topology update at step 4380 took 0.0001s\n",
            "Step 4390 | Loss: 0.040284 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0028s, O: 0.0014s\n",
            "Batch  640/1875 ( 34.1%) | Loss: 0.077855 | Accuracy: 97.66% | Batch time: 0.0224s\n",
            "Step 4400 | Loss: 0.058139 | GPU: 37.3MB / 118.0MB | F: 0.0062s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 4400 took 0.0001s\n",
            "🧹 Memory cleanup at step 4400 took 0.1697s\n",
            "Step 4410 | Loss: 0.109089 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0027s, O: 0.0008s\n",
            "Batch  660/1875 ( 35.2%) | Loss: 0.077347 | Accuracy: 97.67% | Batch time: 0.0229s\n",
            "Step 4420 | Loss: 0.059719 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0027s, O: 0.0022s\n",
            "🔄 Topology update at step 4420 took 0.0001s\n",
            "Step 4430 | Loss: 0.036256 | GPU: 37.3MB / 118.0MB | F: 0.0035s, B: 0.0056s, O: 0.0012s\n",
            "Batch  680/1875 ( 36.3%) | Loss: 0.077007 | Accuracy: 97.67% | Batch time: 0.0225s\n",
            "Step 4440 | Loss: 0.031391 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 4440 took 0.0000s\n",
            "Step 4450 | Loss: 0.013723 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "Batch  700/1875 ( 37.3%) | Loss: 0.077206 | Accuracy: 97.66% | Batch time: 0.0339s\n",
            "Step 4460 | Loss: 0.033926 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0029s, O: 0.0020s\n",
            "🔄 Topology update at step 4460 took 0.0001s\n",
            "Step 4470 | Loss: 0.015281 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0041s, O: 0.0019s\n",
            "Batch  720/1875 ( 38.4%) | Loss: 0.076409 | Accuracy: 97.69% | Batch time: 0.0221s\n",
            "Step 4480 | Loss: 0.013571 | GPU: 37.3MB / 118.0MB | F: 0.0024s, B: 0.0031s, O: 0.0010s\n",
            "🔄 Topology update at step 4480 took 0.0001s\n",
            "Step 4490 | Loss: 0.092602 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "Batch  740/1875 ( 39.5%) | Loss: 0.076826 | Accuracy: 97.68% | Batch time: 0.0505s\n",
            "Step 4500 | Loss: 0.019595 | GPU: 37.3MB / 118.0MB | F: 0.0037s, B: 0.0029s, O: 0.0009s\n",
            "🔄 Topology update at step 4500 took 0.0001s\n",
            "🧹 Memory cleanup at step 4500 took 0.1711s\n",
            "Step 4510 | Loss: 0.095208 | GPU: 37.3MB / 118.0MB | F: 0.0033s, B: 0.0027s, O: 0.0014s\n",
            "Batch  760/1875 ( 40.5%) | Loss: 0.075920 | Accuracy: 97.71% | Batch time: 0.0209s\n",
            "Step 4520 | Loss: 0.075278 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0046s, O: 0.0009s\n",
            "🔄 Topology update at step 4520 took 0.0001s\n",
            "Step 4530 | Loss: 0.221557 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Batch  780/1875 ( 41.6%) | Loss: 0.075832 | Accuracy: 97.71% | Batch time: 0.0240s\n",
            "Step 4540 | Loss: 0.102468 | GPU: 37.3MB / 118.0MB | F: 0.0024s, B: 0.0029s, O: 0.0009s\n",
            "🔄 Topology update at step 4540 took 0.0002s\n",
            "Step 4550 | Loss: 0.202079 | GPU: 37.3MB / 118.0MB | F: 0.0109s, B: 0.0035s, O: 0.0010s\n",
            "Batch  800/1875 ( 42.7%) | Loss: 0.075662 | Accuracy: 97.71% | Batch time: 0.0255s\n",
            "Step 4560 | Loss: 0.025660 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0028s, O: 0.0011s\n",
            "🔄 Topology update at step 4560 took 0.0000s\n",
            "Step 4570 | Loss: 0.018059 | GPU: 37.3MB / 118.0MB | F: 0.0030s, B: 0.0030s, O: 0.0009s\n",
            "Batch  820/1875 ( 43.7%) | Loss: 0.075142 | Accuracy: 97.74% | Batch time: 0.0247s\n",
            "Step 4580 | Loss: 0.013637 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0039s, O: 0.0008s\n",
            "🔄 Topology update at step 4580 took 0.0001s\n",
            "Step 4590 | Loss: 0.012806 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "Batch  840/1875 ( 44.8%) | Loss: 0.074929 | Accuracy: 97.73% | Batch time: 0.0254s\n",
            "Step 4600 | Loss: 0.051953 | GPU: 37.3MB / 118.0MB | F: 0.0037s, B: 0.0029s, O: 0.0009s\n",
            "🔄 Topology update at step 4600 took 0.0000s\n",
            "🧹 Memory cleanup at step 4600 took 0.1649s\n",
            "Step 4610 | Loss: 0.124133 | GPU: 37.3MB / 118.0MB | F: 0.0035s, B: 0.0029s, O: 0.0009s\n",
            "Batch  860/1875 ( 45.9%) | Loss: 0.076278 | Accuracy: 97.71% | Batch time: 0.0212s\n",
            "Step 4620 | Loss: 0.049180 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 4620 took 0.0001s\n",
            "Step 4630 | Loss: 0.013482 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0018s\n",
            "Batch  880/1875 ( 46.9%) | Loss: 0.075492 | Accuracy: 97.73% | Batch time: 0.0278s\n",
            "Step 4640 | Loss: 0.089464 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 4640 took 0.0001s\n",
            "Step 4650 | Loss: 0.039905 | GPU: 37.3MB / 118.0MB | F: 0.0029s, B: 0.0027s, O: 0.0007s\n",
            "Batch  900/1875 ( 48.0%) | Loss: 0.074981 | Accuracy: 97.74% | Batch time: 0.0273s\n",
            "Step 4660 | Loss: 0.047266 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0039s, O: 0.0013s\n",
            "🔄 Topology update at step 4660 took 0.0000s\n",
            "Step 4670 | Loss: 0.226724 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0014s\n",
            "Batch  920/1875 ( 49.1%) | Loss: 0.074828 | Accuracy: 97.74% | Batch time: 0.0235s\n",
            "Step 4680 | Loss: 0.021682 | GPU: 37.3MB / 118.0MB | F: 0.0023s, B: 0.0031s, O: 0.0009s\n",
            "🔄 Topology update at step 4680 took 0.0001s\n",
            "Step 4690 | Loss: 0.042147 | GPU: 37.3MB / 118.0MB | F: 0.0037s, B: 0.0030s, O: 0.0010s\n",
            "Batch  940/1875 ( 50.1%) | Loss: 0.074247 | Accuracy: 97.77% | Batch time: 0.0233s\n",
            "Step 4700 | Loss: 0.072921 | GPU: 37.3MB / 118.0MB | F: 0.0023s, B: 0.0043s, O: 0.0009s\n",
            "🔄 Topology update at step 4700 took 0.0001s\n",
            "🧹 Memory cleanup at step 4700 took 0.1672s\n",
            "Step 4710 | Loss: 0.052812 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0029s, O: 0.0008s\n",
            "Batch  960/1875 ( 51.2%) | Loss: 0.073806 | Accuracy: 97.78% | Batch time: 0.0226s\n",
            "Step 4720 | Loss: 0.101702 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0029s, O: 0.0009s\n",
            "🔄 Topology update at step 4720 took 0.0001s\n",
            "Step 4730 | Loss: 0.125641 | GPU: 37.3MB / 118.0MB | F: 0.0036s, B: 0.0027s, O: 0.0008s\n",
            "Batch  980/1875 ( 52.3%) | Loss: 0.074183 | Accuracy: 97.77% | Batch time: 0.0221s\n",
            "Step 4740 | Loss: 0.027981 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0069s, O: 0.0008s\n",
            "🔄 Topology update at step 4740 took 0.0000s\n",
            "Step 4750 | Loss: 0.052509 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0029s, O: 0.0008s\n",
            "Batch 1000/1875 ( 53.3%) | Loss: 0.073987 | Accuracy: 97.78% | Batch time: 0.0243s\n",
            "Step 4760 | Loss: 0.121995 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 4760 took 0.0001s\n",
            "Step 4770 | Loss: 0.107979 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0026s, O: 0.0008s\n",
            "Batch 1020/1875 ( 54.4%) | Loss: 0.073802 | Accuracy: 97.78% | Batch time: 0.0291s\n",
            "Step 4780 | Loss: 0.023855 | GPU: 37.3MB / 118.0MB | F: 0.0043s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 4780 took 0.0001s\n",
            "Step 4790 | Loss: 0.007568 | GPU: 37.3MB / 118.0MB | F: 0.0030s, B: 0.0031s, O: 0.0010s\n",
            "Batch 1040/1875 ( 55.5%) | Loss: 0.073927 | Accuracy: 97.77% | Batch time: 0.0217s\n",
            "Step 4800 | Loss: 0.099453 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 4800 took 0.0000s\n",
            "🧹 Memory cleanup at step 4800 took 0.1625s\n",
            "Step 4810 | Loss: 0.164841 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1060/1875 ( 56.5%) | Loss: 0.074729 | Accuracy: 97.75% | Batch time: 0.0252s\n",
            "Step 4820 | Loss: 0.010192 | GPU: 37.3MB / 118.0MB | F: 0.0033s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 4820 took 0.0001s\n",
            "Step 4830 | Loss: 0.007572 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "Batch 1080/1875 ( 57.6%) | Loss: 0.074262 | Accuracy: 97.77% | Batch time: 0.0229s\n",
            "Step 4840 | Loss: 0.065547 | GPU: 37.3MB / 118.0MB | F: 0.0038s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 4840 took 0.0001s\n",
            "Step 4850 | Loss: 0.007659 | GPU: 37.3MB / 118.0MB | F: 0.0037s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1100/1875 ( 58.7%) | Loss: 0.074003 | Accuracy: 97.77% | Batch time: 0.0259s\n",
            "Step 4860 | Loss: 0.120354 | GPU: 37.3MB / 118.0MB | F: 0.0035s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 4860 took 0.0000s\n",
            "Step 4870 | Loss: 0.010711 | GPU: 37.3MB / 118.0MB | F: 0.0034s, B: 0.0046s, O: 0.0012s\n",
            "Batch 1120/1875 ( 59.7%) | Loss: 0.073885 | Accuracy: 97.78% | Batch time: 0.0284s\n",
            "Step 4880 | Loss: 0.035870 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 4880 took 0.0000s\n",
            "Step 4890 | Loss: 0.058044 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "Batch 1140/1875 ( 60.8%) | Loss: 0.074107 | Accuracy: 97.77% | Batch time: 0.0210s\n",
            "Step 4900 | Loss: 0.017554 | GPU: 37.3MB / 118.0MB | F: 0.0026s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 4900 took 0.0000s\n",
            "🧹 Memory cleanup at step 4900 took 0.1570s\n",
            "Step 4910 | Loss: 0.005564 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Batch 1160/1875 ( 61.9%) | Loss: 0.074072 | Accuracy: 97.76% | Batch time: 0.0232s\n",
            "Step 4920 | Loss: 0.023056 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 4920 took 0.0001s\n",
            "Step 4930 | Loss: 0.038043 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0071s, O: 0.0008s\n",
            "Batch 1180/1875 ( 62.9%) | Loss: 0.074008 | Accuracy: 97.77% | Batch time: 0.0220s\n",
            "Step 4940 | Loss: 0.019169 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 4940 took 0.0000s\n",
            "Step 4950 | Loss: 0.024802 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0060s, O: 0.0016s\n",
            "Batch 1200/1875 ( 64.0%) | Loss: 0.073814 | Accuracy: 97.79% | Batch time: 0.0303s\n",
            "Step 4960 | Loss: 0.006976 | GPU: 37.3MB / 118.0MB | F: 0.0028s, B: 0.0057s, O: 0.0022s\n",
            "🔄 Topology update at step 4960 took 0.0001s\n",
            "Step 4970 | Loss: 0.051554 | GPU: 37.3MB / 118.0MB | F: 0.0030s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1220/1875 ( 65.1%) | Loss: 0.073441 | Accuracy: 97.79% | Batch time: 0.0243s\n",
            "Step 4980 | Loss: 0.077636 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 4980 took 0.0001s\n",
            "Step 4990 | Loss: 0.031516 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0069s, O: 0.0008s\n",
            "Batch 1240/1875 ( 66.1%) | Loss: 0.073162 | Accuracy: 97.81% | Batch time: 0.0415s\n",
            "Step 5000 | Loss: 0.019626 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0058s, O: 0.0007s\n",
            "🔄 Topology update at step 5000 took 0.0001s\n",
            "🧹 Memory cleanup at step 5000 took 0.2117s\n",
            "Step 5010 | Loss: 0.094582 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0044s, O: 0.0006s\n",
            "Batch 1260/1875 ( 67.2%) | Loss: 0.073065 | Accuracy: 97.82% | Batch time: 0.0426s\n",
            "Step 5020 | Loss: 0.018054 | GPU: 37.3MB / 118.0MB | F: 0.0013s, B: 0.0071s, O: 0.0006s\n",
            "🔄 Topology update at step 5020 took 0.0000s\n",
            "Step 5030 | Loss: 0.010890 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0056s, O: 0.0007s\n",
            "Batch 1280/1875 ( 68.3%) | Loss: 0.072998 | Accuracy: 97.81% | Batch time: 0.0283s\n",
            "Step 5040 | Loss: 0.059953 | GPU: 37.3MB / 118.0MB | F: 0.0012s, B: 0.0017s, O: 0.0007s\n",
            "🔄 Topology update at step 5040 took 0.0000s\n",
            "Step 5050 | Loss: 0.075404 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0018s, O: 0.0007s\n",
            "Batch 1300/1875 ( 69.3%) | Loss: 0.073270 | Accuracy: 97.80% | Batch time: 0.0205s\n",
            "Step 5060 | Loss: 0.084729 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 5060 took 0.0000s\n",
            "Step 5070 | Loss: 0.009044 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0026s, O: 0.0041s\n",
            "Batch 1320/1875 ( 70.4%) | Loss: 0.073771 | Accuracy: 97.78% | Batch time: 0.0443s\n",
            "Step 5080 | Loss: 0.290094 | GPU: 37.3MB / 118.0MB | F: 0.0079s, B: 0.0046s, O: 0.0011s\n",
            "🔄 Topology update at step 5080 took 0.0000s\n",
            "Step 5090 | Loss: 0.018496 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0028s, O: 0.0007s\n",
            "Batch 1340/1875 ( 71.5%) | Loss: 0.073897 | Accuracy: 97.78% | Batch time: 0.0437s\n",
            "Step 5100 | Loss: 0.081306 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0160s, O: 0.0008s\n",
            "🔄 Topology update at step 5100 took 0.0000s\n",
            "🧹 Memory cleanup at step 5100 took 0.1776s\n",
            "Step 5110 | Loss: 0.021104 | GPU: 37.3MB / 118.0MB | F: 0.0034s, B: 0.0029s, O: 0.0009s\n",
            "Batch 1360/1875 ( 72.5%) | Loss: 0.073628 | Accuracy: 97.78% | Batch time: 0.0216s\n",
            "Step 5120 | Loss: 0.010272 | GPU: 37.3MB / 118.0MB | F: 0.0025s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 5120 took 0.0001s\n",
            "Step 5130 | Loss: 0.012350 | GPU: 37.3MB / 118.0MB | F: 0.0023s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1380/1875 ( 73.6%) | Loss: 0.073749 | Accuracy: 97.78% | Batch time: 0.0245s\n",
            "Step 5140 | Loss: 0.293872 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 5140 took 0.0001s\n",
            "Step 5150 | Loss: 0.027539 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0057s, O: 0.0007s\n",
            "Batch 1400/1875 ( 74.7%) | Loss: 0.073499 | Accuracy: 97.80% | Batch time: 0.0246s\n",
            "Step 5160 | Loss: 0.025695 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0018s\n",
            "🔄 Topology update at step 5160 took 0.0000s\n",
            "Step 5170 | Loss: 0.078773 | GPU: 37.3MB / 118.0MB | F: 0.0027s, B: 0.0030s, O: 0.0011s\n",
            "Batch 1420/1875 ( 75.7%) | Loss: 0.073724 | Accuracy: 97.79% | Batch time: 0.0214s\n",
            "Step 5180 | Loss: 0.038209 | GPU: 37.3MB / 118.0MB | F: 0.0031s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 5180 took 0.0001s\n",
            "Step 5190 | Loss: 0.193028 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0026s, O: 0.0008s\n",
            "Batch 1440/1875 ( 76.8%) | Loss: 0.073790 | Accuracy: 97.79% | Batch time: 0.0226s\n",
            "Step 5200 | Loss: 0.138261 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 5200 took 0.0000s\n",
            "🧹 Memory cleanup at step 5200 took 0.1553s\n",
            "Step 5210 | Loss: 0.081499 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1460/1875 ( 77.9%) | Loss: 0.073943 | Accuracy: 97.79% | Batch time: 0.0215s\n",
            "Step 5220 | Loss: 0.198601 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 5220 took 0.0001s\n",
            "Step 5230 | Loss: 0.023153 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "Batch 1480/1875 ( 78.9%) | Loss: 0.073851 | Accuracy: 97.79% | Batch time: 0.0237s\n",
            "Step 5240 | Loss: 0.049876 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0026s, O: 0.0006s\n",
            "🔄 Topology update at step 5240 took 0.0000s\n",
            "Step 5250 | Loss: 0.050440 | GPU: 37.3MB / 118.0MB | F: 0.0060s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1500/1875 ( 80.0%) | Loss: 0.073734 | Accuracy: 97.79% | Batch time: 0.0202s\n",
            "Step 5260 | Loss: 0.226505 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0028s, O: 0.0022s\n",
            "🔄 Topology update at step 5260 took 0.0001s\n",
            "Step 5270 | Loss: 0.037282 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0027s, O: 0.0034s\n",
            "Batch 1520/1875 ( 81.1%) | Loss: 0.073661 | Accuracy: 97.79% | Batch time: 0.0261s\n",
            "Step 5280 | Loss: 0.070798 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 5280 took 0.0001s\n",
            "Step 5290 | Loss: 0.311214 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0046s, O: 0.0029s\n",
            "Batch 1540/1875 ( 82.1%) | Loss: 0.073633 | Accuracy: 97.78% | Batch time: 0.0256s\n",
            "Step 5300 | Loss: 0.225803 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 5300 took 0.0001s\n",
            "🧹 Memory cleanup at step 5300 took 0.1508s\n",
            "Step 5310 | Loss: 0.023292 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Batch 1560/1875 ( 83.2%) | Loss: 0.073716 | Accuracy: 97.78% | Batch time: 0.0218s\n",
            "Step 5320 | Loss: 0.076749 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 5320 took 0.0001s\n",
            "Step 5330 | Loss: 0.022817 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0041s, O: 0.0008s\n",
            "Batch 1580/1875 ( 84.3%) | Loss: 0.073747 | Accuracy: 97.78% | Batch time: 0.0236s\n",
            "Step 5340 | Loss: 0.145209 | GPU: 37.3MB / 118.0MB | F: 0.0036s, B: 0.0020s, O: 0.0006s\n",
            "🔄 Topology update at step 5340 took 0.0000s\n",
            "Step 5350 | Loss: 0.061875 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0026s, O: 0.0026s\n",
            "Batch 1600/1875 ( 85.3%) | Loss: 0.073625 | Accuracy: 97.78% | Batch time: 0.0331s\n",
            "Step 5360 | Loss: 0.022865 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0027s, O: 0.0017s\n",
            "🔄 Topology update at step 5360 took 0.0001s\n",
            "Step 5370 | Loss: 0.038024 | GPU: 37.3MB / 118.0MB | F: 0.0034s, B: 0.0024s, O: 0.0007s\n",
            "Batch 1620/1875 ( 86.4%) | Loss: 0.073604 | Accuracy: 97.77% | Batch time: 0.0225s\n",
            "Step 5380 | Loss: 0.024554 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 5380 took 0.0000s\n",
            "Step 5390 | Loss: 0.217283 | GPU: 37.3MB / 118.0MB | F: 0.0021s, B: 0.0027s, O: 0.0033s\n",
            "Batch 1640/1875 ( 87.5%) | Loss: 0.073804 | Accuracy: 97.76% | Batch time: 0.0259s\n",
            "Step 5400 | Loss: 0.020968 | GPU: 37.3MB / 118.0MB | F: 0.0075s, B: 0.0047s, O: 0.0011s\n",
            "🔄 Topology update at step 5400 took 0.0000s\n",
            "🧹 Memory cleanup at step 5400 took 0.1492s\n",
            "Step 5410 | Loss: 0.059480 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1660/1875 ( 88.5%) | Loss: 0.073887 | Accuracy: 97.76% | Batch time: 0.0210s\n",
            "Step 5420 | Loss: 0.033369 | GPU: 37.3MB / 118.0MB | F: 0.0037s, B: 0.0057s, O: 0.0007s\n",
            "🔄 Topology update at step 5420 took 0.0000s\n",
            "Step 5430 | Loss: 0.120174 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Batch 1680/1875 ( 89.6%) | Loss: 0.073949 | Accuracy: 97.76% | Batch time: 0.0248s\n",
            "Step 5440 | Loss: 0.033430 | GPU: 37.3MB / 118.0MB | F: 0.0035s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 5440 took 0.0001s\n",
            "Step 5450 | Loss: 0.052700 | GPU: 37.3MB / 118.0MB | F: 0.0032s, B: 0.0026s, O: 0.0008s\n",
            "Batch 1700/1875 ( 90.7%) | Loss: 0.073881 | Accuracy: 97.76% | Batch time: 0.0208s\n",
            "Step 5460 | Loss: 0.014014 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0075s, O: 0.0016s\n",
            "🔄 Topology update at step 5460 took 0.0000s\n",
            "Step 5470 | Loss: 0.232302 | GPU: 37.3MB / 118.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Batch 1720/1875 ( 91.7%) | Loss: 0.074094 | Accuracy: 97.76% | Batch time: 0.0203s\n",
            "Step 5480 | Loss: 0.008476 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 5480 took 0.0001s\n",
            "Step 5490 | Loss: 0.041716 | GPU: 37.3MB / 118.0MB | F: 0.0025s, B: 0.0030s, O: 0.0011s\n",
            "Batch 1740/1875 ( 92.8%) | Loss: 0.074415 | Accuracy: 97.75% | Batch time: 0.0216s\n",
            "Step 5500 | Loss: 0.038826 | GPU: 37.3MB / 118.0MB | F: 0.0022s, B: 0.0067s, O: 0.0009s\n",
            "🔄 Topology update at step 5500 took 0.0001s\n",
            "🧹 Memory cleanup at step 5500 took 0.1518s\n",
            "Step 5510 | Loss: 0.083229 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0065s, O: 0.0007s\n",
            "Batch 1760/1875 ( 93.9%) | Loss: 0.074479 | Accuracy: 97.75% | Batch time: 0.0233s\n",
            "Step 5520 | Loss: 0.011597 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 5520 took 0.0000s\n",
            "Step 5530 | Loss: 0.183767 | GPU: 37.3MB / 118.0MB | F: 0.0035s, B: 0.0026s, O: 0.0008s\n",
            "Batch 1780/1875 ( 94.9%) | Loss: 0.074675 | Accuracy: 97.75% | Batch time: 0.0220s\n",
            "Step 5540 | Loss: 0.016149 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 5540 took 0.0001s\n",
            "Step 5550 | Loss: 0.024750 | GPU: 37.3MB / 118.0MB | F: 0.0017s, B: 0.0053s, O: 0.0007s\n",
            "Batch 1800/1875 ( 96.0%) | Loss: 0.074577 | Accuracy: 97.76% | Batch time: 0.0287s\n",
            "Step 5560 | Loss: 0.008319 | GPU: 37.3MB / 118.0MB | F: 0.0028s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 5560 took 0.0000s\n",
            "Step 5570 | Loss: 0.412876 | GPU: 37.3MB / 118.0MB | F: 0.0015s, B: 0.0032s, O: 0.0007s\n",
            "Batch 1820/1875 ( 97.1%) | Loss: 0.074506 | Accuracy: 97.77% | Batch time: 0.0298s\n",
            "Step 5580 | Loss: 0.097498 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0042s, O: 0.0008s\n",
            "🔄 Topology update at step 5580 took 0.0000s\n",
            "Step 5590 | Loss: 0.032952 | GPU: 37.3MB / 118.0MB | F: 0.0023s, B: 0.0029s, O: 0.0009s\n",
            "Batch 1840/1875 ( 98.1%) | Loss: 0.074279 | Accuracy: 97.77% | Batch time: 0.0211s\n",
            "Step 5600 | Loss: 0.103911 | GPU: 37.3MB / 118.0MB | F: 0.0020s, B: 0.0027s, O: 0.0031s\n",
            "🔄 Topology update at step 5600 took 0.0000s\n",
            "🧹 Memory cleanup at step 5600 took 0.1436s\n",
            "Step 5610 | Loss: 0.029761 | GPU: 37.3MB / 118.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "Batch 1860/1875 ( 99.2%) | Loss: 0.074201 | Accuracy: 97.78% | Batch time: 0.0271s\n",
            "Step 5620 | Loss: 0.053029 | GPU: 37.3MB / 118.0MB | F: 0.0018s, B: 0.0024s, O: 0.0038s\n",
            "🔄 Topology update at step 5620 took 0.0001s\n",
            "\n",
            "-------------------- EPOCH 3 SUMMARY --------------------\n",
            "Loss: 0.073899 | Accuracy: 97.78%\n",
            "Time: 30.04s total, 0.0138s per batch\n",
            "🔄 Final Memory - RAM: 1406.9MB, GPU: 37.3MB allocated, 118.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=37.3, peak=37.3\n",
            "===============================\n",
            "\n",
            "⏱️ ImprovedTALT training took 30.0383 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.046961 | Accuracy: 98.22% | Batch time: 0.0014s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.053934 | Accuracy: 98.17% | Batch time: 0.0017s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.054885 | Accuracy: 98.12% | Batch time: 0.0014s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.046117 | Accuracy: 98.43% | Batch time: 0.0020s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.040130 | Accuracy: 98.66% | Batch time: 0.0013s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.036084 | Accuracy: 98.79% | Batch time: 0.0013s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.037313 | Accuracy: 98.75%\n",
            "Time: 2.68s total, 0.0016s per batch\n",
            "⏱️ ImprovedTALT evaluation took 2.6830 seconds\n",
            "ImprovedTALT - Epoch 3:\n",
            "  Train Loss: 0.073899, Train Acc: 97.78%\n",
            "  Test Loss:  0.037313, Test Acc:  98.75%\n",
            "\n",
            "Epoch 3 completed in 103.76s\n",
            "Results saved to ./results/mnist/epoch_3_results.json\n",
            "\n",
            "============================== TRAINING COMPLETED ==============================\n",
            "Total training time: 297.05s\n",
            "\n",
            "Final Test Accuracy Comparison:\n",
            "  SGD: 98.84%\n",
            "  Adam: 99.08%\n",
            "  AdamW: 99.03%\n",
            "  ImprovedTALT: 98.75%\n",
            "\n",
            "🏆 Best optimizer: Adam with 99.08% test accuracy\n",
            "\n",
            "Creating comparative plots...\n",
            "Comparison plots saved to ./plots/mnist\n",
            "Final results saved to ./results/mnist/final_results.json\n",
            "\n",
            "============================== OPTIMIZER COMPARISON ON CIFAR10 ==============================\n",
            "Configuration: epochs=3, batch_size=32, device=cuda\n",
            "Created results directory: ./results/cifar10\n",
            "Created plots directory: ./plots/cifar10\n",
            "\n",
            "Loading datasets...\n",
            "Train set: 50000 samples, 1563 batches\n",
            "Test set: 10000 samples, 313 batches\n",
            "\n",
            "Initializing models and optimizers...\n",
            "Model parameters: 545,290\n",
            "\n",
            "======================================================================\n",
            "STARTING TRAINING FOR 3 EPOCHS WITH 4 OPTIMIZERS\n",
            "======================================================================\n",
            "\n",
            "============================== EPOCH 1/3 ==============================\n",
            "\n",
            "------------------------- SGD Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 1\n",
            "Batches: 1563, Batch size: 32\n",
            "Batch   50/1563 (  3.2%) | Loss: 2.136776 | Acc: 19.73% | Batch time: 0.0041s\n",
            "Batch  100/1563 (  6.4%) | Loss: 2.086996 | Acc: 20.79% | Batch time: 0.0040s\n",
            "Batch  150/1563 (  9.6%) | Loss: 2.071785 | Acc: 21.46% | Batch time: 0.0041s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 2.051554 | Acc: 22.57% | Batch time: 0.0046s\n",
            "Batch  250/1563 ( 16.0%) | Loss: 2.049162 | Acc: 22.60% | Batch time: 0.0037s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 2.050278 | Acc: 22.52% | Batch time: 0.0038s\n",
            "Batch  350/1563 ( 22.4%) | Loss: 2.042316 | Acc: 22.71% | Batch time: 0.0051s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 2.036663 | Acc: 22.67% | Batch time: 0.0039s\n",
            "Batch  450/1563 ( 28.8%) | Loss: 2.036950 | Acc: 22.67% | Batch time: 0.0043s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 2.038739 | Acc: 22.67% | Batch time: 0.0044s\n",
            "Batch  550/1563 ( 35.2%) | Loss: 2.037397 | Acc: 22.66% | Batch time: 0.0039s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 2.036444 | Acc: 22.61% | Batch time: 0.0053s\n",
            "Batch  650/1563 ( 41.6%) | Loss: 2.035473 | Acc: 22.45% | Batch time: 0.0038s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 2.035824 | Acc: 22.26% | Batch time: 0.0038s\n",
            "Batch  750/1563 ( 48.0%) | Loss: 2.033044 | Acc: 22.15% | Batch time: 0.0048s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 2.029545 | Acc: 22.16% | Batch time: 0.0054s\n",
            "Batch  850/1563 ( 54.4%) | Loss: 2.026675 | Acc: 22.16% | Batch time: 0.0041s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 2.023315 | Acc: 22.26% | Batch time: 0.0037s\n",
            "Batch  950/1563 ( 60.8%) | Loss: 2.019713 | Acc: 22.33% | Batch time: 0.0037s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 2.015874 | Acc: 22.55% | Batch time: 0.0041s\n",
            "Batch 1050/1563 ( 67.2%) | Loss: 2.010598 | Acc: 22.69% | Batch time: 0.0051s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 2.005101 | Acc: 22.92% | Batch time: 0.0041s\n",
            "Batch 1150/1563 ( 73.6%) | Loss: 1.998408 | Acc: 23.23% | Batch time: 0.0054s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.993937 | Acc: 23.36% | Batch time: 0.0048s\n",
            "Batch 1250/1563 ( 80.0%) | Loss: 1.989019 | Acc: 23.55% | Batch time: 0.0049s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.984689 | Acc: 23.69% | Batch time: 0.0037s\n",
            "Batch 1350/1563 ( 86.4%) | Loss: 1.979893 | Acc: 23.89% | Batch time: 0.0041s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.974004 | Acc: 24.11% | Batch time: 0.0063s\n",
            "Batch 1450/1563 ( 92.8%) | Loss: 1.969356 | Acc: 24.36% | Batch time: 0.0039s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.964801 | Acc: 24.59% | Batch time: 0.0038s\n",
            "Batch 1550/1563 ( 99.2%) | Loss: 1.959471 | Acc: 24.85% | Batch time: 0.0039s\n",
            "\n",
            "Standard optimizer - Epoch 1 summary:\n",
            "Loss: 1.957727 | Accuracy: 24.90%\n",
            "⏱️ SGD training took 17.6044 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 1.547604 | Accuracy: 41.91% | Batch time: 0.0020s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 1.544220 | Accuracy: 42.88% | Batch time: 0.0015s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 1.544419 | Accuracy: 43.00% | Batch time: 0.0014s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 1.551571 | Accuracy: 43.00% | Batch time: 0.0010s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 1.549827 | Accuracy: 43.02% | Batch time: 0.0012s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 1.554656 | Accuracy: 42.76% | Batch time: 0.0013s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.553962 | Accuracy: 42.59%\n",
            "Time: 3.63s total, 0.0016s per batch\n",
            "⏱️ SGD evaluation took 3.6329 seconds\n",
            "SGD - Epoch 1:\n",
            "  Train Loss: 1.957727, Train Acc: 24.90%\n",
            "  Test Loss:  1.553962, Test Acc:  42.59%\n",
            "\n",
            "------------------------- Adam Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 1\n",
            "Batches: 1563, Batch size: 32\n",
            "Batch   50/1563 (  3.2%) | Loss: 2.269217 | Acc: 15.56% | Batch time: 0.0040s\n",
            "Batch  100/1563 (  6.4%) | Loss: 2.150178 | Acc: 18.53% | Batch time: 0.0044s\n",
            "Batch  150/1563 (  9.6%) | Loss: 2.086813 | Acc: 20.55% | Batch time: 0.0058s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 2.049189 | Acc: 21.88% | Batch time: 0.0057s\n",
            "Batch  250/1563 ( 16.0%) | Loss: 2.014566 | Acc: 22.73% | Batch time: 0.0051s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 1.985245 | Acc: 23.84% | Batch time: 0.0050s\n",
            "Batch  350/1563 ( 22.4%) | Loss: 1.960762 | Acc: 24.65% | Batch time: 0.0052s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 1.937749 | Acc: 25.41% | Batch time: 0.0049s\n",
            "Batch  450/1563 ( 28.8%) | Loss: 1.916098 | Acc: 26.43% | Batch time: 0.0074s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 1.900343 | Acc: 27.03% | Batch time: 0.0043s\n",
            "Batch  550/1563 ( 35.2%) | Loss: 1.884178 | Acc: 27.61% | Batch time: 0.0057s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 1.870734 | Acc: 28.10% | Batch time: 0.0048s\n",
            "Batch  650/1563 ( 41.6%) | Loss: 1.858719 | Acc: 28.65% | Batch time: 0.0107s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 1.845273 | Acc: 29.16% | Batch time: 0.0050s\n",
            "Batch  750/1563 ( 48.0%) | Loss: 1.831807 | Acc: 29.66% | Batch time: 0.0048s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 1.821171 | Acc: 30.06% | Batch time: 0.0051s\n",
            "Batch  850/1563 ( 54.4%) | Loss: 1.812687 | Acc: 30.36% | Batch time: 0.0047s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 1.804292 | Acc: 30.71% | Batch time: 0.0043s\n",
            "Batch  950/1563 ( 60.8%) | Loss: 1.797631 | Acc: 30.98% | Batch time: 0.0034s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 1.790099 | Acc: 31.34% | Batch time: 0.0034s\n",
            "Batch 1050/1563 ( 67.2%) | Loss: 1.780972 | Acc: 31.68% | Batch time: 0.0063s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 1.774498 | Acc: 31.89% | Batch time: 0.0051s\n",
            "Batch 1150/1563 ( 73.6%) | Loss: 1.768923 | Acc: 32.10% | Batch time: 0.0077s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.763057 | Acc: 32.38% | Batch time: 0.0053s\n",
            "Batch 1250/1563 ( 80.0%) | Loss: 1.758339 | Acc: 32.63% | Batch time: 0.0053s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.753101 | Acc: 32.85% | Batch time: 0.0064s\n",
            "Batch 1350/1563 ( 86.4%) | Loss: 1.747654 | Acc: 33.05% | Batch time: 0.0064s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.742233 | Acc: 33.23% | Batch time: 0.0041s\n",
            "Batch 1450/1563 ( 92.8%) | Loss: 1.737982 | Acc: 33.42% | Batch time: 0.0046s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.733496 | Acc: 33.59% | Batch time: 0.0045s\n",
            "Batch 1550/1563 ( 99.2%) | Loss: 1.729318 | Acc: 33.75% | Batch time: 0.0048s\n",
            "\n",
            "Standard optimizer - Epoch 1 summary:\n",
            "Loss: 1.728194 | Accuracy: 33.83%\n",
            "⏱️ Adam training took 18.4610 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 1.298094 | Accuracy: 54.11% | Batch time: 0.0015s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 1.310198 | Accuracy: 53.22% | Batch time: 0.0014s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 1.308921 | Accuracy: 53.60% | Batch time: 0.0019s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 1.313072 | Accuracy: 53.51% | Batch time: 0.0017s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 1.309823 | Accuracy: 53.62% | Batch time: 0.0019s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 1.309707 | Accuracy: 53.63% | Batch time: 0.0014s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.310640 | Accuracy: 53.51%\n",
            "Time: 2.87s total, 0.0016s per batch\n",
            "⏱️ Adam evaluation took 2.8720 seconds\n",
            "Adam - Epoch 1:\n",
            "  Train Loss: 1.728194, Train Acc: 33.83%\n",
            "  Test Loss:  1.310640, Test Acc:  53.51%\n",
            "\n",
            "------------------------- AdamW Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 1\n",
            "Batches: 1563, Batch size: 32\n",
            "Batch   50/1563 (  3.2%) | Loss: 2.205307 | Acc: 20.10% | Batch time: 0.0050s\n",
            "Batch  100/1563 (  6.4%) | Loss: 2.097411 | Acc: 23.17% | Batch time: 0.0042s\n",
            "Batch  150/1563 (  9.6%) | Loss: 2.048025 | Acc: 24.11% | Batch time: 0.0039s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 2.008303 | Acc: 24.92% | Batch time: 0.0076s\n",
            "Batch  250/1563 ( 16.0%) | Loss: 1.967716 | Acc: 26.13% | Batch time: 0.0055s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 1.939160 | Acc: 26.92% | Batch time: 0.0056s\n",
            "Batch  350/1563 ( 22.4%) | Loss: 1.913541 | Acc: 27.54% | Batch time: 0.0070s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 1.889535 | Acc: 28.33% | Batch time: 0.0042s\n",
            "Batch  450/1563 ( 28.8%) | Loss: 1.871924 | Acc: 28.70% | Batch time: 0.0053s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 1.855040 | Acc: 29.25% | Batch time: 0.0048s\n",
            "Batch  550/1563 ( 35.2%) | Loss: 1.843458 | Acc: 29.83% | Batch time: 0.0058s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 1.831979 | Acc: 30.28% | Batch time: 0.0042s\n",
            "Batch  650/1563 ( 41.6%) | Loss: 1.823864 | Acc: 30.48% | Batch time: 0.0044s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 1.811416 | Acc: 30.81% | Batch time: 0.0053s\n",
            "Batch  750/1563 ( 48.0%) | Loss: 1.798823 | Acc: 31.30% | Batch time: 0.0043s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 1.788391 | Acc: 31.64% | Batch time: 0.0044s\n",
            "Batch  850/1563 ( 54.4%) | Loss: 1.780021 | Acc: 31.93% | Batch time: 0.0047s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 1.770007 | Acc: 32.28% | Batch time: 0.0062s\n",
            "Batch  950/1563 ( 60.8%) | Loss: 1.764307 | Acc: 32.60% | Batch time: 0.0058s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 1.758857 | Acc: 32.71% | Batch time: 0.0044s\n",
            "Batch 1050/1563 ( 67.2%) | Loss: 1.750630 | Acc: 33.06% | Batch time: 0.0074s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 1.745556 | Acc: 33.33% | Batch time: 0.0049s\n",
            "Batch 1150/1563 ( 73.6%) | Loss: 1.737879 | Acc: 33.65% | Batch time: 0.0044s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.730839 | Acc: 33.94% | Batch time: 0.0116s\n",
            "Batch 1250/1563 ( 80.0%) | Loss: 1.725084 | Acc: 34.18% | Batch time: 0.0116s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.719021 | Acc: 34.42% | Batch time: 0.0065s\n",
            "Batch 1350/1563 ( 86.4%) | Loss: 1.713802 | Acc: 34.67% | Batch time: 0.0065s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.708996 | Acc: 34.83% | Batch time: 0.0045s\n",
            "Batch 1450/1563 ( 92.8%) | Loss: 1.703779 | Acc: 35.04% | Batch time: 0.0049s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.698741 | Acc: 35.25% | Batch time: 0.0058s\n",
            "Batch 1550/1563 ( 99.2%) | Loss: 1.693831 | Acc: 35.45% | Batch time: 0.0045s\n",
            "\n",
            "Standard optimizer - Epoch 1 summary:\n",
            "Loss: 1.692250 | Accuracy: 35.50%\n",
            "⏱️ AdamW training took 19.1066 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 1.290779 | Accuracy: 51.96% | Batch time: 0.0016s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 1.292816 | Accuracy: 52.78% | Batch time: 0.0017s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 1.292219 | Accuracy: 53.27% | Batch time: 0.0012s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 1.290422 | Accuracy: 53.59% | Batch time: 0.0014s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 1.289546 | Accuracy: 53.50% | Batch time: 0.0019s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 1.297373 | Accuracy: 53.27% | Batch time: 0.0017s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.297122 | Accuracy: 53.10%\n",
            "Time: 2.89s total, 0.0016s per batch\n",
            "⏱️ AdamW evaluation took 2.8944 seconds\n",
            "AdamW - Epoch 1:\n",
            "  Train Loss: 1.692250, Train Acc: 35.50%\n",
            "  Test Loss:  1.297122, Test Acc:  53.10%\n",
            "\n",
            "------------------------- ImprovedTALT Optimizer -------------------------\n",
            "\n",
            "==================== EPOCH 1 TRAINING ====================\n",
            "Device: cuda, Batches: 1563, Batch size: 32\n",
            "🔄 Initial Memory - RAM: 1601.1MB, GPU: 41.4MB allocated, 64.0MB reserved\n",
            "Step    1 | Loss: 2.361633 | GPU: 43.8MB / 132.0MB | F: 0.0191s, B: 0.0113s, O: 0.0013s\n",
            "Batch    0/1563 (  0.0%) | Loss: 2.361633 | Accuracy: 12.50% | Batch time: 0.0573s\n",
            "Step   10 | Loss: 2.276184 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0008s\n",
            "Step   20 | Loss: 2.188202 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 20 took 0.0004s\n",
            "Batch   20/1563 (  1.3%) | Loss: 2.268973 | Accuracy: 15.48% | Batch time: 0.0268s\n",
            "Step   30 | Loss: 2.237152 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step   40 | Loss: 2.248077 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 40 took 0.0001s\n",
            "Batch   40/1563 (  2.6%) | Loss: 2.207134 | Accuracy: 17.99% | Batch time: 0.0292s\n",
            "Step   50 | Loss: 1.988373 | GPU: 43.8MB / 132.0MB | F: 0.0039s, B: 0.0084s, O: 0.0009s\n",
            "Step   60 | Loss: 1.937698 | GPU: 43.8MB / 132.0MB | F: 0.0031s, B: 0.0034s, O: 0.0008s\n",
            "🔄 Topology update at step 60 took 0.0000s\n",
            "Batch   60/1563 (  3.8%) | Loss: 2.164171 | Accuracy: 19.36% | Batch time: 0.0262s\n",
            "Step   70 | Loss: 2.174545 | GPU: 43.8MB / 132.0MB | F: 0.0025s, B: 0.0028s, O: 0.0008s\n",
            "Step   80 | Loss: 1.973343 | GPU: 43.8MB / 132.0MB | F: 0.0039s, B: 0.0095s, O: 0.0008s\n",
            "🔄 Topology update at step 80 took 0.0001s\n",
            "Batch   80/1563 (  5.1%) | Loss: 2.123456 | Accuracy: 21.33% | Batch time: 0.0263s\n",
            "Step   90 | Loss: 1.733337 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0059s, O: 0.0007s\n",
            "Step  100 | Loss: 1.997910 | GPU: 43.8MB / 132.0MB | F: 0.0022s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 100 took 0.0001s\n",
            "🧹 Memory cleanup at step 100 took 0.2352s\n",
            "Batch  100/1563 (  6.4%) | Loss: 2.094974 | Accuracy: 22.68% | Batch time: 0.0287s\n",
            "Step  110 | Loss: 1.855392 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0049s, O: 0.0008s\n",
            "Step  120 | Loss: 2.035378 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 120 took 0.0001s\n",
            "Batch  120/1563 (  7.7%) | Loss: 2.062570 | Accuracy: 23.97% | Batch time: 0.0316s\n",
            "Step  130 | Loss: 2.119850 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "Step  140 | Loss: 1.789505 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0026s, O: 0.0009s\n",
            "🔄 Topology update at step 140 took 0.0000s\n",
            "Batch  140/1563 (  9.0%) | Loss: 2.038064 | Accuracy: 24.89% | Batch time: 0.0275s\n",
            "Step  150 | Loss: 1.846512 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step  160 | Loss: 1.844727 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 160 took 0.0000s\n",
            "Batch  160/1563 ( 10.2%) | Loss: 2.014334 | Accuracy: 25.52% | Batch time: 0.0424s\n",
            "Step  170 | Loss: 1.760605 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step  180 | Loss: 1.889206 | GPU: 43.8MB / 132.0MB | F: 0.0022s, B: 0.0095s, O: 0.0010s\n",
            "🔄 Topology update at step 180 took 0.0001s\n",
            "Batch  180/1563 ( 11.5%) | Loss: 1.990662 | Accuracy: 26.42% | Batch time: 0.0272s\n",
            "Step  190 | Loss: 1.632423 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "Step  200 | Loss: 1.982067 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 200 took 0.0000s\n",
            "🧹 Memory cleanup at step 200 took 0.1625s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 1.973137 | Accuracy: 27.18% | Batch time: 0.0262s\n",
            "Step  210 | Loss: 1.896561 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0064s, O: 0.0010s\n",
            "Step  220 | Loss: 1.818130 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0034s, O: 0.0008s\n",
            "🔄 Topology update at step 220 took 0.0000s\n",
            "Batch  220/1563 ( 14.1%) | Loss: 1.951369 | Accuracy: 27.90% | Batch time: 0.0336s\n",
            "Step  230 | Loss: 1.936424 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step  240 | Loss: 1.538048 | GPU: 43.8MB / 132.0MB | F: 0.0043s, B: 0.0027s, O: 0.0012s\n",
            "🔄 Topology update at step 240 took 0.0001s\n",
            "Batch  240/1563 ( 15.4%) | Loss: 1.932906 | Accuracy: 28.80% | Batch time: 0.0240s\n",
            "Step  250 | Loss: 1.728840 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0026s, O: 0.0025s\n",
            "Step  260 | Loss: 1.762299 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 260 took 0.0000s\n",
            "Batch  260/1563 ( 16.6%) | Loss: 1.914477 | Accuracy: 29.61% | Batch time: 0.0281s\n",
            "Step  270 | Loss: 1.418686 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0021s, O: 0.0006s\n",
            "Step  280 | Loss: 1.814323 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0051s, O: 0.0007s\n",
            "🔄 Topology update at step 280 took 0.0067s\n",
            "Batch  280/1563 ( 17.9%) | Loss: 1.894498 | Accuracy: 30.33% | Batch time: 0.0510s\n",
            "Step  290 | Loss: 1.481754 | GPU: 43.8MB / 132.0MB | F: 0.0071s, B: 0.0020s, O: 0.0006s\n",
            "Step  300 | Loss: 1.761169 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0078s, O: 0.0007s\n",
            "🔄 Topology update at step 300 took 0.0000s\n",
            "🧹 Memory cleanup at step 300 took 0.2170s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 1.881903 | Accuracy: 30.78% | Batch time: 0.0293s\n",
            "Step  310 | Loss: 1.429161 | GPU: 43.8MB / 132.0MB | F: 0.0035s, B: 0.0042s, O: 0.0006s\n",
            "Step  320 | Loss: 1.722290 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0069s, O: 0.0007s\n",
            "🔄 Topology update at step 320 took 0.0000s\n",
            "Batch  320/1563 ( 20.5%) | Loss: 1.866506 | Accuracy: 31.43% | Batch time: 0.0476s\n",
            "Step  330 | Loss: 1.710400 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0129s, O: 0.0007s\n",
            "Step  340 | Loss: 1.336708 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0138s, O: 0.0009s\n",
            "🔄 Topology update at step 340 took 0.0004s\n",
            "Batch  340/1563 ( 21.8%) | Loss: 1.852903 | Accuracy: 32.03% | Batch time: 0.0423s\n",
            "Step  350 | Loss: 1.891766 | GPU: 43.8MB / 132.0MB | F: 0.0033s, B: 0.0136s, O: 0.0009s\n",
            "Step  360 | Loss: 1.466084 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0097s, O: 0.0007s\n",
            "🔄 Topology update at step 360 took 0.0000s\n",
            "Batch  360/1563 ( 23.0%) | Loss: 1.843955 | Accuracy: 32.27% | Batch time: 0.0628s\n",
            "Step  370 | Loss: 1.591789 | GPU: 43.8MB / 132.0MB | F: 0.0025s, B: 0.0093s, O: 0.0071s\n",
            "Step  380 | Loss: 1.438576 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 380 took 0.0001s\n",
            "Batch  380/1563 ( 24.3%) | Loss: 1.832545 | Accuracy: 32.69% | Batch time: 0.0415s\n",
            "Step  390 | Loss: 1.501839 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0027s, O: 0.0008s\n",
            "Step  400 | Loss: 1.838715 | GPU: 43.8MB / 132.0MB | F: 0.0040s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 400 took 0.0001s\n",
            "🧹 Memory cleanup at step 400 took 0.1656s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 1.821858 | Accuracy: 33.15% | Batch time: 0.0303s\n",
            "Step  410 | Loss: 1.325634 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0026s, O: 0.0008s\n",
            "Step  420 | Loss: 1.538403 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 420 took 0.0001s\n",
            "Batch  420/1563 ( 26.9%) | Loss: 1.810962 | Accuracy: 33.53% | Batch time: 0.0279s\n",
            "Step  430 | Loss: 1.696556 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step  440 | Loss: 1.408970 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 440 took 0.0000s\n",
            "Batch  440/1563 ( 28.2%) | Loss: 1.801556 | Accuracy: 33.96% | Batch time: 0.0357s\n",
            "Step  450 | Loss: 1.653522 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0052s, O: 0.0007s\n",
            "Step  460 | Loss: 1.800140 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0053s, O: 0.0007s\n",
            "🔄 Topology update at step 460 took 0.0000s\n",
            "Batch  460/1563 ( 29.4%) | Loss: 1.791502 | Accuracy: 34.42% | Batch time: 0.0262s\n",
            "Step  470 | Loss: 1.270794 | GPU: 43.8MB / 132.0MB | F: 0.0032s, B: 0.0027s, O: 0.0007s\n",
            "Step  480 | Loss: 1.636372 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 480 took 0.0000s\n",
            "Batch  480/1563 ( 30.7%) | Loss: 1.783204 | Accuracy: 34.66% | Batch time: 0.0366s\n",
            "Step  490 | Loss: 1.304321 | GPU: 43.8MB / 132.0MB | F: 0.0042s, B: 0.0027s, O: 0.0008s\n",
            "Step  500 | Loss: 1.565781 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 500 took 0.0001s\n",
            "🧹 Memory cleanup at step 500 took 0.1620s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 1.775053 | Accuracy: 35.02% | Batch time: 0.0260s\n",
            "Step  510 | Loss: 1.588104 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step  520 | Loss: 1.419785 | GPU: 43.8MB / 132.0MB | F: 0.0023s, B: 0.0029s, O: 0.0009s\n",
            "🔄 Topology update at step 520 took 0.0001s\n",
            "Batch  520/1563 ( 33.3%) | Loss: 1.766022 | Accuracy: 35.44% | Batch time: 0.0275s\n",
            "Step  530 | Loss: 1.815292 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0026s, O: 0.0008s\n",
            "Step  540 | Loss: 1.544701 | GPU: 43.8MB / 132.0MB | F: 0.0034s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 540 took 0.0001s\n",
            "Batch  540/1563 ( 34.5%) | Loss: 1.758054 | Accuracy: 35.72% | Batch time: 0.0367s\n",
            "Step  550 | Loss: 1.639294 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "Step  560 | Loss: 1.285374 | GPU: 43.8MB / 132.0MB | F: 0.0032s, B: 0.0030s, O: 0.0008s\n",
            "🔄 Topology update at step 560 took 0.0001s\n",
            "Batch  560/1563 ( 35.8%) | Loss: 1.748502 | Accuracy: 36.03% | Batch time: 0.0410s\n",
            "Step  570 | Loss: 1.402222 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step  580 | Loss: 1.503654 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 580 took 0.0000s\n",
            "Batch  580/1563 ( 37.1%) | Loss: 1.740431 | Accuracy: 36.16% | Batch time: 0.0283s\n",
            "Step  590 | Loss: 1.576826 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0038s, O: 0.0008s\n",
            "Step  600 | Loss: 1.570196 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "🔄 Topology update at step 600 took 0.0000s\n",
            "🧹 Memory cleanup at step 600 took 0.1755s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 1.732651 | Accuracy: 36.50% | Batch time: 0.0279s\n",
            "Step  610 | Loss: 1.588661 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step  620 | Loss: 1.354738 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 620 took 0.0000s\n",
            "Batch  620/1563 ( 39.7%) | Loss: 1.725434 | Accuracy: 36.71% | Batch time: 0.0257s\n",
            "Step  630 | Loss: 1.640289 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0021s\n",
            "Step  640 | Loss: 1.340874 | GPU: 43.8MB / 132.0MB | F: 0.0024s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 640 took 0.0001s\n",
            "Batch  640/1563 ( 40.9%) | Loss: 1.718066 | Accuracy: 36.99% | Batch time: 0.0332s\n",
            "Step  650 | Loss: 1.411690 | GPU: 43.8MB / 132.0MB | F: 0.0022s, B: 0.0037s, O: 0.0008s\n",
            "Step  660 | Loss: 1.589645 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0024s, O: 0.0008s\n",
            "🔄 Topology update at step 660 took 0.0000s\n",
            "Batch  660/1563 ( 42.2%) | Loss: 1.710432 | Accuracy: 37.41% | Batch time: 0.0310s\n",
            "Step  670 | Loss: 1.480064 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0023s, O: 0.0007s\n",
            "Step  680 | Loss: 1.695229 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 680 took 0.0001s\n",
            "Batch  680/1563 ( 43.5%) | Loss: 1.704241 | Accuracy: 37.63% | Batch time: 0.0291s\n",
            "Step  690 | Loss: 1.676544 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0052s, O: 0.0007s\n",
            "Step  700 | Loss: 1.871834 | GPU: 43.8MB / 132.0MB | F: 0.0034s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 700 took 0.0001s\n",
            "🧹 Memory cleanup at step 700 took 0.1652s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 1.698357 | Accuracy: 37.77% | Batch time: 0.0254s\n",
            "Step  710 | Loss: 1.135025 | GPU: 43.8MB / 132.0MB | F: 0.0022s, B: 0.0027s, O: 0.0008s\n",
            "Step  720 | Loss: 1.464923 | GPU: 43.8MB / 132.0MB | F: 0.0022s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 720 took 0.0054s\n",
            "Batch  720/1563 ( 46.1%) | Loss: 1.693155 | Accuracy: 37.99% | Batch time: 0.0317s\n",
            "Step  730 | Loss: 1.569052 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0076s, O: 0.0008s\n",
            "Step  740 | Loss: 1.639679 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 740 took 0.0001s\n",
            "Batch  740/1563 ( 47.3%) | Loss: 1.688418 | Accuracy: 38.18% | Batch time: 0.0342s\n",
            "Step  750 | Loss: 1.403109 | GPU: 43.8MB / 132.0MB | F: 0.0028s, B: 0.0022s, O: 0.0006s\n",
            "Step  760 | Loss: 1.602482 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 760 took 0.0000s\n",
            "Batch  760/1563 ( 48.6%) | Loss: 1.685004 | Accuracy: 38.28% | Batch time: 0.0375s\n",
            "Step  770 | Loss: 1.293612 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step  780 | Loss: 1.551285 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 780 took 0.0000s\n",
            "Batch  780/1563 ( 49.9%) | Loss: 1.678390 | Accuracy: 38.50% | Batch time: 0.0323s\n",
            "Step  790 | Loss: 1.359726 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0054s, O: 0.0021s\n",
            "Step  800 | Loss: 1.622585 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0027s, O: 0.0016s\n",
            "🔄 Topology update at step 800 took 0.0000s\n",
            "🧹 Memory cleanup at step 800 took 0.1703s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 1.672802 | Accuracy: 38.71% | Batch time: 0.0291s\n",
            "Step  810 | Loss: 1.150028 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0072s, O: 0.0033s\n",
            "Step  820 | Loss: 1.577652 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 820 took 0.0001s\n",
            "Batch  820/1563 ( 52.5%) | Loss: 1.668535 | Accuracy: 38.90% | Batch time: 0.0349s\n",
            "Step  830 | Loss: 1.605834 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0070s, O: 0.0016s\n",
            "Step  840 | Loss: 1.491394 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0012s\n",
            "🔄 Topology update at step 840 took 0.0001s\n",
            "Batch  840/1563 ( 53.7%) | Loss: 1.663846 | Accuracy: 39.05% | Batch time: 0.0318s\n",
            "Step  850 | Loss: 1.601891 | GPU: 43.8MB / 132.0MB | F: 0.0035s, B: 0.0029s, O: 0.0008s\n",
            "Step  860 | Loss: 1.534248 | GPU: 43.8MB / 132.0MB | F: 0.0089s, B: 0.0029s, O: 0.0009s\n",
            "🔄 Topology update at step 860 took 0.0000s\n",
            "Batch  860/1563 ( 55.0%) | Loss: 1.659705 | Accuracy: 39.25% | Batch time: 0.0363s\n",
            "Step  870 | Loss: 1.862267 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step  880 | Loss: 1.323143 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 880 took 0.0001s\n",
            "Batch  880/1563 ( 56.3%) | Loss: 1.655129 | Accuracy: 39.44% | Batch time: 0.0248s\n",
            "Step  890 | Loss: 1.416183 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step  900 | Loss: 1.645824 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 900 took 0.0000s\n",
            "🧹 Memory cleanup at step 900 took 0.1800s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 1.650890 | Accuracy: 39.57% | Batch time: 0.0305s\n",
            "Step  910 | Loss: 1.825966 | GPU: 43.8MB / 132.0MB | F: 0.0042s, B: 0.0025s, O: 0.0007s\n",
            "Step  920 | Loss: 1.492172 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0042s, O: 0.0008s\n",
            "🔄 Topology update at step 920 took 0.0001s\n",
            "Batch  920/1563 ( 58.9%) | Loss: 1.646332 | Accuracy: 39.79% | Batch time: 0.0277s\n",
            "Step  930 | Loss: 1.324959 | GPU: 43.8MB / 132.0MB | F: 0.0032s, B: 0.0025s, O: 0.0008s\n",
            "Step  940 | Loss: 1.467251 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 940 took 0.0001s\n",
            "Batch  940/1563 ( 60.1%) | Loss: 1.642276 | Accuracy: 39.95% | Batch time: 0.0263s\n",
            "Step  950 | Loss: 1.501560 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0026s, O: 0.0006s\n",
            "Step  960 | Loss: 1.387907 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 960 took 0.0000s\n",
            "Batch  960/1563 ( 61.4%) | Loss: 1.638847 | Accuracy: 40.07% | Batch time: 0.0291s\n",
            "Step  970 | Loss: 1.494316 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step  980 | Loss: 1.355770 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0059s, O: 0.0026s\n",
            "🔄 Topology update at step 980 took 0.0000s\n",
            "Batch  980/1563 ( 62.7%) | Loss: 1.636621 | Accuracy: 40.22% | Batch time: 0.0282s\n",
            "Step  990 | Loss: 1.074627 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0025s, O: 0.0008s\n",
            "Step 1000 | Loss: 1.563864 | GPU: 43.8MB / 132.0MB | F: 0.0057s, B: 0.0017s, O: 0.0005s\n",
            "🔄 Topology update at step 1000 took 0.0000s\n",
            "🧹 Memory cleanup at step 1000 took 0.2233s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 1.631883 | Accuracy: 40.42% | Batch time: 0.0430s\n",
            "Step 1010 | Loss: 1.194618 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0169s, O: 0.0010s\n",
            "Step 1020 | Loss: 1.795244 | GPU: 43.8MB / 132.0MB | F: 0.0057s, B: 0.0062s, O: 0.0007s\n",
            "🔄 Topology update at step 1020 took 0.0000s\n",
            "Batch 1020/1563 ( 65.3%) | Loss: 1.627530 | Accuracy: 40.59% | Batch time: 0.0361s\n",
            "Step 1030 | Loss: 1.676069 | GPU: 43.8MB / 132.0MB | F: 0.0013s, B: 0.0073s, O: 0.0006s\n",
            "Step 1040 | Loss: 1.321074 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0056s, O: 0.0038s\n",
            "🔄 Topology update at step 1040 took 0.0001s\n",
            "Batch 1040/1563 ( 66.5%) | Loss: 1.623418 | Accuracy: 40.73% | Batch time: 0.0401s\n",
            "Step 1050 | Loss: 1.536922 | GPU: 43.8MB / 132.0MB | F: 0.0015s, B: 0.0080s, O: 0.0006s\n",
            "Step 1060 | Loss: 1.510227 | GPU: 43.8MB / 132.0MB | F: 0.0013s, B: 0.0020s, O: 0.0007s\n",
            "🔄 Topology update at step 1060 took 0.0001s\n",
            "Batch 1060/1563 ( 67.8%) | Loss: 1.620252 | Accuracy: 40.85% | Batch time: 0.0396s\n",
            "Step 1070 | Loss: 1.514927 | GPU: 43.8MB / 132.0MB | F: 0.0098s, B: 0.0027s, O: 0.0060s\n",
            "Step 1080 | Loss: 1.267498 | GPU: 43.8MB / 132.0MB | F: 0.0161s, B: 0.0129s, O: 0.0008s\n",
            "🔄 Topology update at step 1080 took 0.0000s\n",
            "Batch 1080/1563 ( 69.1%) | Loss: 1.617150 | Accuracy: 40.98% | Batch time: 0.0526s\n",
            "Step 1090 | Loss: 1.338631 | GPU: 43.8MB / 132.0MB | F: 0.0013s, B: 0.0048s, O: 0.0086s\n",
            "Step 1100 | Loss: 1.535376 | GPU: 43.8MB / 132.0MB | F: 0.0092s, B: 0.0071s, O: 0.0007s\n",
            "🔄 Topology update at step 1100 took 0.0001s\n",
            "🧹 Memory cleanup at step 1100 took 0.1916s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 1.613270 | Accuracy: 41.12% | Batch time: 0.0325s\n",
            "Step 1110 | Loss: 1.674252 | GPU: 43.8MB / 132.0MB | F: 0.0022s, B: 0.0024s, O: 0.0006s\n",
            "Step 1120 | Loss: 1.266027 | GPU: 43.8MB / 132.0MB | F: 0.0022s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1120 took 0.0000s\n",
            "Batch 1120/1563 ( 71.7%) | Loss: 1.610578 | Accuracy: 41.23% | Batch time: 0.0246s\n",
            "Step 1130 | Loss: 1.273928 | GPU: 43.8MB / 132.0MB | F: 0.0039s, B: 0.0024s, O: 0.0028s\n",
            "Step 1140 | Loss: 1.338331 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1140 took 0.0000s\n",
            "Batch 1140/1563 ( 72.9%) | Loss: 1.606099 | Accuracy: 41.40% | Batch time: 0.0437s\n",
            "Step 1150 | Loss: 1.320526 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0008s\n",
            "Step 1160 | Loss: 1.461792 | GPU: 43.8MB / 132.0MB | F: 0.0027s, B: 0.0028s, O: 0.0009s\n",
            "🔄 Topology update at step 1160 took 0.0000s\n",
            "Batch 1160/1563 ( 74.2%) | Loss: 1.602525 | Accuracy: 41.54% | Batch time: 0.0272s\n",
            "Step 1170 | Loss: 1.540677 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "Step 1180 | Loss: 1.294820 | GPU: 43.8MB / 132.0MB | F: 0.0089s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 1180 took 0.0001s\n",
            "Batch 1180/1563 ( 75.5%) | Loss: 1.598657 | Accuracy: 41.68% | Batch time: 0.0371s\n",
            "Step 1190 | Loss: 1.336334 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0032s\n",
            "Step 1200 | Loss: 1.368069 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1200 took 0.0000s\n",
            "🧹 Memory cleanup at step 1200 took 0.1637s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.596094 | Accuracy: 41.80% | Batch time: 0.0294s\n",
            "Step 1210 | Loss: 0.948534 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "Step 1220 | Loss: 1.382957 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1220 took 0.0000s\n",
            "Batch 1220/1563 ( 78.1%) | Loss: 1.592795 | Accuracy: 41.99% | Batch time: 0.0403s\n",
            "Step 1230 | Loss: 1.481195 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0067s, O: 0.0008s\n",
            "Step 1240 | Loss: 1.646579 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 1240 took 0.0001s\n",
            "Batch 1240/1563 ( 79.3%) | Loss: 1.590878 | Accuracy: 42.04% | Batch time: 0.0251s\n",
            "Step 1250 | Loss: 1.160370 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0027s, O: 0.0008s\n",
            "Step 1260 | Loss: 1.572010 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 1260 took 0.0001s\n",
            "Batch 1260/1563 ( 80.6%) | Loss: 1.588128 | Accuracy: 42.12% | Batch time: 0.0386s\n",
            "Step 1270 | Loss: 1.490545 | GPU: 43.8MB / 132.0MB | F: 0.0039s, B: 0.0028s, O: 0.0009s\n",
            "Step 1280 | Loss: 1.426138 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1280 took 0.0001s\n",
            "Batch 1280/1563 ( 81.9%) | Loss: 1.585482 | Accuracy: 42.20% | Batch time: 0.0399s\n",
            "Step 1290 | Loss: 1.633877 | GPU: 43.8MB / 132.0MB | F: 0.0037s, B: 0.0056s, O: 0.0008s\n",
            "Step 1300 | Loss: 1.274847 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 1300 took 0.0000s\n",
            "🧹 Memory cleanup at step 1300 took 0.1615s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.582370 | Accuracy: 42.33% | Batch time: 0.0283s\n",
            "Step 1310 | Loss: 1.370191 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step 1320 | Loss: 1.518755 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 1320 took 0.0000s\n",
            "Batch 1320/1563 ( 84.5%) | Loss: 1.579520 | Accuracy: 42.45% | Batch time: 0.0355s\n",
            "Step 1330 | Loss: 1.532275 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0026s, O: 0.0008s\n",
            "Step 1340 | Loss: 1.147960 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 1340 took 0.0001s\n",
            "Batch 1340/1563 ( 85.7%) | Loss: 1.576576 | Accuracy: 42.56% | Batch time: 0.0433s\n",
            "Step 1350 | Loss: 1.494901 | GPU: 43.8MB / 132.0MB | F: 0.0032s, B: 0.0028s, O: 0.0008s\n",
            "Step 1360 | Loss: 1.065758 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 1360 took 0.0001s\n",
            "Batch 1360/1563 ( 87.0%) | Loss: 1.573002 | Accuracy: 42.74% | Batch time: 0.0328s\n",
            "Step 1370 | Loss: 1.413054 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0082s, O: 0.0006s\n",
            "Step 1380 | Loss: 1.066647 | GPU: 43.8MB / 132.0MB | F: 0.0033s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 1380 took 0.0000s\n",
            "Batch 1380/1563 ( 88.3%) | Loss: 1.569630 | Accuracy: 42.84% | Batch time: 0.0329s\n",
            "Step 1390 | Loss: 1.522769 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0027s, O: 0.0008s\n",
            "Step 1400 | Loss: 1.700533 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0023s\n",
            "🔄 Topology update at step 1400 took 0.0000s\n",
            "🧹 Memory cleanup at step 1400 took 0.1604s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.566092 | Accuracy: 42.97% | Batch time: 0.0343s\n",
            "Step 1410 | Loss: 1.710690 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 1420 | Loss: 1.384895 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1420 took 0.0001s\n",
            "Batch 1420/1563 ( 90.9%) | Loss: 1.563838 | Accuracy: 43.04% | Batch time: 0.0324s\n",
            "Step 1430 | Loss: 1.449366 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0054s, O: 0.0009s\n",
            "Step 1440 | Loss: 1.150590 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 1440 took 0.0001s\n",
            "Batch 1440/1563 ( 92.1%) | Loss: 1.560892 | Accuracy: 43.19% | Batch time: 0.0332s\n",
            "Step 1450 | Loss: 1.378980 | GPU: 43.8MB / 132.0MB | F: 0.0070s, B: 0.0027s, O: 0.0008s\n",
            "Step 1460 | Loss: 1.587653 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1460 took 0.0001s\n",
            "Batch 1460/1563 ( 93.4%) | Loss: 1.558297 | Accuracy: 43.30% | Batch time: 0.0321s\n",
            "Step 1470 | Loss: 1.378305 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0074s, O: 0.0008s\n",
            "Step 1480 | Loss: 1.253350 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0028s, O: 0.0007s\n",
            "🔄 Topology update at step 1480 took 0.0001s\n",
            "Batch 1480/1563 ( 94.7%) | Loss: 1.554687 | Accuracy: 43.45% | Batch time: 0.0287s\n",
            "Step 1490 | Loss: 1.505749 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0037s, O: 0.0006s\n",
            "Step 1500 | Loss: 1.173595 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 1500 took 0.0000s\n",
            "🧹 Memory cleanup at step 1500 took 0.1718s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.552658 | Accuracy: 43.53% | Batch time: 0.0363s\n",
            "Step 1510 | Loss: 1.200823 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 1520 | Loss: 1.294773 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1520 took 0.0001s\n",
            "Batch 1520/1563 ( 97.2%) | Loss: 1.549088 | Accuracy: 43.69% | Batch time: 0.0294s\n",
            "Step 1530 | Loss: 1.183449 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "Step 1540 | Loss: 1.451752 | GPU: 43.8MB / 132.0MB | F: 0.0032s, B: 0.0029s, O: 0.0013s\n",
            "🔄 Topology update at step 1540 took 0.0001s\n",
            "Batch 1540/1563 ( 98.5%) | Loss: 1.546272 | Accuracy: 43.80% | Batch time: 0.0300s\n",
            "Step 1550 | Loss: 1.341883 | GPU: 43.8MB / 132.0MB | F: 0.0085s, B: 0.0031s, O: 0.0009s\n",
            "Step 1560 | Loss: 1.722832 | GPU: 43.8MB / 132.0MB | F: 0.0014s, B: 0.0017s, O: 0.0006s\n",
            "🔄 Topology update at step 1560 took 0.0000s\n",
            "Batch 1560/1563 ( 99.8%) | Loss: 1.543097 | Accuracy: 43.89% | Batch time: 0.0220s\n",
            "\n",
            "-------------------- EPOCH 1 SUMMARY --------------------\n",
            "Loss: 1.542667 | Accuracy: 43.91%\n",
            "Time: 27.23s total, 0.0151s per batch\n",
            "🔄 Final Memory - RAM: 1602.6MB, GPU: 43.6MB allocated, 70.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=43.8, peak=43.8\n",
            "===============================\n",
            "\n",
            "⏱️ ImprovedTALT training took 27.2348 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 1.249236 | Accuracy: 54.23% | Batch time: 0.0016s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 1.239609 | Accuracy: 55.48% | Batch time: 0.0014s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 1.233101 | Accuracy: 55.71% | Batch time: 0.0013s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 1.231935 | Accuracy: 55.78% | Batch time: 0.0014s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 1.234149 | Accuracy: 55.43% | Batch time: 0.0021s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 1.241326 | Accuracy: 55.09% | Batch time: 0.0011s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.243564 | Accuracy: 54.99%\n",
            "Time: 3.26s total, 0.0017s per batch\n",
            "⏱️ ImprovedTALT evaluation took 3.2639 seconds\n",
            "ImprovedTALT - Epoch 1:\n",
            "  Train Loss: 1.542667, Train Acc: 43.91%\n",
            "  Test Loss:  1.243564, Test Acc:  54.99%\n",
            "\n",
            "Epoch 1 completed in 95.92s\n",
            "Results saved to ./results/cifar10/epoch_1_results.json\n",
            "\n",
            "============================== EPOCH 2/3 ==============================\n",
            "\n",
            "------------------------- SGD Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 2\n",
            "Batches: 1563, Batch size: 32\n",
            "Batch   50/1563 (  3.2%) | Loss: 1.736544 | Acc: 32.05% | Batch time: 0.0037s\n",
            "Batch  100/1563 (  6.4%) | Loss: 1.732493 | Acc: 33.69% | Batch time: 0.0085s\n",
            "Batch  150/1563 (  9.6%) | Loss: 1.733235 | Acc: 33.82% | Batch time: 0.0052s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 1.734856 | Acc: 33.92% | Batch time: 0.0038s\n",
            "Batch  250/1563 ( 16.0%) | Loss: 1.726669 | Acc: 34.61% | Batch time: 0.0039s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 1.716841 | Acc: 34.98% | Batch time: 0.0043s\n",
            "Batch  350/1563 ( 22.4%) | Loss: 1.719397 | Acc: 34.84% | Batch time: 0.0051s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 1.712867 | Acc: 35.34% | Batch time: 0.0058s\n",
            "Batch  450/1563 ( 28.8%) | Loss: 1.706133 | Acc: 35.70% | Batch time: 0.0038s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 1.696555 | Acc: 36.16% | Batch time: 0.0045s\n",
            "Batch  550/1563 ( 35.2%) | Loss: 1.690178 | Acc: 36.43% | Batch time: 0.0040s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 1.683136 | Acc: 36.77% | Batch time: 0.0041s\n",
            "Batch  650/1563 ( 41.6%) | Loss: 1.674358 | Acc: 36.99% | Batch time: 0.0039s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 1.665754 | Acc: 37.29% | Batch time: 0.0043s\n",
            "Batch  750/1563 ( 48.0%) | Loss: 1.659178 | Acc: 37.62% | Batch time: 0.0043s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 1.651784 | Acc: 37.85% | Batch time: 0.0036s\n",
            "Batch  850/1563 ( 54.4%) | Loss: 1.643807 | Acc: 38.15% | Batch time: 0.0048s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 1.634289 | Acc: 38.50% | Batch time: 0.0051s\n",
            "Batch  950/1563 ( 60.8%) | Loss: 1.629753 | Acc: 38.67% | Batch time: 0.0048s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 1.624035 | Acc: 38.99% | Batch time: 0.0055s\n",
            "Batch 1050/1563 ( 67.2%) | Loss: 1.615725 | Acc: 39.25% | Batch time: 0.0067s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 1.610261 | Acc: 39.55% | Batch time: 0.0047s\n",
            "Batch 1150/1563 ( 73.6%) | Loss: 1.603818 | Acc: 39.76% | Batch time: 0.0045s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.598572 | Acc: 39.96% | Batch time: 0.0039s\n",
            "Batch 1250/1563 ( 80.0%) | Loss: 1.591960 | Acc: 40.31% | Batch time: 0.0055s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.586668 | Acc: 40.54% | Batch time: 0.0044s\n",
            "Batch 1350/1563 ( 86.4%) | Loss: 1.580362 | Acc: 40.81% | Batch time: 0.0039s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.573545 | Acc: 41.13% | Batch time: 0.0036s\n",
            "Batch 1450/1563 ( 92.8%) | Loss: 1.570264 | Acc: 41.27% | Batch time: 0.0045s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.564808 | Acc: 41.47% | Batch time: 0.0048s\n",
            "Batch 1550/1563 ( 99.2%) | Loss: 1.560551 | Acc: 41.69% | Batch time: 0.0052s\n",
            "\n",
            "Standard optimizer - Epoch 2 summary:\n",
            "Loss: 1.559338 | Accuracy: 41.74%\n",
            "⏱️ SGD training took 18.6594 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 1.160436 | Accuracy: 60.11% | Batch time: 0.0015s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 1.182095 | Accuracy: 59.62% | Batch time: 0.0013s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 1.181233 | Accuracy: 60.00% | Batch time: 0.0014s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 1.181245 | Accuracy: 60.00% | Batch time: 0.0014s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 1.178634 | Accuracy: 60.10% | Batch time: 0.0016s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 1.179686 | Accuracy: 59.81% | Batch time: 0.0015s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.180880 | Accuracy: 59.65%\n",
            "Time: 2.96s total, 0.0016s per batch\n",
            "⏱️ SGD evaluation took 2.9568 seconds\n",
            "SGD - Epoch 2:\n",
            "  Train Loss: 1.559338, Train Acc: 41.74%\n",
            "  Test Loss:  1.180880, Test Acc:  59.65%\n",
            "\n",
            "------------------------- Adam Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 2\n",
            "Batches: 1563, Batch size: 32\n",
            "Batch   50/1563 (  3.2%) | Loss: 1.552128 | Acc: 39.71% | Batch time: 0.0116s\n",
            "Batch  100/1563 (  6.4%) | Loss: 1.543062 | Acc: 40.19% | Batch time: 0.0093s\n",
            "Batch  150/1563 (  9.6%) | Loss: 1.538735 | Acc: 40.50% | Batch time: 0.0046s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 1.540822 | Acc: 40.87% | Batch time: 0.0053s\n",
            "Batch  250/1563 ( 16.0%) | Loss: 1.549159 | Acc: 40.61% | Batch time: 0.0168s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 1.550271 | Acc: 40.85% | Batch time: 0.0049s\n",
            "Batch  350/1563 ( 22.4%) | Loss: 1.551915 | Acc: 40.95% | Batch time: 0.0036s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 1.547873 | Acc: 41.19% | Batch time: 0.0134s\n",
            "Batch  450/1563 ( 28.8%) | Loss: 1.545824 | Acc: 41.46% | Batch time: 0.0057s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 1.546687 | Acc: 41.45% | Batch time: 0.0063s\n",
            "Batch  550/1563 ( 35.2%) | Loss: 1.542383 | Acc: 41.57% | Batch time: 0.0049s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 1.541802 | Acc: 41.55% | Batch time: 0.0045s\n",
            "Batch  650/1563 ( 41.6%) | Loss: 1.539570 | Acc: 41.61% | Batch time: 0.0053s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 1.535732 | Acc: 41.81% | Batch time: 0.0076s\n",
            "Batch  750/1563 ( 48.0%) | Loss: 1.535582 | Acc: 41.91% | Batch time: 0.0046s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 1.532965 | Acc: 42.02% | Batch time: 0.0053s\n",
            "Batch  850/1563 ( 54.4%) | Loss: 1.530237 | Acc: 42.07% | Batch time: 0.0044s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 1.526612 | Acc: 42.20% | Batch time: 0.0054s\n",
            "Batch  950/1563 ( 60.8%) | Loss: 1.524263 | Acc: 42.27% | Batch time: 0.0067s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 1.521427 | Acc: 42.53% | Batch time: 0.0046s\n",
            "Batch 1050/1563 ( 67.2%) | Loss: 1.519442 | Acc: 42.62% | Batch time: 0.0048s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 1.517889 | Acc: 42.67% | Batch time: 0.0058s\n",
            "Batch 1150/1563 ( 73.6%) | Loss: 1.515169 | Acc: 42.81% | Batch time: 0.0059s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.514259 | Acc: 42.87% | Batch time: 0.0055s\n",
            "Batch 1250/1563 ( 80.0%) | Loss: 1.513777 | Acc: 42.89% | Batch time: 0.0042s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.513110 | Acc: 42.90% | Batch time: 0.0062s\n",
            "Batch 1350/1563 ( 86.4%) | Loss: 1.512096 | Acc: 42.96% | Batch time: 0.0121s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.509665 | Acc: 43.07% | Batch time: 0.0040s\n",
            "Batch 1450/1563 ( 92.8%) | Loss: 1.507842 | Acc: 43.11% | Batch time: 0.0059s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.506100 | Acc: 43.16% | Batch time: 0.0055s\n",
            "Batch 1550/1563 ( 99.2%) | Loss: 1.504901 | Acc: 43.25% | Batch time: 0.0054s\n",
            "\n",
            "Standard optimizer - Epoch 2 summary:\n",
            "Loss: 1.504474 | Accuracy: 43.26%\n",
            "⏱️ Adam training took 19.3889 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 1.174882 | Accuracy: 57.54% | Batch time: 0.0014s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 1.193695 | Accuracy: 56.93% | Batch time: 0.0013s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 1.194621 | Accuracy: 56.89% | Batch time: 0.0016s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 1.195191 | Accuracy: 57.29% | Batch time: 0.0019s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 1.190957 | Accuracy: 57.43% | Batch time: 0.0014s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 1.191228 | Accuracy: 57.36% | Batch time: 0.0013s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.192363 | Accuracy: 57.25%\n",
            "Time: 2.98s total, 0.0017s per batch\n",
            "⏱️ Adam evaluation took 2.9818 seconds\n",
            "Adam - Epoch 2:\n",
            "  Train Loss: 1.504474, Train Acc: 43.26%\n",
            "  Test Loss:  1.192363, Test Acc:  57.25%\n",
            "\n",
            "------------------------- AdamW Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 2\n",
            "Batches: 1563, Batch size: 32\n",
            "Batch   50/1563 (  3.2%) | Loss: 1.536856 | Acc: 42.71% | Batch time: 0.0107s\n",
            "Batch  100/1563 (  6.4%) | Loss: 1.520136 | Acc: 42.45% | Batch time: 0.0045s\n",
            "Batch  150/1563 (  9.6%) | Loss: 1.514256 | Acc: 43.15% | Batch time: 0.0063s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 1.507794 | Acc: 43.63% | Batch time: 0.0050s\n",
            "Batch  250/1563 ( 16.0%) | Loss: 1.510503 | Acc: 43.36% | Batch time: 0.0047s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 1.511025 | Acc: 43.29% | Batch time: 0.0056s\n",
            "Batch  350/1563 ( 22.4%) | Loss: 1.504138 | Acc: 43.32% | Batch time: 0.0048s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 1.505756 | Acc: 43.38% | Batch time: 0.0061s\n",
            "Batch  450/1563 ( 28.8%) | Loss: 1.501090 | Acc: 43.52% | Batch time: 0.0042s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 1.500337 | Acc: 43.54% | Batch time: 0.0089s\n",
            "Batch  550/1563 ( 35.2%) | Loss: 1.503167 | Acc: 43.27% | Batch time: 0.0113s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 1.498984 | Acc: 43.34% | Batch time: 0.0036s\n",
            "Batch  650/1563 ( 41.6%) | Loss: 1.498173 | Acc: 43.44% | Batch time: 0.0063s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 1.495590 | Acc: 43.52% | Batch time: 0.0055s\n",
            "Batch  750/1563 ( 48.0%) | Loss: 1.493020 | Acc: 43.49% | Batch time: 0.0063s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 1.489837 | Acc: 43.61% | Batch time: 0.0053s\n",
            "Batch  850/1563 ( 54.4%) | Loss: 1.486820 | Acc: 43.72% | Batch time: 0.0053s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 1.485382 | Acc: 43.82% | Batch time: 0.0047s\n",
            "Batch  950/1563 ( 60.8%) | Loss: 1.482475 | Acc: 43.90% | Batch time: 0.0047s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 1.482226 | Acc: 43.92% | Batch time: 0.0054s\n",
            "Batch 1050/1563 ( 67.2%) | Loss: 1.480314 | Acc: 43.97% | Batch time: 0.0047s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 1.479116 | Acc: 44.05% | Batch time: 0.0051s\n",
            "Batch 1150/1563 ( 73.6%) | Loss: 1.476299 | Acc: 44.17% | Batch time: 0.0046s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.473963 | Acc: 44.30% | Batch time: 0.0064s\n",
            "Batch 1250/1563 ( 80.0%) | Loss: 1.473722 | Acc: 44.26% | Batch time: 0.0046s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.471139 | Acc: 44.36% | Batch time: 0.0046s\n",
            "Batch 1350/1563 ( 86.4%) | Loss: 1.470602 | Acc: 44.37% | Batch time: 0.0046s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.471553 | Acc: 44.35% | Batch time: 0.0059s\n",
            "Batch 1450/1563 ( 92.8%) | Loss: 1.471182 | Acc: 44.41% | Batch time: 0.0052s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.469082 | Acc: 44.48% | Batch time: 0.0044s\n",
            "Batch 1550/1563 ( 99.2%) | Loss: 1.466298 | Acc: 44.59% | Batch time: 0.0050s\n",
            "\n",
            "Standard optimizer - Epoch 2 summary:\n",
            "Loss: 1.464938 | Accuracy: 44.65%\n",
            "⏱️ AdamW training took 18.6344 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 1.159798 | Accuracy: 58.52% | Batch time: 0.0010s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 1.175559 | Accuracy: 59.31% | Batch time: 0.0036s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 1.176462 | Accuracy: 59.27% | Batch time: 0.0011s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 1.179318 | Accuracy: 58.89% | Batch time: 0.0014s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 1.178136 | Accuracy: 58.65% | Batch time: 0.0014s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 1.182184 | Accuracy: 58.98% | Batch time: 0.0012s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.182857 | Accuracy: 58.85%\n",
            "Time: 3.87s total, 0.0016s per batch\n",
            "⏱️ AdamW evaluation took 3.8658 seconds\n",
            "AdamW - Epoch 2:\n",
            "  Train Loss: 1.464938, Train Acc: 44.65%\n",
            "  Test Loss:  1.182857, Test Acc:  58.85%\n",
            "\n",
            "------------------------- ImprovedTALT Optimizer -------------------------\n",
            "\n",
            "==================== EPOCH 2 TRAINING ====================\n",
            "Device: cuda, Batches: 1563, Batch size: 32\n",
            "🔄 Initial Memory - RAM: 1602.9MB, GPU: 43.5MB allocated, 64.0MB reserved\n",
            "Batch    0/1563 (  0.0%) | Loss: 1.064361 | Accuracy: 56.25% | Batch time: 0.0225s\n",
            "Step 1570 | Loss: 1.234665 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0024s, O: 0.0007s\n",
            "Step 1580 | Loss: 1.143294 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0024s, O: 0.0024s\n",
            "🔄 Topology update at step 1580 took 0.0002s\n",
            "Batch   20/1563 (  1.3%) | Loss: 1.278989 | Accuracy: 55.06% | Batch time: 0.0058s\n",
            "Step 1590 | Loss: 1.456792 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0025s, O: 0.0007s\n",
            "Step 1600 | Loss: 1.294024 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1600 took 0.0000s\n",
            "🧹 Memory cleanup at step 1600 took 0.2545s\n",
            "Batch   40/1563 (  2.6%) | Loss: 1.332804 | Accuracy: 52.67% | Batch time: 0.0057s\n",
            "Step 1610 | Loss: 1.042245 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0080s, O: 0.0009s\n",
            "Step 1620 | Loss: 1.720387 | GPU: 43.8MB / 132.0MB | F: 0.0023s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 1620 took 0.0000s\n",
            "Batch   60/1563 (  3.8%) | Loss: 1.340471 | Accuracy: 52.82% | Batch time: 0.0061s\n",
            "Step 1630 | Loss: 1.255970 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "Step 1640 | Loss: 1.276938 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 1640 took 0.0004s\n",
            "Batch   80/1563 (  5.1%) | Loss: 1.330673 | Accuracy: 53.74% | Batch time: 0.0056s\n",
            "Step 1650 | Loss: 1.094268 | GPU: 43.8MB / 132.0MB | F: 0.0029s, B: 0.0024s, O: 0.0013s\n",
            "Step 1660 | Loss: 1.187378 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0042s, O: 0.0008s\n",
            "🔄 Topology update at step 1660 took 0.0000s\n",
            "Batch  100/1563 (  6.4%) | Loss: 1.308168 | Accuracy: 53.90% | Batch time: 0.0078s\n",
            "Step 1670 | Loss: 1.099388 | GPU: 43.8MB / 132.0MB | F: 0.0070s, B: 0.0029s, O: 0.0009s\n",
            "Step 1680 | Loss: 1.222153 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 1680 took 0.0001s\n",
            "Batch  120/1563 (  7.7%) | Loss: 1.301654 | Accuracy: 54.11% | Batch time: 0.0067s\n",
            "Step 1690 | Loss: 1.238464 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Step 1700 | Loss: 1.335711 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0009s\n",
            "🔄 Topology update at step 1700 took 0.0001s\n",
            "🧹 Memory cleanup at step 1700 took 0.1568s\n",
            "Batch  140/1563 (  9.0%) | Loss: 1.302124 | Accuracy: 53.83% | Batch time: 0.0065s\n",
            "Step 1710 | Loss: 1.092735 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0030s, O: 0.0006s\n",
            "Step 1720 | Loss: 1.471749 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0018s\n",
            "🔄 Topology update at step 1720 took 0.0000s\n",
            "Batch  160/1563 ( 10.2%) | Loss: 1.294991 | Accuracy: 54.04% | Batch time: 0.0074s\n",
            "Step 1730 | Loss: 1.279357 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0090s, O: 0.0006s\n",
            "Step 1740 | Loss: 1.302839 | GPU: 43.8MB / 132.0MB | F: 0.0030s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 1740 took 0.0001s\n",
            "Batch  180/1563 ( 11.5%) | Loss: 1.296991 | Accuracy: 54.09% | Batch time: 0.0056s\n",
            "Step 1750 | Loss: 1.149793 | GPU: 43.8MB / 132.0MB | F: 0.0092s, B: 0.0028s, O: 0.0008s\n",
            "Step 1760 | Loss: 1.432838 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 1760 took 0.0001s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 1.299560 | Accuracy: 54.15% | Batch time: 0.0054s\n",
            "Step 1770 | Loss: 1.274083 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 1780 | Loss: 1.268183 | GPU: 43.8MB / 132.0MB | F: 0.0042s, B: 0.0174s, O: 0.0009s\n",
            "🔄 Topology update at step 1780 took 0.0000s\n",
            "Batch  220/1563 ( 14.1%) | Loss: 1.296732 | Accuracy: 54.43% | Batch time: 0.0083s\n",
            "Step 1790 | Loss: 1.230644 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0027s, O: 0.0007s\n",
            "Step 1800 | Loss: 1.268112 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 1800 took 0.0000s\n",
            "🧹 Memory cleanup at step 1800 took 0.1636s\n",
            "Batch  240/1563 ( 15.4%) | Loss: 1.300413 | Accuracy: 54.08% | Batch time: 0.0100s\n",
            "Step 1810 | Loss: 1.115234 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0022s, O: 0.0007s\n",
            "Step 1820 | Loss: 1.345794 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0040s, O: 0.0007s\n",
            "🔄 Topology update at step 1820 took 0.0000s\n",
            "Batch  260/1563 ( 16.6%) | Loss: 1.295738 | Accuracy: 54.32% | Batch time: 0.0050s\n",
            "Step 1830 | Loss: 1.284101 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0026s, O: 0.0007s\n",
            "Step 1840 | Loss: 1.394033 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0008s\n",
            "🔄 Topology update at step 1840 took 0.0001s\n",
            "Batch  280/1563 ( 17.9%) | Loss: 1.295636 | Accuracy: 54.29% | Batch time: 0.0055s\n",
            "Step 1850 | Loss: 1.343000 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0027s, O: 0.0008s\n",
            "Step 1860 | Loss: 1.257114 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0026s, O: 0.0009s\n",
            "🔄 Topology update at step 1860 took 0.0000s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 1.298945 | Accuracy: 54.15% | Batch time: 0.0055s\n",
            "Step 1870 | Loss: 1.197068 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0026s, O: 0.0007s\n",
            "Step 1880 | Loss: 1.370255 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0096s, O: 0.0008s\n",
            "🔄 Topology update at step 1880 took 0.0001s\n",
            "Batch  320/1563 ( 20.5%) | Loss: 1.297488 | Accuracy: 54.13% | Batch time: 0.0057s\n",
            "Step 1890 | Loss: 1.230041 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0032s, O: 0.0007s\n",
            "Step 1900 | Loss: 1.167473 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 1900 took 0.0000s\n",
            "🧹 Memory cleanup at step 1900 took 0.1649s\n",
            "Batch  340/1563 ( 21.8%) | Loss: 1.295155 | Accuracy: 54.15% | Batch time: 0.0097s\n",
            "Step 1910 | Loss: 1.385889 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 1920 | Loss: 1.198380 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 1920 took 0.0000s\n",
            "Batch  360/1563 ( 23.0%) | Loss: 1.292889 | Accuracy: 54.26% | Batch time: 0.0101s\n",
            "Step 1930 | Loss: 1.314882 | GPU: 43.8MB / 132.0MB | F: 0.0047s, B: 0.0028s, O: 0.0009s\n",
            "Step 1940 | Loss: 1.155555 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0090s, O: 0.0020s\n",
            "🔄 Topology update at step 1940 took 0.0000s\n",
            "Batch  380/1563 ( 24.3%) | Loss: 1.296059 | Accuracy: 54.02% | Batch time: 0.0108s\n",
            "Step 1950 | Loss: 1.103045 | GPU: 43.8MB / 132.0MB | F: 0.0037s, B: 0.0029s, O: 0.0008s\n",
            "Step 1960 | Loss: 1.354150 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 1960 took 0.0001s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 1.296925 | Accuracy: 53.97% | Batch time: 0.0059s\n",
            "Step 1970 | Loss: 1.108041 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 1980 | Loss: 1.330600 | GPU: 43.8MB / 132.0MB | F: 0.0073s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 1980 took 0.0001s\n",
            "Batch  420/1563 ( 26.9%) | Loss: 1.294570 | Accuracy: 54.00% | Batch time: 0.0061s\n",
            "Step 1990 | Loss: 1.376552 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0057s, O: 0.0017s\n",
            "Step 2000 | Loss: 1.199686 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 2000 took 0.0001s\n",
            "🧹 Memory cleanup at step 2000 took 0.1694s\n",
            "Batch  440/1563 ( 28.2%) | Loss: 1.291976 | Accuracy: 54.13% | Batch time: 0.0056s\n",
            "Step 2010 | Loss: 1.258923 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 2020 | Loss: 1.524731 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0026s, O: 0.0026s\n",
            "🔄 Topology update at step 2020 took 0.0000s\n",
            "Batch  460/1563 ( 29.4%) | Loss: 1.294265 | Accuracy: 54.09% | Batch time: 0.0054s\n",
            "Step 2030 | Loss: 1.070314 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0026s, O: 0.0007s\n",
            "Step 2040 | Loss: 1.001808 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 2040 took 0.0000s\n",
            "Batch  480/1563 ( 30.7%) | Loss: 1.293293 | Accuracy: 54.13% | Batch time: 0.0060s\n",
            "Step 2050 | Loss: 1.303947 | GPU: 43.8MB / 132.0MB | F: 0.0024s, B: 0.0030s, O: 0.0021s\n",
            "Step 2060 | Loss: 1.311803 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2060 took 0.0001s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 1.290470 | Accuracy: 54.12% | Batch time: 0.0057s\n",
            "Step 2070 | Loss: 1.499884 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0025s, O: 0.0006s\n",
            "Step 2080 | Loss: 1.027945 | GPU: 43.8MB / 132.0MB | F: 0.0023s, B: 0.0026s, O: 0.0009s\n",
            "🔄 Topology update at step 2080 took 0.0000s\n",
            "Batch  520/1563 ( 33.3%) | Loss: 1.287140 | Accuracy: 54.21% | Batch time: 0.0041s\n",
            "Step 2090 | Loss: 1.386155 | GPU: 43.8MB / 132.0MB | F: 0.0030s, B: 0.0042s, O: 0.0008s\n",
            "Step 2100 | Loss: 1.327638 | GPU: 43.8MB / 132.0MB | F: 0.0050s, B: 0.0033s, O: 0.0007s\n",
            "🔄 Topology update at step 2100 took 0.0000s\n",
            "🧹 Memory cleanup at step 2100 took 0.1954s\n",
            "Batch  540/1563 ( 34.5%) | Loss: 1.285020 | Accuracy: 54.27% | Batch time: 0.0046s\n",
            "Step 2110 | Loss: 1.084148 | GPU: 43.8MB / 132.0MB | F: 0.0014s, B: 0.0070s, O: 0.0007s\n",
            "Step 2120 | Loss: 1.129303 | GPU: 43.8MB / 132.0MB | F: 0.0015s, B: 0.0018s, O: 0.0006s\n",
            "🔄 Topology update at step 2120 took 0.0001s\n",
            "Batch  560/1563 ( 35.8%) | Loss: 1.284064 | Accuracy: 54.29% | Batch time: 0.0039s\n",
            "Step 2130 | Loss: 1.112020 | GPU: 43.8MB / 132.0MB | F: 0.0012s, B: 0.0050s, O: 0.0006s\n",
            "Step 2140 | Loss: 1.628269 | GPU: 43.8MB / 132.0MB | F: 0.0012s, B: 0.0062s, O: 0.0006s\n",
            "🔄 Topology update at step 2140 took 0.0000s\n",
            "Batch  580/1563 ( 37.1%) | Loss: 1.281295 | Accuracy: 54.34% | Batch time: 0.0090s\n",
            "Step 2150 | Loss: 1.310841 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0058s, O: 0.0005s\n",
            "Step 2160 | Loss: 1.110109 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0020s, O: 0.0006s\n",
            "🔄 Topology update at step 2160 took 0.0000s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 1.278494 | Accuracy: 54.46% | Batch time: 0.0062s\n",
            "Step 2170 | Loss: 1.276847 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0082s, O: 0.0007s\n",
            "Step 2180 | Loss: 1.050682 | GPU: 43.8MB / 132.0MB | F: 0.0039s, B: 0.0043s, O: 0.0028s\n",
            "🔄 Topology update at step 2180 took 0.0000s\n",
            "Batch  620/1563 ( 39.7%) | Loss: 1.278279 | Accuracy: 54.45% | Batch time: 0.0087s\n",
            "Step 2190 | Loss: 1.058587 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0040s, O: 0.0008s\n",
            "Step 2200 | Loss: 1.098301 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 2200 took 0.0001s\n",
            "🧹 Memory cleanup at step 2200 took 0.1695s\n",
            "Batch  640/1563 ( 40.9%) | Loss: 1.275696 | Accuracy: 54.47% | Batch time: 0.0064s\n",
            "Step 2210 | Loss: 1.173904 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0011s\n",
            "Step 2220 | Loss: 1.034001 | GPU: 43.8MB / 132.0MB | F: 0.0032s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 2220 took 0.0001s\n",
            "Batch  660/1563 ( 42.2%) | Loss: 1.273368 | Accuracy: 54.56% | Batch time: 0.0053s\n",
            "Step 2230 | Loss: 0.767446 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0027s, O: 0.0021s\n",
            "Step 2240 | Loss: 1.400838 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 2240 took 0.0001s\n",
            "Batch  680/1563 ( 43.5%) | Loss: 1.272822 | Accuracy: 54.56% | Batch time: 0.0056s\n",
            "Step 2250 | Loss: 1.335617 | GPU: 43.8MB / 132.0MB | F: 0.0056s, B: 0.0028s, O: 0.0008s\n",
            "Step 2260 | Loss: 0.894332 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 2260 took 0.0001s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 1.270354 | Accuracy: 54.66% | Batch time: 0.0058s\n",
            "Step 2270 | Loss: 1.489512 | GPU: 43.8MB / 132.0MB | F: 0.0045s, B: 0.0028s, O: 0.0015s\n",
            "Step 2280 | Loss: 1.267881 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 2280 took 0.0001s\n",
            "Batch  720/1563 ( 46.1%) | Loss: 1.270194 | Accuracy: 54.65% | Batch time: 0.0078s\n",
            "Step 2290 | Loss: 1.038178 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 2300 | Loss: 1.041474 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 2300 took 0.0000s\n",
            "🧹 Memory cleanup at step 2300 took 0.1578s\n",
            "Batch  740/1563 ( 47.3%) | Loss: 1.266997 | Accuracy: 54.77% | Batch time: 0.0129s\n",
            "Step 2310 | Loss: 1.032751 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0053s, O: 0.0007s\n",
            "Step 2320 | Loss: 1.430418 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2320 took 0.0000s\n",
            "Batch  760/1563 ( 48.6%) | Loss: 1.265822 | Accuracy: 54.78% | Batch time: 0.0066s\n",
            "Step 2330 | Loss: 1.123182 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 2340 | Loss: 1.035077 | GPU: 43.8MB / 132.0MB | F: 0.0049s, B: 0.0032s, O: 0.0010s\n",
            "🔄 Topology update at step 2340 took 0.0001s\n",
            "Batch  780/1563 ( 49.9%) | Loss: 1.263171 | Accuracy: 54.90% | Batch time: 0.0076s\n",
            "Step 2350 | Loss: 0.763925 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0028s, O: 0.0033s\n",
            "Step 2360 | Loss: 1.221666 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0065s, O: 0.0008s\n",
            "🔄 Topology update at step 2360 took 0.0001s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 1.261360 | Accuracy: 54.97% | Batch time: 0.0056s\n",
            "Step 2370 | Loss: 1.450635 | GPU: 43.8MB / 132.0MB | F: 0.0022s, B: 0.0035s, O: 0.0009s\n",
            "Step 2380 | Loss: 1.440853 | GPU: 43.8MB / 132.0MB | F: 0.0032s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 2380 took 0.0001s\n",
            "Batch  820/1563 ( 52.5%) | Loss: 1.260676 | Accuracy: 54.94% | Batch time: 0.0057s\n",
            "Step 2390 | Loss: 1.215186 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "Step 2400 | Loss: 1.363100 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0028s, O: 0.0014s\n",
            "🔄 Topology update at step 2400 took 0.0001s\n",
            "🧹 Memory cleanup at step 2400 took 0.1545s\n",
            "Batch  840/1563 ( 53.7%) | Loss: 1.260077 | Accuracy: 54.96% | Batch time: 0.0077s\n",
            "Step 2410 | Loss: 1.172421 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 2420 | Loss: 1.145459 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 2420 took 0.0000s\n",
            "Batch  860/1563 ( 55.0%) | Loss: 1.260920 | Accuracy: 54.92% | Batch time: 0.0097s\n",
            "Step 2430 | Loss: 1.277102 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0024s, O: 0.0008s\n",
            "Step 2440 | Loss: 1.378466 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 2440 took 0.0001s\n",
            "Batch  880/1563 ( 56.3%) | Loss: 1.258887 | Accuracy: 55.06% | Batch time: 0.0177s\n",
            "Step 2450 | Loss: 1.136607 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0027s, O: 0.0007s\n",
            "Step 2460 | Loss: 1.057602 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 2460 took 0.0000s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 1.256077 | Accuracy: 55.14% | Batch time: 0.0056s\n",
            "Step 2470 | Loss: 1.083949 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0025s, O: 0.0007s\n",
            "Step 2480 | Loss: 1.348278 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0035s, O: 0.0016s\n",
            "🔄 Topology update at step 2480 took 0.0001s\n",
            "Batch  920/1563 ( 58.9%) | Loss: 1.256172 | Accuracy: 55.13% | Batch time: 0.0073s\n",
            "Step 2490 | Loss: 1.198633 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0024s\n",
            "Step 2500 | Loss: 1.536236 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 2500 took 0.0001s\n",
            "🧹 Memory cleanup at step 2500 took 0.1647s\n",
            "Batch  940/1563 ( 60.1%) | Loss: 1.257114 | Accuracy: 55.11% | Batch time: 0.0085s\n",
            "Step 2510 | Loss: 1.151052 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0025s, O: 0.0006s\n",
            "Step 2520 | Loss: 1.220709 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2520 took 0.0000s\n",
            "Batch  960/1563 ( 61.4%) | Loss: 1.257945 | Accuracy: 55.09% | Batch time: 0.0077s\n",
            "Step 2530 | Loss: 1.426230 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 2540 | Loss: 1.063818 | GPU: 43.8MB / 132.0MB | F: 0.0041s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 2540 took 0.0001s\n",
            "Batch  980/1563 ( 62.7%) | Loss: 1.256340 | Accuracy: 55.09% | Batch time: 0.0086s\n",
            "Step 2550 | Loss: 1.147754 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0024s, O: 0.0008s\n",
            "Step 2560 | Loss: 1.186533 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2560 took 0.0001s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 1.255608 | Accuracy: 55.13% | Batch time: 0.0092s\n",
            "Step 2570 | Loss: 1.306762 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0049s, O: 0.0042s\n",
            "Step 2580 | Loss: 1.415796 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0030s, O: 0.0027s\n",
            "🔄 Topology update at step 2580 took 0.0000s\n",
            "Batch 1020/1563 ( 65.3%) | Loss: 1.255386 | Accuracy: 55.15% | Batch time: 0.0060s\n",
            "Step 2590 | Loss: 1.245046 | GPU: 43.8MB / 132.0MB | F: 0.0045s, B: 0.0024s, O: 0.0006s\n",
            "Step 2600 | Loss: 0.914095 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0024s, O: 0.0019s\n",
            "🔄 Topology update at step 2600 took 0.0001s\n",
            "🧹 Memory cleanup at step 2600 took 0.1603s\n",
            "Batch 1040/1563 ( 66.5%) | Loss: 1.252828 | Accuracy: 55.26% | Batch time: 0.0103s\n",
            "Step 2610 | Loss: 1.218105 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 2620 | Loss: 0.764222 | GPU: 43.8MB / 132.0MB | F: 0.0022s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 2620 took 0.0000s\n",
            "Batch 1060/1563 ( 67.8%) | Loss: 1.251333 | Accuracy: 55.27% | Batch time: 0.0058s\n",
            "Step 2630 | Loss: 1.394951 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0026s, O: 0.0008s\n",
            "Step 2640 | Loss: 1.383741 | GPU: 43.8MB / 132.0MB | F: 0.0026s, B: 0.0093s, O: 0.0007s\n",
            "🔄 Topology update at step 2640 took 0.0000s\n",
            "Batch 1080/1563 ( 69.1%) | Loss: 1.250230 | Accuracy: 55.33% | Batch time: 0.0062s\n",
            "Step 2650 | Loss: 1.275614 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0029s, O: 0.0008s\n",
            "Step 2660 | Loss: 1.357328 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0026s, O: 0.0023s\n",
            "🔄 Topology update at step 2660 took 0.0000s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 1.250493 | Accuracy: 55.29% | Batch time: 0.0082s\n",
            "Step 2670 | Loss: 1.051641 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0061s, O: 0.0008s\n",
            "Step 2680 | Loss: 0.899632 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2680 took 0.0000s\n",
            "Batch 1120/1563 ( 71.7%) | Loss: 1.249638 | Accuracy: 55.30% | Batch time: 0.0060s\n",
            "Step 2690 | Loss: 0.964105 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0022s\n",
            "Step 2700 | Loss: 0.977790 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 2700 took 0.0001s\n",
            "🧹 Memory cleanup at step 2700 took 0.1711s\n",
            "Batch 1140/1563 ( 72.9%) | Loss: 1.247837 | Accuracy: 55.35% | Batch time: 0.0078s\n",
            "Step 2710 | Loss: 0.976294 | GPU: 43.8MB / 132.0MB | F: 0.0032s, B: 0.0025s, O: 0.0007s\n",
            "Step 2720 | Loss: 1.371807 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0024s, O: 0.0104s\n",
            "🔄 Topology update at step 2720 took 0.0001s\n",
            "Batch 1160/1563 ( 74.2%) | Loss: 1.247516 | Accuracy: 55.35% | Batch time: 0.0058s\n",
            "Step 2730 | Loss: 1.150037 | GPU: 43.8MB / 132.0MB | F: 0.0026s, B: 0.0090s, O: 0.0007s\n",
            "Step 2740 | Loss: 0.747353 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2740 took 0.0001s\n",
            "Batch 1180/1563 ( 75.5%) | Loss: 1.245812 | Accuracy: 55.42% | Batch time: 0.0053s\n",
            "Step 2750 | Loss: 1.173956 | GPU: 43.8MB / 132.0MB | F: 0.0043s, B: 0.0029s, O: 0.0027s\n",
            "Step 2760 | Loss: 1.044719 | GPU: 43.8MB / 132.0MB | F: 0.0039s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2760 took 0.0001s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.244779 | Accuracy: 55.47% | Batch time: 0.0056s\n",
            "Step 2770 | Loss: 1.059448 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0027s, O: 0.0008s\n",
            "Step 2780 | Loss: 0.919761 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2780 took 0.0001s\n",
            "Batch 1220/1563 ( 78.1%) | Loss: 1.243383 | Accuracy: 55.52% | Batch time: 0.0056s\n",
            "Step 2790 | Loss: 1.128750 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0025s, O: 0.0017s\n",
            "Step 2800 | Loss: 1.269228 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 2800 took 0.0000s\n",
            "🧹 Memory cleanup at step 2800 took 0.1755s\n",
            "Batch 1240/1563 ( 79.3%) | Loss: 1.242727 | Accuracy: 55.53% | Batch time: 0.0083s\n",
            "Step 2810 | Loss: 0.854926 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0026s, O: 0.0008s\n",
            "Step 2820 | Loss: 1.426139 | GPU: 43.8MB / 132.0MB | F: 0.0020s, B: 0.0064s, O: 0.0007s\n",
            "🔄 Topology update at step 2820 took 0.0000s\n",
            "Batch 1260/1563 ( 80.6%) | Loss: 1.241555 | Accuracy: 55.61% | Batch time: 0.0062s\n",
            "Step 2830 | Loss: 1.433279 | GPU: 43.8MB / 132.0MB | F: 0.0013s, B: 0.0017s, O: 0.0006s\n",
            "Step 2840 | Loss: 1.156253 | GPU: 43.8MB / 132.0MB | F: 0.0101s, B: 0.0027s, O: 0.0018s\n",
            "🔄 Topology update at step 2840 took 0.0000s\n",
            "Batch 1280/1563 ( 81.9%) | Loss: 1.240416 | Accuracy: 55.66% | Batch time: 0.0114s\n",
            "Step 2850 | Loss: 1.395503 | GPU: 43.8MB / 132.0MB | F: 0.0015s, B: 0.0039s, O: 0.0008s\n",
            "Step 2860 | Loss: 1.095695 | GPU: 43.8MB / 132.0MB | F: 0.0085s, B: 0.0017s, O: 0.0006s\n",
            "🔄 Topology update at step 2860 took 0.0000s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.239614 | Accuracy: 55.70% | Batch time: 0.0129s\n",
            "Step 2870 | Loss: 1.055084 | GPU: 43.8MB / 132.0MB | F: 0.0012s, B: 0.0024s, O: 0.0018s\n",
            "Step 2880 | Loss: 1.161744 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0152s, O: 0.0007s\n",
            "🔄 Topology update at step 2880 took 0.0000s\n",
            "Batch 1320/1563 ( 84.5%) | Loss: 1.238376 | Accuracy: 55.76% | Batch time: 0.0107s\n",
            "Step 2890 | Loss: 1.117967 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0082s, O: 0.0007s\n",
            "Step 2900 | Loss: 1.242840 | GPU: 43.8MB / 132.0MB | F: 0.0114s, B: 0.0027s, O: 0.0009s\n",
            "🔄 Topology update at step 2900 took 0.0000s\n",
            "🧹 Memory cleanup at step 2900 took 0.2732s\n",
            "Batch 1340/1563 ( 85.7%) | Loss: 1.237806 | Accuracy: 55.80% | Batch time: 0.0084s\n",
            "Step 2910 | Loss: 1.154493 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0062s, O: 0.0008s\n",
            "Step 2920 | Loss: 1.222983 | GPU: 43.8MB / 132.0MB | F: 0.0025s, B: 0.0029s, O: 0.0008s\n",
            "🔄 Topology update at step 2920 took 0.0001s\n",
            "Batch 1360/1563 ( 87.0%) | Loss: 1.238712 | Accuracy: 55.81% | Batch time: 0.0057s\n",
            "Step 2930 | Loss: 0.784435 | GPU: 43.8MB / 132.0MB | F: 0.0023s, B: 0.0027s, O: 0.0007s\n",
            "Step 2940 | Loss: 1.197139 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 2940 took 0.0001s\n",
            "Batch 1380/1563 ( 88.3%) | Loss: 1.238274 | Accuracy: 55.81% | Batch time: 0.0076s\n",
            "Step 2950 | Loss: 0.959302 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0093s, O: 0.0020s\n",
            "Step 2960 | Loss: 1.178529 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 2960 took 0.0000s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.237557 | Accuracy: 55.85% | Batch time: 0.0080s\n",
            "Step 2970 | Loss: 1.094621 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 2980 | Loss: 1.830728 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 2980 took 0.0001s\n",
            "Batch 1420/1563 ( 90.9%) | Loss: 1.236588 | Accuracy: 55.91% | Batch time: 0.0057s\n",
            "Step 2990 | Loss: 1.409526 | GPU: 43.8MB / 132.0MB | F: 0.0029s, B: 0.0023s, O: 0.0007s\n",
            "Step 3000 | Loss: 1.240727 | GPU: 43.8MB / 132.0MB | F: 0.0029s, B: 0.0026s, O: 0.0008s\n",
            "🔄 Topology update at step 3000 took 0.0000s\n",
            "🧹 Memory cleanup at step 3000 took 0.1697s\n",
            "Batch 1440/1563 ( 92.1%) | Loss: 1.235390 | Accuracy: 55.95% | Batch time: 0.0068s\n",
            "Step 3010 | Loss: 1.244834 | GPU: 43.8MB / 132.0MB | F: 0.0038s, B: 0.0030s, O: 0.0008s\n",
            "Step 3020 | Loss: 1.321424 | GPU: 43.8MB / 132.0MB | F: 0.0023s, B: 0.0035s, O: 0.0009s\n",
            "🔄 Topology update at step 3020 took 0.0001s\n",
            "Batch 1460/1563 ( 93.4%) | Loss: 1.233576 | Accuracy: 56.04% | Batch time: 0.0060s\n",
            "Step 3030 | Loss: 1.221804 | GPU: 43.8MB / 132.0MB | F: 0.0019s, B: 0.0025s, O: 0.0008s\n",
            "Step 3040 | Loss: 1.435457 | GPU: 43.8MB / 132.0MB | F: 0.0033s, B: 0.0028s, O: 0.0008s\n",
            "🔄 Topology update at step 3040 took 0.0001s\n",
            "Batch 1480/1563 ( 94.7%) | Loss: 1.232140 | Accuracy: 56.09% | Batch time: 0.0090s\n",
            "Step 3050 | Loss: 1.254857 | GPU: 43.8MB / 132.0MB | F: 0.0023s, B: 0.0029s, O: 0.0008s\n",
            "Step 3060 | Loss: 0.990347 | GPU: 43.8MB / 132.0MB | F: 0.0018s, B: 0.0119s, O: 0.0009s\n",
            "🔄 Topology update at step 3060 took 0.0001s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.231967 | Accuracy: 56.09% | Batch time: 0.0060s\n",
            "Step 3070 | Loss: 1.138134 | GPU: 43.8MB / 132.0MB | F: 0.0016s, B: 0.0025s, O: 0.0007s\n",
            "Step 3080 | Loss: 1.467828 | GPU: 43.8MB / 132.0MB | F: 0.0036s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 3080 took 0.0000s\n",
            "Batch 1520/1563 ( 97.2%) | Loss: 1.231923 | Accuracy: 56.10% | Batch time: 0.0088s\n",
            "Step 3090 | Loss: 1.061569 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 3100 | Loss: 1.061287 | GPU: 43.8MB / 132.0MB | F: 0.0017s, B: 0.0044s, O: 0.0007s\n",
            "🔄 Topology update at step 3100 took 0.0000s\n",
            "🧹 Memory cleanup at step 3100 took 0.1717s\n",
            "Batch 1540/1563 ( 98.5%) | Loss: 1.230722 | Accuracy: 56.15% | Batch time: 0.0089s\n",
            "Step 3110 | Loss: 1.084212 | GPU: 43.8MB / 132.0MB | F: 0.0021s, B: 0.0026s, O: 0.0008s\n",
            "Step 3120 | Loss: 1.144658 | GPU: 43.8MB / 132.0MB | F: 0.0023s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 3120 took 0.0000s\n",
            "Batch 1560/1563 ( 99.8%) | Loss: 1.230038 | Accuracy: 56.19% | Batch time: 0.0049s\n",
            "\n",
            "-------------------- EPOCH 2 SUMMARY --------------------\n",
            "Loss: 1.230153 | Accuracy: 56.20%\n",
            "Time: 27.30s total, 0.0150s per batch\n",
            "🔄 Final Memory - RAM: 1602.9MB, GPU: 43.6MB allocated, 134.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=43.8, peak=43.8\n",
            "===============================\n",
            "\n",
            "⏱️ ImprovedTALT training took 27.3015 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 1.083962 | Accuracy: 61.52% | Batch time: 0.0015s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 1.079956 | Accuracy: 62.16% | Batch time: 0.0018s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 1.078876 | Accuracy: 62.31% | Batch time: 0.0012s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 1.085839 | Accuracy: 61.82% | Batch time: 0.0014s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 1.086300 | Accuracy: 62.01% | Batch time: 0.0013s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 1.088522 | Accuracy: 61.78% | Batch time: 0.0018s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.090631 | Accuracy: 61.67%\n",
            "Time: 2.92s total, 0.0016s per batch\n",
            "⏱️ ImprovedTALT evaluation took 2.9228 seconds\n",
            "ImprovedTALT - Epoch 2:\n",
            "  Train Loss: 1.230153, Train Acc: 56.20%\n",
            "  Test Loss:  1.090631, Test Acc:  61.67%\n",
            "\n",
            "Epoch 2 completed in 97.40s\n",
            "Results saved to ./results/cifar10/epoch_2_results.json\n",
            "\n",
            "============================== EPOCH 3/3 ==============================\n",
            "\n",
            "------------------------- SGD Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 3\n",
            "Batches: 1563, Batch size: 32\n",
            "Batch   50/1563 (  3.2%) | Loss: 1.313101 | Acc: 53.43% | Batch time: 0.0039s\n",
            "Batch  100/1563 (  6.4%) | Loss: 1.356428 | Acc: 51.64% | Batch time: 0.0049s\n",
            "Batch  150/1563 (  9.6%) | Loss: 1.366047 | Acc: 50.95% | Batch time: 0.0037s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 1.340429 | Acc: 51.63% | Batch time: 0.0062s\n",
            "Batch  250/1563 ( 16.0%) | Loss: 1.338337 | Acc: 51.49% | Batch time: 0.0047s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 1.342324 | Acc: 51.42% | Batch time: 0.0060s\n",
            "Batch  350/1563 ( 22.4%) | Loss: 1.340744 | Acc: 51.29% | Batch time: 0.0132s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 1.344704 | Acc: 51.31% | Batch time: 0.0042s\n",
            "Batch  450/1563 ( 28.8%) | Loss: 1.343377 | Acc: 51.45% | Batch time: 0.0058s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 1.342011 | Acc: 51.40% | Batch time: 0.0036s\n",
            "Batch  550/1563 ( 35.2%) | Loss: 1.341450 | Acc: 51.33% | Batch time: 0.0049s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 1.338747 | Acc: 51.41% | Batch time: 0.0038s\n",
            "Batch  650/1563 ( 41.6%) | Loss: 1.334391 | Acc: 51.61% | Batch time: 0.0063s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 1.331706 | Acc: 51.80% | Batch time: 0.0047s\n",
            "Batch  750/1563 ( 48.0%) | Loss: 1.328445 | Acc: 52.02% | Batch time: 0.0046s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 1.324751 | Acc: 52.21% | Batch time: 0.0036s\n",
            "Batch  850/1563 ( 54.4%) | Loss: 1.320062 | Acc: 52.45% | Batch time: 0.0053s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 1.317551 | Acc: 52.57% | Batch time: 0.0038s\n",
            "Batch  950/1563 ( 60.8%) | Loss: 1.315095 | Acc: 52.66% | Batch time: 0.0042s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 1.311952 | Acc: 52.80% | Batch time: 0.0051s\n",
            "Batch 1050/1563 ( 67.2%) | Loss: 1.309004 | Acc: 52.97% | Batch time: 0.0038s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 1.306705 | Acc: 53.10% | Batch time: 0.0040s\n",
            "Batch 1150/1563 ( 73.6%) | Loss: 1.305527 | Acc: 53.20% | Batch time: 0.0044s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.302149 | Acc: 53.33% | Batch time: 0.0038s\n",
            "Batch 1250/1563 ( 80.0%) | Loss: 1.301245 | Acc: 53.39% | Batch time: 0.0066s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.297875 | Acc: 53.51% | Batch time: 0.0047s\n",
            "Batch 1350/1563 ( 86.4%) | Loss: 1.294158 | Acc: 53.68% | Batch time: 0.0042s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.292272 | Acc: 53.75% | Batch time: 0.0046s\n",
            "Batch 1450/1563 ( 92.8%) | Loss: 1.290644 | Acc: 53.82% | Batch time: 0.0102s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.289587 | Acc: 53.89% | Batch time: 0.0036s\n",
            "Batch 1550/1563 ( 99.2%) | Loss: 1.287903 | Acc: 53.99% | Batch time: 0.0124s\n",
            "\n",
            "Standard optimizer - Epoch 3 summary:\n",
            "Loss: 1.287233 | Accuracy: 54.03%\n",
            "⏱️ SGD training took 18.8859 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 1.018651 | Accuracy: 62.87% | Batch time: 0.0014s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 1.028926 | Accuracy: 63.21% | Batch time: 0.0021s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 1.031631 | Accuracy: 63.43% | Batch time: 0.0013s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 1.033790 | Accuracy: 63.36% | Batch time: 0.0014s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 1.034402 | Accuracy: 63.40% | Batch time: 0.0013s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 1.035136 | Accuracy: 63.61% | Batch time: 0.0015s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.037530 | Accuracy: 63.48%\n",
            "Time: 2.97s total, 0.0016s per batch\n",
            "⏱️ SGD evaluation took 2.9707 seconds\n",
            "SGD - Epoch 3:\n",
            "  Train Loss: 1.287233, Train Acc: 54.03%\n",
            "  Test Loss:  1.037530, Test Acc:  63.48%\n",
            "\n",
            "------------------------- Adam Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 3\n",
            "Batches: 1563, Batch size: 32\n",
            "Batch   50/1563 (  3.2%) | Loss: 1.450290 | Acc: 45.16% | Batch time: 0.0050s\n",
            "Batch  100/1563 (  6.4%) | Loss: 1.448286 | Acc: 46.50% | Batch time: 0.0052s\n",
            "Batch  150/1563 (  9.6%) | Loss: 1.433294 | Acc: 46.50% | Batch time: 0.0047s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 1.432226 | Acc: 46.38% | Batch time: 0.0066s\n",
            "Batch  250/1563 ( 16.0%) | Loss: 1.429415 | Acc: 46.68% | Batch time: 0.0057s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 1.425909 | Acc: 46.68% | Batch time: 0.0047s\n",
            "Batch  350/1563 ( 22.4%) | Loss: 1.429967 | Acc: 46.47% | Batch time: 0.0094s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 1.431788 | Acc: 46.26% | Batch time: 0.0062s\n",
            "Batch  450/1563 ( 28.8%) | Loss: 1.428131 | Acc: 46.37% | Batch time: 0.0042s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 1.425859 | Acc: 46.25% | Batch time: 0.0055s\n",
            "Batch  550/1563 ( 35.2%) | Loss: 1.422349 | Acc: 46.23% | Batch time: 0.0048s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 1.418803 | Acc: 46.54% | Batch time: 0.0045s\n",
            "Batch  650/1563 ( 41.6%) | Loss: 1.418901 | Acc: 46.58% | Batch time: 0.0097s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 1.418824 | Acc: 46.64% | Batch time: 0.0043s\n",
            "Batch  750/1563 ( 48.0%) | Loss: 1.419231 | Acc: 46.69% | Batch time: 0.0042s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 1.420178 | Acc: 46.69% | Batch time: 0.0067s\n",
            "Batch  850/1563 ( 54.4%) | Loss: 1.416840 | Acc: 46.82% | Batch time: 0.0078s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 1.414215 | Acc: 46.91% | Batch time: 0.0044s\n",
            "Batch  950/1563 ( 60.8%) | Loss: 1.414499 | Acc: 46.91% | Batch time: 0.0069s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 1.413141 | Acc: 46.91% | Batch time: 0.0044s\n",
            "Batch 1050/1563 ( 67.2%) | Loss: 1.411017 | Acc: 47.01% | Batch time: 0.0045s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 1.407928 | Acc: 47.13% | Batch time: 0.0049s\n",
            "Batch 1150/1563 ( 73.6%) | Loss: 1.408227 | Acc: 47.14% | Batch time: 0.0050s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.407924 | Acc: 47.11% | Batch time: 0.0046s\n",
            "Batch 1250/1563 ( 80.0%) | Loss: 1.408572 | Acc: 47.13% | Batch time: 0.0087s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.408908 | Acc: 47.19% | Batch time: 0.0061s\n",
            "Batch 1350/1563 ( 86.4%) | Loss: 1.407860 | Acc: 47.16% | Batch time: 0.0051s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.406275 | Acc: 47.25% | Batch time: 0.0059s\n",
            "Batch 1450/1563 ( 92.8%) | Loss: 1.405383 | Acc: 47.30% | Batch time: 0.0048s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.405226 | Acc: 47.29% | Batch time: 0.0044s\n",
            "Batch 1550/1563 ( 99.2%) | Loss: 1.405068 | Acc: 47.32% | Batch time: 0.0048s\n",
            "\n",
            "Standard optimizer - Epoch 3 summary:\n",
            "Loss: 1.405343 | Accuracy: 47.29%\n",
            "⏱️ Adam training took 18.1550 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 1.106249 | Accuracy: 62.75% | Batch time: 0.0014s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 1.116006 | Accuracy: 62.13% | Batch time: 0.0017s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 1.117732 | Accuracy: 62.40% | Batch time: 0.0013s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 1.119105 | Accuracy: 62.31% | Batch time: 0.0009s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 1.115611 | Accuracy: 62.19% | Batch time: 0.0010s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 1.116117 | Accuracy: 61.97% | Batch time: 0.0012s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.116322 | Accuracy: 61.93%\n",
            "Time: 3.54s total, 0.0014s per batch\n",
            "⏱️ Adam evaluation took 3.5428 seconds\n",
            "Adam - Epoch 3:\n",
            "  Train Loss: 1.405343, Train Acc: 47.29%\n",
            "  Test Loss:  1.116322, Test Acc:  61.93%\n",
            "\n",
            "------------------------- AdamW Optimizer -------------------------\n",
            "Training with standard optimizer - Epoch 3\n",
            "Batches: 1563, Batch size: 32\n",
            "Batch   50/1563 (  3.2%) | Loss: 1.324386 | Acc: 49.14% | Batch time: 0.0041s\n",
            "Batch  100/1563 (  6.4%) | Loss: 1.385944 | Acc: 47.52% | Batch time: 0.0078s\n",
            "Batch  150/1563 (  9.6%) | Loss: 1.393134 | Acc: 47.04% | Batch time: 0.0043s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 1.395448 | Acc: 47.37% | Batch time: 0.0042s\n",
            "Batch  250/1563 ( 16.0%) | Loss: 1.392574 | Acc: 47.50% | Batch time: 0.0047s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 1.387380 | Acc: 47.65% | Batch time: 0.0137s\n",
            "Batch  350/1563 ( 22.4%) | Loss: 1.383916 | Acc: 47.71% | Batch time: 0.0040s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 1.386293 | Acc: 47.45% | Batch time: 0.0081s\n",
            "Batch  450/1563 ( 28.8%) | Loss: 1.384617 | Acc: 47.50% | Batch time: 0.0048s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 1.380262 | Acc: 47.81% | Batch time: 0.0042s\n",
            "Batch  550/1563 ( 35.2%) | Loss: 1.379129 | Acc: 47.82% | Batch time: 0.0044s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 1.381001 | Acc: 47.96% | Batch time: 0.0043s\n",
            "Batch  650/1563 ( 41.6%) | Loss: 1.382686 | Acc: 48.00% | Batch time: 0.0045s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 1.382020 | Acc: 48.03% | Batch time: 0.0053s\n",
            "Batch  750/1563 ( 48.0%) | Loss: 1.381770 | Acc: 48.07% | Batch time: 0.0049s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 1.384312 | Acc: 48.13% | Batch time: 0.0041s\n",
            "Batch  850/1563 ( 54.4%) | Loss: 1.382620 | Acc: 48.18% | Batch time: 0.0042s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 1.379436 | Acc: 48.38% | Batch time: 0.0045s\n",
            "Batch  950/1563 ( 60.8%) | Loss: 1.375647 | Acc: 48.44% | Batch time: 0.0041s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 1.377710 | Acc: 48.45% | Batch time: 0.0103s\n",
            "Batch 1050/1563 ( 67.2%) | Loss: 1.378177 | Acc: 48.43% | Batch time: 0.0042s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 1.376967 | Acc: 48.43% | Batch time: 0.0032s\n",
            "Batch 1150/1563 ( 73.6%) | Loss: 1.375681 | Acc: 48.52% | Batch time: 0.0041s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.375691 | Acc: 48.57% | Batch time: 0.0044s\n",
            "Batch 1250/1563 ( 80.0%) | Loss: 1.375738 | Acc: 48.60% | Batch time: 0.0047s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.376396 | Acc: 48.58% | Batch time: 0.0043s\n",
            "Batch 1350/1563 ( 86.4%) | Loss: 1.375992 | Acc: 48.66% | Batch time: 0.0057s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.374028 | Acc: 48.76% | Batch time: 0.0046s\n",
            "Batch 1450/1563 ( 92.8%) | Loss: 1.371879 | Acc: 48.84% | Batch time: 0.0044s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.371696 | Acc: 48.83% | Batch time: 0.0046s\n",
            "Batch 1550/1563 ( 99.2%) | Loss: 1.369877 | Acc: 48.91% | Batch time: 0.0042s\n",
            "\n",
            "Standard optimizer - Epoch 3 summary:\n",
            "Loss: 1.369423 | Accuracy: 48.91%\n",
            "⏱️ AdamW training took 17.1683 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 1.074868 | Accuracy: 63.60% | Batch time: 0.0015s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 1.085423 | Accuracy: 63.03% | Batch time: 0.0014s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 1.082947 | Accuracy: 63.60% | Batch time: 0.0014s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 1.086923 | Accuracy: 63.34% | Batch time: 0.0014s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 1.083033 | Accuracy: 63.56% | Batch time: 0.0013s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 1.083161 | Accuracy: 63.54% | Batch time: 0.0013s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 1.084360 | Accuracy: 63.45%\n",
            "Time: 2.74s total, 0.0014s per batch\n",
            "⏱️ AdamW evaluation took 2.7410 seconds\n",
            "AdamW - Epoch 3:\n",
            "  Train Loss: 1.369423, Train Acc: 48.91%\n",
            "  Test Loss:  1.084360, Test Acc:  63.45%\n",
            "\n",
            "------------------------- ImprovedTALT Optimizer -------------------------\n",
            "\n",
            "==================== EPOCH 3 TRAINING ====================\n",
            "Device: cuda, Batches: 1563, Batch size: 32\n",
            "🔄 Initial Memory - RAM: 1602.9MB, GPU: 43.5MB allocated, 64.0MB reserved\n",
            "Batch    0/1563 (  0.0%) | Loss: 1.546945 | Accuracy: 50.00% | Batch time: 0.0150s\n",
            "Step 3130 | Loss: 1.238124 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 3140 | Loss: 1.185894 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 3140 took 0.0001s\n",
            "Batch   20/1563 (  1.3%) | Loss: 1.162277 | Accuracy: 58.48% | Batch time: 0.0104s\n",
            "Step 3150 | Loss: 1.088257 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "Step 3160 | Loss: 1.089559 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3160 took 0.0000s\n",
            "Batch   40/1563 (  2.6%) | Loss: 1.167888 | Accuracy: 58.92% | Batch time: 0.0062s\n",
            "Step 3170 | Loss: 1.302895 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0021s, O: 0.0006s\n",
            "Step 3180 | Loss: 1.359365 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 3180 took 0.0000s\n",
            "Batch   60/1563 (  3.8%) | Loss: 1.133408 | Accuracy: 59.99% | Batch time: 0.0072s\n",
            "Step 3190 | Loss: 1.145784 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0046s, O: 0.0007s\n",
            "Step 3200 | Loss: 1.096106 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 3200 took 0.0000s\n",
            "🧹 Memory cleanup at step 3200 took 0.2052s\n",
            "Batch   80/1563 (  5.1%) | Loss: 1.141361 | Accuracy: 59.65% | Batch time: 0.0053s\n",
            "Step 3210 | Loss: 1.178311 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0071s, O: 0.0006s\n",
            "Step 3220 | Loss: 1.080764 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0070s, O: 0.0007s\n",
            "🔄 Topology update at step 3220 took 0.0001s\n",
            "Batch  100/1563 (  6.4%) | Loss: 1.140682 | Accuracy: 59.96% | Batch time: 0.0054s\n",
            "Step 3230 | Loss: 1.262124 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0024s, O: 0.0007s\n",
            "Step 3240 | Loss: 0.857559 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 3240 took 0.0000s\n",
            "Batch  120/1563 (  7.7%) | Loss: 1.136322 | Accuracy: 59.87% | Batch time: 0.0086s\n",
            "Step 3250 | Loss: 1.095058 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0049s, O: 0.0035s\n",
            "Step 3260 | Loss: 1.170551 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 3260 took 0.0000s\n",
            "Batch  140/1563 (  9.0%) | Loss: 1.133522 | Accuracy: 60.02% | Batch time: 0.0103s\n",
            "Step 3270 | Loss: 1.152830 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0023s, O: 0.0006s\n",
            "Step 3280 | Loss: 1.145039 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 3280 took 0.0000s\n",
            "Batch  160/1563 ( 10.2%) | Loss: 1.142190 | Accuracy: 59.70% | Batch time: 0.0070s\n",
            "Step 3290 | Loss: 1.006983 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0027s, O: 0.0018s\n",
            "Step 3300 | Loss: 1.122061 | GPU: 43.8MB / 134.0MB | F: 0.0024s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 3300 took 0.0000s\n",
            "🧹 Memory cleanup at step 3300 took 0.1528s\n",
            "Batch  180/1563 ( 11.5%) | Loss: 1.140612 | Accuracy: 59.67% | Batch time: 0.0132s\n",
            "Step 3310 | Loss: 1.342461 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 3320 | Loss: 1.202299 | GPU: 43.8MB / 134.0MB | F: 0.0015s, B: 0.0052s, O: 0.0006s\n",
            "🔄 Topology update at step 3320 took 0.0000s\n",
            "Batch  200/1563 ( 12.8%) | Loss: 1.137048 | Accuracy: 59.73% | Batch time: 0.0075s\n",
            "Step 3330 | Loss: 1.011618 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0017s, O: 0.0006s\n",
            "Step 3340 | Loss: 1.182581 | GPU: 43.8MB / 134.0MB | F: 0.0012s, B: 0.0019s, O: 0.0006s\n",
            "🔄 Topology update at step 3340 took 0.0000s\n",
            "Batch  220/1563 ( 14.1%) | Loss: 1.138301 | Accuracy: 59.73% | Batch time: 0.0093s\n",
            "Step 3350 | Loss: 1.132456 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0032s, O: 0.0005s\n",
            "Step 3360 | Loss: 1.447676 | GPU: 43.8MB / 134.0MB | F: 0.0012s, B: 0.0016s, O: 0.0006s\n",
            "🔄 Topology update at step 3360 took 0.0001s\n",
            "Batch  240/1563 ( 15.4%) | Loss: 1.149909 | Accuracy: 59.31% | Batch time: 0.0073s\n",
            "Step 3370 | Loss: 0.935384 | GPU: 43.8MB / 70.0MB | F: 0.0014s, B: 0.0036s, O: 0.0011s\n",
            "Step 3380 | Loss: 0.996475 | GPU: 43.8MB / 134.0MB | F: 0.0012s, B: 0.0016s, O: 0.0006s\n",
            "🔄 Topology update at step 3380 took 0.0001s\n",
            "Batch  260/1563 ( 16.6%) | Loss: 1.143675 | Accuracy: 59.64% | Batch time: 0.0169s\n",
            "Step 3390 | Loss: 0.711381 | GPU: 43.8MB / 70.0MB | F: 0.0038s, B: 0.0037s, O: 0.0006s\n",
            "Step 3400 | Loss: 1.350713 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0024s, O: 0.0011s\n",
            "🔄 Topology update at step 3400 took 0.0000s\n",
            "🧹 Memory cleanup at step 3400 took 0.1921s\n",
            "Batch  280/1563 ( 17.9%) | Loss: 1.142641 | Accuracy: 59.73% | Batch time: 0.0082s\n",
            "Step 3410 | Loss: 1.444477 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0032s, O: 0.0007s\n",
            "Step 3420 | Loss: 1.150441 | GPU: 43.8MB / 134.0MB | F: 0.0012s, B: 0.0065s, O: 0.0006s\n",
            "🔄 Topology update at step 3420 took 0.0000s\n",
            "Batch  300/1563 ( 19.2%) | Loss: 1.142828 | Accuracy: 59.67% | Batch time: 0.0058s\n",
            "Step 3430 | Loss: 0.863661 | GPU: 43.8MB / 70.0MB | F: 0.0024s, B: 0.0026s, O: 0.0009s\n",
            "Step 3440 | Loss: 1.187621 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0043s, O: 0.0090s\n",
            "🔄 Topology update at step 3440 took 0.0000s\n",
            "Batch  320/1563 ( 20.5%) | Loss: 1.140130 | Accuracy: 59.83% | Batch time: 0.0053s\n",
            "Step 3450 | Loss: 1.511520 | GPU: 43.8MB / 70.0MB | F: 0.0035s, B: 0.0063s, O: 0.0007s\n",
            "Step 3460 | Loss: 0.950553 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 3460 took 0.0000s\n",
            "Batch  340/1563 ( 21.8%) | Loss: 1.140076 | Accuracy: 59.71% | Batch time: 0.0054s\n",
            "Step 3470 | Loss: 1.147751 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0028s, O: 0.0007s\n",
            "Step 3480 | Loss: 0.999124 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0028s, O: 0.0007s\n",
            "🔄 Topology update at step 3480 took 0.0000s\n",
            "Batch  360/1563 ( 23.0%) | Loss: 1.141252 | Accuracy: 59.58% | Batch time: 0.0054s\n",
            "Step 3490 | Loss: 1.454886 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 3500 | Loss: 1.305433 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 3500 took 0.0001s\n",
            "🧹 Memory cleanup at step 3500 took 0.1408s\n",
            "Batch  380/1563 ( 24.3%) | Loss: 1.140899 | Accuracy: 59.59% | Batch time: 0.0053s\n",
            "Step 3510 | Loss: 1.437158 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0025s, O: 0.0006s\n",
            "Step 3520 | Loss: 1.280679 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0041s, O: 0.0021s\n",
            "🔄 Topology update at step 3520 took 0.0001s\n",
            "Batch  400/1563 ( 25.6%) | Loss: 1.138594 | Accuracy: 59.57% | Batch time: 0.0058s\n",
            "Step 3530 | Loss: 0.818016 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 3540 | Loss: 0.974588 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0028s, O: 0.0007s\n",
            "🔄 Topology update at step 3540 took 0.0001s\n",
            "Batch  420/1563 ( 26.9%) | Loss: 1.139506 | Accuracy: 59.54% | Batch time: 0.0092s\n",
            "Step 3550 | Loss: 0.899553 | GPU: 43.8MB / 70.0MB | F: 0.0029s, B: 0.0111s, O: 0.0008s\n",
            "Step 3560 | Loss: 1.010433 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3560 took 0.0001s\n",
            "Batch  440/1563 ( 28.2%) | Loss: 1.138216 | Accuracy: 59.57% | Batch time: 0.0074s\n",
            "Step 3570 | Loss: 1.466105 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0039s, O: 0.0007s\n",
            "Step 3580 | Loss: 1.000430 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 3580 took 0.0001s\n",
            "Batch  460/1563 ( 29.4%) | Loss: 1.137975 | Accuracy: 59.69% | Batch time: 0.0058s\n",
            "Step 3590 | Loss: 1.530848 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "Step 3600 | Loss: 1.055137 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 3600 took 0.0000s\n",
            "🧹 Memory cleanup at step 3600 took 0.1622s\n",
            "Batch  480/1563 ( 30.7%) | Loss: 1.138303 | Accuracy: 59.64% | Batch time: 0.0076s\n",
            "Step 3610 | Loss: 0.899477 | GPU: 43.8MB / 70.0MB | F: 0.0032s, B: 0.0026s, O: 0.0007s\n",
            "Step 3620 | Loss: 0.798570 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "🔄 Topology update at step 3620 took 0.0000s\n",
            "Batch  500/1563 ( 32.0%) | Loss: 1.134534 | Accuracy: 59.77% | Batch time: 0.0091s\n",
            "Step 3630 | Loss: 1.139994 | GPU: 43.8MB / 70.0MB | F: 0.0050s, B: 0.0050s, O: 0.0006s\n",
            "Step 3640 | Loss: 1.033304 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 3640 took 0.0000s\n",
            "Batch  520/1563 ( 33.3%) | Loss: 1.135441 | Accuracy: 59.76% | Batch time: 0.0083s\n",
            "Step 3650 | Loss: 0.914821 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0063s, O: 0.0006s\n",
            "Step 3660 | Loss: 1.115552 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 3660 took 0.0001s\n",
            "Batch  540/1563 ( 34.5%) | Loss: 1.135485 | Accuracy: 59.76% | Batch time: 0.0071s\n",
            "Step 3670 | Loss: 0.890123 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 3680 | Loss: 0.833604 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0026s, O: 0.0018s\n",
            "🔄 Topology update at step 3680 took 0.0000s\n",
            "Batch  560/1563 ( 35.8%) | Loss: 1.132614 | Accuracy: 59.88% | Batch time: 0.0090s\n",
            "Step 3690 | Loss: 1.054591 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "Step 3700 | Loss: 1.515081 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 3700 took 0.0000s\n",
            "🧹 Memory cleanup at step 3700 took 0.1512s\n",
            "Batch  580/1563 ( 37.1%) | Loss: 1.130051 | Accuracy: 60.03% | Batch time: 0.0059s\n",
            "Step 3710 | Loss: 1.326758 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 3720 | Loss: 0.967366 | GPU: 43.8MB / 134.0MB | F: 0.0019s, B: 0.0026s, O: 0.0007s\n",
            "🔄 Topology update at step 3720 took 0.0000s\n",
            "Batch  600/1563 ( 38.4%) | Loss: 1.130199 | Accuracy: 59.97% | Batch time: 0.0061s\n",
            "Step 3730 | Loss: 1.252369 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0032s, O: 0.0007s\n",
            "Step 3740 | Loss: 1.139973 | GPU: 43.8MB / 134.0MB | F: 0.0019s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 3740 took 0.0000s\n",
            "Batch  620/1563 ( 39.7%) | Loss: 1.130843 | Accuracy: 59.84% | Batch time: 0.0058s\n",
            "Step 3750 | Loss: 1.241502 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Step 3760 | Loss: 0.721335 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 3760 took 0.0000s\n",
            "Batch  640/1563 ( 40.9%) | Loss: 1.131139 | Accuracy: 59.93% | Batch time: 0.0054s\n",
            "Step 3770 | Loss: 1.108940 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "Step 3780 | Loss: 1.065017 | GPU: 43.8MB / 134.0MB | F: 0.0015s, B: 0.0032s, O: 0.0019s\n",
            "🔄 Topology update at step 3780 took 0.0000s\n",
            "Batch  660/1563 ( 42.2%) | Loss: 1.130153 | Accuracy: 60.01% | Batch time: 0.0059s\n",
            "Step 3790 | Loss: 1.444536 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0023s, O: 0.0021s\n",
            "Step 3800 | Loss: 1.032598 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0021s, O: 0.0006s\n",
            "🔄 Topology update at step 3800 took 0.0000s\n",
            "🧹 Memory cleanup at step 3800 took 0.1397s\n",
            "Batch  680/1563 ( 43.5%) | Loss: 1.130153 | Accuracy: 60.01% | Batch time: 0.0056s\n",
            "Step 3810 | Loss: 1.085495 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0031s, O: 0.0006s\n",
            "Step 3820 | Loss: 0.994196 | GPU: 43.8MB / 134.0MB | F: 0.0038s, B: 0.0039s, O: 0.0069s\n",
            "🔄 Topology update at step 3820 took 0.0000s\n",
            "Batch  700/1563 ( 44.8%) | Loss: 1.129632 | Accuracy: 60.02% | Batch time: 0.0052s\n",
            "Step 3830 | Loss: 1.036882 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0032s, O: 0.0077s\n",
            "Step 3840 | Loss: 0.892137 | GPU: 43.8MB / 134.0MB | F: 0.0044s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 3840 took 0.0000s\n",
            "Batch  720/1563 ( 46.1%) | Loss: 1.128365 | Accuracy: 60.00% | Batch time: 0.0068s\n",
            "Step 3850 | Loss: 0.994523 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0023s, O: 0.0008s\n",
            "Step 3860 | Loss: 0.832567 | GPU: 43.8MB / 134.0MB | F: 0.0019s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 3860 took 0.0000s\n",
            "Batch  740/1563 ( 47.3%) | Loss: 1.127337 | Accuracy: 60.02% | Batch time: 0.0069s\n",
            "Step 3870 | Loss: 1.180668 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Step 3880 | Loss: 0.962161 | GPU: 43.8MB / 134.0MB | F: 0.0019s, B: 0.0027s, O: 0.0006s\n",
            "🔄 Topology update at step 3880 took 0.0001s\n",
            "Batch  760/1563 ( 48.6%) | Loss: 1.126162 | Accuracy: 60.05% | Batch time: 0.0057s\n",
            "Step 3890 | Loss: 1.331126 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0066s, O: 0.0007s\n",
            "Step 3900 | Loss: 1.199619 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0027s, O: 0.0016s\n",
            "🔄 Topology update at step 3900 took 0.0000s\n",
            "🧹 Memory cleanup at step 3900 took 0.1486s\n",
            "Batch  780/1563 ( 49.9%) | Loss: 1.126992 | Accuracy: 60.06% | Batch time: 0.0058s\n",
            "Step 3910 | Loss: 1.263706 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 3920 | Loss: 1.113870 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 3920 took 0.0000s\n",
            "Batch  800/1563 ( 51.2%) | Loss: 1.127571 | Accuracy: 60.07% | Batch time: 0.0073s\n",
            "Step 3930 | Loss: 1.034758 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "Step 3940 | Loss: 1.377233 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0061s, O: 0.0006s\n",
            "🔄 Topology update at step 3940 took 0.0000s\n",
            "Batch  820/1563 ( 52.5%) | Loss: 1.127831 | Accuracy: 60.05% | Batch time: 0.0052s\n",
            "Step 3950 | Loss: 1.346995 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0054s, O: 0.0006s\n",
            "Step 3960 | Loss: 0.869904 | GPU: 43.8MB / 134.0MB | F: 0.0015s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 3960 took 0.0001s\n",
            "Batch  840/1563 ( 53.7%) | Loss: 1.127547 | Accuracy: 60.11% | Batch time: 0.0066s\n",
            "Step 3970 | Loss: 0.944847 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0038s, O: 0.0007s\n",
            "Step 3980 | Loss: 1.210743 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 3980 took 0.0001s\n",
            "Batch  860/1563 ( 55.0%) | Loss: 1.126413 | Accuracy: 60.16% | Batch time: 0.0068s\n",
            "Step 3990 | Loss: 0.891880 | GPU: 43.8MB / 70.0MB | F: 0.0019s, B: 0.0027s, O: 0.0007s\n",
            "Step 4000 | Loss: 1.326040 | GPU: 43.8MB / 134.0MB | F: 0.0029s, B: 0.0082s, O: 0.0017s\n",
            "🔄 Topology update at step 4000 took 0.0000s\n",
            "🧹 Memory cleanup at step 4000 took 0.1492s\n",
            "Batch  880/1563 ( 56.3%) | Loss: 1.126022 | Accuracy: 60.14% | Batch time: 0.0059s\n",
            "Step 4010 | Loss: 0.993751 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "Step 4020 | Loss: 1.062609 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 4020 took 0.0001s\n",
            "Batch  900/1563 ( 57.6%) | Loss: 1.124023 | Accuracy: 60.21% | Batch time: 0.0095s\n",
            "Step 4030 | Loss: 1.457639 | GPU: 43.8MB / 70.0MB | F: 0.0026s, B: 0.0025s, O: 0.0007s\n",
            "Step 4040 | Loss: 1.050629 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 4040 took 0.0001s\n",
            "Batch  920/1563 ( 58.9%) | Loss: 1.123286 | Accuracy: 60.24% | Batch time: 0.0130s\n",
            "Step 4050 | Loss: 1.160977 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "Step 4060 | Loss: 0.812165 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 4060 took 0.0001s\n",
            "Batch  940/1563 ( 60.1%) | Loss: 1.122647 | Accuracy: 60.25% | Batch time: 0.0055s\n",
            "Step 4070 | Loss: 1.103676 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0026s, O: 0.0007s\n",
            "Step 4080 | Loss: 1.155781 | GPU: 43.8MB / 134.0MB | F: 0.0057s, B: 0.0072s, O: 0.0007s\n",
            "🔄 Topology update at step 4080 took 0.0000s\n",
            "Batch  960/1563 ( 61.4%) | Loss: 1.122884 | Accuracy: 60.24% | Batch time: 0.0073s\n",
            "Step 4090 | Loss: 0.802383 | GPU: 43.8MB / 70.0MB | F: 0.0014s, B: 0.0040s, O: 0.0006s\n",
            "Step 4100 | Loss: 1.337700 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0049s, O: 0.0007s\n",
            "🔄 Topology update at step 4100 took 0.0000s\n",
            "🧹 Memory cleanup at step 4100 took 0.1860s\n",
            "Batch  980/1563 ( 62.7%) | Loss: 1.121945 | Accuracy: 60.27% | Batch time: 0.0127s\n",
            "Step 4110 | Loss: 1.266510 | GPU: 43.8MB / 70.0MB | F: 0.0012s, B: 0.0059s, O: 0.0006s\n",
            "Step 4120 | Loss: 1.163138 | GPU: 43.8MB / 134.0MB | F: 0.0012s, B: 0.0061s, O: 0.0006s\n",
            "🔄 Topology update at step 4120 took 0.0000s\n",
            "Batch 1000/1563 ( 64.0%) | Loss: 1.122617 | Accuracy: 60.24% | Batch time: 0.0047s\n",
            "Step 4130 | Loss: 1.088648 | GPU: 43.8MB / 70.0MB | F: 0.0062s, B: 0.0016s, O: 0.0006s\n",
            "Step 4140 | Loss: 0.944360 | GPU: 43.8MB / 134.0MB | F: 0.0012s, B: 0.0094s, O: 0.0005s\n",
            "🔄 Topology update at step 4140 took 0.0001s\n",
            "Batch 1020/1563 ( 65.3%) | Loss: 1.123620 | Accuracy: 60.23% | Batch time: 0.0042s\n",
            "Step 4150 | Loss: 1.071231 | GPU: 43.8MB / 70.0MB | F: 0.0012s, B: 0.0060s, O: 0.0006s\n",
            "Step 4160 | Loss: 0.942389 | GPU: 43.8MB / 134.0MB | F: 0.0037s, B: 0.0023s, O: 0.0018s\n",
            "🔄 Topology update at step 4160 took 0.0000s\n",
            "Batch 1040/1563 ( 66.5%) | Loss: 1.122446 | Accuracy: 60.26% | Batch time: 0.0073s\n",
            "Step 4170 | Loss: 0.854982 | GPU: 43.8MB / 70.0MB | F: 0.0056s, B: 0.0039s, O: 0.0007s\n",
            "Step 4180 | Loss: 0.897662 | GPU: 43.8MB / 134.0MB | F: 0.0101s, B: 0.0093s, O: 0.0067s\n",
            "🔄 Topology update at step 4180 took 0.0000s\n",
            "Batch 1060/1563 ( 67.8%) | Loss: 1.122037 | Accuracy: 60.28% | Batch time: 0.0186s\n",
            "Step 4190 | Loss: 0.964118 | GPU: 43.8MB / 70.0MB | F: 0.0072s, B: 0.0070s, O: 0.0006s\n",
            "Step 4200 | Loss: 1.705674 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0097s, O: 0.0007s\n",
            "🔄 Topology update at step 4200 took 0.0001s\n",
            "🧹 Memory cleanup at step 4200 took 0.1857s\n",
            "Batch 1080/1563 ( 69.1%) | Loss: 1.122418 | Accuracy: 60.26% | Batch time: 0.0075s\n",
            "Step 4210 | Loss: 1.081908 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0025s, O: 0.0007s\n",
            "Step 4220 | Loss: 1.178692 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 4220 took 0.0000s\n",
            "Batch 1100/1563 ( 70.4%) | Loss: 1.120717 | Accuracy: 60.34% | Batch time: 0.0061s\n",
            "Step 4230 | Loss: 0.897386 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0024s, O: 0.0054s\n",
            "Step 4240 | Loss: 1.331523 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0029s, O: 0.0018s\n",
            "🔄 Topology update at step 4240 took 0.0052s\n",
            "Batch 1120/1563 ( 71.7%) | Loss: 1.120806 | Accuracy: 60.33% | Batch time: 0.0052s\n",
            "Step 4250 | Loss: 1.330119 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0078s, O: 0.0008s\n",
            "Step 4260 | Loss: 1.082156 | GPU: 43.8MB / 134.0MB | F: 0.0026s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 4260 took 0.0000s\n",
            "Batch 1140/1563 ( 72.9%) | Loss: 1.120516 | Accuracy: 60.38% | Batch time: 0.0054s\n",
            "Step 4270 | Loss: 0.849411 | GPU: 43.8MB / 70.0MB | F: 0.0036s, B: 0.0024s, O: 0.0007s\n",
            "Step 4280 | Loss: 0.764951 | GPU: 43.8MB / 134.0MB | F: 0.0018s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 4280 took 0.0000s\n",
            "Batch 1160/1563 ( 74.2%) | Loss: 1.120064 | Accuracy: 60.35% | Batch time: 0.0087s\n",
            "Step 4290 | Loss: 1.160156 | GPU: 43.8MB / 70.0MB | F: 0.0019s, B: 0.0024s, O: 0.0006s\n",
            "Step 4300 | Loss: 1.165118 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 4300 took 0.0000s\n",
            "🧹 Memory cleanup at step 4300 took 0.1562s\n",
            "Batch 1180/1563 ( 75.5%) | Loss: 1.118661 | Accuracy: 60.38% | Batch time: 0.0150s\n",
            "Step 4310 | Loss: 0.947811 | GPU: 43.8MB / 70.0MB | F: 0.0052s, B: 0.0037s, O: 0.0006s\n",
            "Step 4320 | Loss: 1.034399 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 4320 took 0.0000s\n",
            "Batch 1200/1563 ( 76.8%) | Loss: 1.117967 | Accuracy: 60.39% | Batch time: 0.0053s\n",
            "Step 4330 | Loss: 1.158715 | GPU: 43.8MB / 70.0MB | F: 0.0051s, B: 0.0029s, O: 0.0012s\n",
            "Step 4340 | Loss: 1.136491 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "🔄 Topology update at step 4340 took 0.0001s\n",
            "Batch 1220/1563 ( 78.1%) | Loss: 1.117047 | Accuracy: 60.40% | Batch time: 0.0056s\n",
            "Step 4350 | Loss: 0.886219 | GPU: 43.8MB / 70.0MB | F: 0.0073s, B: 0.0025s, O: 0.0006s\n",
            "Step 4360 | Loss: 1.020941 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 4360 took 0.0001s\n",
            "Batch 1240/1563 ( 79.3%) | Loss: 1.116789 | Accuracy: 60.40% | Batch time: 0.0054s\n",
            "Step 4370 | Loss: 0.785821 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0023s, O: 0.0007s\n",
            "Step 4380 | Loss: 1.038420 | GPU: 43.8MB / 134.0MB | F: 0.0019s, B: 0.0027s, O: 0.0008s\n",
            "🔄 Topology update at step 4380 took 0.0001s\n",
            "Batch 1260/1563 ( 80.6%) | Loss: 1.116776 | Accuracy: 60.38% | Batch time: 0.0118s\n",
            "Step 4390 | Loss: 0.904750 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 4400 | Loss: 1.049106 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 4400 took 0.0001s\n",
            "🧹 Memory cleanup at step 4400 took 0.1530s\n",
            "Batch 1280/1563 ( 81.9%) | Loss: 1.116419 | Accuracy: 60.38% | Batch time: 0.0054s\n",
            "Step 4410 | Loss: 1.247398 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0024s, O: 0.0007s\n",
            "Step 4420 | Loss: 1.213672 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0069s, O: 0.0023s\n",
            "🔄 Topology update at step 4420 took 0.0001s\n",
            "Batch 1300/1563 ( 83.2%) | Loss: 1.116415 | Accuracy: 60.38% | Batch time: 0.0056s\n",
            "Step 4430 | Loss: 1.875309 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "Step 4440 | Loss: 0.997722 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0024s, O: 0.0007s\n",
            "🔄 Topology update at step 4440 took 0.0000s\n",
            "Batch 1320/1563 ( 84.5%) | Loss: 1.116787 | Accuracy: 60.38% | Batch time: 0.0057s\n",
            "Step 4450 | Loss: 0.892102 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0022s, O: 0.0006s\n",
            "Step 4460 | Loss: 0.543052 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 4460 took 0.0000s\n",
            "Batch 1340/1563 ( 85.7%) | Loss: 1.115452 | Accuracy: 60.42% | Batch time: 0.0063s\n",
            "Step 4470 | Loss: 1.490649 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0092s, O: 0.0019s\n",
            "Step 4480 | Loss: 1.002024 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0048s, O: 0.0006s\n",
            "🔄 Topology update at step 4480 took 0.0000s\n",
            "Batch 1360/1563 ( 87.0%) | Loss: 1.115753 | Accuracy: 60.42% | Batch time: 0.0055s\n",
            "Step 4490 | Loss: 1.373569 | GPU: 43.8MB / 70.0MB | F: 0.0031s, B: 0.0023s, O: 0.0006s\n",
            "Step 4500 | Loss: 1.030031 | GPU: 43.8MB / 134.0MB | F: 0.0032s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 4500 took 0.0000s\n",
            "🧹 Memory cleanup at step 4500 took 0.1349s\n",
            "Batch 1380/1563 ( 88.3%) | Loss: 1.115894 | Accuracy: 60.39% | Batch time: 0.0054s\n",
            "Step 4510 | Loss: 0.921583 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0024s, O: 0.0006s\n",
            "Step 4520 | Loss: 0.933638 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0044s, O: 0.0006s\n",
            "🔄 Topology update at step 4520 took 0.0000s\n",
            "Batch 1400/1563 ( 89.6%) | Loss: 1.114589 | Accuracy: 60.45% | Batch time: 0.0065s\n",
            "Step 4530 | Loss: 0.826823 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0058s, O: 0.0007s\n",
            "Step 4540 | Loss: 0.728855 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0022s, O: 0.0007s\n",
            "🔄 Topology update at step 4540 took 0.0000s\n",
            "Batch 1420/1563 ( 90.9%) | Loss: 1.113496 | Accuracy: 60.47% | Batch time: 0.0056s\n",
            "Step 4550 | Loss: 0.724518 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0024s, O: 0.0020s\n",
            "Step 4560 | Loss: 0.934744 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0022s, O: 0.0006s\n",
            "🔄 Topology update at step 4560 took 0.0000s\n",
            "Batch 1440/1563 ( 92.1%) | Loss: 1.113408 | Accuracy: 60.50% | Batch time: 0.0066s\n",
            "Step 4570 | Loss: 1.041566 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "Step 4580 | Loss: 1.335496 | GPU: 43.8MB / 134.0MB | F: 0.0017s, B: 0.0023s, O: 0.0012s\n",
            "🔄 Topology update at step 4580 took 0.0000s\n",
            "Batch 1460/1563 ( 93.4%) | Loss: 1.112847 | Accuracy: 60.54% | Batch time: 0.0058s\n",
            "Step 4590 | Loss: 1.223625 | GPU: 43.8MB / 70.0MB | F: 0.0018s, B: 0.0024s, O: 0.0006s\n",
            "Step 4600 | Loss: 1.423543 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 4600 took 0.0000s\n",
            "🧹 Memory cleanup at step 4600 took 0.1446s\n",
            "Batch 1480/1563 ( 94.7%) | Loss: 1.113706 | Accuracy: 60.54% | Batch time: 0.0051s\n",
            "Step 4610 | Loss: 1.066311 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0024s, O: 0.0011s\n",
            "Step 4620 | Loss: 1.074045 | GPU: 43.8MB / 134.0MB | F: 0.0015s, B: 0.0025s, O: 0.0006s\n",
            "🔄 Topology update at step 4620 took 0.0001s\n",
            "Batch 1500/1563 ( 96.0%) | Loss: 1.112419 | Accuracy: 60.62% | Batch time: 0.0052s\n",
            "Step 4630 | Loss: 0.974827 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0025s, O: 0.0007s\n",
            "Step 4640 | Loss: 0.781111 | GPU: 43.8MB / 134.0MB | F: 0.0016s, B: 0.0024s, O: 0.0006s\n",
            "🔄 Topology update at step 4640 took 0.0000s\n",
            "Batch 1520/1563 ( 97.2%) | Loss: 1.111504 | Accuracy: 60.64% | Batch time: 0.0056s\n",
            "Step 4650 | Loss: 0.942385 | GPU: 43.8MB / 70.0MB | F: 0.0016s, B: 0.0023s, O: 0.0006s\n",
            "Step 4660 | Loss: 1.202599 | GPU: 43.8MB / 134.0MB | F: 0.0015s, B: 0.0021s, O: 0.0006s\n",
            "🔄 Topology update at step 4660 took 0.0000s\n",
            "Batch 1540/1563 ( 98.5%) | Loss: 1.111455 | Accuracy: 60.64% | Batch time: 0.0052s\n",
            "Step 4670 | Loss: 1.310631 | GPU: 43.8MB / 70.0MB | F: 0.0017s, B: 0.0038s, O: 0.0006s\n",
            "Step 4680 | Loss: 0.927358 | GPU: 43.8MB / 134.0MB | F: 0.0047s, B: 0.0023s, O: 0.0006s\n",
            "🔄 Topology update at step 4680 took 0.0000s\n",
            "Batch 1560/1563 ( 99.8%) | Loss: 1.111466 | Accuracy: 60.62% | Batch time: 0.0036s\n",
            "\n",
            "-------------------- EPOCH 3 SUMMARY --------------------\n",
            "Loss: 1.111336 | Accuracy: 60.61%\n",
            "Time: 25.68s total, 0.0138s per batch\n",
            "🔄 Final Memory - RAM: 1602.9MB, GPU: 43.6MB allocated, 70.0MB reserved\n",
            "\n",
            "===== PERFORMANCE SUMMARY =====\n",
            "⏱️ Timing Statistics (in seconds):\n",
            "🔄 Memory Usage (MB): avg=43.8, peak=43.8\n",
            "===============================\n",
            "\n",
            "⏱️ ImprovedTALT training took 25.6869 seconds\n",
            "\n",
            "==================== EVALUATION ====================\n",
            "Device: cuda, Batches: 313, Batch size: 32\n",
            "Batch   50/ 313 ( 16.0%) | Loss: 0.960184 | Accuracy: 64.77% | Batch time: 0.0014s\n",
            "Batch  100/ 313 ( 31.9%) | Loss: 0.975890 | Accuracy: 64.67% | Batch time: 0.0013s\n",
            "Batch  150/ 313 ( 47.9%) | Loss: 0.967493 | Accuracy: 65.42% | Batch time: 0.0014s\n",
            "Batch  200/ 313 ( 63.9%) | Loss: 0.965669 | Accuracy: 65.69% | Batch time: 0.0021s\n",
            "Batch  250/ 313 ( 79.9%) | Loss: 0.967891 | Accuracy: 65.90% | Batch time: 0.0013s\n",
            "Batch  300/ 313 ( 95.8%) | Loss: 0.970313 | Accuracy: 65.94% | Batch time: 0.0012s\n",
            "\n",
            "-------------------- EVALUATION SUMMARY --------------------\n",
            "Loss: 0.972062 | Accuracy: 65.74%\n",
            "Time: 2.86s total, 0.0014s per batch\n",
            "⏱️ ImprovedTALT evaluation took 2.8563 seconds\n",
            "ImprovedTALT - Epoch 3:\n",
            "  Train Loss: 1.111336, Train Acc: 60.61%\n",
            "  Test Loss:  0.972062, Test Acc:  65.74%\n",
            "\n",
            "Epoch 3 completed in 92.75s\n",
            "Results saved to ./results/cifar10/epoch_3_results.json\n",
            "\n",
            "============================== TRAINING COMPLETED ==============================\n",
            "Total training time: 286.07s\n",
            "\n",
            "Final Test Accuracy Comparison:\n",
            "  SGD: 63.48%\n",
            "  Adam: 61.93%\n",
            "  AdamW: 63.45%\n",
            "  ImprovedTALT: 65.74%\n",
            "\n",
            "🏆 Best optimizer: ImprovedTALT with 65.74% test accuracy\n",
            "\n",
            "Creating comparative plots...\n",
            "Comparison plots saved to ./plots/cifar10\n",
            "Final results saved to ./results/cifar10/final_results.json\n",
            "\n",
            "Training and visualization complete!\n",
            "Results saved in ./results\n",
            "Plots saved in ./plots\n"
          ]
        }
      ]
    }
  ]
}